{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "import utils.utils as utils\n",
    "import utils.datasets as datasets\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import f1_score\n",
    "from skimage.transform import resize\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure everything is deterministic\n",
    "random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed(1)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, load_data = datasets.megc(\"cropped\")\n",
    "\n",
    "uv_frames = np.load(\"../data/megc_uv_frames_secrets_of_OF.npy\")\n",
    "uv_frames = resize(uv_frames, (uv_frames.shape[0], 3, 60, 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(df[\"emotion\"])\n",
    "dataset = le.fit_transform(df[\"dataset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MEData(Dataset):\n",
    "    def __init__(self, frames, labels, dataset, transform=None):\n",
    "        self.frames = frames\n",
    "        self.labels = labels\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.frames.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.frames[idx, ...]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        label = self.labels[idx]\n",
    "        dataset = self.dataset[idx]\n",
    "        return sample, label, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BDCNN(nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super(BDCNN, self).__init__()\n",
    "        self.feature_num = 128\n",
    "        self.size = size\n",
    "        self.net_dict = {\n",
    "            \"conv2_0\": {8: 5400, 10: 3456, 20: 1152, 30: 512, 40: 288},\n",
    "            \"conv2_1\": {8: 384, 10: 384, 20: 256, 30: 128, 40: 32},\n",
    "            \"fc1_0\": {8: 3456, 10: 6144, 20: 12544, 30: 12800, 40: 6272},\n",
    "        }\n",
    "        self.pool = nn.MaxPool2d(3, 3, 1)\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1, out_channels=8, kernel_size=3, stride=1, padding=1\n",
    "        )\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            self.net_dict[\"conv2_0\"][self.size], self.net_dict[\"conv2_1\"][self.size], 1\n",
    "        )\n",
    "        self.fc1 = nn.Linear(self.net_dict[\"fc1_0\"][self.size], 1024)\n",
    "        self.fc2 = nn.Linear(1024, 128)\n",
    "\n",
    "    def forward(self, input):\n",
    "        input1 = input[:, 0:1]\n",
    "        input2 = input[:, 1:2]\n",
    "        input3 = input[:, 2:3]\n",
    "\n",
    "        blocks1 = []\n",
    "        n = 120 // self.size\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                blocks1.append(\n",
    "                    input1[\n",
    "                        :,\n",
    "                        :,\n",
    "                        self.size * i : self.size * (i + 1),\n",
    "                        self.size * j : self.size * (j + 1),\n",
    "                    ]\n",
    "                )\n",
    "        convs1 = []\n",
    "        for i in range(n**2):\n",
    "            convs1.append(self.pool(F.relu(self.conv1(blocks1[i]))))\n",
    "        x1 = torch.cat((convs1[0], convs1[1]), dim=1)\n",
    "        for i in range(2, n**2):\n",
    "            x1 = torch.cat((x1, convs1[i]), dim=1)\n",
    "\n",
    "        blocks2 = []\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                blocks2.append(\n",
    "                    input2[\n",
    "                        :,\n",
    "                        :,\n",
    "                        self.size * i : self.size * (i + 1),\n",
    "                        self.size * j : self.size * (j + 1),\n",
    "                    ]\n",
    "                )\n",
    "        convs2 = []\n",
    "        for i in range(n**2):\n",
    "            convs2.append(self.pool(F.relu(self.conv1(blocks2[i]))))\n",
    "        x2 = torch.cat((convs2[0], convs2[1]), dim=1)\n",
    "        for i in range(2, n**2):\n",
    "            x2 = torch.cat((x2, convs2[i]), dim=1)\n",
    "\n",
    "        blocks3 = []\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                blocks3.append(\n",
    "                    input3[\n",
    "                        :,\n",
    "                        :,\n",
    "                        self.size * i : self.size * (i + 1),\n",
    "                        self.size * j : self.size * (j + 1),\n",
    "                    ]\n",
    "                )\n",
    "        convs3 = []\n",
    "        for i in range(n**2):\n",
    "            convs3.append(self.pool(F.relu(self.conv1(blocks3[i]))))\n",
    "        x3 = torch.cat((convs3[0], convs3[1]), dim=1)\n",
    "        for i in range(2, n**2):\n",
    "            x3 = torch.cat((x3, convs3[i]), dim=1)\n",
    "\n",
    "        x = torch.cat((x1, x2, x3), dim=1)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class EstimatorCV:\n",
    "    def __init__(self, feature_num, class_num):\n",
    "        super(EstimatorCV, self).__init__()\n",
    "        self.class_num = class_num\n",
    "        self.CoVariance = torch.zeros(class_num, feature_num, feature_num).to(device)\n",
    "        self.Ave = torch.zeros(class_num, feature_num).to(device)\n",
    "        self.Amount = torch.zeros(class_num).to(device)\n",
    "\n",
    "    def update_CV(self, features, labels):\n",
    "        # N,C,A  batch_size,class_num,feature_num\n",
    "        N = features.size(0)\n",
    "        C = self.class_num\n",
    "        A = features.size(1)\n",
    "\n",
    "        NxCxFeatures = features.view(N, 1, A).expand(N, C, A)\n",
    "\n",
    "        onehot = torch.zeros(N, C).to(device)\n",
    "        onehot.scatter_(1, labels.view(-1, 1), 1)\n",
    "\n",
    "        NxCxA_onehot = onehot.view(N, C, 1).expand(N, C, A)\n",
    "\n",
    "        features_by_sort = NxCxFeatures.mul(NxCxA_onehot)\n",
    "\n",
    "        Amount_CxA = NxCxA_onehot.sum(0)\n",
    "\n",
    "        Amount_CxA[Amount_CxA == 0] = 1\n",
    "\n",
    "        # C*A\n",
    "        ave_CxA = features_by_sort.sum(0) / Amount_CxA\n",
    "\n",
    "        # N*C*A\n",
    "        var_temp = features_by_sort - ave_CxA.expand(N, C, A).mul(NxCxA_onehot)\n",
    "        # permute  bmm  b*n*m b*m*p ->b*n*p\n",
    "        # C*A*N C*N*A-> C*A*A\n",
    "        var_temp = torch.bmm(var_temp.permute(1, 2, 0), var_temp.permute(1, 0, 2)).div(\n",
    "            Amount_CxA.view(C, A, 1).expand(C, A, A)\n",
    "        )\n",
    "\n",
    "        sum_weight_CV = onehot.sum(0).view(C, 1, 1).expand(C, A, A)\n",
    "\n",
    "        sum_weight_AV = onehot.sum(0).view(C, 1).expand(C, A)\n",
    "\n",
    "        weight_CV = sum_weight_CV.div(\n",
    "            sum_weight_CV + self.Amount.view(C, 1, 1).expand(C, A, A)\n",
    "        )\n",
    "        weight_CV[weight_CV != weight_CV] = 0\n",
    "\n",
    "        weight_AV = sum_weight_AV.div(\n",
    "            sum_weight_AV + self.Amount.view(C, 1).expand(C, A)\n",
    "        )\n",
    "        weight_AV[weight_AV != weight_AV] = 0\n",
    "\n",
    "        additional_CV = weight_CV.mul(1 - weight_CV).mul(\n",
    "            torch.bmm(\n",
    "                (self.Ave - ave_CxA).view(C, A, 1), (self.Ave - ave_CxA).view(C, 1, A)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.CoVariance = (\n",
    "            self.CoVariance.mul(1 - weight_CV) + var_temp.mul(weight_CV)\n",
    "        ).detach() + additional_CV.detach()\n",
    "\n",
    "        self.Ave = (self.Ave.mul(1 - weight_AV) + ave_CxA.mul(weight_AV)).detach()\n",
    "\n",
    "        self.Amount += onehot.sum(0)\n",
    "\n",
    "\n",
    "class ISDALoss(nn.Module):\n",
    "    def __init__(self, feature_num, class_num, u):\n",
    "        super(ISDALoss, self).__init__()\n",
    "        self.estimator = EstimatorCV(feature_num, class_num)\n",
    "        self.class_num = class_num\n",
    "        self.cross_entropy = nn.CrossEntropyLoss(\n",
    "            weight=torch.tensor(u), reduction=\"mean\"\n",
    "        )\n",
    "\n",
    "    def isda_aug(self, fc, features, y, labels, cv_matrix, ratio):\n",
    "\n",
    "        N = features.size(0)\n",
    "        C = self.class_num\n",
    "        A = features.size(1)\n",
    "\n",
    "        weight_m = list(fc.parameters())[0]\n",
    "        NxW_ij = weight_m.expand(N, C, A)\n",
    "        NxW_kj = torch.gather(NxW_ij, 1, labels.view(N, 1, 1).expand(N, C, A))\n",
    "        CV_temp = cv_matrix[labels]\n",
    "        sigma2 = ratio * torch.bmm(\n",
    "            torch.bmm(NxW_ij - NxW_kj, CV_temp), (NxW_ij - NxW_kj).permute(0, 2, 1)\n",
    "        )\n",
    "        sigma2 = sigma2.mul(torch.eye(C).to(device).expand(N, C, C)).sum(2).view(N, C)\n",
    "        aug_result = y + 0.5 * sigma2\n",
    "\n",
    "        return aug_result\n",
    "\n",
    "    def forward(self, model, fc, x, target_x, ratio):\n",
    "        features = model(x)\n",
    "        y = fc(features)\n",
    "        self.estimator.update_CV(features.detach(), target_x)\n",
    "        isda_aug_y = self.isda_aug(\n",
    "            fc, features, y, target_x, self.estimator.CoVariance.detach(), ratio\n",
    "        )\n",
    "        loss = self.cross_entropy(isda_aug_y, target_x)\n",
    "\n",
    "        return loss, y\n",
    "    \n",
    "    \n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate\"\"\"\n",
    "    if epoch in [80, 120]:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] *= 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BDCNN(nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super(BDCNN, self).__init__()\n",
    "        self.feature_num = 128\n",
    "        self.size = size\n",
    "        self.net_dict = {\n",
    "            \"conv2_0\": {8: 5400, 10: 3456, 20: 1152, 30: 512, 40: 288},\n",
    "            \"conv2_1\": {8: 384, 10: 384, 20: 256, 30: 128, 40: 32},\n",
    "            \"fc1_0\": {8: 3456, 10: 6144, 20: 12544, 30: 12800, 40: 6272},\n",
    "        }\n",
    "        self.pool = nn.MaxPool2d(3, 3, 1)\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1, out_channels=8, kernel_size=3, stride=1, padding=1\n",
    "        )\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            self.net_dict[\"conv2_0\"][self.size], self.net_dict[\"conv2_1\"][self.size], 1\n",
    "        )\n",
    "        self.fc1 = nn.Linear(self.net_dict[\"fc1_0\"][self.size], 1024)\n",
    "        self.fc2 = nn.Linear(1024, 128)\n",
    "        self.fc = nn.Linear(128, 3)\n",
    "        self.isda_loss = ISDALoss(feature_num=128, class_num=3,u=[0.15,0.425,0.425])\n",
    "\n",
    "    def forward(self, input):\n",
    "        input1 = input[:, 0:1]\n",
    "        input2 = input[:, 1:2]\n",
    "        input3 = input[:, 2:3]\n",
    "\n",
    "        blocks1 = []\n",
    "        n = 120 // self.size\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                blocks1.append(\n",
    "                    input1[\n",
    "                        :,\n",
    "                        :,\n",
    "                        self.size * i : self.size * (i + 1),\n",
    "                        self.size * j : self.size * (j + 1),\n",
    "                    ]\n",
    "                )\n",
    "        convs1 = []\n",
    "        for i in range(n**2):\n",
    "            convs1.append(self.pool(F.relu(self.conv1(blocks1[i]))))\n",
    "        x1 = torch.cat((convs1[0], convs1[1]), dim=1)\n",
    "        for i in range(2, n**2):\n",
    "            x1 = torch.cat((x1, convs1[i]), dim=1)\n",
    "\n",
    "        blocks2 = []\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                blocks2.append(\n",
    "                    input2[\n",
    "                        :,\n",
    "                        :,\n",
    "                        self.size * i : self.size * (i + 1),\n",
    "                        self.size * j : self.size * (j + 1),\n",
    "                    ]\n",
    "                )\n",
    "        convs2 = []\n",
    "        for i in range(n**2):\n",
    "            convs2.append(self.pool(F.relu(self.conv1(blocks2[i]))))\n",
    "        x2 = torch.cat((convs2[0], convs2[1]), dim=1)\n",
    "        for i in range(2, n**2):\n",
    "            x2 = torch.cat((x2, convs2[i]), dim=1)\n",
    "\n",
    "        blocks3 = []\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                blocks3.append(\n",
    "                    input3[\n",
    "                        :,\n",
    "                        :,\n",
    "                        self.size * i : self.size * (i + 1),\n",
    "                        self.size * j : self.size * (j + 1),\n",
    "                    ]\n",
    "                )\n",
    "        convs3 = []\n",
    "        for i in range(n**2):\n",
    "            convs3.append(self.pool(F.relu(self.conv1(blocks3[i]))))\n",
    "        x3 = torch.cat((convs3[0], convs3[1]), dim=1)\n",
    "        for i in range(2, n**2):\n",
    "            x3 = torch.cat((x3, convs3[i]), dim=1)\n",
    "\n",
    "        x = torch.cat((x1, x2, x3), dim=1)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EstimatorCV:\n",
    "    def __init__(self, feature_num, class_num):\n",
    "        super(EstimatorCV, self).__init__()\n",
    "        self.class_num = class_num\n",
    "        self.CoVariance = torch.zeros(class_num, feature_num, feature_num).to(device)\n",
    "        self.Ave = torch.zeros(class_num, feature_num).to(device)\n",
    "        self.Amount = torch.zeros(class_num).to(device)\n",
    "\n",
    "    def update_CV(self, features, labels):\n",
    "        # N,C,A  batch_size,class_num,feature_num\n",
    "        N = features.size(0)\n",
    "        C = self.class_num\n",
    "        A = features.size(1)\n",
    "\n",
    "        NxCxFeatures = features.view(N, 1, A).expand(N, C, A)\n",
    "\n",
    "        onehot = torch.zeros(N, C).to(device)\n",
    "        onehot.scatter_(1, labels.view(-1, 1), 1)\n",
    "\n",
    "        NxCxA_onehot = onehot.view(N, C, 1).expand(N, C, A)\n",
    "\n",
    "        features_by_sort = NxCxFeatures.mul(NxCxA_onehot)\n",
    "\n",
    "        Amount_CxA = NxCxA_onehot.sum(0)\n",
    "\n",
    "        Amount_CxA[Amount_CxA == 0] = 1\n",
    "\n",
    "        # C*A\n",
    "        ave_CxA = features_by_sort.sum(0) / Amount_CxA\n",
    "\n",
    "        # N*C*A\n",
    "        var_temp = features_by_sort - ave_CxA.expand(N, C, A).mul(NxCxA_onehot)\n",
    "        # permute  bmm  b*n*m b*m*p ->b*n*p\n",
    "        # C*A*N C*N*A-> C*A*A\n",
    "        var_temp = torch.bmm(var_temp.permute(1, 2, 0), var_temp.permute(1, 0, 2)).div(\n",
    "            Amount_CxA.view(C, A, 1).expand(C, A, A)\n",
    "        )\n",
    "\n",
    "        sum_weight_CV = onehot.sum(0).view(C, 1, 1).expand(C, A, A)\n",
    "\n",
    "        sum_weight_AV = onehot.sum(0).view(C, 1).expand(C, A)\n",
    "\n",
    "        weight_CV = sum_weight_CV.div(\n",
    "            sum_weight_CV + self.Amount.view(C, 1, 1).expand(C, A, A)\n",
    "        )\n",
    "        weight_CV[weight_CV != weight_CV] = 0\n",
    "\n",
    "        weight_AV = sum_weight_AV.div(\n",
    "            sum_weight_AV + self.Amount.view(C, 1).expand(C, A)\n",
    "        )\n",
    "        weight_AV[weight_AV != weight_AV] = 0\n",
    "\n",
    "        additional_CV = weight_CV.mul(1 - weight_CV).mul(\n",
    "            torch.bmm(\n",
    "                (self.Ave - ave_CxA).view(C, A, 1), (self.Ave - ave_CxA).view(C, 1, A)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.CoVariance = (\n",
    "            self.CoVariance.mul(1 - weight_CV) + var_temp.mul(weight_CV)\n",
    "        ).detach() + additional_CV.detach()\n",
    "\n",
    "        self.Ave = (self.Ave.mul(1 - weight_AV) + ave_CxA.mul(weight_AV)).detach()\n",
    "\n",
    "        self.Amount += onehot.sum(0)\n",
    "\n",
    "\n",
    "class ISDALoss(nn.Module):\n",
    "    def __init__(self, feature_num: int, class_num: int):\n",
    "        super(ISDALoss, self).__init__()\n",
    "        self.feature_num = feature_num\n",
    "        self.class_num = class_num\n",
    "        self.estimator = EstimatorCV(self.feature_num, self.class_num)\n",
    "\n",
    "    def isda_aug(self, features, y, labels, cv_matrix, ratio):\n",
    "\n",
    "        N = features.size(0)\n",
    "        C = self.class_num\n",
    "        A = features.size(1)\n",
    "\n",
    "        weight_m = list(fc.parameters())[0]\n",
    "        NxW_ij = weight_m.expand(N, C, A)\n",
    "        NxW_kj = torch.gather(NxW_ij, 1, labels.view(N, 1, 1).expand(N, C, A))\n",
    "        CV_temp = cv_matrix[labels]\n",
    "        sigma2 = ratio * torch.bmm(\n",
    "            torch.bmm(NxW_ij - NxW_kj, CV_temp), (NxW_ij - NxW_kj).permute(0, 2, 1)\n",
    "        )\n",
    "        sigma2 = sigma2.mul(torch.eye(C).to(device).expand(N, C, C)).sum(2).view(N, C)\n",
    "        aug_result = y + 0.5 * sigma2\n",
    "\n",
    "        return aug_result\n",
    "\n",
    "    def forward(self, features, predictions, fc_weights, target_x, ratio):\n",
    "        self.estimator.update_CV(features.detach(), target_x)\n",
    "        isda_aug_y = self.isda_aug(\n",
    "            fc_weights, features, predictions, target_x, self.estimator.CoVariance.detach(), ratio\n",
    "        )\n",
    "\n",
    "        return isda_aug_y\n",
    "    \n",
    "    \n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate\"\"\"\n",
    "    if epoch in [80, 120]:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] *= 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BDCN - Minor changes to the original\n",
    "* Flownet is not used. This is simply to make the expriments faster. The authors show ablation studies without flownet input (Table IX). With the removal of vis (Flownet optical flow) the performance drops by 2 percentage units.\n",
    "\n",
    "* Only use 1 channel inputs. All of the optical flow components only have 1 channel originally---making them have three would just add redundancy. (When Flownet is not used) (Figure 1 shows optical strain as the combination of u+v+os, not sure which one it is)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "uv_frames = resize(uv_frames, (df.shape[0], 3, 120, 120))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " without val set\n",
    "0.72\n",
    "with val\n",
    "Total f1: 0.5461341408311106, SMIC: 0.6573265559144891, CASME2: 0.4632412455521449, SAMM: 0.42188076039588984"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 006, n=11 | train_f1: 0.85887 | test_f1: 0.55556, best_epoch\n",
      "Subject: 007, n=08 | train_f1: 0.76650 | test_f1: 0.11111, best_epoch\n",
      "Subject: 009, n=04 | train_f1: 0.34783 | test_f1: 0.42857, best_epoch\n",
      "Subject: 01, n=03 | train_f1: 0.81841 | test_f1: 1.0, best_epoch\n",
      "Subject: 010, n=04 | train_f1: 0.88994 | test_f1: 1.0, best_epoch\n",
      "Subject: 011, n=20 | train_f1: 0.70752 | test_f1: 0.26032, best_epoch\n",
      "Subject: 012, n=03 | train_f1: 0.83763 | test_f1: 0.0, best_epoch\n",
      "Subject: 013, n=06 | train_f1: 0.83083 | test_f1: 0.16667, best_epoch\n",
      "Subject: 014, n=10 | train_f1: 0.21890 | test_f1: 0.20635, best_epoch\n",
      "Subject: 015, n=03 | train_f1: 0.83825 | test_f1: 0.66667, best_epoch\n",
      "Subject: 016, n=05 | train_f1: 0.60875 | test_f1: 1.0, best_epoch\n",
      "Subject: 017, n=04 | train_f1: 0.61069 | test_f1: 0.42857, best_epoch\n",
      "Subject: 018, n=03 | train_f1: 0.46235 | test_f1: 0.66667, best_epoch\n",
      "Subject: 019, n=01 | train_f1: 0.33377 | test_f1: 0.0, best_epoch\n",
      "Subject: 02, n=09 | train_f1: 0.59542 | test_f1: 0.22222, best_epoch\n",
      "Subject: 020, n=04 | train_f1: 0.28862 | test_f1: 0.33333, best_epoch\n",
      "Subject: 021, n=02 | train_f1: 0.61795 | test_f1: 1.0, best_epoch\n",
      "Subject: 022, n=05 | train_f1: 0.44406 | test_f1: 1.0, best_epoch\n",
      "Subject: 023, n=01 | train_f1: 0.54921 | test_f1: 1.0, best_epoch\n",
      "Subject: 024, n=01 | train_f1: 0.90355 | test_f1: 0.0, best_epoch\n",
      "Subject: 026, n=09 | train_f1: 0.89353 | test_f1: 0.4375, best_epoch\n",
      "Subject: 028, n=03 | train_f1: 0.83468 | test_f1: 0.33333, best_epoch\n",
      "Subject: 03, n=05 | train_f1: 0.41087 | test_f1: 0.16667, best_epoch\n",
      "Subject: 030, n=03 | train_f1: 0.63209 | test_f1: 1.0, best_epoch\n",
      "Subject: 031, n=01 | train_f1: 0.84477 | test_f1: 1.0, best_epoch\n",
      "Subject: 032, n=04 | train_f1: 0.73438 | test_f1: 0.42857, best_epoch\n",
      "Subject: 033, n=05 | train_f1: 0.42765 | test_f1: 0.0, best_epoch\n",
      "Subject: 034, n=03 | train_f1: 0.77813 | test_f1: 0.4, best_epoch\n",
      "Subject: 035, n=08 | train_f1: 0.73871 | test_f1: 0.36667, best_epoch\n",
      "Subject: 036, n=01 | train_f1: 0.70330 | test_f1: 0.0, best_epoch\n",
      "Subject: 037, n=01 | train_f1: 0.85850 | test_f1: 0.0, best_epoch\n",
      "Subject: 04, n=02 | train_f1: 0.83811 | test_f1: 1.0, best_epoch\n",
      "Subject: 05, n=06 | train_f1: 0.81413 | test_f1: 0.62963, best_epoch\n",
      "Subject: 06, n=04 | train_f1: 0.52635 | test_f1: 0.55556, best_epoch\n",
      "Subject: 07, n=05 | train_f1: 0.43167 | test_f1: 0.0, best_epoch\n",
      "Subject: 08, n=01 | train_f1: 0.85428 | test_f1: 0.0, best_epoch\n",
      "Subject: 09, n=10 | train_f1: 0.07430 | test_f1: 0.0, best_epoch\n",
      "Subject: 11, n=04 | train_f1: 0.84581 | test_f1: 1.0, best_epoch\n",
      "Subject: 12, n=11 | train_f1: 0.07182 | test_f1: 0.0, best_epoch\n",
      "Subject: 13, n=02 | train_f1: 0.85215 | test_f1: 1.0, best_epoch\n",
      "Subject: 14, n=03 | train_f1: 0.77542 | test_f1: 1.0, best_epoch\n",
      "Subject: 15, n=03 | train_f1: 0.81013 | test_f1: 0.55556, best_epoch\n",
      "Subject: 16, n=03 | train_f1: 0.42973 | test_f1: 0.22222, best_epoch\n",
      "Subject: 17, n=31 | train_f1: 0.26562 | test_f1: 0.13276, best_epoch\n",
      "Subject: 19, n=11 | train_f1: 0.85887 | test_f1: 0.83333, best_epoch\n",
      "Subject: 20, n=02 | train_f1: 0.77073 | test_f1: 1.0, best_epoch\n",
      "Subject: 21, n=01 | train_f1: 0.27546 | test_f1: 0.0, best_epoch\n",
      "Subject: 22, n=02 | train_f1: 0.85024 | test_f1: 1.0, best_epoch\n",
      "Subject: 23, n=08 | train_f1: 0.69362 | test_f1: 0.46667, best_epoch\n",
      "Subject: 24, n=03 | train_f1: 0.63495 | test_f1: 0.55556, best_epoch\n",
      "Subject: 25, n=05 | train_f1: 0.80531 | test_f1: 1.0, best_epoch\n",
      "Subject: 26, n=11 | train_f1: 0.71653 | test_f1: 0.45, best_epoch\n",
      "Subject: s1, n=06 | train_f1: 0.86519 | test_f1: 0.43333, best_epoch\n",
      "Subject: s11, n=07 | train_f1: 0.76789 | test_f1: 1.0, best_epoch\n",
      "Subject: s12, n=09 | train_f1: 0.80130 | test_f1: 1.0, best_epoch\n",
      "Subject: s13, n=10 | train_f1: 0.90496 | test_f1: 0.47368, best_epoch\n",
      "Subject: s14, n=10 | train_f1: 0.84638 | test_f1: 1.0, best_epoch\n",
      "Subject: s15, n=04 | train_f1: 0.13642 | test_f1: 0.0, best_epoch\n",
      "Subject: s18, n=07 | train_f1: 0.86465 | test_f1: 1.0, best_epoch\n",
      "Subject: s19, n=02 | train_f1: 0.76643 | test_f1: 1.0, best_epoch\n",
      "Subject: s2, n=06 | train_f1: 0.84959 | test_f1: 0.77778, best_epoch\n",
      "Subject: s20, n=22 | train_f1: 0.84805 | test_f1: 0.50121, best_epoch\n",
      "Subject: s3, n=39 | train_f1: 0.76290 | test_f1: 0.5798, best_epoch\n",
      "Subject: s4, n=19 | train_f1: 0.83439 | test_f1: 0.36923, best_epoch\n",
      "Subject: s5, n=02 | train_f1: 0.80486 | test_f1: 0.33333, best_epoch\n",
      "Subject: s6, n=04 | train_f1: 0.83015 | test_f1: 0.16667, best_epoch\n",
      "Subject: s8, n=13 | train_f1: 0.85512 | test_f1: 0.26667, best_epoch\n",
      "Subject: s9, n=04 | train_f1: 0.76303 | test_f1: 1.0, best_epoch\n",
      "Total f1: 0.5461341408311106, SMIC: 0.6573265559144891, CASME2: 0.4632412455521449, SAMM: 0.42188076039588984\n"
     ]
    }
   ],
   "source": [
    "LOSO(\n",
    "    uv_frames, df, epochs=100, lr=0.01, weight_decay=1e-4, dropout=0.5, batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LOSO(\n",
    "    features,\n",
    "    df,\n",
    "    epochs=200,\n",
    "    lr=0.01,\n",
    "    batch_size=128,\n",
    "    dropout=0.5,\n",
    "    weight_decay=0.001,\n",
    "    verbose=True,\n",
    "):\n",
    "    outputs_list = []\n",
    "    # groupby reorders elements, now the labels are in same order as outputs\n",
    "    df_groupby = pd.concat([i[1] for i in df.groupby(\"subject\")])\n",
    "    dataset_groupby = df_groupby[\"dataset\"]\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    labels = le.fit_transform(df[\"emotion\"])\n",
    "    labels_groupby = le.transform(df_groupby[\"emotion\"])\n",
    "\n",
    "    # loop over each subject\n",
    "    for group in df.groupby(\"subject\"):\n",
    "        subject = group[0]\n",
    "        # split data to train and test based on the subject index\n",
    "        train_index = df[df[\"subject\"] != subject].index\n",
    "        X_train = features[train_index, :]\n",
    "        y_train = labels[train_index]\n",
    "        dataset_train = dataset[train_index]\n",
    "\n",
    "        test_index = df[df[\"subject\"] == subject].index\n",
    "        X_test = features[test_index, :]\n",
    "        y_test = labels[test_index]\n",
    "        dataset_test = dataset[test_index]\n",
    "\n",
    "        # create pytorch dataloaders from the split\n",
    "        megc_dataset_train = MEData(X_train, y_train, dataset_train, None)\n",
    "        dataset_loader_train = torch.utils.data.DataLoader(\n",
    "            megc_dataset_train, batch_size=batch_size, shuffle=True, num_workers=0\n",
    "        )\n",
    "\n",
    "        megc_dataset_test = MEData(X_test, y_test, dataset_test, None)\n",
    "        dataset_loader_test = torch.utils.data.DataLoader(\n",
    "            megc_dataset_test, batch_size=100, shuffle=False, num_workers=0\n",
    "        )\n",
    "\n",
    "        model = BDCNN(size=10).to(device)\n",
    "        criterion = ISDALoss(model.feature_num, df[\"emotion\"].nunique(), [0.15,0.425,0.425]).to(device)\n",
    "        fc = nn.Linear(model.feature_num, df[\"emotion\"].nunique()).to(device)\n",
    "        optimizer = optim.SGD([{'params': model.parameters()}, {'params': fc.parameters()}],\n",
    "                              lr=lr, momentum=0.9, weight_decay=weight_decay\n",
    "        )\n",
    "        model.train()\n",
    "        for epoch in range(epochs):\n",
    "            adjust_learning_rate(optimizer, epoch + 1)\n",
    "            for batch in dataset_loader_train:\n",
    "                data_batch, labels_batch = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                ratio = 0.5 * (epoch / epochs)\n",
    "                loss, outputs = criterion(model, fc, data_batch.float(), labels_batch, ratio)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # Test model\n",
    "        model.eval()\n",
    "        (\n",
    "            data_batch_test,\n",
    "            labels_batch_test,\n",
    "            _,\n",
    "        ) = dataset_loader_test.__iter__().__next__()\n",
    "        data_batch_test, labels_batch_test = data_batch_test.to(\n",
    "            device\n",
    "        ), labels_batch_test.to(device)\n",
    "        outputs = fc(model(data_batch_test.float()))\n",
    "        _, prediction = outputs.max(1)\n",
    "        prediction = prediction.cpu().data.numpy()\n",
    "        outputs_list.append(prediction)\n",
    "\n",
    "        train_outputs = fc(model(data_batch.float()))\n",
    "        _, train_prediction = train_outputs.max(1)\n",
    "        train_prediction = train_prediction.cpu().data.numpy()\n",
    "        train_f1 = f1_score(\n",
    "            labels_batch.cpu().data.numpy(), train_prediction, average=\"macro\"\n",
    "        )\n",
    "        test_f1 = f1_score(\n",
    "            labels_batch_test.cpu().data.numpy(), prediction, average=\"macro\"\n",
    "        )\n",
    "\n",
    "        # Print statistics\n",
    "        if verbose:\n",
    "            print(\n",
    "                \"Subject: {}, n={} | train_f1: {:.5f} | test_f1: {:.5}\".format(\n",
    "                    subject, str(labels_batch_test.shape[0]).zfill(2), train_f1, test_f1\n",
    "                )\n",
    "            )\n",
    "\n",
    "    outputs = np.concatenate(outputs_list)\n",
    "    f1_total = f1_score(labels_groupby, outputs, average=\"macro\")\n",
    "    idx = dataset_groupby == \"smic\"\n",
    "    f1_smic = f1_score(labels_groupby[idx], outputs[idx], average=\"macro\")\n",
    "    idx = dataset_groupby == \"casme2\"\n",
    "    f1_casme2 = f1_score(labels_groupby[idx], outputs[idx], average=\"macro\")\n",
    "    idx = dataset_groupby == \"samm\"\n",
    "    f1_samm = f1_score(labels_groupby[idx], outputs[idx], average=\"macro\")\n",
    "    print(\n",
    "        \"Total f1: {}, SMIC: {}, CASME2: {}, SAMM: {}\".format(\n",
    "            f1_total, f1_smic, f1_casme2, f1_samm\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LOSO(\n",
    "    features,\n",
    "    df,\n",
    "    epochs=200,\n",
    "    lr=0.01,\n",
    "    batch_size=128,\n",
    "    dropout=0.5,\n",
    "    weight_decay=0.001,\n",
    "    verbose=True,\n",
    "):\n",
    "    outputs_list = []\n",
    "    # groupby reorders elements, now the labels are in same order as outputs\n",
    "    df_groupby = pd.concat([i[1] for i in df.groupby(\"subject\")])\n",
    "    dataset_groupby = df_groupby[\"dataset\"]\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    labels = le.fit_transform(df[\"emotion\"])\n",
    "    labels_groupby = le.transform(df_groupby[\"emotion\"])\n",
    "\n",
    "    # loop over each subject\n",
    "    for group in df.groupby(\"subject\"):\n",
    "        subject = group[0]\n",
    "        # split data to train and test based on the subject index\n",
    "        train_index = df[df[\"subject\"] != subject].index\n",
    "        X_train = features[train_index, :]\n",
    "        y_train = labels[train_index]\n",
    "        dataset_train = dataset[train_index]\n",
    "\n",
    "        test_index = df[df[\"subject\"] == subject].index\n",
    "        X_test = features[test_index, :]\n",
    "        y_test = labels[test_index]\n",
    "        dataset_test = dataset[test_index]\n",
    "        \n",
    "        # Train val split\n",
    "        X_train, X_val, y_train, y_val, dataset_train, dataset_val = train_test_split(\n",
    "        X_train, y_train, dataset_train, test_size=0.2, random_state=0)\n",
    "        # Create pytorch dataloaders from the split\n",
    "        megc_dataset_train = MEData(X_train, y_train, dataset_train, None)\n",
    "        dataset_loader_train = torch.utils.data.DataLoader(\n",
    "            megc_dataset_train, batch_size=batch_size, shuffle=True, num_workers=0\n",
    "        )\n",
    "        megc_dataset_val = MEData(X_val, y_val, dataset_val, None)\n",
    "        dataset_loader_val = torch.utils.data.DataLoader(\n",
    "            megc_dataset_val, batch_size=100, shuffle=False, num_workers=0\n",
    "        )\n",
    "        megc_dataset_test = MEData(X_test, y_test, dataset_test, None)\n",
    "        dataset_loader_test = torch.utils.data.DataLoader(\n",
    "            megc_dataset_test, batch_size=100, shuffle=False, num_workers=0\n",
    "        )\n",
    "\n",
    "        model = BDCNN(size=10).to(device)\n",
    "        criterion = ISDALoss(model.feature_num, df[\"emotion\"].nunique(), [0.15,0.425,0.425]).to(device)\n",
    "        fc = nn.Linear(model.feature_num, df[\"emotion\"].nunique()).to(device)\n",
    "        optimizer = optim.SGD([{'params': model.parameters()}, {'params': fc.parameters()}],\n",
    "                              lr=lr, momentum=0.9, weight_decay=weight_decay\n",
    "        )\n",
    "        model.train()\n",
    "        best_f1 = 0\n",
    "        best_model = model\n",
    "        best_epoch = 0\n",
    "        for epoch in range(epochs):\n",
    "            adjust_learning_rate(optimizer, epoch + 1)\n",
    "            for batch in dataset_loader_train:\n",
    "                data_batch, labels_batch = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                ratio = 0.5 * (epoch / epochs)\n",
    "                loss, outputs = criterion(model, fc, data_batch.float(), labels_batch, ratio)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            # Validate and choose best epoch\n",
    "            model.eval()\n",
    "            (\n",
    "                data_batch_val,\n",
    "                labels_batch_val,\n",
    "                _,\n",
    "            ) = dataset_loader_val.__iter__().__next__()\n",
    "            data_batch_val = data_batch_val.to(device)\n",
    "            outputs = fc(model(data_batch_val.float()))\n",
    "            _, prediction = outputs.max(1)\n",
    "            prediction = prediction.cpu().data.numpy()\n",
    "            f1_val = f1_score(labels_batch_val, prediction, average=\"macro\")\n",
    "            if f1_val > best_f1:\n",
    "                best_f1 = f1_val\n",
    "                best_model = copy.deepcopy(model)\n",
    "                best_epoch = epoch\n",
    "            model.train()\n",
    "            \n",
    "\n",
    "        # Test model\n",
    "        best_model.eval()\n",
    "        (\n",
    "            data_batch_test,\n",
    "            labels_batch_test,\n",
    "            _,\n",
    "        ) = dataset_loader_test.__iter__().__next__()\n",
    "        data_batch_test = data_batch_test.to(device)\n",
    "        outputs = fc(best_model(data_batch_test.float()))\n",
    "        _, prediction = outputs.max(1)\n",
    "        prediction = prediction.cpu().data.numpy()\n",
    "        outputs_list.append(prediction)\n",
    "\n",
    "        train_outputs = fc(best_model(data_batch.float()))\n",
    "        _, train_prediction = train_outputs.max(1)\n",
    "        train_prediction = train_prediction.cpu().data.numpy()\n",
    "        train_f1 = f1_score(\n",
    "            labels_batch.cpu().data.numpy(), train_prediction, average=\"macro\"\n",
    "        )\n",
    "        test_f1 = f1_score(\n",
    "            labels_batch_test.cpu().data.numpy(), prediction, average=\"macro\"\n",
    "        )\n",
    "\n",
    "        # Print statistics\n",
    "        if verbose:\n",
    "            print(\n",
    "                \"Subject: {}, n={} | train_f1: {:.5f} | test_f1: {:.5}, {}\".format(\n",
    "                    subject, str(labels_batch_test.shape[0]).zfill(2), train_f1, test_f1,\n",
    "                    best_epoch\n",
    "                )\n",
    "            )\n",
    "\n",
    "    outputs = np.concatenate(outputs_list)\n",
    "    f1_total = f1_score(labels_groupby, outputs, average=\"macro\")\n",
    "    idx = dataset_groupby == \"smic\"\n",
    "    f1_smic = f1_score(labels_groupby[idx], outputs[idx], average=\"macro\")\n",
    "    idx = dataset_groupby == \"casme2\"\n",
    "    f1_casme2 = f1_score(labels_groupby[idx], outputs[idx], average=\"macro\")\n",
    "    idx = dataset_groupby == \"samm\"\n",
    "    f1_samm = f1_score(labels_groupby[idx], outputs[idx], average=\"macro\")\n",
    "    print(\n",
    "        \"Total f1: {}, SMIC: {}, CASME2: {}, SAMM: {}\".format(\n",
    "            f1_total, f1_smic, f1_casme2, f1_samm\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import utils.utils as utils\n",
    "import utils.datasets as datasets\n",
    "import utils.py_evm as py_evm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import f1_score\n",
    "from skimage.transform import resize\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torchvision import transforms, models\n",
    "import dlib\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a bug in the original code\n",
    "Prepare.py line 341. If the image is float it's max should be 1, not 255. This causes the HSV image to have values of -10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure everything is deterministic\n",
    "random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed(1)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, load_data = datasets.megc(color=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tvaranka/.local/lib/python3.6/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "df, load_data = datasets.megc(\"raw\", color=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"../shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mner_preprocess(onset, apex):\n",
    "    onset = (onset * 255.0).astype(\"uint8\")\n",
    "    apex = (apex * 255.0).astype(\"uint8\")\n",
    "    onset_det = detector(onset, 1)[0] if detector(onset, 1) else detector(onset, 0)[0]\n",
    "    apex_dets = detector(apex, 1)\n",
    "    if len(apex_dets) > 0:\n",
    "        apex_det = apex_dets[0]\n",
    "    else:\n",
    "        apex_det = onset_det\n",
    "    #apex_det = detector(apex, 1)[0]\n",
    "\n",
    "    onset_face = dlib.full_object_detections()\n",
    "    apex_face = dlib.full_object_detections()\n",
    "\n",
    "    onset_face.append(predictor(onset, onset_det))\n",
    "    apex_face.append(predictor(apex, apex_det))\n",
    "\n",
    "    onset_crops = dlib.get_face_chips(onset, onset_face, size=320)\n",
    "    apex_crops = dlib.get_face_chips(apex, apex_face, size=320)\n",
    "\n",
    "    #Not used, but are in the original code\n",
    "    #onset_crop = onset_crops[0][:280, 50:270]\n",
    "    #apex_crop = apex_crops[0][:280, 50:270]\n",
    "\n",
    "    onset_g = cv2.cvtColor(onset_crops[0], cv2.COLOR_RGB2GRAY)\n",
    "    apex_g = cv2.cvtColor(apex_crops[0], cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    pic_size = onset_crops[0].shape\n",
    "    hsv = np.zeros(pic_size)\n",
    "    hsv[:, :, 1] = cv2.cvtColor(apex_crops[0], cv2.COLOR_RGB2HSV)[:, :, 1]\n",
    "\n",
    "    flow = cv2.calcOpticalFlowFarneback(onset_g, apex_g, flow=None,\n",
    "                                        pyr_scale=0.5, levels=1, winsize=15,\n",
    "                                        iterations=2,\n",
    "                                        poly_n=5, poly_sigma=1.1, flags=0)\n",
    "\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    hsv[:, :, 0] = ang * (180 / np.pi / 2)\n",
    "    hsv[:, :, 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    hsv = np.asarray(hsv, dtype=np.float32)\n",
    "    # This line is added to avoid the bug\n",
    "    hsv /= 255.0\n",
    "    rgb_flow = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "    return rgb_flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/442 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 1/442 [00:01<09:57,  1.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 2/442 [00:02<08:59,  1.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 3/442 [00:03<07:59,  1.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 4/442 [00:03<07:25,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 5/442 [00:04<07:23,  1.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 6/442 [00:05<07:25,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 7/442 [00:06<07:03,  1.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 8/442 [00:08<07:44,  1.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 9/442 [00:09<09:02,  1.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 10/442 [00:11<10:26,  1.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 11/442 [00:13<11:27,  1.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 12/442 [00:15<11:36,  1.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 13/442 [00:16<10:45,  1.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 14/442 [00:18<11:38,  1.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 15/442 [00:19<10:11,  1.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 16/442 [00:21<10:53,  1.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 17/442 [00:22<10:05,  1.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 18/442 [00:23<09:54,  1.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 19/442 [00:25<10:10,  1.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 20/442 [00:27<11:00,  1.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 21/442 [00:28<10:52,  1.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 22/442 [00:30<10:34,  1.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 23/442 [00:31<11:11,  1.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 24/442 [00:33<10:28,  1.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 25/442 [00:34<10:36,  1.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 26/442 [00:36<11:47,  1.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 27/442 [00:38<11:57,  1.73s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 28/442 [00:40<11:43,  1.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 29/442 [00:41<11:05,  1.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 30/442 [00:43<11:01,  1.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 31/442 [00:45<11:22,  1.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 32/442 [00:46<11:43,  1.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 33/442 [00:48<12:09,  1.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 34/442 [00:50<11:29,  1.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 35/442 [00:52<12:31,  1.85s/it]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 36/442 [00:54<12:37,  1.87s/it]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 37/442 [00:56<12:42,  1.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▊         | 38/442 [00:58<12:19,  1.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 39/442 [00:59<11:46,  1.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 40/442 [01:01<11:33,  1.73s/it]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 41/442 [01:03<11:48,  1.77s/it]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 42/442 [01:04<11:41,  1.75s/it]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 43/442 [01:06<12:11,  1.83s/it]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 44/442 [01:08<12:32,  1.89s/it]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 45/442 [01:10<11:28,  1.73s/it]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 46/442 [01:11<11:17,  1.71s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 47/442 [01:13<11:03,  1.68s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 48/442 [01:15<11:33,  1.76s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 49/442 [01:16<10:57,  1.67s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█▏        | 50/442 [01:18<10:36,  1.62s/it]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 51/442 [01:19<09:44,  1.49s/it]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 52/442 [01:21<09:34,  1.47s/it]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 53/442 [01:22<09:57,  1.54s/it]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 54/442 [01:24<09:45,  1.51s/it]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 55/442 [01:26<10:41,  1.66s/it]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 56/442 [01:27<09:42,  1.51s/it]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 57/442 [01:28<08:49,  1.37s/it]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 58/442 [01:30<09:12,  1.44s/it]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 59/442 [01:31<09:30,  1.49s/it]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▎        | 60/442 [01:33<09:22,  1.47s/it]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 61/442 [01:34<08:53,  1.40s/it]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 62/442 [01:34<07:30,  1.19s/it]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 63/442 [01:36<07:57,  1.26s/it]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 64/442 [01:37<08:18,  1.32s/it]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 65/442 [01:38<07:38,  1.22s/it]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 66/442 [01:40<07:47,  1.24s/it]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 67/442 [01:41<07:07,  1.14s/it]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 68/442 [01:41<06:27,  1.04s/it]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 69/442 [01:43<07:46,  1.25s/it]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 70/442 [01:44<07:59,  1.29s/it]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 71/442 [01:45<06:58,  1.13s/it]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 72/442 [01:46<07:12,  1.17s/it]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 73/442 [01:48<07:42,  1.25s/it]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 74/442 [01:49<08:05,  1.32s/it]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 75/442 [01:51<09:12,  1.50s/it]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 76/442 [01:53<09:59,  1.64s/it]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 77/442 [01:55<10:18,  1.70s/it]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 78/442 [01:56<09:05,  1.50s/it]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 79/442 [01:58<09:21,  1.55s/it]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 80/442 [01:59<08:23,  1.39s/it]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 81/442 [02:01<09:37,  1.60s/it]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▊        | 82/442 [02:03<09:47,  1.63s/it]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 83/442 [02:04<08:42,  1.45s/it]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 84/442 [02:05<08:06,  1.36s/it]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 85/442 [02:06<07:44,  1.30s/it]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 86/442 [02:06<06:10,  1.04s/it]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 87/442 [02:07<05:44,  1.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 88/442 [02:08<05:48,  1.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 89/442 [02:10<06:48,  1.16s/it]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 90/442 [02:11<06:48,  1.16s/it]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 91/442 [02:13<07:28,  1.28s/it]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 92/442 [02:13<06:46,  1.16s/it]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 93/442 [02:15<07:12,  1.24s/it]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██▏       | 94/442 [02:16<07:01,  1.21s/it]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██▏       | 95/442 [02:17<06:25,  1.11s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 96/442 [02:18<06:44,  1.17s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 97/442 [02:19<06:38,  1.15s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 98/442 [02:21<07:13,  1.26s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 99/442 [02:21<06:11,  1.08s/it]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 100/442 [02:23<06:33,  1.15s/it]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 101/442 [02:24<07:10,  1.26s/it]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 102/442 [02:26<07:34,  1.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 103/442 [02:27<07:17,  1.29s/it]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▎       | 104/442 [02:28<06:23,  1.14s/it]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 105/442 [02:29<06:15,  1.11s/it]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 106/442 [02:30<06:10,  1.10s/it]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 107/442 [02:31<06:51,  1.23s/it]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 108/442 [02:32<06:02,  1.08s/it]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 109/442 [02:33<06:06,  1.10s/it]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 110/442 [02:35<06:16,  1.13s/it]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 111/442 [02:36<06:02,  1.10s/it]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 112/442 [02:37<06:54,  1.26s/it]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 113/442 [02:38<06:54,  1.26s/it]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 114/442 [02:40<07:29,  1.37s/it]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 115/442 [02:41<06:43,  1.23s/it]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 116/442 [02:42<05:43,  1.06s/it]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 117/442 [02:43<06:04,  1.12s/it]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 118/442 [02:44<05:29,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 119/442 [02:44<05:01,  1.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 120/442 [02:46<05:54,  1.10s/it]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 121/442 [02:47<05:45,  1.08s/it]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 122/442 [02:48<05:28,  1.03s/it]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 123/442 [02:49<05:47,  1.09s/it]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 124/442 [02:50<05:33,  1.05s/it]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 125/442 [02:51<05:46,  1.09s/it]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▊       | 126/442 [02:53<06:04,  1.15s/it]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▊       | 127/442 [02:53<05:40,  1.08s/it]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 128/442 [02:54<05:25,  1.04s/it]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 129/442 [02:55<05:26,  1.04s/it]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 130/442 [02:56<05:20,  1.03s/it]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 131/442 [02:58<05:33,  1.07s/it]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 132/442 [02:59<06:06,  1.18s/it]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 133/442 [03:00<06:16,  1.22s/it]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 134/442 [03:01<05:50,  1.14s/it]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 135/442 [03:03<06:43,  1.32s/it]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 136/442 [03:04<06:25,  1.26s/it]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 137/442 [03:06<07:25,  1.46s/it]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 138/442 [03:07<07:22,  1.45s/it]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███▏      | 139/442 [03:08<06:39,  1.32s/it]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 140/442 [03:09<05:53,  1.17s/it]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 141/442 [03:10<05:35,  1.12s/it]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 142/442 [03:12<06:17,  1.26s/it]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 143/442 [03:14<07:07,  1.43s/it]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 144/442 [03:15<07:09,  1.44s/it]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 145/442 [03:17<07:15,  1.47s/it]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 146/442 [03:18<06:17,  1.28s/it]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 147/442 [03:19<06:37,  1.35s/it]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 148/442 [03:21<06:53,  1.41s/it]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▎      | 149/442 [03:22<06:49,  1.40s/it]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 150/442 [03:23<06:40,  1.37s/it]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 151/442 [03:25<07:03,  1.46s/it]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 152/442 [03:27<07:50,  1.62s/it]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 153/442 [03:29<08:36,  1.79s/it]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 154/442 [03:30<07:28,  1.56s/it]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 155/442 [03:31<07:01,  1.47s/it]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 156/442 [03:33<07:25,  1.56s/it]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 157/442 [03:35<07:22,  1.55s/it]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 158/442 [03:36<06:50,  1.45s/it]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 159/442 [03:37<06:58,  1.48s/it]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 160/442 [03:39<07:27,  1.59s/it]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 161/442 [03:41<07:53,  1.69s/it]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 162/442 [03:42<07:15,  1.56s/it]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 163/442 [03:44<07:44,  1.67s/it]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 164/442 [03:46<08:04,  1.74s/it]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 165/442 [03:51<11:33,  2.50s/it]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 166/442 [03:56<15:20,  3.33s/it]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 167/442 [04:10<29:58,  6.54s/it]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 168/442 [04:17<29:59,  6.57s/it]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 169/442 [04:29<38:12,  8.40s/it]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 170/442 [04:44<47:16, 10.43s/it]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▊      | 171/442 [04:57<50:03, 11.08s/it]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 172/442 [05:07<48:10, 10.70s/it]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 173/442 [05:19<50:36, 11.29s/it]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 174/442 [05:31<50:32, 11.32s/it]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 175/442 [05:38<44:57, 10.10s/it]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 176/442 [05:44<39:15,  8.85s/it]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 177/442 [05:49<34:20,  7.77s/it]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 178/442 [05:59<37:18,  8.48s/it]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 179/442 [06:07<36:02,  8.22s/it]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 180/442 [06:19<40:35,  9.30s/it]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 181/442 [06:24<35:12,  8.09s/it]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 182/442 [06:31<33:10,  7.66s/it]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████▏     | 183/442 [06:42<37:54,  8.78s/it]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 184/442 [06:50<36:31,  8.49s/it]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 185/442 [06:58<35:42,  8.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 186/442 [07:04<33:10,  7.78s/it]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 187/442 [07:11<31:20,  7.37s/it]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 188/442 [07:21<35:21,  8.35s/it]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 189/442 [07:29<33:33,  7.96s/it]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 190/442 [07:36<32:21,  7.70s/it]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 191/442 [07:42<30:19,  7.25s/it]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 192/442 [07:48<29:04,  6.98s/it]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▎     | 193/442 [07:56<29:42,  7.16s/it]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 194/442 [08:05<31:45,  7.68s/it]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 195/442 [08:15<34:53,  8.47s/it]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 196/442 [08:22<33:02,  8.06s/it]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 197/442 [08:29<31:35,  7.74s/it]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 198/442 [08:36<30:12,  7.43s/it]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 199/442 [08:46<33:51,  8.36s/it]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 200/442 [08:55<33:42,  8.36s/it]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 201/442 [09:01<31:00,  7.72s/it]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 202/442 [09:14<37:45,  9.44s/it]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 203/442 [09:25<39:09,  9.83s/it]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 204/442 [09:38<43:04, 10.86s/it]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▋     | 205/442 [09:48<41:22, 10.47s/it]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 206/442 [09:55<36:57,  9.40s/it]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 207/442 [10:05<37:23,  9.55s/it]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 208/442 [10:11<33:27,  8.58s/it]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 209/442 [10:19<32:49,  8.45s/it]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 210/442 [10:25<29:30,  7.63s/it]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 211/442 [10:35<31:42,  8.24s/it]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 212/442 [10:43<31:27,  8.21s/it]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 213/442 [10:54<34:52,  9.14s/it]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 214/442 [11:03<34:39,  9.12s/it]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 215/442 [11:15<37:35,  9.94s/it]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 216/442 [11:26<39:11, 10.41s/it]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 217/442 [11:38<40:45, 10.87s/it]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 218/442 [11:47<38:35, 10.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 219/442 [11:55<35:18,  9.50s/it]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 220/442 [12:05<35:14,  9.53s/it]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 221/442 [12:14<34:44,  9.43s/it]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 222/442 [12:19<30:24,  8.29s/it]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 223/442 [12:24<26:37,  7.30s/it]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 224/442 [12:35<30:07,  8.29s/it]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 225/442 [12:44<31:16,  8.65s/it]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 226/442 [12:54<31:32,  8.76s/it]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████▏    | 227/442 [12:58<26:40,  7.44s/it]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 228/442 [13:08<29:31,  8.28s/it]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 229/442 [13:18<30:46,  8.67s/it]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 230/442 [13:25<29:12,  8.27s/it]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 231/442 [13:35<31:12,  8.87s/it]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 232/442 [13:42<29:03,  8.30s/it]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 233/442 [13:54<32:43,  9.40s/it]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 234/442 [13:57<25:56,  7.48s/it]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 235/442 [14:08<29:19,  8.50s/it]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 236/442 [14:13<25:36,  7.46s/it]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▎    | 237/442 [14:24<29:13,  8.55s/it]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 238/442 [14:29<25:29,  7.50s/it]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 239/442 [14:35<23:52,  7.06s/it]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 240/442 [14:42<22:56,  6.81s/it]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 241/442 [14:48<21:58,  6.56s/it]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 242/442 [14:58<26:10,  7.85s/it]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 243/442 [15:04<23:30,  7.09s/it]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 244/442 [15:13<25:39,  7.78s/it]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 245/442 [15:25<29:39,  9.03s/it]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 246/442 [15:35<30:25,  9.31s/it]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 247/442 [15:43<28:58,  8.91s/it]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 248/442 [15:51<28:00,  8.66s/it]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▋    | 249/442 [16:00<28:29,  8.86s/it]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 250/442 [16:05<24:42,  7.72s/it]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 251/442 [16:17<27:46,  8.72s/it]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 252/442 [16:20<22:59,  7.26s/it]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 253/442 [16:29<24:28,  7.77s/it]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 254/442 [16:40<27:27,  8.77s/it]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 255/442 [16:49<27:00,  8.66s/it]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 256/442 [16:56<25:17,  8.16s/it]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 257/442 [17:01<22:32,  7.31s/it]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 258/442 [17:12<25:41,  8.38s/it]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 259/442 [17:19<23:51,  7.82s/it]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 260/442 [17:31<27:47,  9.16s/it]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 261/442 [17:35<23:15,  7.71s/it]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 262/442 [17:41<21:11,  7.06s/it]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 263/442 [17:52<24:58,  8.37s/it]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 264/442 [18:01<25:34,  8.62s/it]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 265/442 [18:09<24:36,  8.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 266/442 [18:18<25:03,  8.54s/it]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 267/442 [18:30<27:43,  9.51s/it]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 268/442 [18:41<28:48,  9.93s/it]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 269/442 [18:48<26:30,  9.19s/it]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 270/442 [18:55<24:17,  8.47s/it]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████▏   | 271/442 [19:04<24:26,  8.58s/it]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 272/442 [19:10<22:37,  7.99s/it]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 273/442 [19:20<23:56,  8.50s/it]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 274/442 [19:26<21:51,  7.80s/it]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 275/442 [19:31<19:00,  6.83s/it]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 276/442 [19:36<17:28,  6.32s/it]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 277/442 [19:43<17:35,  6.40s/it]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 278/442 [19:49<17:11,  6.29s/it]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 279/442 [19:52<15:05,  5.56s/it]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 280/442 [20:05<20:42,  7.67s/it]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▎   | 281/442 [20:16<23:31,  8.76s/it]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 282/442 [20:29<26:24,  9.90s/it]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 283/442 [20:39<26:19,  9.94s/it]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 284/442 [20:46<23:39,  8.99s/it]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 285/442 [20:57<25:16,  9.66s/it]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 286/442 [21:04<23:04,  8.88s/it]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 287/442 [21:13<22:54,  8.87s/it]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 288/442 [21:22<23:08,  9.01s/it]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 289/442 [21:30<22:12,  8.71s/it]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 290/442 [21:37<20:46,  8.20s/it]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 291/442 [21:48<22:39,  9.01s/it]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 292/442 [21:52<18:57,  7.59s/it]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▋   | 293/442 [21:56<16:02,  6.46s/it]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 294/442 [22:01<14:27,  5.86s/it]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 295/442 [22:10<16:51,  6.88s/it]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 296/442 [22:23<21:09,  8.70s/it]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 297/442 [22:30<19:37,  8.12s/it]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 298/442 [22:36<17:54,  7.46s/it]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 299/442 [22:47<20:25,  8.57s/it]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 300/442 [22:55<19:47,  8.36s/it]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 301/442 [23:02<18:44,  7.98s/it]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 302/442 [23:13<20:47,  8.91s/it]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▊   | 303/442 [23:24<21:56,  9.47s/it]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 304/442 [23:30<19:46,  8.60s/it]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 305/442 [23:38<18:55,  8.29s/it]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 306/442 [23:49<20:38,  9.11s/it]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 307/442 [23:57<20:05,  8.93s/it]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 308/442 [24:08<21:26,  9.60s/it]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 309/442 [24:16<19:56,  8.99s/it]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 310/442 [24:38<28:19, 12.88s/it]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 311/442 [25:02<35:16, 16.16s/it]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 312/442 [25:27<40:39, 18.77s/it]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 313/442 [25:52<44:34, 20.73s/it]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 314/442 [26:22<50:24, 23.63s/it]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████▏  | 315/442 [26:52<53:42, 25.38s/it]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████▏  | 316/442 [27:11<49:45, 23.69s/it]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 317/442 [27:33<48:00, 23.04s/it]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 318/442 [27:58<48:48, 23.62s/it]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 319/442 [28:28<52:15, 25.49s/it]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 320/442 [28:57<54:01, 26.57s/it]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 321/442 [29:13<47:22, 23.49s/it]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 322/442 [29:40<48:56, 24.47s/it]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 323/442 [29:56<43:39, 22.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 324/442 [30:25<47:28, 24.14s/it]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▎  | 325/442 [30:46<44:50, 23.00s/it]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 326/442 [31:12<46:26, 24.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 327/442 [31:27<40:42, 21.24s/it]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 328/442 [31:56<45:06, 23.74s/it]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 329/442 [32:15<41:47, 22.19s/it]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 330/442 [32:37<41:17, 22.12s/it]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 331/442 [32:59<41:04, 22.21s/it]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 332/442 [33:24<42:04, 22.95s/it]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 333/442 [33:31<33:05, 18.21s/it]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 334/442 [33:45<30:20, 16.86s/it]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 335/442 [33:50<23:51, 13.38s/it]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 336/442 [33:56<19:27, 11.01s/it]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 337/442 [34:21<26:43, 15.27s/it]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▋  | 338/442 [34:33<24:38, 14.22s/it]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 339/442 [34:49<25:36, 14.92s/it]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 340/442 [35:14<30:38, 18.03s/it]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 341/442 [35:39<33:52, 20.13s/it]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 342/442 [35:54<30:33, 18.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 343/442 [36:16<32:08, 19.48s/it]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 344/442 [36:40<34:18, 21.00s/it]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 345/442 [37:08<37:22, 23.12s/it]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 346/442 [37:24<33:36, 21.01s/it]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▊  | 347/442 [37:53<36:47, 23.23s/it]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▊  | 348/442 [38:22<39:05, 24.95s/it]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 349/442 [38:39<35:09, 22.68s/it]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 350/442 [38:51<29:50, 19.46s/it]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 351/442 [39:10<29:00, 19.12s/it]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 352/442 [39:38<32:41, 21.79s/it]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 353/442 [40:06<35:19, 23.82s/it]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 354/442 [40:28<33:57, 23.15s/it]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 355/442 [40:42<29:41, 20.48s/it]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 356/442 [41:05<30:28, 21.26s/it]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 357/442 [41:25<29:28, 20.80s/it]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 358/442 [41:59<34:59, 24.99s/it]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 359/442 [42:18<31:57, 23.11s/it]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 360/442 [42:46<33:36, 24.59s/it]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 361/442 [43:15<35:03, 25.96s/it]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 362/442 [43:46<36:31, 27.39s/it]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 363/442 [44:11<35:05, 26.66s/it]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 364/442 [44:54<40:59, 31.54s/it]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 365/442 [45:23<39:26, 30.73s/it]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 366/442 [45:37<32:46, 25.88s/it]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 367/442 [46:08<34:01, 27.22s/it]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 368/442 [46:40<35:21, 28.67s/it]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 369/442 [47:07<34:22, 28.25s/it]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▎ | 370/442 [47:40<35:38, 29.70s/it]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 371/442 [48:11<35:33, 30.05s/it]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 372/442 [48:24<28:57, 24.81s/it]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 373/442 [48:47<27:55, 24.28s/it]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▍ | 374/442 [49:11<27:36, 24.35s/it]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▍ | 375/442 [49:36<27:23, 24.53s/it]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 376/442 [49:55<25:02, 22.76s/it]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 377/442 [50:17<24:29, 22.60s/it]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 378/442 [50:40<24:16, 22.76s/it]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 379/442 [50:58<22:20, 21.27s/it]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 380/442 [51:17<21:26, 20.74s/it]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 381/442 [51:37<20:42, 20.36s/it]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▋ | 382/442 [52:09<23:45, 23.76s/it]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 383/442 [52:43<26:31, 26.97s/it]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 384/442 [53:10<26:06, 27.01s/it]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 385/442 [53:40<26:31, 27.92s/it]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 386/442 [54:13<27:25, 29.38s/it]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 387/442 [54:40<26:21, 28.76s/it]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 388/442 [55:10<26:12, 29.12s/it]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 389/442 [55:33<23:54, 27.06s/it]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 390/442 [55:46<19:58, 23.04s/it]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 391/442 [56:04<18:12, 21.42s/it]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▊ | 392/442 [56:20<16:32, 19.85s/it]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 393/442 [56:34<14:42, 18.00s/it]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 394/442 [56:50<14:04, 17.60s/it]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 395/442 [57:16<15:47, 20.15s/it]\u001b[A\u001b[A\n",
      "\n",
      " 90%|████████▉ | 396/442 [57:34<14:55, 19.47s/it]\u001b[A\u001b[A\n",
      "\n",
      " 90%|████████▉ | 397/442 [58:02<16:25, 21.90s/it]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 398/442 [58:35<18:31, 25.27s/it]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 399/442 [58:53<16:29, 23.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 400/442 [59:07<14:18, 20.45s/it]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 401/442 [59:34<15:18, 22.41s/it]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 402/442 [59:58<15:11, 22.80s/it]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 403/442 [1:00:15<13:40, 21.03s/it]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████▏| 404/442 [1:00:36<13:21, 21.08s/it]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 405/442 [1:00:59<13:20, 21.63s/it]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 406/442 [1:01:20<12:51, 21.44s/it]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 407/442 [1:01:43<12:48, 21.97s/it]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 408/442 [1:02:07<12:45, 22.50s/it]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 409/442 [1:02:18<10:26, 18.98s/it]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 410/442 [1:02:36<10:02, 18.84s/it]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 411/442 [1:02:59<10:23, 20.13s/it]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 412/442 [1:03:28<11:22, 22.77s/it]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 413/442 [1:03:54<11:25, 23.64s/it]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▎| 414/442 [1:04:15<10:41, 22.91s/it]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 415/442 [1:04:39<10:24, 23.13s/it]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 416/442 [1:05:08<10:48, 24.95s/it]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 417/442 [1:05:32<10:13, 24.53s/it]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▍| 418/442 [1:05:57<09:58, 24.93s/it]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▍| 419/442 [1:06:19<09:13, 24.06s/it]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 420/442 [1:06:33<07:36, 20.77s/it]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 421/442 [1:06:50<06:54, 19.73s/it]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 422/442 [1:07:09<06:32, 19.60s/it]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 423/442 [1:07:28<06:10, 19.51s/it]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 424/442 [1:07:44<05:29, 18.28s/it]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 425/442 [1:08:00<05:01, 17.73s/it]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▋| 426/442 [1:08:22<05:01, 18.83s/it]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 427/442 [1:08:48<05:16, 21.07s/it]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 428/442 [1:09:14<05:17, 22.67s/it]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 429/442 [1:09:46<05:29, 25.31s/it]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 430/442 [1:10:12<05:04, 25.42s/it]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 431/442 [1:10:33<04:25, 24.15s/it]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 432/442 [1:10:55<03:57, 23.71s/it]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 433/442 [1:11:07<03:01, 20.13s/it]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 434/442 [1:11:17<02:15, 16.90s/it]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 435/442 [1:11:34<01:59, 17.09s/it]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▊| 436/442 [1:11:52<01:43, 17.26s/it]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 437/442 [1:12:16<01:36, 19.30s/it]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 438/442 [1:12:31<01:12, 18.16s/it]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 439/442 [1:12:43<00:49, 16.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████▉| 440/442 [1:13:09<00:38, 19.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████▉| 441/442 [1:13:41<00:23, 23.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 442/442 [1:14:12<00:00, 10.07s/it]\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "flows = np.zeros((n_samples, 3, 320, 320))\n",
    "for i, video in enumerate(tqdm(load_data, total=n_samples)):\n",
    "    mm_video = py_evm.magnify(video)\n",
    "    flow = mner_preprocess(mm_video[0], mm_video[df.loc[i, \"apexf\"]])\n",
    "    flows[i] = flow.transpose(2, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(df[\"emotion\"])\n",
    "dataset = le.fit_transform(df[\"dataset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MEData(Dataset):\n",
    "    def __init__(self, frames, labels, transform=None):\n",
    "        self.frames = frames\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.frames.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.frames[idx]\n",
    "        if self.transform:\n",
    "            sample = Image.fromarray((sample.transpose(1, 2, 0) * 255).astype(\"uint8\"))\n",
    "            sample = self.transform(sample)\n",
    "        label = self.labels[idx]\n",
    "        return {\"image\": sample, \"label\": label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet18_pt_mcn_removed(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Resnet18_pt_mcn_removed, self).__init__()\n",
    "        self.meta = {'mean': [0.485, 0.456, 0.406],\n",
    "                     'std': [0.229, 0.224, 0.225],\n",
    "                     'imageSize': [224, 224]}\n",
    "        self.backbone = models.resnet18(pretrained=True)\n",
    "        self.backbone = torch.nn.Sequential(*(list(self.backbone.children())[:-2]))\n",
    "        self.features_8 = nn.AvgPool2d(kernel_size=[7, 7], stride=[1, 1], padding=0, ceil_mode=False, count_include_pad=False)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features_7 = self.backbone(x)\n",
    "        \n",
    "        top = features_7[:, :, :3]\n",
    "        bottom = features_7[:, :, 3:]\n",
    "        \n",
    "        top = self.avgpool(top)\n",
    "        bottom = self.avgpool(bottom)\n",
    "        \n",
    "        top = top.view(top.size(0), -1)\n",
    "        bottom = bottom.view(bottom.size(0), -1)\n",
    "        \n",
    "        return top, bottom\n",
    "    \n",
    "    \n",
    "class FC_3(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(FC_3, self).__init__()\n",
    "        self.fc_3 = nn.Sequential(\n",
    "            nn.Linear(512, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc_3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    \n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_classes=3, num_classes=3):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc = nn.Linear(64 * input_classes, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Flow_Part_npic(num_pic=2, num_classes=3, **kwargs):\n",
    "\n",
    "    model = {}\n",
    "\n",
    "    model['resnet'] = Resnet18_pt_mcn_removed()\n",
    "    model['fc_top'] = FC_3()\n",
    "    model['fc_bottom'] = FC_3()\n",
    "    model['classifier'] = Classifier(input_classes=num_pic, num_classes=num_classes)\n",
    "    model['classifier_top'] = Classifier(input_classes=1, num_classes=num_classes)\n",
    "    model['classifier_bottom'] = Classifier(input_classes=1, num_classes=num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "        transforms.RandomCrop((224, 224), pad_if_needed=True),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                             std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "def weight_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        nn.init.xavier_normal_(m.weight.data)\n",
    "        nn.init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sssnet\n",
    "Total f1: 0.7617842853527486, SMIC: 0.7241661846925004, CASME2: 0.8568498168498168, SAMM: 0.6528043905093086"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE =  0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.312\tLabel_Loss: 1.3918\tTop_Loss: 1.1304\tBottom_Loss: 1.4040\tLoss: 3.9263\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.344\tLabel_Loss: 1.2801\tTop_Loss: 1.2615\tBottom_Loss: 1.3924\tLoss: 3.9340\t\n",
      "Subject: 006, n=11 | test_f1: 0.2807 |best_f1: 0.2807\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.500\tLabel_Loss: 1.0769\tTop_Loss: 1.1487\tBottom_Loss: 1.0673\tLoss: 3.2929\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.219\tLabel_Loss: 1.5872\tTop_Loss: 1.5969\tBottom_Loss: 1.5141\tLoss: 4.6982\t\n",
      "Subject: 006, n=11 | test_f1: 0.25926 |best_f1: 0.2807\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.531\tLabel_Loss: 0.9751\tTop_Loss: 1.0569\tBottom_Loss: 1.1075\tLoss: 3.1395\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.562\tLabel_Loss: 0.8990\tTop_Loss: 0.8245\tBottom_Loss: 0.9107\tLoss: 2.6342\t\n",
      "Subject: 006, n=11 | test_f1: 0.45 |best_f1: 0.45\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.531\tLabel_Loss: 0.9144\tTop_Loss: 0.7261\tBottom_Loss: 1.0349\tLoss: 2.6753\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.531\tLabel_Loss: 1.0093\tTop_Loss: 0.8429\tBottom_Loss: 1.0732\tLoss: 2.9255\t\n",
      "Subject: 006, n=11 | test_f1: 0.45 |best_f1: 0.45\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.531\tLabel_Loss: 0.8592\tTop_Loss: 0.9750\tBottom_Loss: 0.9595\tLoss: 2.7937\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.562\tLabel_Loss: 0.8882\tTop_Loss: 0.8211\tBottom_Loss: 1.0087\tLoss: 2.7181\t\n",
      "Subject: 006, n=11 | test_f1: 0.2807 |best_f1: 0.45\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8700\tTop_Loss: 0.8213\tBottom_Loss: 0.8429\tLoss: 2.5342\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.469\tLabel_Loss: 0.9695\tTop_Loss: 0.8845\tBottom_Loss: 0.8780\tLoss: 2.7320\t\n",
      "Subject: 006, n=11 | test_f1: 0.2807 |best_f1: 0.45\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7380\tTop_Loss: 0.6872\tBottom_Loss: 0.7182\tLoss: 2.1434\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.562\tLabel_Loss: 0.9424\tTop_Loss: 0.8500\tBottom_Loss: 0.9757\tLoss: 2.7681\t\n",
      "Subject: 006, n=11 | test_f1: 0.42105 |best_f1: 0.45\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.719\tLabel_Loss: 0.7637\tTop_Loss: 0.8992\tBottom_Loss: 0.7784\tLoss: 2.4414\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.406\tLabel_Loss: 1.1858\tTop_Loss: 1.2174\tBottom_Loss: 1.1511\tLoss: 3.5543\t\n",
      "Subject: 006, n=11 | test_f1: 0.23529 |best_f1: 0.45\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7690\tTop_Loss: 0.7860\tBottom_Loss: 0.8140\tLoss: 2.3690\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8055\tTop_Loss: 0.8234\tBottom_Loss: 0.7822\tLoss: 2.4110\t\n",
      "Subject: 006, n=11 | test_f1: 0.45 |best_f1: 0.45\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.656\tLabel_Loss: 0.8769\tTop_Loss: 1.0490\tBottom_Loss: 0.9108\tLoss: 2.8368\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.531\tLabel_Loss: 0.8475\tTop_Loss: 0.8067\tBottom_Loss: 1.0019\tLoss: 2.6560\t\n",
      "Subject: 006, n=11 | test_f1: 0.2807 |best_f1: 0.45\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6718\tTop_Loss: 0.7703\tBottom_Loss: 0.8919\tLoss: 2.3340\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7935\tTop_Loss: 0.7141\tBottom_Loss: 0.8315\tLoss: 2.3391\t\n",
      "Subject: 006, n=11 | test_f1: 0.45 |best_f1: 0.45\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8786\tTop_Loss: 0.9053\tBottom_Loss: 1.0697\tLoss: 2.8537\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5379\tTop_Loss: 0.5863\tBottom_Loss: 0.6692\tLoss: 1.7933\t\n",
      "Subject: 006, n=11 | test_f1: 0.42105 |best_f1: 0.45\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5927\tTop_Loss: 0.8268\tBottom_Loss: 0.7400\tLoss: 2.1595\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5856\tTop_Loss: 0.7437\tBottom_Loss: 0.7524\tLoss: 2.0816\t\n",
      "Subject: 006, n=11 | test_f1: 0.45 |best_f1: 0.45\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5621\tTop_Loss: 0.6576\tBottom_Loss: 0.5829\tLoss: 1.8026\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.844\tLabel_Loss: 0.5079\tTop_Loss: 0.8338\tBottom_Loss: 0.6995\tLoss: 2.0412\t\n",
      "Subject: 006, n=11 | test_f1: 0.42105 |best_f1: 0.45\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7166\tTop_Loss: 0.5863\tBottom_Loss: 0.7316\tLoss: 2.0346\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.719\tLabel_Loss: 0.8433\tTop_Loss: 0.8617\tBottom_Loss: 0.9114\tLoss: 2.6164\t\n",
      "Subject: 006, n=11 | test_f1: 0.45 |best_f1: 0.45\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5511\tTop_Loss: 0.7578\tBottom_Loss: 0.5793\tLoss: 1.8881\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6682\tTop_Loss: 0.9390\tBottom_Loss: 0.7820\tLoss: 2.3891\t\n",
      "Subject: 006, n=11 | test_f1: 0.45 |best_f1: 0.45\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.844\tLabel_Loss: 0.5435\tTop_Loss: 0.6554\tBottom_Loss: 0.8848\tLoss: 2.0836\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5466\tTop_Loss: 0.7590\tBottom_Loss: 0.6252\tLoss: 1.9308\t\n",
      "Subject: 006, n=11 | test_f1: 0.42105 |best_f1: 0.45\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4668\tTop_Loss: 0.6206\tBottom_Loss: 0.6797\tLoss: 1.7671\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.781\tLabel_Loss: 0.6063\tTop_Loss: 0.6027\tBottom_Loss: 0.6810\tLoss: 1.8900\t\n",
      "Subject: 006, n=11 | test_f1: 0.42105 |best_f1: 0.45\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3100\tTop_Loss: 0.4354\tBottom_Loss: 0.5283\tLoss: 1.2736\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6657\tTop_Loss: 0.5989\tBottom_Loss: 0.6689\tLoss: 1.9335\t\n",
      "Subject: 006, n=11 | test_f1: 0.25926 |best_f1: 0.45\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6279\tTop_Loss: 0.6935\tBottom_Loss: 0.8058\tLoss: 2.1271\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8369\tTop_Loss: 0.8086\tBottom_Loss: 0.7951\tLoss: 2.4406\t\n",
      "Subject: 006, n=11 | test_f1: 0.42105 |best_f1: 0.45\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4017\tTop_Loss: 0.4209\tBottom_Loss: 0.5170\tLoss: 1.3396\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5406\tTop_Loss: 0.6191\tBottom_Loss: 0.7718\tLoss: 1.9315\t\n",
      "Subject: 006, n=11 | test_f1: 0.25926 |best_f1: 0.45\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3639\tTop_Loss: 0.3626\tBottom_Loss: 0.4449\tLoss: 1.1714\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2812\tTop_Loss: 0.4302\tBottom_Loss: 0.5829\tLoss: 1.2942\t\n",
      "Subject: 006, n=11 | test_f1: 0.25926 |best_f1: 0.45\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.938\tLabel_Loss: 0.3474\tTop_Loss: 0.4941\tBottom_Loss: 0.5607\tLoss: 1.4021\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.688\tLabel_Loss: 0.5748\tTop_Loss: 0.7595\tBottom_Loss: 0.5326\tLoss: 1.8669\t\n",
      "Subject: 006, n=11 | test_f1: 0.42105 |best_f1: 0.45\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5238\tTop_Loss: 0.6608\tBottom_Loss: 0.6318\tLoss: 1.8163\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.688\tLabel_Loss: 0.5677\tTop_Loss: 0.7609\tBottom_Loss: 0.8004\tLoss: 2.1290\t\n",
      "Subject: 006, n=11 | test_f1: 0.25926 |best_f1: 0.45\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2926\tTop_Loss: 0.4234\tBottom_Loss: 0.4357\tLoss: 1.1517\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.750\tLabel_Loss: 0.4567\tTop_Loss: 0.4329\tBottom_Loss: 0.6849\tLoss: 1.5745\t\n",
      "Subject: 006, n=11 | test_f1: 0.42105 |best_f1: 0.45\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2173\tTop_Loss: 0.4113\tBottom_Loss: 0.3604\tLoss: 0.9890\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2697\tTop_Loss: 0.4317\tBottom_Loss: 0.4331\tLoss: 1.1345\t\n",
      "Subject: 006, n=11 | test_f1: 0.25926 |best_f1: 0.45\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2666\tTop_Loss: 0.3064\tBottom_Loss: 0.6665\tLoss: 1.2395\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3196\tTop_Loss: 0.4431\tBottom_Loss: 0.4438\tLoss: 1.2066\t\n",
      "Subject: 006, n=11 | test_f1: 0.38889 |best_f1: 0.45\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3204\tTop_Loss: 0.3725\tBottom_Loss: 0.4628\tLoss: 1.1557\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2390\tTop_Loss: 0.3098\tBottom_Loss: 0.4803\tLoss: 1.0291\t\n",
      "Subject: 006, n=11 | test_f1: 0.35294 |best_f1: 0.45\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4034\tTop_Loss: 0.4469\tBottom_Loss: 0.5759\tLoss: 1.4262\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3428\tTop_Loss: 0.3518\tBottom_Loss: 0.5048\tLoss: 1.1994\t\n",
      "Subject: 006, n=11 | test_f1: 0.38889 |best_f1: 0.45\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2362\tTop_Loss: 0.3888\tBottom_Loss: 0.4008\tLoss: 1.0257\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1888\tTop_Loss: 0.2985\tBottom_Loss: 0.2767\tLoss: 0.7641\t\n",
      "Subject: 006, n=11 | test_f1: 0.80702 |best_f1: 0.80702\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2535\tTop_Loss: 0.3970\tBottom_Loss: 0.4268\tLoss: 1.0774\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3504\tTop_Loss: 0.5599\tBottom_Loss: 0.4666\tLoss: 1.3770\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 006, n=11 | test_f1: 0.23529 |best_f1: 0.80702\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2778\tTop_Loss: 0.4302\tBottom_Loss: 0.4581\tLoss: 1.1661\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2297\tTop_Loss: 0.2833\tBottom_Loss: 0.4421\tLoss: 0.9552\t\n",
      "Subject: 006, n=11 | test_f1: 0.42105 |best_f1: 0.80702\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3106\tTop_Loss: 0.4212\tBottom_Loss: 0.4797\tLoss: 1.2116\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1453\tTop_Loss: 0.2348\tBottom_Loss: 0.2873\tLoss: 0.6674\t\n",
      "Subject: 006, n=11 | test_f1: 0.35294 |best_f1: 0.80702\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1990\tTop_Loss: 0.3552\tBottom_Loss: 0.2709\tLoss: 0.8251\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3264\tTop_Loss: 0.4251\tBottom_Loss: 0.5347\tLoss: 1.2861\t\n",
      "Subject: 006, n=11 | test_f1: 0.2807 |best_f1: 0.80702\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4011\tTop_Loss: 0.5832\tBottom_Loss: 0.3902\tLoss: 1.3745\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3378\tTop_Loss: 0.5249\tBottom_Loss: 0.3904\tLoss: 1.2531\t\n",
      "Subject: 006, n=11 | test_f1: 0.42105 |best_f1: 0.80702\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1811\tTop_Loss: 0.3946\tBottom_Loss: 0.4033\tLoss: 0.9790\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1570\tTop_Loss: 0.3105\tBottom_Loss: 0.3731\tLoss: 0.8406\t\n",
      "Subject: 006, n=11 | test_f1: 0.20833 |best_f1: 0.80702\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2639\tTop_Loss: 0.3760\tBottom_Loss: 0.3709\tLoss: 1.0108\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1693\tTop_Loss: 0.2440\tBottom_Loss: 0.2676\tLoss: 0.6809\t\n",
      "Subject: 006, n=11 | test_f1: 0.38889 |best_f1: 0.80702\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1419\tTop_Loss: 0.2654\tBottom_Loss: 0.2591\tLoss: 0.6664\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2800\tTop_Loss: 0.4305\tBottom_Loss: 0.4045\tLoss: 1.1150\t\n",
      "Subject: 006, n=11 | test_f1: 0.45 |best_f1: 0.80702\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0895\tTop_Loss: 0.2198\tBottom_Loss: 0.1471\tLoss: 0.4565\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2283\tTop_Loss: 0.4043\tBottom_Loss: 0.4125\tLoss: 1.0452\t\n",
      "Subject: 006, n=11 | test_f1: 0.38889 |best_f1: 0.80702\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0775\tTop_Loss: 0.1684\tBottom_Loss: 0.2918\tLoss: 0.5377\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3525\tTop_Loss: 0.4805\tBottom_Loss: 0.4408\tLoss: 1.2737\t\n",
      "Subject: 006, n=11 | test_f1: 0.31579 |best_f1: 0.80702\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2300\tTop_Loss: 0.2741\tBottom_Loss: 0.3463\tLoss: 0.8503\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2211\tTop_Loss: 0.4772\tBottom_Loss: 0.4746\tLoss: 1.1729\t\n",
      "Subject: 006, n=11 | test_f1: 0.42105 |best_f1: 0.80702\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2254\tTop_Loss: 0.6203\tBottom_Loss: 0.2472\tLoss: 1.0929\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3485\tTop_Loss: 0.3923\tBottom_Loss: 0.3366\tLoss: 1.0774\t\n",
      "Subject: 006, n=11 | test_f1: 0.35294 |best_f1: 0.80702\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2333\tTop_Loss: 0.2873\tBottom_Loss: 0.4029\tLoss: 0.9235\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1373\tTop_Loss: 0.3486\tBottom_Loss: 0.1835\tLoss: 0.6693\t\n",
      "Subject: 006, n=11 | test_f1: 0.42105 |best_f1: 0.80702\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1639\tTop_Loss: 0.3490\tBottom_Loss: 0.2629\tLoss: 0.7757\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1954\tTop_Loss: 0.2665\tBottom_Loss: 0.3733\tLoss: 0.8352\t\n",
      "Subject: 006, n=11 | test_f1: 0.42105 |best_f1: 0.80702\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2311\tTop_Loss: 0.4585\tBottom_Loss: 0.3268\tLoss: 1.0165\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1033\tTop_Loss: 0.2814\tBottom_Loss: 0.2328\tLoss: 0.6175\t\n",
      "Subject: 006, n=11 | test_f1: 0.45 |best_f1: 0.80702\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0799\tTop_Loss: 0.1624\tBottom_Loss: 0.1909\tLoss: 0.4332\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0969\tTop_Loss: 0.1375\tBottom_Loss: 0.2281\tLoss: 0.4626\t\n",
      "Subject: 006, n=11 | test_f1: 0.45 |best_f1: 0.80702\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1438\tTop_Loss: 0.2991\tBottom_Loss: 0.2525\tLoss: 0.6953\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1070\tTop_Loss: 0.2074\tBottom_Loss: 0.1842\tLoss: 0.4986\t\n",
      "Subject: 006, n=11 | test_f1: 0.45 |best_f1: 0.80702\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1792\tTop_Loss: 0.3985\tBottom_Loss: 0.2206\tLoss: 0.7983\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1810\tTop_Loss: 0.3295\tBottom_Loss: 0.3330\tLoss: 0.8435\t\n",
      "Subject: 006, n=11 | test_f1: 0.23529 |best_f1: 0.80702\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1102\tTop_Loss: 0.3211\tBottom_Loss: 0.1738\tLoss: 0.6052\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0794\tTop_Loss: 0.2204\tBottom_Loss: 0.1750\tLoss: 0.4748\t\n",
      "Subject: 006, n=11 | test_f1: 0.45 |best_f1: 0.80702\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0561\tTop_Loss: 0.1469\tBottom_Loss: 0.1226\tLoss: 0.3256\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0983\tTop_Loss: 0.2920\tBottom_Loss: 0.1744\tLoss: 0.5647\t\n",
      "Subject: 006, n=11 | test_f1: 0.45 |best_f1: 0.80702\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.844\tLabel_Loss: 0.2572\tTop_Loss: 0.3384\tBottom_Loss: 0.2606\tLoss: 0.8562\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0657\tTop_Loss: 0.2342\tBottom_Loss: 0.1369\tLoss: 0.4368\t\n",
      "Subject: 006, n=11 | test_f1: 0.25926 |best_f1: 0.80702\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0897\tTop_Loss: 0.3146\tBottom_Loss: 0.1279\tLoss: 0.5321\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2394\tTop_Loss: 0.2053\tBottom_Loss: 0.3073\tLoss: 0.7520\t\n",
      "Subject: 006, n=11 | test_f1: 0.2807 |best_f1: 0.80702\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0793\tTop_Loss: 0.1930\tBottom_Loss: 0.1559\tLoss: 0.4282\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0528\tTop_Loss: 0.1050\tBottom_Loss: 0.1854\tLoss: 0.3433\t\n",
      "Subject: 006, n=11 | test_f1: 0.25926 |best_f1: 0.80702\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0554\tTop_Loss: 0.1758\tBottom_Loss: 0.1331\tLoss: 0.3643\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0597\tTop_Loss: 0.1844\tBottom_Loss: 0.1517\tLoss: 0.3959\t\n",
      "Subject: 006, n=11 | test_f1: 0.42105 |best_f1: 0.80702\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0900\tTop_Loss: 0.2137\tBottom_Loss: 0.1606\tLoss: 0.4643\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1214\tTop_Loss: 0.1589\tBottom_Loss: 0.1586\tLoss: 0.4389\t\n",
      "Subject: 006, n=11 | test_f1: 0.45 |best_f1: 0.80702\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0798\tTop_Loss: 0.2284\tBottom_Loss: 0.2040\tLoss: 0.5122\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0219\tTop_Loss: 0.1116\tBottom_Loss: 0.1129\tLoss: 0.2464\t\n",
      "Subject: 006, n=11 | test_f1: 0.45 |best_f1: 0.80702\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1186\tTop_Loss: 0.2373\tBottom_Loss: 0.2026\tLoss: 0.5585\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0871\tTop_Loss: 0.1966\tBottom_Loss: 0.1516\tLoss: 0.4352\t\n",
      "Subject: 006, n=11 | test_f1: 0.42105 |best_f1: 0.80702\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0823\tTop_Loss: 0.1102\tBottom_Loss: 0.2300\tLoss: 0.4226\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0712\tTop_Loss: 0.1076\tBottom_Loss: 0.1447\tLoss: 0.3235\t\n",
      "Subject: 006, n=11 | test_f1: 0.2807 |best_f1: 0.80702\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1214\tTop_Loss: 0.2345\tBottom_Loss: 0.1629\tLoss: 0.5187\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0392\tTop_Loss: 0.1312\tBottom_Loss: 0.1020\tLoss: 0.2723\t\n",
      "Subject: 006, n=11 | test_f1: 0.42105 |best_f1: 0.80702\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0626\tTop_Loss: 0.1492\tBottom_Loss: 0.1572\tLoss: 0.3690\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0384\tTop_Loss: 0.1102\tBottom_Loss: 0.1142\tLoss: 0.2629\t\n",
      "Subject: 006, n=11 | test_f1: 0.45 |best_f1: 0.80702\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0168\tTop_Loss: 0.0858\tBottom_Loss: 0.0750\tLoss: 0.1776\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0622\tTop_Loss: 0.1420\tBottom_Loss: 0.1938\tLoss: 0.3979\t\n",
      "Subject: 006, n=11 | test_f1: 0.23529 |best_f1: 0.80702\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1284\tTop_Loss: 0.1163\tBottom_Loss: 0.2121\tLoss: 0.4568\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[61][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0784\tTop_Loss: 0.1507\tBottom_Loss: 0.1336\tLoss: 0.3627\t\n",
      "Subject: 006, n=11 | test_f1: 0.80702 |best_f1: 0.80702\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0601\tTop_Loss: 0.2049\tBottom_Loss: 0.0840\tLoss: 0.3489\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1622\tTop_Loss: 0.2025\tBottom_Loss: 0.2052\tLoss: 0.5700\t\n",
      "Subject: 006, n=11 | test_f1: 0.38889 |best_f1: 0.80702\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0321\tTop_Loss: 0.1106\tBottom_Loss: 0.1142\tLoss: 0.2569\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1315\tTop_Loss: 0.3579\tBottom_Loss: 0.1400\tLoss: 0.6295\t\n",
      "Subject: 006, n=11 | test_f1: 0.42105 |best_f1: 0.80702\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0521\tTop_Loss: 0.0977\tBottom_Loss: 0.1736\tLoss: 0.3234\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0605\tTop_Loss: 0.2321\tBottom_Loss: 0.1235\tLoss: 0.4162\t\n",
      "Subject: 006, n=11 | test_f1: 0.2807 |best_f1: 0.80702\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0731\tTop_Loss: 0.2463\tBottom_Loss: 0.0625\tLoss: 0.3820\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0410\tTop_Loss: 0.0888\tBottom_Loss: 0.0670\tLoss: 0.1968\t\n",
      "Subject: 006, n=11 | test_f1: 0.25926 |best_f1: 0.80702\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0738\tTop_Loss: 0.1097\tBottom_Loss: 0.1168\tLoss: 0.3002\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0500\tTop_Loss: 0.1137\tBottom_Loss: 0.1498\tLoss: 0.3135\t\n",
      "Subject: 006, n=11 | test_f1: 0.42105 |best_f1: 0.80702\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0728\tTop_Loss: 0.1941\tBottom_Loss: 0.0912\tLoss: 0.3581\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0797\tTop_Loss: 0.1492\tBottom_Loss: 0.1509\tLoss: 0.3798\t\n",
      "Subject: 006, n=11 | test_f1: 0.23529 |best_f1: 0.80702\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0571\tTop_Loss: 0.1137\tBottom_Loss: 0.1212\tLoss: 0.2920\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2038\tTop_Loss: 0.2410\tBottom_Loss: 0.2435\tLoss: 0.6883\t\n",
      "Subject: 006, n=11 | test_f1: 0.45 |best_f1: 0.80702\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0593\tTop_Loss: 0.1538\tBottom_Loss: 0.0817\tLoss: 0.2948\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0406\tTop_Loss: 0.0958\tBottom_Loss: 0.0554\tLoss: 0.1918\t\n",
      "Subject: 006, n=11 | test_f1: 0.42105 |best_f1: 0.80702\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0467\tTop_Loss: 0.1346\tBottom_Loss: 0.1115\tLoss: 0.2929\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0213\tTop_Loss: 0.0682\tBottom_Loss: 0.0835\tLoss: 0.1729\t\n",
      "Subject: 006, n=11 | test_f1: 0.45 |best_f1: 0.80702\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0470\tTop_Loss: 0.0997\tBottom_Loss: 0.1020\tLoss: 0.2487\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0342\tTop_Loss: 0.1533\tBottom_Loss: 0.0432\tLoss: 0.2307\t\n",
      "Subject: 006, n=11 | test_f1: 0.38889 |best_f1: 0.80702\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0214\tTop_Loss: 0.1044\tBottom_Loss: 0.0516\tLoss: 0.1774\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0439\tTop_Loss: 0.1044\tBottom_Loss: 0.0990\tLoss: 0.2473\t\n",
      "Subject: 006, n=11 | test_f1: 0.25926 |best_f1: 0.80702\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1298\tTop_Loss: 0.2202\tBottom_Loss: 0.1365\tLoss: 0.4865\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0735\tTop_Loss: 0.1056\tBottom_Loss: 0.1665\tLoss: 0.3456\t\n",
      "Subject: 006, n=11 | test_f1: 0.42105 |best_f1: 0.80702\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0214\tTop_Loss: 0.0737\tBottom_Loss: 0.0324\tLoss: 0.1275\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0249\tTop_Loss: 0.0818\tBottom_Loss: 0.0484\tLoss: 0.1550\t\n",
      "Subject: 006, n=11 | test_f1: 0.2807 |best_f1: 0.80702\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0265\tTop_Loss: 0.0660\tBottom_Loss: 0.1600\tLoss: 0.2525\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0140\tTop_Loss: 0.0394\tBottom_Loss: 0.0742\tLoss: 0.1275\t\n",
      "Subject: 006, n=11 | test_f1: 0.45 |best_f1: 0.80702\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0195\tTop_Loss: 0.0755\tBottom_Loss: 0.0783\tLoss: 0.1732\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0250\tTop_Loss: 0.0505\tBottom_Loss: 0.0703\tLoss: 0.1458\t\n",
      "Subject: 006, n=11 | test_f1: 0.23529 |best_f1: 0.80702\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0218\tTop_Loss: 0.1080\tBottom_Loss: 0.0972\tLoss: 0.2269\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0258\tTop_Loss: 0.0369\tBottom_Loss: 0.0721\tLoss: 0.1348\t\n",
      "Subject: 006, n=11 | test_f1: 0.45 |best_f1: 0.80702\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0790\tTop_Loss: 0.1303\tBottom_Loss: 0.0571\tLoss: 0.2664\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0118\tTop_Loss: 0.0676\tBottom_Loss: 0.0328\tLoss: 0.1122\t\n",
      "Subject: 006, n=11 | test_f1: 0.45 |best_f1: 0.80702\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0238\tTop_Loss: 0.1147\tBottom_Loss: 0.0951\tLoss: 0.2336\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0173\tTop_Loss: 0.0667\tBottom_Loss: 0.0796\tLoss: 0.1636\t\n",
      "Subject: 006, n=11 | test_f1: 0.45 |best_f1: 0.80702\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0155\tTop_Loss: 0.0369\tBottom_Loss: 0.0426\tLoss: 0.0950\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0312\tTop_Loss: 0.0426\tBottom_Loss: 0.0631\tLoss: 0.1370\t\n",
      "Subject: 006, n=11 | test_f1: 0.45 |best_f1: 0.80702\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0579\tTop_Loss: 0.0645\tBottom_Loss: 0.0861\tLoss: 0.2085\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0104\tTop_Loss: 0.0382\tBottom_Loss: 0.0469\tLoss: 0.0955\t\n",
      "Subject: 006, n=11 | test_f1: 0.42105 |best_f1: 0.80702\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0474\tTop_Loss: 0.1398\tBottom_Loss: 0.0761\tLoss: 0.2634\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0188\tTop_Loss: 0.0443\tBottom_Loss: 0.0288\tLoss: 0.0919\t\n",
      "Subject: 006, n=11 | test_f1: 0.2807 |best_f1: 0.80702\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0176\tTop_Loss: 0.0454\tBottom_Loss: 0.0596\tLoss: 0.1226\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0223\tTop_Loss: 0.0555\tBottom_Loss: 0.0521\tLoss: 0.1299\t\n",
      "Subject: 006, n=11 | test_f1: 0.42105 |best_f1: 0.80702\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0200\tTop_Loss: 0.0532\tBottom_Loss: 0.0657\tLoss: 0.1389\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0649\tTop_Loss: 0.0638\tBottom_Loss: 0.0928\tLoss: 0.2215\t\n",
      "Subject: 006, n=11 | test_f1: 0.2807 |best_f1: 0.80702\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0052\tTop_Loss: 0.0300\tBottom_Loss: 0.0374\tLoss: 0.0725\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0121\tTop_Loss: 0.0307\tBottom_Loss: 0.0510\tLoss: 0.0938\t\n",
      "Subject: 006, n=11 | test_f1: 0.38889 |best_f1: 0.80702\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0054\tTop_Loss: 0.0250\tBottom_Loss: 0.0216\tLoss: 0.0521\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0130\tTop_Loss: 0.0470\tBottom_Loss: 0.0495\tLoss: 0.1095\t\n",
      "Subject: 006, n=11 | test_f1: 0.45 |best_f1: 0.80702\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0148\tTop_Loss: 0.0443\tBottom_Loss: 0.0533\tLoss: 0.1125\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0120\tTop_Loss: 0.0555\tBottom_Loss: 0.0367\tLoss: 0.1042\t\n",
      "Subject: 006, n=11 | test_f1: 0.42105 |best_f1: 0.80702\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0301\tTop_Loss: 0.0421\tBottom_Loss: 0.0693\tLoss: 0.1415\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0069\tTop_Loss: 0.0557\tBottom_Loss: 0.0409\tLoss: 0.1034\t\n",
      "Subject: 006, n=11 | test_f1: 0.2807 |best_f1: 0.80702\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0548\tTop_Loss: 0.1813\tBottom_Loss: 0.0352\tLoss: 0.2713\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0083\tTop_Loss: 0.0282\tBottom_Loss: 0.0912\tLoss: 0.1278\t\n",
      "Subject: 006, n=11 | test_f1: 0.2807 |best_f1: 0.80702\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0065\tTop_Loss: 0.0361\tBottom_Loss: 0.0407\tLoss: 0.0833\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0334\tTop_Loss: 0.1275\tBottom_Loss: 0.0697\tLoss: 0.2306\t\n",
      "Subject: 006, n=11 | test_f1: 0.20833 |best_f1: 0.80702\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0087\tTop_Loss: 0.0281\tBottom_Loss: 0.0233\tLoss: 0.0601\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0156\tTop_Loss: 0.0465\tBottom_Loss: 0.0737\tLoss: 0.1358\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 006, n=11 | test_f1: 0.2807 |best_f1: 0.80702\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0148\tTop_Loss: 0.0516\tBottom_Loss: 0.0355\tLoss: 0.1019\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0331\tTop_Loss: 0.0513\tBottom_Loss: 0.1401\tLoss: 0.2245\t\n",
      "Subject: 006, n=11 | test_f1: 0.42105 |best_f1: 0.80702\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0041\tTop_Loss: 0.0183\tBottom_Loss: 0.0207\tLoss: 0.0431\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0066\tTop_Loss: 0.0207\tBottom_Loss: 0.0336\tLoss: 0.0609\t\n",
      "Subject: 006, n=11 | test_f1: 0.45 |best_f1: 0.80702\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0099\tTop_Loss: 0.0272\tBottom_Loss: 0.0254\tLoss: 0.0626\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0056\tTop_Loss: 0.0260\tBottom_Loss: 0.0315\tLoss: 0.0631\t\n",
      "Subject: 006, n=11 | test_f1: 0.2807 |best_f1: 0.80702\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0317\tTop_Loss: 0.0893\tBottom_Loss: 0.0519\tLoss: 0.1729\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0040\tTop_Loss: 0.0174\tBottom_Loss: 0.0142\tLoss: 0.0355\t\n",
      "Subject: 006, n=11 | test_f1: 0.38889 |best_f1: 0.80702\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0052\tTop_Loss: 0.0220\tBottom_Loss: 0.0212\tLoss: 0.0484\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0046\tTop_Loss: 0.0175\tBottom_Loss: 0.0293\tLoss: 0.0514\t\n",
      "Subject: 006, n=11 | test_f1: 0.42105 |best_f1: 0.80702\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0076\tTop_Loss: 0.0434\tBottom_Loss: 0.0495\tLoss: 0.1006\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0036\tTop_Loss: 0.0132\tBottom_Loss: 0.0217\tLoss: 0.0385\t\n",
      "Subject: 006, n=11 | test_f1: 0.42105 |best_f1: 0.80702\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0057\tTop_Loss: 0.0373\tBottom_Loss: 0.0295\tLoss: 0.0726\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0106\tTop_Loss: 0.0225\tBottom_Loss: 0.0247\tLoss: 0.0577\t\n",
      "Subject: 006, n=11 | test_f1: 0.25926 |best_f1: 0.80702\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0217\tTop_Loss: 0.0740\tBottom_Loss: 0.0149\tLoss: 0.1107\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0041\tTop_Loss: 0.0134\tBottom_Loss: 0.0433\tLoss: 0.0608\t\n",
      "Subject: 006, n=11 | test_f1: 0.45 |best_f1: 0.80702\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.344\tLabel_Loss: 1.2607\tTop_Loss: 1.7724\tBottom_Loss: 2.3025\tLoss: 5.3357\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.562\tLabel_Loss: 0.9824\tTop_Loss: 1.0336\tBottom_Loss: 1.2643\tLoss: 3.2802\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.074074\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.438\tLabel_Loss: 1.0457\tTop_Loss: 1.0931\tBottom_Loss: 1.1516\tLoss: 3.2904\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.656\tLabel_Loss: 0.8520\tTop_Loss: 0.8182\tBottom_Loss: 0.7888\tLoss: 2.4590\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.074074\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.531\tLabel_Loss: 0.9679\tTop_Loss: 0.8649\tBottom_Loss: 1.0454\tLoss: 2.8782\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.469\tLabel_Loss: 1.0452\tTop_Loss: 0.8519\tBottom_Loss: 0.9087\tLoss: 2.8057\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.074074\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6866\tTop_Loss: 0.7702\tBottom_Loss: 0.7515\tLoss: 2.2083\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7687\tTop_Loss: 0.8338\tBottom_Loss: 0.9181\tLoss: 2.5205\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.074074\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7692\tTop_Loss: 0.7673\tBottom_Loss: 0.7836\tLoss: 2.3201\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.469\tLabel_Loss: 1.1861\tTop_Loss: 1.2300\tBottom_Loss: 1.2068\tLoss: 3.6230\t\n",
      "Subject: 007, n=08 | test_f1: 0.0 |best_f1: 0.074074\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7701\tTop_Loss: 0.7678\tBottom_Loss: 0.9950\tLoss: 2.5329\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.594\tLabel_Loss: 0.9080\tTop_Loss: 0.8642\tBottom_Loss: 1.0507\tLoss: 2.8229\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.074074\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7965\tTop_Loss: 0.7884\tBottom_Loss: 0.8354\tLoss: 2.4203\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.656\tLabel_Loss: 0.8324\tTop_Loss: 0.8864\tBottom_Loss: 1.0300\tLoss: 2.7488\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.074074\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8991\tTop_Loss: 0.9686\tBottom_Loss: 0.8357\tLoss: 2.7034\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.594\tLabel_Loss: 0.7966\tTop_Loss: 0.7557\tBottom_Loss: 1.0868\tLoss: 2.6390\t\n",
      "Subject: 007, n=08 | test_f1: 0.0 |best_f1: 0.074074\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.562\tLabel_Loss: 0.8662\tTop_Loss: 0.7704\tBottom_Loss: 0.8425\tLoss: 2.4791\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8301\tTop_Loss: 0.7792\tBottom_Loss: 0.8044\tLoss: 2.4137\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.074074\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.500\tLabel_Loss: 1.0837\tTop_Loss: 1.1862\tBottom_Loss: 0.9387\tLoss: 3.2086\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7543\tTop_Loss: 0.8196\tBottom_Loss: 0.7867\tLoss: 2.3605\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.074074\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7456\tTop_Loss: 0.6694\tBottom_Loss: 0.7711\tLoss: 2.1860\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6369\tTop_Loss: 0.7692\tBottom_Loss: 0.6861\tLoss: 2.0923\t\n",
      "Subject: 007, n=08 | test_f1: 0.083333 |best_f1: 0.083333\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6675\tTop_Loss: 0.8708\tBottom_Loss: 0.6997\tLoss: 2.2380\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.594\tLabel_Loss: 0.7792\tTop_Loss: 0.8511\tBottom_Loss: 0.8502\tLoss: 2.4806\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.083333\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6516\tTop_Loss: 0.7373\tBottom_Loss: 0.7392\tLoss: 2.1282\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.688\tLabel_Loss: 0.8266\tTop_Loss: 0.7568\tBottom_Loss: 0.8983\tLoss: 2.4817\t\n",
      "Subject: 007, n=08 | test_f1: 0.0 |best_f1: 0.083333\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.656\tLabel_Loss: 0.6817\tTop_Loss: 0.8139\tBottom_Loss: 0.7298\tLoss: 2.2253\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.656\tLabel_Loss: 0.8771\tTop_Loss: 0.9104\tBottom_Loss: 0.9542\tLoss: 2.7418\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.083333\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5799\tTop_Loss: 0.8036\tBottom_Loss: 0.6764\tLoss: 2.0598\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.500\tLabel_Loss: 0.8537\tTop_Loss: 0.8714\tBottom_Loss: 0.9649\tLoss: 2.6900\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.083333\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.875\tLabel_Loss: 0.5009\tTop_Loss: 0.6109\tBottom_Loss: 0.7136\tLoss: 1.8253\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.719\tLabel_Loss: 0.7162\tTop_Loss: 0.7357\tBottom_Loss: 0.8410\tLoss: 2.2929\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.083333\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4847\tTop_Loss: 0.5109\tBottom_Loss: 0.5932\tLoss: 1.5889\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4463\tTop_Loss: 0.6032\tBottom_Loss: 0.3958\tLoss: 1.4453\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.083333\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5944\tTop_Loss: 0.7134\tBottom_Loss: 0.6951\tLoss: 2.0030\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4287\tTop_Loss: 0.5927\tBottom_Loss: 0.5069\tLoss: 1.5283\t\n",
      "Subject: 007, n=08 | test_f1: 0.0 |best_f1: 0.083333\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5503\tTop_Loss: 0.5561\tBottom_Loss: 0.7609\tLoss: 1.8673\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4497\tTop_Loss: 0.5803\tBottom_Loss: 0.5545\tLoss: 1.5845\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.083333\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6060\tTop_Loss: 0.5975\tBottom_Loss: 0.7494\tLoss: 1.9528\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5415\tTop_Loss: 0.6551\tBottom_Loss: 0.6422\tLoss: 1.8389\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.083333\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4515\tTop_Loss: 0.5090\tBottom_Loss: 0.6763\tLoss: 1.6368\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7334\tTop_Loss: 0.5938\tBottom_Loss: 0.6348\tLoss: 1.9620\t\n",
      "Subject: 007, n=08 | test_f1: 0.0 |best_f1: 0.083333\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3916\tTop_Loss: 0.4506\tBottom_Loss: 0.6479\tLoss: 1.4901\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4288\tTop_Loss: 0.6644\tBottom_Loss: 0.4796\tLoss: 1.5728\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.083333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5307\tTop_Loss: 0.7197\tBottom_Loss: 0.6064\tLoss: 1.8567\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6500\tTop_Loss: 0.6397\tBottom_Loss: 0.6108\tLoss: 1.9005\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.083333\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4472\tTop_Loss: 0.5538\tBottom_Loss: 0.5313\tLoss: 1.5323\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3749\tTop_Loss: 0.4907\tBottom_Loss: 0.5432\tLoss: 1.4088\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.083333\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7499\tTop_Loss: 0.8119\tBottom_Loss: 0.6707\tLoss: 2.2325\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4237\tTop_Loss: 0.4394\tBottom_Loss: 0.4810\tLoss: 1.3440\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.083333\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5028\tTop_Loss: 0.6390\tBottom_Loss: 0.5579\tLoss: 1.6997\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3873\tTop_Loss: 0.6293\tBottom_Loss: 0.4943\tLoss: 1.5109\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.083333\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2851\tTop_Loss: 0.4756\tBottom_Loss: 0.3911\tLoss: 1.1518\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2713\tTop_Loss: 0.5019\tBottom_Loss: 0.5401\tLoss: 1.3132\t\n",
      "Subject: 007, n=08 | test_f1: 0.0 |best_f1: 0.083333\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3380\tTop_Loss: 0.5272\tBottom_Loss: 0.4236\tLoss: 1.2888\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.844\tLabel_Loss: 0.2601\tTop_Loss: 0.3158\tBottom_Loss: 0.4410\tLoss: 1.0168\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.083333\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3540\tTop_Loss: 0.4987\tBottom_Loss: 0.3961\tLoss: 1.2487\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2708\tTop_Loss: 0.5290\tBottom_Loss: 0.2715\tLoss: 1.0713\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.083333\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5633\tTop_Loss: 0.6180\tBottom_Loss: 0.8324\tLoss: 2.0137\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3738\tTop_Loss: 0.3617\tBottom_Loss: 0.5129\tLoss: 1.2484\t\n",
      "Subject: 007, n=08 | test_f1: 0.11111 |best_f1: 0.11111\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3283\tTop_Loss: 0.5764\tBottom_Loss: 0.3885\tLoss: 1.2932\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2227\tTop_Loss: 0.3374\tBottom_Loss: 0.3533\tLoss: 0.9135\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.11111\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1738\tTop_Loss: 0.5535\tBottom_Loss: 0.3758\tLoss: 1.1031\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3279\tTop_Loss: 0.5483\tBottom_Loss: 0.5909\tLoss: 1.4671\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.11111\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4158\tTop_Loss: 0.5715\tBottom_Loss: 0.6882\tLoss: 1.6754\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1882\tTop_Loss: 0.3417\tBottom_Loss: 0.3664\tLoss: 0.8963\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.11111\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3932\tTop_Loss: 0.6260\tBottom_Loss: 0.5374\tLoss: 1.5566\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1346\tTop_Loss: 0.3613\tBottom_Loss: 0.2331\tLoss: 0.7290\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.11111\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1205\tTop_Loss: 0.2054\tBottom_Loss: 0.3258\tLoss: 0.6518\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3660\tTop_Loss: 0.4816\tBottom_Loss: 0.3264\tLoss: 1.1740\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.11111\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2503\tTop_Loss: 0.3748\tBottom_Loss: 0.3298\tLoss: 0.9549\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2240\tTop_Loss: 0.4645\tBottom_Loss: 0.2469\tLoss: 0.9354\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.11111\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3177\tTop_Loss: 0.4710\tBottom_Loss: 0.3436\tLoss: 1.1323\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2934\tTop_Loss: 0.5000\tBottom_Loss: 0.4807\tLoss: 1.2742\t\n",
      "Subject: 007, n=08 | test_f1: 0.19444 |best_f1: 0.19444\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1522\tTop_Loss: 0.2589\tBottom_Loss: 0.3107\tLoss: 0.7218\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2458\tTop_Loss: 0.4052\tBottom_Loss: 0.2575\tLoss: 0.9085\t\n",
      "Subject: 007, n=08 | test_f1: 0.0 |best_f1: 0.19444\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1951\tTop_Loss: 0.3648\tBottom_Loss: 0.2438\tLoss: 0.8037\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1663\tTop_Loss: 0.2560\tBottom_Loss: 0.2915\tLoss: 0.7138\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1651\tTop_Loss: 0.4282\tBottom_Loss: 0.2260\tLoss: 0.8193\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2513\tTop_Loss: 0.4441\tBottom_Loss: 0.3167\tLoss: 1.0122\t\n",
      "Subject: 007, n=08 | test_f1: 0.0 |best_f1: 0.19444\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1446\tTop_Loss: 0.4239\tBottom_Loss: 0.1802\tLoss: 0.7487\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1696\tTop_Loss: 0.5498\tBottom_Loss: 0.1777\tLoss: 0.8971\t\n",
      "Subject: 007, n=08 | test_f1: 0.0 |best_f1: 0.19444\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1855\tTop_Loss: 0.3574\tBottom_Loss: 0.2634\tLoss: 0.8063\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1232\tTop_Loss: 0.3032\tBottom_Loss: 0.1747\tLoss: 0.6010\t\n",
      "Subject: 007, n=08 | test_f1: 0.0 |best_f1: 0.19444\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1572\tTop_Loss: 0.3320\tBottom_Loss: 0.2001\tLoss: 0.6893\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1951\tTop_Loss: 0.3886\tBottom_Loss: 0.3119\tLoss: 0.8956\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1370\tTop_Loss: 0.2942\tBottom_Loss: 0.1571\tLoss: 0.5884\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1811\tTop_Loss: 0.3373\tBottom_Loss: 0.2589\tLoss: 0.7773\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2217\tTop_Loss: 0.2944\tBottom_Loss: 0.2831\tLoss: 0.7992\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2423\tTop_Loss: 0.4776\tBottom_Loss: 0.3578\tLoss: 1.0778\t\n",
      "Subject: 007, n=08 | test_f1: 0.0 |best_f1: 0.19444\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1132\tTop_Loss: 0.2233\tBottom_Loss: 0.2141\tLoss: 0.5505\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1953\tTop_Loss: 0.3175\tBottom_Loss: 0.3084\tLoss: 0.8212\t\n",
      "Subject: 007, n=08 | test_f1: 0.0 |best_f1: 0.19444\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1643\tTop_Loss: 0.3808\tBottom_Loss: 0.2966\tLoss: 0.8417\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1528\tTop_Loss: 0.3282\tBottom_Loss: 0.1754\tLoss: 0.6565\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1036\tTop_Loss: 0.3470\tBottom_Loss: 0.1214\tLoss: 0.5720\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1148\tTop_Loss: 0.2995\tBottom_Loss: 0.2087\tLoss: 0.6229\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1721\tTop_Loss: 0.2658\tBottom_Loss: 0.2592\tLoss: 0.6971\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0873\tTop_Loss: 0.2211\tBottom_Loss: 0.1687\tLoss: 0.4771\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1940\tTop_Loss: 0.3417\tBottom_Loss: 0.2960\tLoss: 0.8317\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0648\tTop_Loss: 0.1881\tBottom_Loss: 0.1361\tLoss: 0.3890\t\n",
      "Subject: 007, n=08 | test_f1: 0.0 |best_f1: 0.19444\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1047\tTop_Loss: 0.2589\tBottom_Loss: 0.1711\tLoss: 0.5347\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1296\tTop_Loss: 0.4063\tBottom_Loss: 0.1698\tLoss: 0.7057\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1097\tTop_Loss: 0.2419\tBottom_Loss: 0.2638\tLoss: 0.6154\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1240\tTop_Loss: 0.2856\tBottom_Loss: 0.1336\tLoss: 0.5432\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0747\tTop_Loss: 0.2772\tBottom_Loss: 0.1164\tLoss: 0.4683\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2548\tTop_Loss: 0.4666\tBottom_Loss: 0.2136\tLoss: 0.9350\t\n",
      "Subject: 007, n=08 | test_f1: 0.0 |best_f1: 0.19444\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0516\tTop_Loss: 0.1856\tBottom_Loss: 0.1043\tLoss: 0.3415\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0991\tTop_Loss: 0.2340\tBottom_Loss: 0.1350\tLoss: 0.4681\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0713\tTop_Loss: 0.2906\tBottom_Loss: 0.1711\tLoss: 0.5330\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0511\tTop_Loss: 0.1878\tBottom_Loss: 0.1170\tLoss: 0.3558\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0558\tTop_Loss: 0.1462\tBottom_Loss: 0.1086\tLoss: 0.3106\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0319\tTop_Loss: 0.1974\tBottom_Loss: 0.0944\tLoss: 0.3237\t\n",
      "Subject: 007, n=08 | test_f1: 0.19444 |best_f1: 0.19444\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1306\tTop_Loss: 0.2202\tBottom_Loss: 0.1645\tLoss: 0.5153\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0624\tTop_Loss: 0.2388\tBottom_Loss: 0.0862\tLoss: 0.3874\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0824\tTop_Loss: 0.2017\tBottom_Loss: 0.1159\tLoss: 0.4000\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0766\tTop_Loss: 0.2110\tBottom_Loss: 0.0606\tLoss: 0.3482\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1484\tTop_Loss: 0.2494\tBottom_Loss: 0.1867\tLoss: 0.5846\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0382\tTop_Loss: 0.1455\tBottom_Loss: 0.0639\tLoss: 0.2475\t\n",
      "Subject: 007, n=08 | test_f1: 0.0 |best_f1: 0.19444\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1320\tTop_Loss: 0.1661\tBottom_Loss: 0.1486\tLoss: 0.4467\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0307\tTop_Loss: 0.2189\tBottom_Loss: 0.0993\tLoss: 0.3489\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 0.938\tLabel_Loss: 0.0918\tTop_Loss: 0.1620\tBottom_Loss: 0.1060\tLoss: 0.3599\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0384\tTop_Loss: 0.1868\tBottom_Loss: 0.0563\tLoss: 0.2815\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0620\tTop_Loss: 0.2697\tBottom_Loss: 0.1000\tLoss: 0.4317\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0267\tTop_Loss: 0.1006\tBottom_Loss: 0.0784\tLoss: 0.2057\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0281\tTop_Loss: 0.1480\tBottom_Loss: 0.0760\tLoss: 0.2521\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0501\tTop_Loss: 0.1798\tBottom_Loss: 0.0589\tLoss: 0.2889\t\n",
      "Subject: 007, n=08 | test_f1: 0.0 |best_f1: 0.19444\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0319\tTop_Loss: 0.1858\tBottom_Loss: 0.0891\tLoss: 0.3069\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0612\tTop_Loss: 0.2514\tBottom_Loss: 0.1347\tLoss: 0.4473\t\n",
      "Subject: 007, n=08 | test_f1: 0.0 |best_f1: 0.19444\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0186\tTop_Loss: 0.0380\tBottom_Loss: 0.0641\tLoss: 0.1207\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0248\tTop_Loss: 0.1372\tBottom_Loss: 0.0498\tLoss: 0.2118\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0569\tTop_Loss: 0.1079\tBottom_Loss: 0.1265\tLoss: 0.2913\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1009\tTop_Loss: 0.2688\tBottom_Loss: 0.1445\tLoss: 0.5142\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0203\tTop_Loss: 0.0719\tBottom_Loss: 0.0592\tLoss: 0.1514\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0430\tTop_Loss: 0.1764\tBottom_Loss: 0.0696\tLoss: 0.2890\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0482\tTop_Loss: 0.1450\tBottom_Loss: 0.0634\tLoss: 0.2567\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0157\tTop_Loss: 0.1002\tBottom_Loss: 0.0380\tLoss: 0.1539\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0190\tTop_Loss: 0.0729\tBottom_Loss: 0.0758\tLoss: 0.1677\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0127\tTop_Loss: 0.0524\tBottom_Loss: 0.0421\tLoss: 0.1072\t\n",
      "Subject: 007, n=08 | test_f1: 0.0 |best_f1: 0.19444\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0200\tTop_Loss: 0.0846\tBottom_Loss: 0.0667\tLoss: 0.1713\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0304\tTop_Loss: 0.1077\tBottom_Loss: 0.1369\tLoss: 0.2750\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0153\tTop_Loss: 0.0836\tBottom_Loss: 0.0553\tLoss: 0.1542\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1040\tTop_Loss: 0.2192\tBottom_Loss: 0.2402\tLoss: 0.5634\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0758\tTop_Loss: 0.1565\tBottom_Loss: 0.1818\tLoss: 0.4141\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0235\tTop_Loss: 0.1047\tBottom_Loss: 0.0384\tLoss: 0.1666\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0411\tTop_Loss: 0.0858\tBottom_Loss: 0.0634\tLoss: 0.1903\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0424\tTop_Loss: 0.0807\tBottom_Loss: 0.1131\tLoss: 0.2362\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0321\tTop_Loss: 0.1004\tBottom_Loss: 0.0465\tLoss: 0.1789\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0150\tTop_Loss: 0.0956\tBottom_Loss: 0.0585\tLoss: 0.1691\t\n",
      "Subject: 007, n=08 | test_f1: 0.0 |best_f1: 0.19444\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 0.938\tLabel_Loss: 0.0800\tTop_Loss: 0.1135\tBottom_Loss: 0.1127\tLoss: 0.3063\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0424\tTop_Loss: 0.1137\tBottom_Loss: 0.0444\tLoss: 0.2004\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0149\tTop_Loss: 0.1304\tBottom_Loss: 0.0383\tLoss: 0.1837\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0151\tTop_Loss: 0.0417\tBottom_Loss: 0.1005\tLoss: 0.1574\t\n",
      "Subject: 007, n=08 | test_f1: 0.0 |best_f1: 0.19444\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0565\tTop_Loss: 0.1037\tBottom_Loss: 0.1514\tLoss: 0.3117\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0956\tTop_Loss: 0.1677\tBottom_Loss: 0.0635\tLoss: 0.3268\t\n",
      "Subject: 007, n=08 | test_f1: 0.0 |best_f1: 0.19444\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0457\tTop_Loss: 0.1171\tBottom_Loss: 0.0832\tLoss: 0.2460\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0137\tTop_Loss: 0.0910\tBottom_Loss: 0.0209\tLoss: 0.1256\t\n",
      "Subject: 007, n=08 | test_f1: 0.0 |best_f1: 0.19444\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0359\tTop_Loss: 0.1020\tBottom_Loss: 0.0736\tLoss: 0.2115\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0223\tTop_Loss: 0.1067\tBottom_Loss: 0.0814\tLoss: 0.2104\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0176\tTop_Loss: 0.1000\tBottom_Loss: 0.0948\tLoss: 0.2125\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0198\tTop_Loss: 0.1074\tBottom_Loss: 0.0584\tLoss: 0.1856\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0233\tTop_Loss: 0.0915\tBottom_Loss: 0.0645\tLoss: 0.1793\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0175\tTop_Loss: 0.0462\tBottom_Loss: 0.0373\tLoss: 0.1011\t\n",
      "Subject: 007, n=08 | test_f1: 0.19444 |best_f1: 0.19444\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0113\tTop_Loss: 0.1133\tBottom_Loss: 0.0225\tLoss: 0.1471\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0382\tTop_Loss: 0.1113\tBottom_Loss: 0.0632\tLoss: 0.2126\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0103\tTop_Loss: 0.0936\tBottom_Loss: 0.0452\tLoss: 0.1492\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0105\tTop_Loss: 0.0469\tBottom_Loss: 0.0313\tLoss: 0.0887\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0349\tTop_Loss: 0.0728\tBottom_Loss: 0.0572\tLoss: 0.1649\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0264\tTop_Loss: 0.0401\tBottom_Loss: 0.0530\tLoss: 0.1195\t\n",
      "Subject: 007, n=08 | test_f1: 0.0 |best_f1: 0.19444\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0106\tTop_Loss: 0.0361\tBottom_Loss: 0.0628\tLoss: 0.1095\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0178\tTop_Loss: 0.0396\tBottom_Loss: 0.0290\tLoss: 0.0865\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0174\tTop_Loss: 0.0916\tBottom_Loss: 0.0639\tLoss: 0.1729\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0686\tTop_Loss: 0.1504\tBottom_Loss: 0.1621\tLoss: 0.3812\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0172\tTop_Loss: 0.0200\tBottom_Loss: 0.0273\tLoss: 0.0645\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0330\tTop_Loss: 0.1582\tBottom_Loss: 0.0339\tLoss: 0.2251\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0067\tTop_Loss: 0.0896\tBottom_Loss: 0.0197\tLoss: 0.1160\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0414\tTop_Loss: 0.0861\tBottom_Loss: 0.1414\tLoss: 0.2689\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0264\tTop_Loss: 0.0882\tBottom_Loss: 0.0668\tLoss: 0.1814\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0085\tTop_Loss: 0.0288\tBottom_Loss: 0.0333\tLoss: 0.0705\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0203\tTop_Loss: 0.0454\tBottom_Loss: 0.0276\tLoss: 0.0933\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0120\tTop_Loss: 0.0520\tBottom_Loss: 0.0365\tLoss: 0.1006\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0075\tTop_Loss: 0.0771\tBottom_Loss: 0.0343\tLoss: 0.1189\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0429\tTop_Loss: 0.0875\tBottom_Loss: 0.1271\tLoss: 0.2575\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0093\tTop_Loss: 0.0759\tBottom_Loss: 0.0176\tLoss: 0.1028\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0249\tTop_Loss: 0.0667\tBottom_Loss: 0.0338\tLoss: 0.1254\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0217\tTop_Loss: 0.1261\tBottom_Loss: 0.0181\tLoss: 0.1658\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0141\tTop_Loss: 0.0484\tBottom_Loss: 0.0335\tLoss: 0.0961\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0133\tTop_Loss: 0.1130\tBottom_Loss: 0.0121\tLoss: 0.1383\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0173\tTop_Loss: 0.1456\tBottom_Loss: 0.0472\tLoss: 0.2100\t\n",
      "Subject: 007, n=08 | test_f1: 0.083333 |best_f1: 0.19444\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0084\tTop_Loss: 0.0209\tBottom_Loss: 0.0168\tLoss: 0.0460\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0265\tTop_Loss: 0.0908\tBottom_Loss: 0.0673\tLoss: 0.1847\t\n",
      "Subject: 007, n=08 | test_f1: 0.0 |best_f1: 0.19444\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0051\tTop_Loss: 0.0534\tBottom_Loss: 0.0198\tLoss: 0.0783\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0185\tTop_Loss: 0.0624\tBottom_Loss: 0.0324\tLoss: 0.1132\t\n",
      "Subject: 007, n=08 | test_f1: 0.0 |best_f1: 0.19444\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0058\tTop_Loss: 0.0500\tBottom_Loss: 0.0210\tLoss: 0.0768\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0311\tTop_Loss: 0.0562\tBottom_Loss: 0.1349\tLoss: 0.2222\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0036\tTop_Loss: 0.0233\tBottom_Loss: 0.0168\tLoss: 0.0437\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0074\tTop_Loss: 0.0437\tBottom_Loss: 0.0129\tLoss: 0.0640\t\n",
      "Subject: 007, n=08 | test_f1: 0.0 |best_f1: 0.19444\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0179\tTop_Loss: 0.0452\tBottom_Loss: 0.0370\tLoss: 0.1000\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0173\tTop_Loss: 0.0490\tBottom_Loss: 0.0553\tLoss: 0.1216\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0042\tTop_Loss: 0.0151\tBottom_Loss: 0.0342\tLoss: 0.0535\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0130\tTop_Loss: 0.0503\tBottom_Loss: 0.0424\tLoss: 0.1058\t\n",
      "Subject: 007, n=08 | test_f1: 0.074074 |best_f1: 0.19444\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.250\tLabel_Loss: 1.6486\tTop_Loss: 1.5266\tBottom_Loss: 1.1104\tLoss: 4.2856\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.562\tLabel_Loss: 1.0513\tTop_Loss: 1.0937\tBottom_Loss: 1.0241\tLoss: 3.1691\t\n",
      "Subject: 009, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.594\tLabel_Loss: 1.0533\tTop_Loss: 1.0826\tBottom_Loss: 1.0840\tLoss: 3.2199\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8386\tTop_Loss: 0.9496\tBottom_Loss: 1.0173\tLoss: 2.8055\t\n",
      "Subject: 009, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.500\tLabel_Loss: 0.9178\tTop_Loss: 0.8675\tBottom_Loss: 1.0373\tLoss: 2.8226\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.531\tLabel_Loss: 0.9657\tTop_Loss: 1.1409\tBottom_Loss: 0.9770\tLoss: 3.0836\t\n",
      "Subject: 009, n=04 | test_f1: 0.22222 |best_f1: 0.42857\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.438\tLabel_Loss: 1.0386\tTop_Loss: 0.8908\tBottom_Loss: 0.9874\tLoss: 2.9168\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7817\tTop_Loss: 0.7894\tBottom_Loss: 0.8387\tLoss: 2.4098\t\n",
      "Subject: 009, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.438\tLabel_Loss: 1.2284\tTop_Loss: 1.1426\tBottom_Loss: 0.9910\tLoss: 3.3620\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.562\tLabel_Loss: 0.8948\tTop_Loss: 1.0080\tBottom_Loss: 0.9080\tLoss: 2.8108\t\n",
      "Subject: 009, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8641\tTop_Loss: 0.7786\tBottom_Loss: 0.9205\tLoss: 2.5632\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.500\tLabel_Loss: 1.0758\tTop_Loss: 0.9395\tBottom_Loss: 1.0181\tLoss: 3.0334\t\n",
      "Subject: 009, n=04 | test_f1: 0.22222 |best_f1: 0.42857\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.469\tLabel_Loss: 0.9295\tTop_Loss: 0.9708\tBottom_Loss: 0.8268\tLoss: 2.7270\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6376\tTop_Loss: 0.7976\tBottom_Loss: 0.6038\tLoss: 2.0391\t\n",
      "Subject: 009, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.688\tLabel_Loss: 0.8304\tTop_Loss: 0.9425\tBottom_Loss: 0.7878\tLoss: 2.5607\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.562\tLabel_Loss: 0.9850\tTop_Loss: 1.0175\tBottom_Loss: 0.9493\tLoss: 2.9517\t\n",
      "Subject: 009, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.500\tLabel_Loss: 0.8788\tTop_Loss: 0.8041\tBottom_Loss: 0.8449\tLoss: 2.5278\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.562\tLabel_Loss: 0.8818\tTop_Loss: 0.7778\tBottom_Loss: 0.7372\tLoss: 2.3967\t\n",
      "Subject: 009, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7338\tTop_Loss: 0.8478\tBottom_Loss: 0.7453\tLoss: 2.3269\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5976\tTop_Loss: 0.7384\tBottom_Loss: 0.6681\tLoss: 2.0041\t\n",
      "Subject: 009, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.531\tLabel_Loss: 0.7592\tTop_Loss: 0.8778\tBottom_Loss: 0.8979\tLoss: 2.5349\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5991\tTop_Loss: 0.7187\tBottom_Loss: 0.8331\tLoss: 2.1509\t\n",
      "Subject: 009, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8872\tTop_Loss: 0.9719\tBottom_Loss: 0.7811\tLoss: 2.6403\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7107\tTop_Loss: 0.8817\tBottom_Loss: 0.7201\tLoss: 2.3125\t\n",
      "Subject: 009, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8675\tTop_Loss: 0.8009\tBottom_Loss: 0.8666\tLoss: 2.5349\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.906\tLabel_Loss: 0.4500\tTop_Loss: 0.5458\tBottom_Loss: 0.6132\tLoss: 1.6089\t\n",
      "Subject: 009, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7053\tTop_Loss: 0.8259\tBottom_Loss: 0.8049\tLoss: 2.3361\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4730\tTop_Loss: 0.5806\tBottom_Loss: 0.6364\tLoss: 1.6900\t\n",
      "Subject: 009, n=04 | test_f1: 0.22222 |best_f1: 0.42857\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6822\tTop_Loss: 0.6840\tBottom_Loss: 0.5741\tLoss: 1.9403\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7119\tTop_Loss: 0.7214\tBottom_Loss: 0.7592\tLoss: 2.1925\t\n",
      "Subject: 009, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5994\tTop_Loss: 0.5825\tBottom_Loss: 0.6964\tLoss: 1.8784\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6609\tTop_Loss: 0.6724\tBottom_Loss: 0.7175\tLoss: 2.0508\t\n",
      "Subject: 009, n=04 | test_f1: 0.33333 |best_f1: 0.42857\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4723\tTop_Loss: 0.6467\tBottom_Loss: 0.5040\tLoss: 1.6230\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.719\tLabel_Loss: 0.7728\tTop_Loss: 1.0112\tBottom_Loss: 1.1083\tLoss: 2.8924\t\n",
      "Subject: 009, n=04 | test_f1: 0.13333 |best_f1: 0.42857\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5263\tTop_Loss: 0.6381\tBottom_Loss: 0.7386\tLoss: 1.9029\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.781\tLabel_Loss: 0.6058\tTop_Loss: 0.6282\tBottom_Loss: 0.7694\tLoss: 2.0034\t\n",
      "Subject: 009, n=04 | test_f1: 0.33333 |best_f1: 0.42857\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6577\tTop_Loss: 0.6017\tBottom_Loss: 0.8254\tLoss: 2.0848\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4386\tTop_Loss: 0.5507\tBottom_Loss: 0.5096\tLoss: 1.4989\t\n",
      "Subject: 009, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4794\tTop_Loss: 0.5598\tBottom_Loss: 0.5576\tLoss: 1.5969\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4139\tTop_Loss: 0.5083\tBottom_Loss: 0.4294\tLoss: 1.3516\t\n",
      "Subject: 009, n=04 | test_f1: 0.22222 |best_f1: 0.42857\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5034\tTop_Loss: 0.6486\tBottom_Loss: 0.5686\tLoss: 1.7206\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4878\tTop_Loss: 0.6792\tBottom_Loss: 0.6837\tLoss: 1.8506\t\n",
      "Subject: 009, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5191\tTop_Loss: 0.6776\tBottom_Loss: 0.5989\tLoss: 1.7955\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4401\tTop_Loss: 0.6096\tBottom_Loss: 0.5133\tLoss: 1.5630\t\n",
      "Subject: 009, n=04 | test_f1: 0.33333 |best_f1: 0.42857\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4114\tTop_Loss: 0.5894\tBottom_Loss: 0.5282\tLoss: 1.5290\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4737\tTop_Loss: 0.4409\tBottom_Loss: 0.6939\tLoss: 1.6085\t\n",
      "Subject: 009, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3508\tTop_Loss: 0.5541\tBottom_Loss: 0.5105\tLoss: 1.4154\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.688\tLabel_Loss: 0.5798\tTop_Loss: 0.6154\tBottom_Loss: 0.6030\tLoss: 1.7982\t\n",
      "Subject: 009, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3858\tTop_Loss: 0.5337\tBottom_Loss: 0.4941\tLoss: 1.4137\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4473\tTop_Loss: 0.5233\tBottom_Loss: 0.4276\tLoss: 1.3982\t\n",
      "Subject: 009, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4812\tTop_Loss: 0.8144\tBottom_Loss: 0.5713\tLoss: 1.8669\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2999\tTop_Loss: 0.4742\tBottom_Loss: 0.3797\tLoss: 1.1538\t\n",
      "Subject: 009, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.750\tLabel_Loss: 0.4483\tTop_Loss: 0.5760\tBottom_Loss: 0.5889\tLoss: 1.6131\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.719\tLabel_Loss: 0.5731\tTop_Loss: 0.6872\tBottom_Loss: 0.7488\tLoss: 2.0091\t\n",
      "Subject: 009, n=04 | test_f1: 0.13333 |best_f1: 1.0\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4524\tTop_Loss: 0.7385\tBottom_Loss: 0.5615\tLoss: 1.7524\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3160\tTop_Loss: 0.4977\tBottom_Loss: 0.6228\tLoss: 1.4365\t\n",
      "Subject: 009, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2472\tTop_Loss: 0.4243\tBottom_Loss: 0.4200\tLoss: 1.0916\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3913\tTop_Loss: 0.6782\tBottom_Loss: 0.5605\tLoss: 1.6300\t\n",
      "Subject: 009, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3224\tTop_Loss: 0.6015\tBottom_Loss: 0.3648\tLoss: 1.2887\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2464\tTop_Loss: 0.4575\tBottom_Loss: 0.3340\tLoss: 1.0380\t\n",
      "Subject: 009, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4335\tTop_Loss: 0.6510\tBottom_Loss: 0.4927\tLoss: 1.5773\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.781\tLabel_Loss: 0.3610\tTop_Loss: 0.5562\tBottom_Loss: 0.5295\tLoss: 1.4466\t\n",
      "Subject: 009, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2146\tTop_Loss: 0.4725\tBottom_Loss: 0.4105\tLoss: 1.0976\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4021\tTop_Loss: 0.4260\tBottom_Loss: 0.5947\tLoss: 1.4228\t\n",
      "Subject: 009, n=04 | test_f1: 0.2 |best_f1: 1.0\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2622\tTop_Loss: 0.4123\tBottom_Loss: 0.4164\tLoss: 1.0909\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3483\tTop_Loss: 0.4708\tBottom_Loss: 0.4229\tLoss: 1.2420\t\n",
      "Subject: 009, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4175\tTop_Loss: 0.6083\tBottom_Loss: 0.5401\tLoss: 1.5658\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4180\tTop_Loss: 0.5925\tBottom_Loss: 0.4058\tLoss: 1.4163\t\n",
      "Subject: 009, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1705\tTop_Loss: 0.3287\tBottom_Loss: 0.3772\tLoss: 0.8764\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.938\tLabel_Loss: 0.3558\tTop_Loss: 0.5289\tBottom_Loss: 0.4511\tLoss: 1.3357\t\n",
      "Subject: 009, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2480\tTop_Loss: 0.4401\tBottom_Loss: 0.2290\tLoss: 0.9172\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1987\tTop_Loss: 0.4510\tBottom_Loss: 0.2729\tLoss: 0.9226\t\n",
      "Subject: 009, n=04 | test_f1: 0.13333 |best_f1: 1.0\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2123\tTop_Loss: 0.3680\tBottom_Loss: 0.2896\tLoss: 0.8699\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1677\tTop_Loss: 0.4551\tBottom_Loss: 0.2251\tLoss: 0.8479\t\n",
      "Subject: 009, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1897\tTop_Loss: 0.3061\tBottom_Loss: 0.3829\tLoss: 0.8787\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2615\tTop_Loss: 0.3758\tBottom_Loss: 0.3247\tLoss: 0.9620\t\n",
      "Subject: 009, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1978\tTop_Loss: 0.3060\tBottom_Loss: 0.2284\tLoss: 0.7321\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2174\tTop_Loss: 0.4282\tBottom_Loss: 0.2892\tLoss: 0.9347\t\n",
      "Subject: 009, n=04 | test_f1: 0.13333 |best_f1: 1.0\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2463\tTop_Loss: 0.3743\tBottom_Loss: 0.4508\tLoss: 1.0715\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1680\tTop_Loss: 0.3853\tBottom_Loss: 0.2398\tLoss: 0.7930\t\n",
      "Subject: 009, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2205\tTop_Loss: 0.3800\tBottom_Loss: 0.3051\tLoss: 0.9057\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1825\tTop_Loss: 0.3667\tBottom_Loss: 0.2599\tLoss: 0.8090\t\n",
      "Subject: 009, n=04 | test_f1: 0.13333 |best_f1: 1.0\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2153\tTop_Loss: 0.3428\tBottom_Loss: 0.2031\tLoss: 0.7612\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1719\tTop_Loss: 0.2972\tBottom_Loss: 0.3418\tLoss: 0.8108\t\n",
      "Subject: 009, n=04 | test_f1: 0.38889 |best_f1: 1.0\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1706\tTop_Loss: 0.3731\tBottom_Loss: 0.2357\tLoss: 0.7794\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0958\tTop_Loss: 0.2475\tBottom_Loss: 0.1575\tLoss: 0.5007\t\n",
      "Subject: 009, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1741\tTop_Loss: 0.2896\tBottom_Loss: 0.2355\tLoss: 0.6992\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2414\tTop_Loss: 0.3603\tBottom_Loss: 0.2994\tLoss: 0.9012\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 009, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1119\tTop_Loss: 0.1838\tBottom_Loss: 0.2495\tLoss: 0.5452\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1626\tTop_Loss: 0.2787\tBottom_Loss: 0.2450\tLoss: 0.6863\t\n",
      "Subject: 009, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0702\tTop_Loss: 0.2721\tBottom_Loss: 0.1549\tLoss: 0.4971\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2201\tTop_Loss: 0.3774\tBottom_Loss: 0.3763\tLoss: 0.9737\t\n",
      "Subject: 009, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1076\tTop_Loss: 0.3308\tBottom_Loss: 0.1962\tLoss: 0.6346\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2125\tTop_Loss: 0.3224\tBottom_Loss: 0.2560\tLoss: 0.7908\t\n",
      "Subject: 009, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1293\tTop_Loss: 0.3319\tBottom_Loss: 0.1703\tLoss: 0.6314\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2338\tTop_Loss: 0.4438\tBottom_Loss: 0.2982\tLoss: 0.9758\t\n",
      "Subject: 009, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1301\tTop_Loss: 0.3913\tBottom_Loss: 0.1819\tLoss: 0.7032\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0917\tTop_Loss: 0.2112\tBottom_Loss: 0.1458\tLoss: 0.4487\t\n",
      "Subject: 009, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0624\tTop_Loss: 0.2369\tBottom_Loss: 0.1117\tLoss: 0.4110\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1309\tTop_Loss: 0.1911\tBottom_Loss: 0.2312\tLoss: 0.5532\t\n",
      "Subject: 009, n=04 | test_f1: 0.13333 |best_f1: 1.0\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2244\tTop_Loss: 0.3485\tBottom_Loss: 0.2120\tLoss: 0.7850\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1607\tTop_Loss: 0.1940\tBottom_Loss: 0.3298\tLoss: 0.6845\t\n",
      "Subject: 009, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1236\tTop_Loss: 0.2225\tBottom_Loss: 0.1950\tLoss: 0.5411\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1304\tTop_Loss: 0.2243\tBottom_Loss: 0.1701\tLoss: 0.5248\t\n",
      "Subject: 009, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1787\tTop_Loss: 0.2541\tBottom_Loss: 0.2944\tLoss: 0.7272\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1380\tTop_Loss: 0.3370\tBottom_Loss: 0.1277\tLoss: 0.6027\t\n",
      "Subject: 009, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0932\tTop_Loss: 0.2539\tBottom_Loss: 0.1408\tLoss: 0.4879\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1062\tTop_Loss: 0.2544\tBottom_Loss: 0.2012\tLoss: 0.5618\t\n",
      "Subject: 009, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0643\tTop_Loss: 0.2776\tBottom_Loss: 0.1251\tLoss: 0.4671\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1366\tTop_Loss: 0.2351\tBottom_Loss: 0.2102\tLoss: 0.5819\t\n",
      "Subject: 009, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0794\tTop_Loss: 0.1918\tBottom_Loss: 0.2112\tLoss: 0.4824\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0638\tTop_Loss: 0.2575\tBottom_Loss: 0.1122\tLoss: 0.4335\t\n",
      "Subject: 009, n=04 | test_f1: 0.13333 |best_f1: 1.0\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1536\tTop_Loss: 0.1907\tBottom_Loss: 0.1737\tLoss: 0.5180\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0645\tTop_Loss: 0.1298\tBottom_Loss: 0.0910\tLoss: 0.2853\t\n",
      "Subject: 009, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0868\tTop_Loss: 0.2208\tBottom_Loss: 0.1853\tLoss: 0.4928\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1585\tTop_Loss: 0.3070\tBottom_Loss: 0.2555\tLoss: 0.7210\t\n",
      "Subject: 009, n=04 | test_f1: 0.13333 |best_f1: 1.0\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0896\tTop_Loss: 0.1784\tBottom_Loss: 0.1694\tLoss: 0.4374\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0563\tTop_Loss: 0.1419\tBottom_Loss: 0.1247\tLoss: 0.3229\t\n",
      "Subject: 009, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0963\tTop_Loss: 0.2746\tBottom_Loss: 0.1156\tLoss: 0.4865\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0974\tTop_Loss: 0.2484\tBottom_Loss: 0.1765\tLoss: 0.5222\t\n",
      "Subject: 009, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0594\tTop_Loss: 0.1972\tBottom_Loss: 0.0858\tLoss: 0.3423\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1320\tTop_Loss: 0.1749\tBottom_Loss: 0.1282\tLoss: 0.4351\t\n",
      "Subject: 009, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0669\tTop_Loss: 0.1654\tBottom_Loss: 0.1128\tLoss: 0.3451\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0706\tTop_Loss: 0.2265\tBottom_Loss: 0.1116\tLoss: 0.4087\t\n",
      "Subject: 009, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0706\tTop_Loss: 0.1872\tBottom_Loss: 0.0772\tLoss: 0.3349\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1056\tTop_Loss: 0.1034\tBottom_Loss: 0.1224\tLoss: 0.3314\t\n",
      "Subject: 009, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0606\tTop_Loss: 0.1708\tBottom_Loss: 0.0940\tLoss: 0.3253\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0919\tTop_Loss: 0.1774\tBottom_Loss: 0.1097\tLoss: 0.3790\t\n",
      "Subject: 009, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1128\tTop_Loss: 0.2173\tBottom_Loss: 0.2211\tLoss: 0.5511\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0230\tTop_Loss: 0.1022\tBottom_Loss: 0.0726\tLoss: 0.1978\t\n",
      "Subject: 009, n=04 | test_f1: 0.2 |best_f1: 1.0\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0215\tTop_Loss: 0.1233\tBottom_Loss: 0.0656\tLoss: 0.2103\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0666\tTop_Loss: 0.0934\tBottom_Loss: 0.1107\tLoss: 0.2707\t\n",
      "Subject: 009, n=04 | test_f1: 0.13333 |best_f1: 1.0\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0546\tTop_Loss: 0.1290\tBottom_Loss: 0.0824\tLoss: 0.2661\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1410\tTop_Loss: 0.1179\tBottom_Loss: 0.1617\tLoss: 0.4206\t\n",
      "Subject: 009, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0485\tTop_Loss: 0.0867\tBottom_Loss: 0.1520\tLoss: 0.2871\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0541\tTop_Loss: 0.0865\tBottom_Loss: 0.1109\tLoss: 0.2515\t\n",
      "Subject: 009, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0491\tTop_Loss: 0.1379\tBottom_Loss: 0.0983\tLoss: 0.2853\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0303\tTop_Loss: 0.0642\tBottom_Loss: 0.0931\tLoss: 0.1877\t\n",
      "Subject: 009, n=04 | test_f1: 0.13333 |best_f1: 1.0\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0448\tTop_Loss: 0.1376\tBottom_Loss: 0.1057\tLoss: 0.2881\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0276\tTop_Loss: 0.1650\tBottom_Loss: 0.0404\tLoss: 0.2331\t\n",
      "Subject: 009, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0442\tTop_Loss: 0.0954\tBottom_Loss: 0.0954\tLoss: 0.2350\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0582\tTop_Loss: 0.1357\tBottom_Loss: 0.0863\tLoss: 0.2801\t\n",
      "Subject: 009, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0354\tTop_Loss: 0.1080\tBottom_Loss: 0.0387\tLoss: 0.1821\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0569\tTop_Loss: 0.0949\tBottom_Loss: 0.1117\tLoss: 0.2635\t\n",
      "Subject: 009, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0702\tTop_Loss: 0.1862\tBottom_Loss: 0.0514\tLoss: 0.3078\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0494\tTop_Loss: 0.1114\tBottom_Loss: 0.0909\tLoss: 0.2517\t\n",
      "Subject: 009, n=04 | test_f1: 0.13333 |best_f1: 1.0\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0212\tTop_Loss: 0.1316\tBottom_Loss: 0.0349\tLoss: 0.1877\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0479\tTop_Loss: 0.0978\tBottom_Loss: 0.1590\tLoss: 0.3048\t\n",
      "Subject: 009, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0149\tTop_Loss: 0.0987\tBottom_Loss: 0.0396\tLoss: 0.1532\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0522\tTop_Loss: 0.1870\tBottom_Loss: 0.1080\tLoss: 0.3473\t\n",
      "Subject: 009, n=04 | test_f1: 0.13333 |best_f1: 1.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0322\tTop_Loss: 0.1426\tBottom_Loss: 0.0456\tLoss: 0.2204\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0452\tTop_Loss: 0.0745\tBottom_Loss: 0.1138\tLoss: 0.2336\t\n",
      "Subject: 009, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0167\tTop_Loss: 0.1120\tBottom_Loss: 0.0476\tLoss: 0.1763\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1082\tTop_Loss: 0.2042\tBottom_Loss: 0.1601\tLoss: 0.4725\t\n",
      "Subject: 009, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0727\tTop_Loss: 0.1851\tBottom_Loss: 0.0920\tLoss: 0.3498\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0559\tTop_Loss: 0.0934\tBottom_Loss: 0.0838\tLoss: 0.2332\t\n",
      "Subject: 009, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0364\tTop_Loss: 0.0983\tBottom_Loss: 0.1167\tLoss: 0.2514\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0110\tTop_Loss: 0.0732\tBottom_Loss: 0.0296\tLoss: 0.1139\t\n",
      "Subject: 009, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0712\tTop_Loss: 0.1108\tBottom_Loss: 0.0735\tLoss: 0.2555\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0654\tTop_Loss: 0.1011\tBottom_Loss: 0.1007\tLoss: 0.2672\t\n",
      "Subject: 009, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0302\tTop_Loss: 0.0894\tBottom_Loss: 0.0590\tLoss: 0.1786\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0163\tTop_Loss: 0.0688\tBottom_Loss: 0.0591\tLoss: 0.1443\t\n",
      "Subject: 009, n=04 | test_f1: 0.13333 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0203\tTop_Loss: 0.1862\tBottom_Loss: 0.0368\tLoss: 0.2433\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0113\tTop_Loss: 0.0849\tBottom_Loss: 0.0379\tLoss: 0.1341\t\n",
      "Subject: 009, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0262\tTop_Loss: 0.0593\tBottom_Loss: 0.0606\tLoss: 0.1461\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0152\tTop_Loss: 0.0537\tBottom_Loss: 0.0525\tLoss: 0.1213\t\n",
      "Subject: 009, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0216\tTop_Loss: 0.0634\tBottom_Loss: 0.0559\tLoss: 0.1410\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0232\tTop_Loss: 0.0780\tBottom_Loss: 0.0500\tLoss: 0.1513\t\n",
      "Subject: 009, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0183\tTop_Loss: 0.0821\tBottom_Loss: 0.0329\tLoss: 0.1333\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0236\tTop_Loss: 0.0474\tBottom_Loss: 0.0375\tLoss: 0.1086\t\n",
      "Subject: 009, n=04 | test_f1: 0.6 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0082\tTop_Loss: 0.0337\tBottom_Loss: 0.0273\tLoss: 0.0692\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0121\tTop_Loss: 0.0461\tBottom_Loss: 0.0464\tLoss: 0.1046\t\n",
      "Subject: 009, n=04 | test_f1: 0.73333 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0247\tTop_Loss: 0.0547\tBottom_Loss: 0.0653\tLoss: 0.1447\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0132\tTop_Loss: 0.0287\tBottom_Loss: 0.0334\tLoss: 0.0753\t\n",
      "Subject: 009, n=04 | test_f1: 0.73333 |best_f1: 1.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0124\tTop_Loss: 0.0220\tBottom_Loss: 0.0434\tLoss: 0.0777\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0350\tTop_Loss: 0.1133\tBottom_Loss: 0.0435\tLoss: 0.1918\t\n",
      "Subject: 009, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0076\tTop_Loss: 0.0409\tBottom_Loss: 0.0163\tLoss: 0.0648\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0324\tTop_Loss: 0.0640\tBottom_Loss: 0.0483\tLoss: 0.1447\t\n",
      "Subject: 009, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0181\tTop_Loss: 0.0535\tBottom_Loss: 0.0453\tLoss: 0.1170\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0227\tTop_Loss: 0.0878\tBottom_Loss: 0.0337\tLoss: 0.1442\t\n",
      "Subject: 009, n=04 | test_f1: 0.73333 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0235\tTop_Loss: 0.0513\tBottom_Loss: 0.0624\tLoss: 0.1372\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0096\tTop_Loss: 0.0212\tBottom_Loss: 0.0510\tLoss: 0.0818\t\n",
      "Subject: 009, n=04 | test_f1: 0.13333 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0104\tTop_Loss: 0.0493\tBottom_Loss: 0.0241\tLoss: 0.0838\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0116\tTop_Loss: 0.0312\tBottom_Loss: 0.0378\tLoss: 0.0806\t\n",
      "Subject: 009, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0271\tTop_Loss: 0.0692\tBottom_Loss: 0.0529\tLoss: 0.1492\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0345\tTop_Loss: 0.1176\tBottom_Loss: 0.0728\tLoss: 0.2249\t\n",
      "Subject: 009, n=04 | test_f1: 0.73333 |best_f1: 1.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0171\tTop_Loss: 0.0420\tBottom_Loss: 0.0454\tLoss: 0.1045\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0713\tTop_Loss: 0.1368\tBottom_Loss: 0.1123\tLoss: 0.3204\t\n",
      "Subject: 009, n=04 | test_f1: 0.73333 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0105\tTop_Loss: 0.0351\tBottom_Loss: 0.0526\tLoss: 0.0982\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0048\tTop_Loss: 0.0244\tBottom_Loss: 0.0138\tLoss: 0.0430\t\n",
      "Subject: 009, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0191\tTop_Loss: 0.0722\tBottom_Loss: 0.0335\tLoss: 0.1248\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0769\tTop_Loss: 0.0770\tBottom_Loss: 0.1763\tLoss: 0.3302\t\n",
      "Subject: 009, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0159\tTop_Loss: 0.1459\tBottom_Loss: 0.0416\tLoss: 0.2034\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0071\tTop_Loss: 0.0529\tBottom_Loss: 0.0207\tLoss: 0.0806\t\n",
      "Subject: 009, n=04 | test_f1: 0.73333 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0103\tTop_Loss: 0.0238\tBottom_Loss: 0.0296\tLoss: 0.0637\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0102\tTop_Loss: 0.0513\tBottom_Loss: 0.0235\tLoss: 0.0850\t\n",
      "Subject: 009, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0145\tTop_Loss: 0.0672\tBottom_Loss: 0.0679\tLoss: 0.1496\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0102\tTop_Loss: 0.0438\tBottom_Loss: 0.0119\tLoss: 0.0659\t\n",
      "Subject: 009, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0132\tTop_Loss: 0.0534\tBottom_Loss: 0.0378\tLoss: 0.1044\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0111\tTop_Loss: 0.0731\tBottom_Loss: 0.0259\tLoss: 0.1101\t\n",
      "Subject: 009, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.344\tLabel_Loss: 1.2228\tTop_Loss: 1.1881\tBottom_Loss: 1.4529\tLoss: 3.8638\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.719\tLabel_Loss: 0.7201\tTop_Loss: 0.7468\tBottom_Loss: 0.9936\tLoss: 2.4605\t\n",
      "Subject: 01, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.531\tLabel_Loss: 0.9676\tTop_Loss: 1.0245\tBottom_Loss: 0.9772\tLoss: 2.9694\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.531\tLabel_Loss: 0.8709\tTop_Loss: 0.8783\tBottom_Loss: 1.0094\tLoss: 2.7586\t\n",
      "Subject: 01, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.562\tLabel_Loss: 1.0384\tTop_Loss: 0.8703\tBottom_Loss: 0.8925\tLoss: 2.8013\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.656\tLabel_Loss: 0.9377\tTop_Loss: 0.9853\tBottom_Loss: 0.9642\tLoss: 2.8872\t\n",
      "Subject: 01, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.781\tLabel_Loss: 0.6765\tTop_Loss: 0.8150\tBottom_Loss: 0.8471\tLoss: 2.3387\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.469\tLabel_Loss: 1.0008\tTop_Loss: 1.2187\tBottom_Loss: 1.0727\tLoss: 3.2922\t\n",
      "Subject: 01, n=03 | test_f1: 0.55556 |best_f1: 0.55556\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.531\tLabel_Loss: 0.9145\tTop_Loss: 0.7513\tBottom_Loss: 0.7044\tLoss: 2.3703\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.688\tLabel_Loss: 0.8675\tTop_Loss: 0.7736\tBottom_Loss: 1.0256\tLoss: 2.6667\t\n",
      "Subject: 01, n=03 | test_f1: 0.4 |best_f1: 0.55556\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.688\tLabel_Loss: 0.8324\tTop_Loss: 0.8001\tBottom_Loss: 0.9865\tLoss: 2.6191\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8072\tTop_Loss: 0.8867\tBottom_Loss: 0.7557\tLoss: 2.4495\t\n",
      "Subject: 01, n=03 | test_f1: 0.4 |best_f1: 0.55556\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7293\tTop_Loss: 0.7249\tBottom_Loss: 0.8892\tLoss: 2.3433\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7812\tTop_Loss: 0.9191\tBottom_Loss: 0.7591\tLoss: 2.4594\t\n",
      "Subject: 01, n=03 | test_f1: 0.55556 |best_f1: 0.55556\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.562\tLabel_Loss: 0.8958\tTop_Loss: 0.9775\tBottom_Loss: 0.7950\tLoss: 2.6684\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7689\tTop_Loss: 0.7665\tBottom_Loss: 0.6864\tLoss: 2.2219\t\n",
      "Subject: 01, n=03 | test_f1: 0.66667 |best_f1: 0.66667\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.688\tLabel_Loss: 0.8544\tTop_Loss: 0.9509\tBottom_Loss: 0.7308\tLoss: 2.5361\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.719\tLabel_Loss: 0.8327\tTop_Loss: 0.9011\tBottom_Loss: 0.8869\tLoss: 2.6207\t\n",
      "Subject: 01, n=03 | test_f1: 0.4 |best_f1: 0.66667\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6402\tTop_Loss: 0.6742\tBottom_Loss: 0.7667\tLoss: 2.0810\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.750\tLabel_Loss: 0.7041\tTop_Loss: 0.8475\tBottom_Loss: 0.6766\tLoss: 2.2282\t\n",
      "Subject: 01, n=03 | test_f1: 0.4 |best_f1: 0.66667\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.500\tLabel_Loss: 1.0817\tTop_Loss: 1.0144\tBottom_Loss: 0.8259\tLoss: 2.9219\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5586\tTop_Loss: 0.6779\tBottom_Loss: 0.8479\tLoss: 2.0843\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7723\tTop_Loss: 0.8467\tBottom_Loss: 0.7688\tLoss: 2.3879\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5581\tTop_Loss: 0.7321\tBottom_Loss: 0.6346\tLoss: 1.9248\t\n",
      "Subject: 01, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7431\tTop_Loss: 0.8025\tBottom_Loss: 0.7391\tLoss: 2.2847\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6974\tTop_Loss: 0.7518\tBottom_Loss: 0.7365\tLoss: 2.1857\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.594\tLabel_Loss: 0.6770\tTop_Loss: 0.8462\tBottom_Loss: 0.7410\tLoss: 2.2642\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.719\tLabel_Loss: 0.7380\tTop_Loss: 0.7428\tBottom_Loss: 0.8328\tLoss: 2.3135\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6621\tTop_Loss: 0.6101\tBottom_Loss: 0.7155\tLoss: 1.9877\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5214\tTop_Loss: 0.6474\tBottom_Loss: 0.7001\tLoss: 1.8688\t\n",
      "Subject: 01, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6201\tTop_Loss: 0.6157\tBottom_Loss: 0.5694\tLoss: 1.8053\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3541\tTop_Loss: 0.4643\tBottom_Loss: 0.5284\tLoss: 1.3468\t\n",
      "Subject: 01, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4696\tTop_Loss: 0.5339\tBottom_Loss: 0.5240\tLoss: 1.5276\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5833\tTop_Loss: 0.7828\tBottom_Loss: 0.6787\tLoss: 2.0447\t\n",
      "Subject: 01, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6896\tTop_Loss: 0.8308\tBottom_Loss: 0.7966\tLoss: 2.3171\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.688\tLabel_Loss: 0.5433\tTop_Loss: 0.6945\tBottom_Loss: 0.6140\tLoss: 1.8517\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5040\tTop_Loss: 0.5911\tBottom_Loss: 0.7407\tLoss: 1.8358\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6420\tTop_Loss: 0.8399\tBottom_Loss: 0.7333\tLoss: 2.2152\t\n",
      "Subject: 01, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3960\tTop_Loss: 0.5137\tBottom_Loss: 0.4967\tLoss: 1.4064\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5356\tTop_Loss: 0.6493\tBottom_Loss: 0.5724\tLoss: 1.7573\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.875\tLabel_Loss: 0.5212\tTop_Loss: 0.5640\tBottom_Loss: 0.6213\tLoss: 1.7064\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5645\tTop_Loss: 0.5848\tBottom_Loss: 0.5906\tLoss: 1.7399\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4937\tTop_Loss: 0.4775\tBottom_Loss: 0.5598\tLoss: 1.5310\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3784\tTop_Loss: 0.5639\tBottom_Loss: 0.5649\tLoss: 1.5072\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.656\tLabel_Loss: 0.6507\tTop_Loss: 0.8371\tBottom_Loss: 0.7029\tLoss: 2.1907\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4687\tTop_Loss: 0.6739\tBottom_Loss: 0.4906\tLoss: 1.6332\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2435\tTop_Loss: 0.4553\tBottom_Loss: 0.4140\tLoss: 1.1127\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5950\tTop_Loss: 0.7077\tBottom_Loss: 0.7582\tLoss: 2.0609\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3421\tTop_Loss: 0.4620\tBottom_Loss: 0.3885\tLoss: 1.1925\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4459\tTop_Loss: 0.4473\tBottom_Loss: 0.5401\tLoss: 1.4333\t\n",
      "Subject: 01, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3958\tTop_Loss: 0.5823\tBottom_Loss: 0.4803\tLoss: 1.4584\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4076\tTop_Loss: 0.6305\tBottom_Loss: 0.4143\tLoss: 1.4524\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3886\tTop_Loss: 0.5845\tBottom_Loss: 0.4844\tLoss: 1.4575\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2631\tTop_Loss: 0.4495\tBottom_Loss: 0.3719\tLoss: 1.0845\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3108\tTop_Loss: 0.5660\tBottom_Loss: 0.5336\tLoss: 1.4105\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3210\tTop_Loss: 0.4973\tBottom_Loss: 0.3378\tLoss: 1.1561\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2803\tTop_Loss: 0.5681\tBottom_Loss: 0.3654\tLoss: 1.2138\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3410\tTop_Loss: 0.6088\tBottom_Loss: 0.4673\tLoss: 1.4172\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2160\tTop_Loss: 0.4597\tBottom_Loss: 0.3395\tLoss: 1.0152\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3101\tTop_Loss: 0.4644\tBottom_Loss: 0.4106\tLoss: 1.1852\t\n",
      "Subject: 01, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3077\tTop_Loss: 0.4414\tBottom_Loss: 0.4606\tLoss: 1.2097\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2075\tTop_Loss: 0.4657\tBottom_Loss: 0.4151\tLoss: 1.0884\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2965\tTop_Loss: 0.5039\tBottom_Loss: 0.3391\tLoss: 1.1394\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2496\tTop_Loss: 0.5715\tBottom_Loss: 0.4028\tLoss: 1.2239\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4049\tTop_Loss: 0.5510\tBottom_Loss: 0.4997\tLoss: 1.4556\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.844\tLabel_Loss: 0.2760\tTop_Loss: 0.3124\tBottom_Loss: 0.4885\tLoss: 1.0769\t\n",
      "Subject: 01, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2139\tTop_Loss: 0.3115\tBottom_Loss: 0.2893\tLoss: 0.8148\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3065\tTop_Loss: 0.5783\tBottom_Loss: 0.4165\tLoss: 1.3012\t\n",
      "Subject: 01, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1682\tTop_Loss: 0.4509\tBottom_Loss: 0.2644\tLoss: 0.8834\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1606\tTop_Loss: 0.2730\tBottom_Loss: 0.2337\tLoss: 0.6673\t\n",
      "Subject: 01, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1614\tTop_Loss: 0.2741\tBottom_Loss: 0.2566\tLoss: 0.6921\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.844\tLabel_Loss: 0.2889\tTop_Loss: 0.4958\tBottom_Loss: 0.3323\tLoss: 1.1170\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1810\tTop_Loss: 0.3303\tBottom_Loss: 0.2858\tLoss: 0.7971\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1634\tTop_Loss: 0.5028\tBottom_Loss: 0.2629\tLoss: 0.9290\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 01, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2511\tTop_Loss: 0.4827\tBottom_Loss: 0.4444\tLoss: 1.1783\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1827\tTop_Loss: 0.4100\tBottom_Loss: 0.2906\tLoss: 0.8833\t\n",
      "Subject: 01, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2620\tTop_Loss: 0.3975\tBottom_Loss: 0.3588\tLoss: 1.0183\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2623\tTop_Loss: 0.3850\tBottom_Loss: 0.3636\tLoss: 1.0109\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1962\tTop_Loss: 0.3865\tBottom_Loss: 0.3661\tLoss: 0.9488\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0850\tTop_Loss: 0.2768\tBottom_Loss: 0.2012\tLoss: 0.5630\t\n",
      "Subject: 01, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1607\tTop_Loss: 0.3332\tBottom_Loss: 0.2199\tLoss: 0.7137\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1461\tTop_Loss: 0.2602\tBottom_Loss: 0.2238\tLoss: 0.6302\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1039\tTop_Loss: 0.2223\tBottom_Loss: 0.2089\tLoss: 0.5351\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1674\tTop_Loss: 0.2856\tBottom_Loss: 0.2430\tLoss: 0.6961\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2271\tTop_Loss: 0.4332\tBottom_Loss: 0.2462\tLoss: 0.9066\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1766\tTop_Loss: 0.3869\tBottom_Loss: 0.2180\tLoss: 0.7815\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2143\tTop_Loss: 0.4477\tBottom_Loss: 0.2455\tLoss: 0.9075\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.844\tLabel_Loss: 0.2688\tTop_Loss: 0.3790\tBottom_Loss: 0.3078\tLoss: 0.9556\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1420\tTop_Loss: 0.3068\tBottom_Loss: 0.1372\tLoss: 0.5860\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1684\tTop_Loss: 0.2234\tBottom_Loss: 0.2624\tLoss: 0.6542\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2456\tTop_Loss: 0.4358\tBottom_Loss: 0.2796\tLoss: 0.9609\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0491\tTop_Loss: 0.1651\tBottom_Loss: 0.1914\tLoss: 0.4056\t\n",
      "Subject: 01, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2041\tTop_Loss: 0.3742\tBottom_Loss: 0.2675\tLoss: 0.8458\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1141\tTop_Loss: 0.2451\tBottom_Loss: 0.1667\tLoss: 0.5259\t\n",
      "Subject: 01, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1390\tTop_Loss: 0.3919\tBottom_Loss: 0.2055\tLoss: 0.7364\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0777\tTop_Loss: 0.1827\tBottom_Loss: 0.1361\tLoss: 0.3966\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1275\tTop_Loss: 0.2846\tBottom_Loss: 0.1835\tLoss: 0.5956\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0782\tTop_Loss: 0.2053\tBottom_Loss: 0.1412\tLoss: 0.4247\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2357\tTop_Loss: 0.2451\tBottom_Loss: 0.2752\tLoss: 0.7560\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2297\tTop_Loss: 0.2900\tBottom_Loss: 0.2126\tLoss: 0.7322\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3009\tTop_Loss: 0.4603\tBottom_Loss: 0.3199\tLoss: 1.0811\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0945\tTop_Loss: 0.4540\tBottom_Loss: 0.1711\tLoss: 0.7196\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0496\tTop_Loss: 0.2664\tBottom_Loss: 0.1163\tLoss: 0.4323\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1412\tTop_Loss: 0.2655\tBottom_Loss: 0.1623\tLoss: 0.5690\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0394\tTop_Loss: 0.1615\tBottom_Loss: 0.1650\tLoss: 0.3659\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0904\tTop_Loss: 0.1621\tBottom_Loss: 0.3486\tLoss: 0.6011\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0711\tTop_Loss: 0.3142\tBottom_Loss: 0.1299\tLoss: 0.5152\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0549\tTop_Loss: 0.2045\tBottom_Loss: 0.1146\tLoss: 0.3740\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0709\tTop_Loss: 0.1537\tBottom_Loss: 0.1916\tLoss: 0.4162\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0561\tTop_Loss: 0.1307\tBottom_Loss: 0.1111\tLoss: 0.2979\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0762\tTop_Loss: 0.2732\tBottom_Loss: 0.1044\tLoss: 0.4538\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1234\tTop_Loss: 0.2186\tBottom_Loss: 0.1897\tLoss: 0.5318\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1577\tTop_Loss: 0.3218\tBottom_Loss: 0.2467\tLoss: 0.7263\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0274\tTop_Loss: 0.1672\tBottom_Loss: 0.0723\tLoss: 0.2669\t\n",
      "Subject: 01, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0963\tTop_Loss: 0.2858\tBottom_Loss: 0.1556\tLoss: 0.5377\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0272\tTop_Loss: 0.1147\tBottom_Loss: 0.0888\tLoss: 0.2306\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0589\tTop_Loss: 0.1768\tBottom_Loss: 0.1279\tLoss: 0.3636\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0737\tTop_Loss: 0.1381\tBottom_Loss: 0.1534\tLoss: 0.3653\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0476\tTop_Loss: 0.1512\tBottom_Loss: 0.1508\tLoss: 0.3496\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0483\tTop_Loss: 0.2170\tBottom_Loss: 0.1343\tLoss: 0.3996\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0244\tTop_Loss: 0.1130\tBottom_Loss: 0.0649\tLoss: 0.2022\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0423\tTop_Loss: 0.1279\tBottom_Loss: 0.1066\tLoss: 0.2768\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0338\tTop_Loss: 0.2304\tBottom_Loss: 0.0960\tLoss: 0.3601\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0802\tTop_Loss: 0.1844\tBottom_Loss: 0.1517\tLoss: 0.4162\t\n",
      "Subject: 01, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1204\tTop_Loss: 0.2033\tBottom_Loss: 0.2184\tLoss: 0.5422\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0237\tTop_Loss: 0.1167\tBottom_Loss: 0.1112\tLoss: 0.2516\t\n",
      "Subject: 01, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0198\tTop_Loss: 0.1157\tBottom_Loss: 0.0637\tLoss: 0.1993\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0284\tTop_Loss: 0.1411\tBottom_Loss: 0.1021\tLoss: 0.2716\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 0.938\tLabel_Loss: 0.0952\tTop_Loss: 0.1614\tBottom_Loss: 0.1389\tLoss: 0.3955\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0442\tTop_Loss: 0.1053\tBottom_Loss: 0.0685\tLoss: 0.2181\t\n",
      "Subject: 01, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0403\tTop_Loss: 0.1466\tBottom_Loss: 0.1209\tLoss: 0.3078\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0150\tTop_Loss: 0.1248\tBottom_Loss: 0.0581\tLoss: 0.1979\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0187\tTop_Loss: 0.1156\tBottom_Loss: 0.0450\tLoss: 0.1793\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0294\tTop_Loss: 0.0765\tBottom_Loss: 0.0574\tLoss: 0.1633\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0593\tTop_Loss: 0.1289\tBottom_Loss: 0.0655\tLoss: 0.2537\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 0.938\tLabel_Loss: 0.0912\tTop_Loss: 0.1271\tBottom_Loss: 0.1614\tLoss: 0.3797\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0315\tTop_Loss: 0.1069\tBottom_Loss: 0.0768\tLoss: 0.2153\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0343\tTop_Loss: 0.1676\tBottom_Loss: 0.0740\tLoss: 0.2759\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0154\tTop_Loss: 0.1389\tBottom_Loss: 0.0303\tLoss: 0.1845\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0297\tTop_Loss: 0.0728\tBottom_Loss: 0.0881\tLoss: 0.1906\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0530\tTop_Loss: 0.1753\tBottom_Loss: 0.0776\tLoss: 0.3059\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 0.938\tLabel_Loss: 0.0933\tTop_Loss: 0.1163\tBottom_Loss: 0.1554\tLoss: 0.3649\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0196\tTop_Loss: 0.1275\tBottom_Loss: 0.0687\tLoss: 0.2158\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0635\tTop_Loss: 0.1209\tBottom_Loss: 0.1451\tLoss: 0.3296\t\n",
      "Subject: 01, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0418\tTop_Loss: 0.0926\tBottom_Loss: 0.0879\tLoss: 0.2223\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0216\tTop_Loss: 0.0862\tBottom_Loss: 0.0633\tLoss: 0.1710\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0633\tTop_Loss: 0.0710\tBottom_Loss: 0.1111\tLoss: 0.2454\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0175\tTop_Loss: 0.0646\tBottom_Loss: 0.0489\tLoss: 0.1310\t\n",
      "Subject: 01, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0209\tTop_Loss: 0.0733\tBottom_Loss: 0.0394\tLoss: 0.1336\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0219\tTop_Loss: 0.1004\tBottom_Loss: 0.0386\tLoss: 0.1608\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0147\tTop_Loss: 0.0621\tBottom_Loss: 0.0389\tLoss: 0.1157\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0247\tTop_Loss: 0.0853\tBottom_Loss: 0.0618\tLoss: 0.1718\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0316\tTop_Loss: 0.1456\tBottom_Loss: 0.0618\tLoss: 0.2390\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0417\tTop_Loss: 0.1442\tBottom_Loss: 0.0751\tLoss: 0.2611\t\n",
      "Subject: 01, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0333\tTop_Loss: 0.1492\tBottom_Loss: 0.0513\tLoss: 0.2338\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0146\tTop_Loss: 0.0500\tBottom_Loss: 0.0396\tLoss: 0.1042\t\n",
      "Subject: 01, n=03 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0102\tTop_Loss: 0.0553\tBottom_Loss: 0.0545\tLoss: 0.1200\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0618\tTop_Loss: 0.1018\tBottom_Loss: 0.0886\tLoss: 0.2522\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0236\tTop_Loss: 0.0990\tBottom_Loss: 0.0636\tLoss: 0.1861\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0493\tTop_Loss: 0.1002\tBottom_Loss: 0.0703\tLoss: 0.2198\t\n",
      "Subject: 01, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0091\tTop_Loss: 0.0772\tBottom_Loss: 0.0353\tLoss: 0.1216\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0114\tTop_Loss: 0.0267\tBottom_Loss: 0.0341\tLoss: 0.0722\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0285\tTop_Loss: 0.0911\tBottom_Loss: 0.0706\tLoss: 0.1902\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0187\tTop_Loss: 0.0842\tBottom_Loss: 0.0424\tLoss: 0.1452\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0153\tTop_Loss: 0.0980\tBottom_Loss: 0.0460\tLoss: 0.1592\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0959\tTop_Loss: 0.0939\tBottom_Loss: 0.2235\tLoss: 0.4134\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0295\tTop_Loss: 0.0670\tBottom_Loss: 0.0708\tLoss: 0.1674\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0192\tTop_Loss: 0.0949\tBottom_Loss: 0.0676\tLoss: 0.1816\t\n",
      "Subject: 01, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0293\tTop_Loss: 0.1133\tBottom_Loss: 0.0560\tLoss: 0.1986\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0045\tTop_Loss: 0.0455\tBottom_Loss: 0.0176\tLoss: 0.0676\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0069\tTop_Loss: 0.0614\tBottom_Loss: 0.0486\tLoss: 0.1169\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0451\tTop_Loss: 0.0739\tBottom_Loss: 0.1120\tLoss: 0.2311\t\n",
      "Subject: 01, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0101\tTop_Loss: 0.0606\tBottom_Loss: 0.0248\tLoss: 0.0954\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0141\tTop_Loss: 0.0650\tBottom_Loss: 0.0525\tLoss: 0.1316\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0298\tTop_Loss: 0.0949\tBottom_Loss: 0.0445\tLoss: 0.1693\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0341\tTop_Loss: 0.0848\tBottom_Loss: 0.0652\tLoss: 0.1841\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0073\tTop_Loss: 0.0480\tBottom_Loss: 0.0412\tLoss: 0.0965\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0044\tTop_Loss: 0.0340\tBottom_Loss: 0.0215\tLoss: 0.0599\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0081\tTop_Loss: 0.0335\tBottom_Loss: 0.0208\tLoss: 0.0623\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0190\tTop_Loss: 0.0504\tBottom_Loss: 0.0535\tLoss: 0.1230\t\n",
      "Subject: 01, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0252\tTop_Loss: 0.0656\tBottom_Loss: 0.0537\tLoss: 0.1445\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0042\tTop_Loss: 0.0293\tBottom_Loss: 0.0181\tLoss: 0.0516\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0069\tTop_Loss: 0.0851\tBottom_Loss: 0.0138\tLoss: 0.1058\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0230\tTop_Loss: 0.0506\tBottom_Loss: 0.0239\tLoss: 0.0976\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0175\tTop_Loss: 0.0801\tBottom_Loss: 0.0288\tLoss: 0.1264\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0049\tTop_Loss: 0.0367\tBottom_Loss: 0.0223\tLoss: 0.0639\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0060\tTop_Loss: 0.0320\tBottom_Loss: 0.0223\tLoss: 0.0603\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0082\tTop_Loss: 0.1088\tBottom_Loss: 0.0200\tLoss: 0.1370\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0055\tTop_Loss: 0.0295\tBottom_Loss: 0.0182\tLoss: 0.0532\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0081\tTop_Loss: 0.0505\tBottom_Loss: 0.0472\tLoss: 0.1057\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0199\tTop_Loss: 0.0290\tBottom_Loss: 0.0767\tLoss: 0.1255\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0114\tTop_Loss: 0.0266\tBottom_Loss: 0.0165\tLoss: 0.0545\t\n",
      "Subject: 01, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0060\tTop_Loss: 0.0245\tBottom_Loss: 0.0206\tLoss: 0.0510\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0048\tTop_Loss: 0.0185\tBottom_Loss: 0.0214\tLoss: 0.0447\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0246\tTop_Loss: 0.0551\tBottom_Loss: 0.0634\tLoss: 0.1430\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0056\tTop_Loss: 0.0252\tBottom_Loss: 0.0223\tLoss: 0.0531\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0033\tTop_Loss: 0.0494\tBottom_Loss: 0.0109\tLoss: 0.0636\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0213\tTop_Loss: 0.0413\tBottom_Loss: 0.0344\tLoss: 0.0971\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0049\tTop_Loss: 0.0329\tBottom_Loss: 0.0126\tLoss: 0.0504\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0063\tTop_Loss: 0.0558\tBottom_Loss: 0.0330\tLoss: 0.0951\t\n",
      "Subject: 01, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.375\tLabel_Loss: 1.2253\tTop_Loss: 1.5999\tBottom_Loss: 2.3024\tLoss: 5.1276\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.406\tLabel_Loss: 1.6382\tTop_Loss: 1.2892\tBottom_Loss: 1.2658\tLoss: 4.1932\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.500\tLabel_Loss: 1.0659\tTop_Loss: 1.0446\tBottom_Loss: 1.0594\tLoss: 3.1698\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.500\tLabel_Loss: 1.2628\tTop_Loss: 1.0982\tBottom_Loss: 1.0283\tLoss: 3.3892\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.656\tLabel_Loss: 0.8275\tTop_Loss: 1.0553\tBottom_Loss: 0.8296\tLoss: 2.7124\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8470\tTop_Loss: 0.9543\tBottom_Loss: 0.8736\tLoss: 2.6750\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7503\tTop_Loss: 0.7984\tBottom_Loss: 0.7177\tLoss: 2.2664\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.625\tLabel_Loss: 0.9429\tTop_Loss: 0.8198\tBottom_Loss: 0.9057\tLoss: 2.6684\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.562\tLabel_Loss: 0.9017\tTop_Loss: 0.9252\tBottom_Loss: 1.0275\tLoss: 2.8545\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.594\tLabel_Loss: 0.9650\tTop_Loss: 1.0659\tBottom_Loss: 0.8872\tLoss: 2.9181\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.594\tLabel_Loss: 0.9758\tTop_Loss: 1.0810\tBottom_Loss: 1.1277\tLoss: 3.1846\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.656\tLabel_Loss: 0.8133\tTop_Loss: 0.7527\tBottom_Loss: 0.8498\tLoss: 2.4159\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6876\tTop_Loss: 0.7618\tBottom_Loss: 0.8755\tLoss: 2.3249\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6766\tTop_Loss: 0.6651\tBottom_Loss: 0.7434\tLoss: 2.0851\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.531\tLabel_Loss: 0.9755\tTop_Loss: 0.8593\tBottom_Loss: 0.7208\tLoss: 2.5556\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.562\tLabel_Loss: 0.8241\tTop_Loss: 0.7749\tBottom_Loss: 0.7821\tLoss: 2.3811\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.500\tLabel_Loss: 1.1263\tTop_Loss: 0.9449\tBottom_Loss: 0.9209\tLoss: 2.9921\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8566\tTop_Loss: 0.8778\tBottom_Loss: 1.0043\tLoss: 2.7387\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7141\tTop_Loss: 0.7762\tBottom_Loss: 0.6717\tLoss: 2.1619\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7381\tTop_Loss: 0.7857\tBottom_Loss: 0.7630\tLoss: 2.2868\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5425\tTop_Loss: 0.6646\tBottom_Loss: 0.6653\tLoss: 1.8724\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7925\tTop_Loss: 0.8047\tBottom_Loss: 0.8787\tLoss: 2.4759\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7081\tTop_Loss: 0.8410\tBottom_Loss: 0.9134\tLoss: 2.4625\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5880\tTop_Loss: 0.7803\tBottom_Loss: 0.7440\tLoss: 2.1122\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6352\tTop_Loss: 0.6781\tBottom_Loss: 0.6964\tLoss: 2.0097\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6806\tTop_Loss: 0.7601\tBottom_Loss: 0.7111\tLoss: 2.1519\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5639\tTop_Loss: 0.7531\tBottom_Loss: 0.7168\tLoss: 2.0338\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.781\tLabel_Loss: 0.6001\tTop_Loss: 0.6685\tBottom_Loss: 0.6891\tLoss: 1.9577\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6642\tTop_Loss: 0.6711\tBottom_Loss: 0.7395\tLoss: 2.0748\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4502\tTop_Loss: 0.7506\tBottom_Loss: 0.6727\tLoss: 1.8736\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5599\tTop_Loss: 0.7871\tBottom_Loss: 0.6852\tLoss: 2.0322\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3770\tTop_Loss: 0.6492\tBottom_Loss: 0.4437\tLoss: 1.4699\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5469\tTop_Loss: 0.8041\tBottom_Loss: 0.6484\tLoss: 1.9994\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6380\tTop_Loss: 0.9568\tBottom_Loss: 0.6455\tLoss: 2.2403\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5447\tTop_Loss: 0.6368\tBottom_Loss: 0.6398\tLoss: 1.8213\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6826\tTop_Loss: 0.6805\tBottom_Loss: 0.9218\tLoss: 2.2849\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6179\tTop_Loss: 0.7868\tBottom_Loss: 0.7595\tLoss: 2.1643\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5443\tTop_Loss: 0.6385\tBottom_Loss: 0.6649\tLoss: 1.8477\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3911\tTop_Loss: 0.5511\tBottom_Loss: 0.5526\tLoss: 1.4947\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6301\tTop_Loss: 0.7774\tBottom_Loss: 0.5432\tLoss: 1.9506\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.875\tLabel_Loss: 0.5061\tTop_Loss: 0.7178\tBottom_Loss: 0.5135\tLoss: 1.7374\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4920\tTop_Loss: 0.6033\tBottom_Loss: 0.6003\tLoss: 1.6956\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4725\tTop_Loss: 0.6798\tBottom_Loss: 0.5905\tLoss: 1.7429\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.750\tLabel_Loss: 0.4500\tTop_Loss: 0.6034\tBottom_Loss: 0.5558\tLoss: 1.6091\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5351\tTop_Loss: 0.7206\tBottom_Loss: 0.6195\tLoss: 1.8752\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3819\tTop_Loss: 0.5973\tBottom_Loss: 0.4256\tLoss: 1.4048\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5536\tTop_Loss: 0.5332\tBottom_Loss: 0.6807\tLoss: 1.7675\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4419\tTop_Loss: 0.8188\tBottom_Loss: 0.4890\tLoss: 1.7496\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.688\tLabel_Loss: 0.5766\tTop_Loss: 0.8371\tBottom_Loss: 0.5544\tLoss: 1.9681\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3429\tTop_Loss: 0.5635\tBottom_Loss: 0.4507\tLoss: 1.3572\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2251\tTop_Loss: 0.3888\tBottom_Loss: 0.2712\tLoss: 0.8851\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3569\tTop_Loss: 0.5268\tBottom_Loss: 0.4862\tLoss: 1.3699\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4024\tTop_Loss: 0.5063\tBottom_Loss: 0.5366\tLoss: 1.4453\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2577\tTop_Loss: 0.4243\tBottom_Loss: 0.5122\tLoss: 1.1943\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2613\tTop_Loss: 0.3996\tBottom_Loss: 0.4317\tLoss: 1.0926\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2404\tTop_Loss: 0.6213\tBottom_Loss: 0.2907\tLoss: 1.1524\t\n",
      "Subject: 010, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.969\tLabel_Loss: 0.3325\tTop_Loss: 0.5248\tBottom_Loss: 0.5796\tLoss: 1.4370\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4281\tTop_Loss: 0.5148\tBottom_Loss: 0.4799\tLoss: 1.4227\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2825\tTop_Loss: 0.3807\tBottom_Loss: 0.3181\tLoss: 0.9813\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3253\tTop_Loss: 0.4509\tBottom_Loss: 0.4433\tLoss: 1.2195\t\n",
      "Subject: 010, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2890\tTop_Loss: 0.3030\tBottom_Loss: 0.4838\tLoss: 1.0758\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3228\tTop_Loss: 0.6029\tBottom_Loss: 0.3827\tLoss: 1.3084\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.969\tLabel_Loss: 0.3003\tTop_Loss: 0.5363\tBottom_Loss: 0.3439\tLoss: 1.1805\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3179\tTop_Loss: 0.4820\tBottom_Loss: 0.4227\tLoss: 1.2227\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.844\tLabel_Loss: 0.2876\tTop_Loss: 0.4955\tBottom_Loss: 0.3738\tLoss: 1.1568\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2190\tTop_Loss: 0.3358\tBottom_Loss: 0.3754\tLoss: 0.9302\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2435\tTop_Loss: 0.4413\tBottom_Loss: 0.3931\tLoss: 1.0779\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2288\tTop_Loss: 0.4709\tBottom_Loss: 0.2778\tLoss: 0.9775\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2435\tTop_Loss: 0.5179\tBottom_Loss: 0.2753\tLoss: 1.0367\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3189\tTop_Loss: 0.3611\tBottom_Loss: 0.3407\tLoss: 1.0207\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2321\tTop_Loss: 0.5317\tBottom_Loss: 0.3887\tLoss: 1.1524\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1977\tTop_Loss: 0.3794\tBottom_Loss: 0.2683\tLoss: 0.8454\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1789\tTop_Loss: 0.3245\tBottom_Loss: 0.2593\tLoss: 0.7627\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2445\tTop_Loss: 0.4154\tBottom_Loss: 0.3212\tLoss: 0.9810\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2377\tTop_Loss: 0.3220\tBottom_Loss: 0.2877\tLoss: 0.8475\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2593\tTop_Loss: 0.3646\tBottom_Loss: 0.2684\tLoss: 0.8923\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1975\tTop_Loss: 0.4386\tBottom_Loss: 0.3031\tLoss: 0.9392\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2185\tTop_Loss: 0.4163\tBottom_Loss: 0.2699\tLoss: 0.9047\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1545\tTop_Loss: 0.2837\tBottom_Loss: 0.3087\tLoss: 0.7469\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1802\tTop_Loss: 0.4485\tBottom_Loss: 0.2658\tLoss: 0.8945\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1523\tTop_Loss: 0.4011\tBottom_Loss: 0.2939\tLoss: 0.8472\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2422\tTop_Loss: 0.3549\tBottom_Loss: 0.2310\tLoss: 0.8281\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1273\tTop_Loss: 0.2831\tBottom_Loss: 0.2074\tLoss: 0.6179\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1150\tTop_Loss: 0.2858\tBottom_Loss: 0.2262\tLoss: 0.6271\t\n",
      "Subject: 010, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1427\tTop_Loss: 0.2923\tBottom_Loss: 0.2130\tLoss: 0.6479\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2284\tTop_Loss: 0.3318\tBottom_Loss: 0.2403\tLoss: 0.8006\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1258\tTop_Loss: 0.3269\tBottom_Loss: 0.1717\tLoss: 0.6244\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1996\tTop_Loss: 0.5536\tBottom_Loss: 0.2748\tLoss: 1.0280\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1228\tTop_Loss: 0.3359\tBottom_Loss: 0.1610\tLoss: 0.6197\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1686\tTop_Loss: 0.3937\tBottom_Loss: 0.2909\tLoss: 0.8531\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0768\tTop_Loss: 0.2283\tBottom_Loss: 0.2187\tLoss: 0.5238\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1718\tTop_Loss: 0.2517\tBottom_Loss: 0.2535\tLoss: 0.6769\t\n",
      "Subject: 010, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1026\tTop_Loss: 0.1944\tBottom_Loss: 0.2022\tLoss: 0.4993\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1841\tTop_Loss: 0.3363\tBottom_Loss: 0.2303\tLoss: 0.7507\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1167\tTop_Loss: 0.2966\tBottom_Loss: 0.1941\tLoss: 0.6073\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0881\tTop_Loss: 0.1678\tBottom_Loss: 0.1138\tLoss: 0.3697\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1720\tTop_Loss: 0.3072\tBottom_Loss: 0.3062\tLoss: 0.7854\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0847\tTop_Loss: 0.1363\tBottom_Loss: 0.1778\tLoss: 0.3988\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1220\tTop_Loss: 0.1987\tBottom_Loss: 0.1840\tLoss: 0.5047\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2332\tTop_Loss: 0.4813\tBottom_Loss: 0.1372\tLoss: 0.8516\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1100\tTop_Loss: 0.3103\tBottom_Loss: 0.1395\tLoss: 0.5598\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1456\tTop_Loss: 0.2872\tBottom_Loss: 0.2167\tLoss: 0.6495\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0658\tTop_Loss: 0.1703\tBottom_Loss: 0.1291\tLoss: 0.3651\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0821\tTop_Loss: 0.1883\tBottom_Loss: 0.1368\tLoss: 0.4072\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0594\tTop_Loss: 0.1895\tBottom_Loss: 0.2585\tLoss: 0.5074\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0910\tTop_Loss: 0.2605\tBottom_Loss: 0.1855\tLoss: 0.5370\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0920\tTop_Loss: 0.2306\tBottom_Loss: 0.1730\tLoss: 0.4956\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0787\tTop_Loss: 0.2147\tBottom_Loss: 0.2115\tLoss: 0.5049\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0423\tTop_Loss: 0.1506\tBottom_Loss: 0.1178\tLoss: 0.3107\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1371\tTop_Loss: 0.2310\tBottom_Loss: 0.1849\tLoss: 0.5530\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1147\tTop_Loss: 0.2709\tBottom_Loss: 0.1180\tLoss: 0.5036\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0763\tTop_Loss: 0.2745\tBottom_Loss: 0.1042\tLoss: 0.4550\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1081\tTop_Loss: 0.1981\tBottom_Loss: 0.1336\tLoss: 0.4398\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0596\tTop_Loss: 0.2823\tBottom_Loss: 0.0724\tLoss: 0.4143\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1354\tTop_Loss: 0.2222\tBottom_Loss: 0.1427\tLoss: 0.5003\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1113\tTop_Loss: 0.2997\tBottom_Loss: 0.1205\tLoss: 0.5314\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0258\tTop_Loss: 0.1591\tBottom_Loss: 0.0583\tLoss: 0.2432\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0880\tTop_Loss: 0.2378\tBottom_Loss: 0.1805\tLoss: 0.5062\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1486\tTop_Loss: 0.3155\tBottom_Loss: 0.1553\tLoss: 0.6194\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0772\tTop_Loss: 0.2083\tBottom_Loss: 0.1270\tLoss: 0.4125\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0589\tTop_Loss: 0.1824\tBottom_Loss: 0.1058\tLoss: 0.3470\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0846\tTop_Loss: 0.2924\tBottom_Loss: 0.1407\tLoss: 0.5177\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0272\tTop_Loss: 0.0956\tBottom_Loss: 0.1044\tLoss: 0.2271\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0547\tTop_Loss: 0.2372\tBottom_Loss: 0.0760\tLoss: 0.3679\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0358\tTop_Loss: 0.1346\tBottom_Loss: 0.1471\tLoss: 0.3176\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0503\tTop_Loss: 0.1374\tBottom_Loss: 0.1214\tLoss: 0.3091\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0801\tTop_Loss: 0.2553\tBottom_Loss: 0.2110\tLoss: 0.5465\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0573\tTop_Loss: 0.1803\tBottom_Loss: 0.1063\tLoss: 0.3439\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0366\tTop_Loss: 0.1083\tBottom_Loss: 0.0627\tLoss: 0.2076\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0437\tTop_Loss: 0.1725\tBottom_Loss: 0.0843\tLoss: 0.3005\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0322\tTop_Loss: 0.0856\tBottom_Loss: 0.0647\tLoss: 0.1825\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0395\tTop_Loss: 0.1365\tBottom_Loss: 0.0883\tLoss: 0.2643\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0730\tTop_Loss: 0.1947\tBottom_Loss: 0.0954\tLoss: 0.3631\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0739\tTop_Loss: 0.1173\tBottom_Loss: 0.1019\tLoss: 0.2931\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1455\tTop_Loss: 0.1695\tBottom_Loss: 0.2190\tLoss: 0.5340\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0813\tTop_Loss: 0.2264\tBottom_Loss: 0.1403\tLoss: 0.4481\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0709\tTop_Loss: 0.2285\tBottom_Loss: 0.1049\tLoss: 0.4043\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0514\tTop_Loss: 0.1248\tBottom_Loss: 0.1081\tLoss: 0.2843\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0399\tTop_Loss: 0.1694\tBottom_Loss: 0.0926\tLoss: 0.3019\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0308\tTop_Loss: 0.1723\tBottom_Loss: 0.0400\tLoss: 0.2431\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0585\tTop_Loss: 0.1541\tBottom_Loss: 0.1016\tLoss: 0.3141\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0508\tTop_Loss: 0.0778\tBottom_Loss: 0.0575\tLoss: 0.1861\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0307\tTop_Loss: 0.1058\tBottom_Loss: 0.0895\tLoss: 0.2260\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0382\tTop_Loss: 0.1043\tBottom_Loss: 0.0493\tLoss: 0.1918\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0239\tTop_Loss: 0.1293\tBottom_Loss: 0.0639\tLoss: 0.2171\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0572\tTop_Loss: 0.1515\tBottom_Loss: 0.1588\tLoss: 0.3674\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0398\tTop_Loss: 0.0994\tBottom_Loss: 0.0619\tLoss: 0.2011\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0186\tTop_Loss: 0.1012\tBottom_Loss: 0.0446\tLoss: 0.1644\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0331\tTop_Loss: 0.0737\tBottom_Loss: 0.0547\tLoss: 0.1615\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0705\tTop_Loss: 0.1298\tBottom_Loss: 0.0462\tLoss: 0.2465\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0900\tTop_Loss: 0.2815\tBottom_Loss: 0.1114\tLoss: 0.4829\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0711\tTop_Loss: 0.2999\tBottom_Loss: 0.0706\tLoss: 0.4415\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1087\tTop_Loss: 0.1212\tBottom_Loss: 0.0995\tLoss: 0.3293\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0358\tTop_Loss: 0.1185\tBottom_Loss: 0.1483\tLoss: 0.3026\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0236\tTop_Loss: 0.1327\tBottom_Loss: 0.0561\tLoss: 0.2125\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0295\tTop_Loss: 0.0986\tBottom_Loss: 0.0647\tLoss: 0.1928\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0269\tTop_Loss: 0.0690\tBottom_Loss: 0.0711\tLoss: 0.1670\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0821\tTop_Loss: 0.1004\tBottom_Loss: 0.0711\tLoss: 0.2537\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0449\tTop_Loss: 0.0829\tBottom_Loss: 0.0869\tLoss: 0.2147\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0131\tTop_Loss: 0.0393\tBottom_Loss: 0.0556\tLoss: 0.1080\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0250\tTop_Loss: 0.1125\tBottom_Loss: 0.0761\tLoss: 0.2136\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0116\tTop_Loss: 0.1013\tBottom_Loss: 0.0243\tLoss: 0.1372\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0477\tTop_Loss: 0.0618\tBottom_Loss: 0.0351\tLoss: 0.1445\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0302\tTop_Loss: 0.0651\tBottom_Loss: 0.1034\tLoss: 0.1987\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0119\tTop_Loss: 0.0374\tBottom_Loss: 0.0340\tLoss: 0.0833\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0187\tTop_Loss: 0.0354\tBottom_Loss: 0.0332\tLoss: 0.0873\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0241\tTop_Loss: 0.0634\tBottom_Loss: 0.0283\tLoss: 0.1158\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0098\tTop_Loss: 0.0410\tBottom_Loss: 0.0337\tLoss: 0.0845\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0291\tTop_Loss: 0.0616\tBottom_Loss: 0.0379\tLoss: 0.1285\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0355\tTop_Loss: 0.0482\tBottom_Loss: 0.0407\tLoss: 0.1244\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0421\tTop_Loss: 0.0884\tBottom_Loss: 0.0587\tLoss: 0.1891\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0225\tTop_Loss: 0.0573\tBottom_Loss: 0.0336\tLoss: 0.1134\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0244\tTop_Loss: 0.1402\tBottom_Loss: 0.0345\tLoss: 0.1992\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0060\tTop_Loss: 0.0338\tBottom_Loss: 0.0187\tLoss: 0.0585\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0092\tTop_Loss: 0.0495\tBottom_Loss: 0.0594\tLoss: 0.1181\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0343\tTop_Loss: 0.1302\tBottom_Loss: 0.0495\tLoss: 0.2141\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0332\tTop_Loss: 0.0732\tBottom_Loss: 0.0581\tLoss: 0.1644\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0410\tTop_Loss: 0.1154\tBottom_Loss: 0.1001\tLoss: 0.2566\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0889\tTop_Loss: 0.1719\tBottom_Loss: 0.0489\tLoss: 0.3096\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1089\tTop_Loss: 0.1345\tBottom_Loss: 0.0739\tLoss: 0.3172\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0368\tTop_Loss: 0.0977\tBottom_Loss: 0.0755\tLoss: 0.2100\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0111\tTop_Loss: 0.0673\tBottom_Loss: 0.0284\tLoss: 0.1068\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0303\tTop_Loss: 0.0684\tBottom_Loss: 0.1045\tLoss: 0.2033\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0288\tTop_Loss: 0.1487\tBottom_Loss: 0.0737\tLoss: 0.2512\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0246\tTop_Loss: 0.0536\tBottom_Loss: 0.0952\tLoss: 0.1734\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0066\tTop_Loss: 0.0260\tBottom_Loss: 0.0386\tLoss: 0.0712\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0198\tTop_Loss: 0.0412\tBottom_Loss: 0.0372\tLoss: 0.0983\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0170\tTop_Loss: 0.0619\tBottom_Loss: 0.0251\tLoss: 0.1040\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0121\tTop_Loss: 0.0293\tBottom_Loss: 0.0345\tLoss: 0.0759\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0138\tTop_Loss: 0.0938\tBottom_Loss: 0.0364\tLoss: 0.1441\t\n",
      "Subject: 010, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0098\tTop_Loss: 0.0364\tBottom_Loss: 0.0410\tLoss: 0.0873\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0212\tTop_Loss: 0.0782\tBottom_Loss: 0.0464\tLoss: 0.1458\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0057\tTop_Loss: 0.0351\tBottom_Loss: 0.0239\tLoss: 0.0647\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0097\tTop_Loss: 0.0394\tBottom_Loss: 0.0288\tLoss: 0.0778\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0122\tTop_Loss: 0.0202\tBottom_Loss: 0.0133\tLoss: 0.0457\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0182\tTop_Loss: 0.0271\tBottom_Loss: 0.0474\tLoss: 0.0927\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0253\tTop_Loss: 0.0825\tBottom_Loss: 0.0292\tLoss: 0.1369\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0236\tTop_Loss: 0.0911\tBottom_Loss: 0.0496\tLoss: 0.1643\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0161\tTop_Loss: 0.0675\tBottom_Loss: 0.0341\tLoss: 0.1177\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0117\tTop_Loss: 0.0209\tBottom_Loss: 0.0687\tLoss: 0.1013\t\n",
      "Subject: 010, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.469\tLabel_Loss: 1.1992\tTop_Loss: 1.1696\tBottom_Loss: 1.7283\tLoss: 4.0971\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.562\tLabel_Loss: 0.9439\tTop_Loss: 1.0019\tBottom_Loss: 0.9841\tLoss: 2.9299\t\n",
      "Subject: 011, n=20 | test_f1: 0.39394 |best_f1: 0.39394\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.438\tLabel_Loss: 1.1817\tTop_Loss: 1.2267\tBottom_Loss: 1.1899\tLoss: 3.5983\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.406\tLabel_Loss: 1.3721\tTop_Loss: 1.1400\tBottom_Loss: 1.3858\tLoss: 3.8979\t\n",
      "Subject: 011, n=20 | test_f1: 0.39394 |best_f1: 0.39394\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.500\tLabel_Loss: 1.0359\tTop_Loss: 1.1625\tBottom_Loss: 1.3804\tLoss: 3.5788\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.406\tLabel_Loss: 0.9820\tTop_Loss: 0.9811\tBottom_Loss: 0.9505\tLoss: 2.9137\t\n",
      "Subject: 011, n=20 | test_f1: 0.39394 |best_f1: 0.39394\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.594\tLabel_Loss: 0.9116\tTop_Loss: 0.8914\tBottom_Loss: 0.9549\tLoss: 2.7579\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.656\tLabel_Loss: 0.8814\tTop_Loss: 0.9037\tBottom_Loss: 0.8727\tLoss: 2.6577\t\n",
      "Subject: 011, n=20 | test_f1: 0.27083 |best_f1: 0.39394\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.562\tLabel_Loss: 0.9132\tTop_Loss: 0.8873\tBottom_Loss: 0.9808\tLoss: 2.7813\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.500\tLabel_Loss: 0.9257\tTop_Loss: 0.9342\tBottom_Loss: 1.0739\tLoss: 2.9338\t\n",
      "Subject: 011, n=20 | test_f1: 0.39394 |best_f1: 0.39394\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7586\tTop_Loss: 0.8375\tBottom_Loss: 0.8851\tLoss: 2.4812\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6689\tTop_Loss: 0.8220\tBottom_Loss: 0.7376\tLoss: 2.2284\t\n",
      "Subject: 011, n=20 | test_f1: 0.39394 |best_f1: 0.39394\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.750\tLabel_Loss: 0.7060\tTop_Loss: 0.8112\tBottom_Loss: 0.7288\tLoss: 2.2459\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.719\tLabel_Loss: 0.8034\tTop_Loss: 0.8139\tBottom_Loss: 0.7471\tLoss: 2.3644\t\n",
      "Subject: 011, n=20 | test_f1: 0.39394 |best_f1: 0.39394\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.562\tLabel_Loss: 0.9772\tTop_Loss: 0.9489\tBottom_Loss: 0.9951\tLoss: 2.9212\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8921\tTop_Loss: 0.9438\tBottom_Loss: 0.9534\tLoss: 2.7892\t\n",
      "Subject: 011, n=20 | test_f1: 0.27083 |best_f1: 0.39394\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.531\tLabel_Loss: 0.8726\tTop_Loss: 1.0673\tBottom_Loss: 0.9014\tLoss: 2.8412\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7143\tTop_Loss: 0.7678\tBottom_Loss: 0.8660\tLoss: 2.3482\t\n",
      "Subject: 011, n=20 | test_f1: 0.39394 |best_f1: 0.39394\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.656\tLabel_Loss: 0.8859\tTop_Loss: 0.7928\tBottom_Loss: 1.0175\tLoss: 2.6962\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.750\tLabel_Loss: 0.7052\tTop_Loss: 0.7958\tBottom_Loss: 0.7633\tLoss: 2.2644\t\n",
      "Subject: 011, n=20 | test_f1: 0.39394 |best_f1: 0.39394\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.562\tLabel_Loss: 0.8226\tTop_Loss: 0.9097\tBottom_Loss: 0.7681\tLoss: 2.5004\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7827\tTop_Loss: 0.6846\tBottom_Loss: 0.8577\tLoss: 2.3251\t\n",
      "Subject: 011, n=20 | test_f1: 0.39394 |best_f1: 0.39394\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6678\tTop_Loss: 0.7045\tBottom_Loss: 0.8667\tLoss: 2.2390\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4897\tTop_Loss: 0.5801\tBottom_Loss: 0.5757\tLoss: 1.6455\t\n",
      "Subject: 011, n=20 | test_f1: 0.53125 |best_f1: 0.53125\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.844\tLabel_Loss: 0.5204\tTop_Loss: 0.6037\tBottom_Loss: 0.8075\tLoss: 1.9316\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.812\tLabel_Loss: 0.6307\tTop_Loss: 0.8585\tBottom_Loss: 0.7090\tLoss: 2.1983\t\n",
      "Subject: 011, n=20 | test_f1: 0.39394 |best_f1: 0.53125\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7898\tTop_Loss: 0.7898\tBottom_Loss: 0.7912\tLoss: 2.3707\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.688\tLabel_Loss: 0.5937\tTop_Loss: 0.5092\tBottom_Loss: 0.7745\tLoss: 1.8774\t\n",
      "Subject: 011, n=20 | test_f1: 0.23656 |best_f1: 0.53125\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4370\tTop_Loss: 0.5160\tBottom_Loss: 0.6367\tLoss: 1.5896\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4813\tTop_Loss: 0.6026\tBottom_Loss: 0.6507\tLoss: 1.7346\t\n",
      "Subject: 011, n=20 | test_f1: 0.39394 |best_f1: 0.53125\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.938\tLabel_Loss: 0.3382\tTop_Loss: 0.5327\tBottom_Loss: 0.4756\tLoss: 1.3465\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7150\tTop_Loss: 0.8839\tBottom_Loss: 0.7266\tLoss: 2.3255\t\n",
      "Subject: 011, n=20 | test_f1: 0.27957 |best_f1: 0.53125\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6066\tTop_Loss: 0.8146\tBottom_Loss: 0.8585\tLoss: 2.2797\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6700\tTop_Loss: 0.8321\tBottom_Loss: 0.6301\tLoss: 2.1322\t\n",
      "Subject: 011, n=20 | test_f1: 0.27957 |best_f1: 0.53125\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7733\tTop_Loss: 0.7085\tBottom_Loss: 0.8662\tLoss: 2.3481\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6642\tTop_Loss: 0.6551\tBottom_Loss: 0.7687\tLoss: 2.0880\t\n",
      "Subject: 011, n=20 | test_f1: 0.25 |best_f1: 0.53125\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3766\tTop_Loss: 0.4304\tBottom_Loss: 0.5642\tLoss: 1.3713\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5733\tTop_Loss: 0.5824\tBottom_Loss: 0.4487\tLoss: 1.6044\t\n",
      "Subject: 011, n=20 | test_f1: 0.27083 |best_f1: 0.53125\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4900\tTop_Loss: 0.5731\tBottom_Loss: 0.5137\tLoss: 1.5767\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.750\tLabel_Loss: 0.4948\tTop_Loss: 0.6620\tBottom_Loss: 0.6157\tLoss: 1.7725\t\n",
      "Subject: 011, n=20 | test_f1: 0.25 |best_f1: 0.53125\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3937\tTop_Loss: 0.5194\tBottom_Loss: 0.5159\tLoss: 1.4290\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.938\tLabel_Loss: 0.3779\tTop_Loss: 0.5950\tBottom_Loss: 0.5131\tLoss: 1.4859\t\n",
      "Subject: 011, n=20 | test_f1: 0.25806 |best_f1: 0.53125\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3541\tTop_Loss: 0.4397\tBottom_Loss: 0.4383\tLoss: 1.2321\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.594\tLabel_Loss: 0.7149\tTop_Loss: 0.9521\tBottom_Loss: 0.7117\tLoss: 2.3788\t\n",
      "Subject: 011, n=20 | test_f1: 0.27957 |best_f1: 0.53125\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3679\tTop_Loss: 0.5180\tBottom_Loss: 0.5572\tLoss: 1.4431\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3882\tTop_Loss: 0.5216\tBottom_Loss: 0.5483\tLoss: 1.4581\t\n",
      "Subject: 011, n=20 | test_f1: 0.39394 |best_f1: 0.53125\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5353\tTop_Loss: 0.6559\tBottom_Loss: 0.6872\tLoss: 1.8784\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6020\tTop_Loss: 0.7100\tBottom_Loss: 0.6591\tLoss: 1.9711\t\n",
      "Subject: 011, n=20 | test_f1: 0.25806 |best_f1: 0.53125\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3628\tTop_Loss: 0.5077\tBottom_Loss: 0.4772\tLoss: 1.3477\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3977\tTop_Loss: 0.4404\tBottom_Loss: 0.5249\tLoss: 1.3631\t\n",
      "Subject: 011, n=20 | test_f1: 0.27957 |best_f1: 0.53125\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.656\tLabel_Loss: 0.5686\tTop_Loss: 0.6404\tBottom_Loss: 0.5767\tLoss: 1.7857\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2650\tTop_Loss: 0.4420\tBottom_Loss: 0.4696\tLoss: 1.1766\t\n",
      "Subject: 011, n=20 | test_f1: 0.27957 |best_f1: 0.53125\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2800\tTop_Loss: 0.5028\tBottom_Loss: 0.4096\tLoss: 1.1923\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4867\tTop_Loss: 0.5190\tBottom_Loss: 0.5737\tLoss: 1.5794\t\n",
      "Subject: 011, n=20 | test_f1: 0.27083 |best_f1: 0.53125\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3457\tTop_Loss: 0.4853\tBottom_Loss: 0.5137\tLoss: 1.3447\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2617\tTop_Loss: 0.3235\tBottom_Loss: 0.5033\tLoss: 1.0885\t\n",
      "Subject: 011, n=20 | test_f1: 0.27083 |best_f1: 0.53125\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3666\tTop_Loss: 0.5455\tBottom_Loss: 0.5048\tLoss: 1.4169\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3519\tTop_Loss: 0.4917\tBottom_Loss: 0.3094\tLoss: 1.1530\t\n",
      "Subject: 011, n=20 | test_f1: 0.27083 |best_f1: 0.53125\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2799\tTop_Loss: 0.4186\tBottom_Loss: 0.4963\tLoss: 1.1948\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4583\tTop_Loss: 0.6145\tBottom_Loss: 0.4809\tLoss: 1.5536\t\n",
      "Subject: 011, n=20 | test_f1: 0.27083 |best_f1: 0.53125\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.781\tLabel_Loss: 0.3931\tTop_Loss: 0.4811\tBottom_Loss: 0.5353\tLoss: 1.4096\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2274\tTop_Loss: 0.4583\tBottom_Loss: 0.3683\tLoss: 1.0539\t\n",
      "Subject: 011, n=20 | test_f1: 0.25806 |best_f1: 0.53125\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3040\tTop_Loss: 0.4423\tBottom_Loss: 0.3856\tLoss: 1.1319\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4220\tTop_Loss: 0.4773\tBottom_Loss: 0.6358\tLoss: 1.5351\t\n",
      "Subject: 011, n=20 | test_f1: 0.39394 |best_f1: 0.53125\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3817\tTop_Loss: 0.4502\tBottom_Loss: 0.4540\tLoss: 1.2859\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2967\tTop_Loss: 0.5667\tBottom_Loss: 0.3723\tLoss: 1.2357\t\n",
      "Subject: 011, n=20 | test_f1: 0.27083 |best_f1: 0.53125\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4532\tTop_Loss: 0.4206\tBottom_Loss: 0.4967\tLoss: 1.3704\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2332\tTop_Loss: 0.3966\tBottom_Loss: 0.4156\tLoss: 1.0455\t\n",
      "Subject: 011, n=20 | test_f1: 0.27083 |best_f1: 0.53125\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1612\tTop_Loss: 0.3579\tBottom_Loss: 0.3675\tLoss: 0.8866\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2425\tTop_Loss: 0.5020\tBottom_Loss: 0.3906\tLoss: 1.1351\t\n",
      "Subject: 011, n=20 | test_f1: 0.27083 |best_f1: 0.53125\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2933\tTop_Loss: 0.3517\tBottom_Loss: 0.5477\tLoss: 1.1927\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3536\tTop_Loss: 0.5373\tBottom_Loss: 0.4366\tLoss: 1.3275\t\n",
      "Subject: 011, n=20 | test_f1: 0.27957 |best_f1: 0.53125\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2613\tTop_Loss: 0.3590\tBottom_Loss: 0.4461\tLoss: 1.0663\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2880\tTop_Loss: 0.5528\tBottom_Loss: 0.3879\tLoss: 1.2288\t\n",
      "Subject: 011, n=20 | test_f1: 0.27957 |best_f1: 0.53125\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2953\tTop_Loss: 0.4708\tBottom_Loss: 0.2582\tLoss: 1.0243\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1126\tTop_Loss: 0.1888\tBottom_Loss: 0.3824\tLoss: 0.6837\t\n",
      "Subject: 011, n=20 | test_f1: 0.53125 |best_f1: 0.53125\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1912\tTop_Loss: 0.3507\tBottom_Loss: 0.2887\tLoss: 0.8306\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2673\tTop_Loss: 0.4365\tBottom_Loss: 0.5539\tLoss: 1.2577\t\n",
      "Subject: 011, n=20 | test_f1: 0.25806 |best_f1: 0.53125\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2814\tTop_Loss: 0.5098\tBottom_Loss: 0.3067\tLoss: 1.0979\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1256\tTop_Loss: 0.2327\tBottom_Loss: 0.2796\tLoss: 0.6379\t\n",
      "Subject: 011, n=20 | test_f1: 0.27083 |best_f1: 0.53125\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1866\tTop_Loss: 0.3571\tBottom_Loss: 0.1565\tLoss: 0.7002\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1497\tTop_Loss: 0.3216\tBottom_Loss: 0.2352\tLoss: 0.7065\t\n",
      "Subject: 011, n=20 | test_f1: 0.39394 |best_f1: 0.53125\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1571\tTop_Loss: 0.2826\tBottom_Loss: 0.3122\tLoss: 0.7519\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3510\tTop_Loss: 0.5258\tBottom_Loss: 0.2814\tLoss: 1.1582\t\n",
      "Subject: 011, n=20 | test_f1: 0.27957 |best_f1: 0.53125\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2052\tTop_Loss: 0.2736\tBottom_Loss: 0.2947\tLoss: 0.7735\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1402\tTop_Loss: 0.2758\tBottom_Loss: 0.1873\tLoss: 0.6033\t\n",
      "Subject: 011, n=20 | test_f1: 0.27957 |best_f1: 0.53125\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1885\tTop_Loss: 0.4002\tBottom_Loss: 0.3002\tLoss: 0.8889\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1705\tTop_Loss: 0.4658\tBottom_Loss: 0.3103\tLoss: 0.9466\t\n",
      "Subject: 011, n=20 | test_f1: 0.27083 |best_f1: 0.53125\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1258\tTop_Loss: 0.3580\tBottom_Loss: 0.1625\tLoss: 0.6463\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2217\tTop_Loss: 0.3068\tBottom_Loss: 0.2264\tLoss: 0.7550\t\n",
      "Subject: 011, n=20 | test_f1: 0.39394 |best_f1: 0.53125\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2132\tTop_Loss: 0.3516\tBottom_Loss: 0.3386\tLoss: 0.9035\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1181\tTop_Loss: 0.2386\tBottom_Loss: 0.2268\tLoss: 0.5835\t\n",
      "Subject: 011, n=20 | test_f1: 0.25806 |best_f1: 0.53125\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1334\tTop_Loss: 0.3030\tBottom_Loss: 0.2507\tLoss: 0.6872\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1189\tTop_Loss: 0.3903\tBottom_Loss: 0.1810\tLoss: 0.6902\t\n",
      "Subject: 011, n=20 | test_f1: 0.39394 |best_f1: 0.53125\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1408\tTop_Loss: 0.2814\tBottom_Loss: 0.2254\tLoss: 0.6477\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2296\tTop_Loss: 0.3640\tBottom_Loss: 0.2479\tLoss: 0.8416\t\n",
      "Subject: 011, n=20 | test_f1: 0.39394 |best_f1: 0.53125\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1476\tTop_Loss: 0.2782\tBottom_Loss: 0.1915\tLoss: 0.6174\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2535\tTop_Loss: 0.3414\tBottom_Loss: 0.3514\tLoss: 0.9463\t\n",
      "Subject: 011, n=20 | test_f1: 0.39394 |best_f1: 0.53125\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1067\tTop_Loss: 0.2251\tBottom_Loss: 0.2092\tLoss: 0.5409\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1997\tTop_Loss: 0.3453\tBottom_Loss: 0.3205\tLoss: 0.8654\t\n",
      "Subject: 011, n=20 | test_f1: 0.27083 |best_f1: 0.53125\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1470\tTop_Loss: 0.2052\tBottom_Loss: 0.2298\tLoss: 0.5821\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1371\tTop_Loss: 0.3064\tBottom_Loss: 0.2629\tLoss: 0.7063\t\n",
      "Subject: 011, n=20 | test_f1: 0.39394 |best_f1: 0.53125\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0826\tTop_Loss: 0.2226\tBottom_Loss: 0.0862\tLoss: 0.3914\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0507\tTop_Loss: 0.2037\tBottom_Loss: 0.1028\tLoss: 0.3572\t\n",
      "Subject: 011, n=20 | test_f1: 0.27083 |best_f1: 0.53125\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0875\tTop_Loss: 0.2912\tBottom_Loss: 0.1348\tLoss: 0.5135\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2097\tTop_Loss: 0.2874\tBottom_Loss: 0.2787\tLoss: 0.7758\t\n",
      "Subject: 011, n=20 | test_f1: 0.27083 |best_f1: 0.53125\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1697\tTop_Loss: 0.2936\tBottom_Loss: 0.1911\tLoss: 0.6544\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0602\tTop_Loss: 0.1481\tBottom_Loss: 0.1641\tLoss: 0.3724\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 011, n=20 | test_f1: 0.27083 |best_f1: 0.53125\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0648\tTop_Loss: 0.1777\tBottom_Loss: 0.1503\tLoss: 0.3928\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0816\tTop_Loss: 0.1756\tBottom_Loss: 0.1797\tLoss: 0.4369\t\n",
      "Subject: 011, n=20 | test_f1: 0.3629 |best_f1: 0.53125\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0844\tTop_Loss: 0.2467\tBottom_Loss: 0.1868\tLoss: 0.5179\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1298\tTop_Loss: 0.2010\tBottom_Loss: 0.2064\tLoss: 0.5372\t\n",
      "Subject: 011, n=20 | test_f1: 0.39394 |best_f1: 0.53125\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1579\tTop_Loss: 0.2576\tBottom_Loss: 0.1957\tLoss: 0.6112\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0527\tTop_Loss: 0.2233\tBottom_Loss: 0.0738\tLoss: 0.3498\t\n",
      "Subject: 011, n=20 | test_f1: 0.39394 |best_f1: 0.53125\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0504\tTop_Loss: 0.1766\tBottom_Loss: 0.1510\tLoss: 0.3779\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0438\tTop_Loss: 0.1197\tBottom_Loss: 0.1256\tLoss: 0.2892\t\n",
      "Subject: 011, n=20 | test_f1: 0.27957 |best_f1: 0.53125\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0679\tTop_Loss: 0.1483\tBottom_Loss: 0.1905\tLoss: 0.4067\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1204\tTop_Loss: 0.2592\tBottom_Loss: 0.1667\tLoss: 0.5463\t\n",
      "Subject: 011, n=20 | test_f1: 0.27083 |best_f1: 0.53125\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0840\tTop_Loss: 0.2054\tBottom_Loss: 0.1684\tLoss: 0.4578\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1021\tTop_Loss: 0.2533\tBottom_Loss: 0.1494\tLoss: 0.5048\t\n",
      "Subject: 011, n=20 | test_f1: 0.26667 |best_f1: 0.53125\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1030\tTop_Loss: 0.1892\tBottom_Loss: 0.1811\tLoss: 0.4733\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2093\tTop_Loss: 0.2408\tBottom_Loss: 0.1962\tLoss: 0.6463\t\n",
      "Subject: 011, n=20 | test_f1: 0.25 |best_f1: 0.53125\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0550\tTop_Loss: 0.1766\tBottom_Loss: 0.1123\tLoss: 0.3440\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0349\tTop_Loss: 0.1295\tBottom_Loss: 0.0605\tLoss: 0.2249\t\n",
      "Subject: 011, n=20 | test_f1: 0.39394 |best_f1: 0.53125\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0496\tTop_Loss: 0.1447\tBottom_Loss: 0.1464\tLoss: 0.3406\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0322\tTop_Loss: 0.0789\tBottom_Loss: 0.0992\tLoss: 0.2103\t\n",
      "Subject: 011, n=20 | test_f1: 0.53125 |best_f1: 0.53125\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0855\tTop_Loss: 0.1436\tBottom_Loss: 0.1560\tLoss: 0.3852\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0260\tTop_Loss: 0.1131\tBottom_Loss: 0.0587\tLoss: 0.1978\t\n",
      "Subject: 011, n=20 | test_f1: 0.39394 |best_f1: 0.53125\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0947\tTop_Loss: 0.1196\tBottom_Loss: 0.1687\tLoss: 0.3830\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0695\tTop_Loss: 0.2310\tBottom_Loss: 0.1010\tLoss: 0.4015\t\n",
      "Subject: 011, n=20 | test_f1: 0.39394 |best_f1: 0.53125\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1334\tTop_Loss: 0.1439\tBottom_Loss: 0.2547\tLoss: 0.5320\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1201\tTop_Loss: 0.1969\tBottom_Loss: 0.1408\tLoss: 0.4578\t\n",
      "Subject: 011, n=20 | test_f1: 0.27083 |best_f1: 0.53125\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0964\tTop_Loss: 0.1680\tBottom_Loss: 0.1560\tLoss: 0.4204\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0459\tTop_Loss: 0.1348\tBottom_Loss: 0.1034\tLoss: 0.2841\t\n",
      "Subject: 011, n=20 | test_f1: 0.37222 |best_f1: 0.53125\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1103\tTop_Loss: 0.1569\tBottom_Loss: 0.1421\tLoss: 0.4093\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0416\tTop_Loss: 0.2402\tBottom_Loss: 0.1142\tLoss: 0.3960\t\n",
      "Subject: 011, n=20 | test_f1: 0.27083 |best_f1: 0.53125\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0701\tTop_Loss: 0.1838\tBottom_Loss: 0.1540\tLoss: 0.4079\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0743\tTop_Loss: 0.1012\tBottom_Loss: 0.0680\tLoss: 0.2435\t\n",
      "Subject: 011, n=20 | test_f1: 0.27083 |best_f1: 0.53125\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0152\tTop_Loss: 0.0967\tBottom_Loss: 0.0636\tLoss: 0.1756\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0884\tTop_Loss: 0.1134\tBottom_Loss: 0.1651\tLoss: 0.3669\t\n",
      "Subject: 011, n=20 | test_f1: 0.39394 |best_f1: 0.53125\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1043\tTop_Loss: 0.1942\tBottom_Loss: 0.1417\tLoss: 0.4402\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1623\tTop_Loss: 0.2610\tBottom_Loss: 0.1380\tLoss: 0.5613\t\n",
      "Subject: 011, n=20 | test_f1: 0.39394 |best_f1: 0.53125\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0767\tTop_Loss: 0.1138\tBottom_Loss: 0.1177\tLoss: 0.3082\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0642\tTop_Loss: 0.1606\tBottom_Loss: 0.0726\tLoss: 0.2973\t\n",
      "Subject: 011, n=20 | test_f1: 0.3629 |best_f1: 0.53125\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0221\tTop_Loss: 0.0891\tBottom_Loss: 0.0439\tLoss: 0.1551\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0342\tTop_Loss: 0.1382\tBottom_Loss: 0.0684\tLoss: 0.2408\t\n",
      "Subject: 011, n=20 | test_f1: 0.27586 |best_f1: 0.53125\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 0.938\tLabel_Loss: 0.0845\tTop_Loss: 0.1963\tBottom_Loss: 0.1586\tLoss: 0.4395\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0858\tTop_Loss: 0.1493\tBottom_Loss: 0.1062\tLoss: 0.3413\t\n",
      "Subject: 011, n=20 | test_f1: 0.27957 |best_f1: 0.53125\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0238\tTop_Loss: 0.0476\tBottom_Loss: 0.0821\tLoss: 0.1535\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0349\tTop_Loss: 0.0903\tBottom_Loss: 0.1275\tLoss: 0.2527\t\n",
      "Subject: 011, n=20 | test_f1: 0.27957 |best_f1: 0.53125\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0238\tTop_Loss: 0.0608\tBottom_Loss: 0.0622\tLoss: 0.1468\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0293\tTop_Loss: 0.1006\tBottom_Loss: 0.0708\tLoss: 0.2006\t\n",
      "Subject: 011, n=20 | test_f1: 0.3629 |best_f1: 0.53125\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0249\tTop_Loss: 0.0886\tBottom_Loss: 0.0779\tLoss: 0.1913\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0320\tTop_Loss: 0.1022\tBottom_Loss: 0.0538\tLoss: 0.1880\t\n",
      "Subject: 011, n=20 | test_f1: 0.28889 |best_f1: 0.53125\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0796\tTop_Loss: 0.2360\tBottom_Loss: 0.1463\tLoss: 0.4618\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0189\tTop_Loss: 0.0504\tBottom_Loss: 0.0809\tLoss: 0.1502\t\n",
      "Subject: 011, n=20 | test_f1: 0.27083 |best_f1: 0.53125\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1131\tTop_Loss: 0.1889\tBottom_Loss: 0.1312\tLoss: 0.4332\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0183\tTop_Loss: 0.1057\tBottom_Loss: 0.0381\tLoss: 0.1621\t\n",
      "Subject: 011, n=20 | test_f1: 0.53125 |best_f1: 0.53125\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0299\tTop_Loss: 0.0885\tBottom_Loss: 0.1093\tLoss: 0.2277\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0165\tTop_Loss: 0.0466\tBottom_Loss: 0.0567\tLoss: 0.1198\t\n",
      "Subject: 011, n=20 | test_f1: 0.39394 |best_f1: 0.53125\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0539\tTop_Loss: 0.1885\tBottom_Loss: 0.0581\tLoss: 0.3006\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0251\tTop_Loss: 0.1128\tBottom_Loss: 0.0491\tLoss: 0.1870\t\n",
      "Subject: 011, n=20 | test_f1: 0.25806 |best_f1: 0.53125\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0143\tTop_Loss: 0.0546\tBottom_Loss: 0.0351\tLoss: 0.1040\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0163\tTop_Loss: 0.0516\tBottom_Loss: 0.0370\tLoss: 0.1049\t\n",
      "Subject: 011, n=20 | test_f1: 0.39394 |best_f1: 0.53125\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0416\tTop_Loss: 0.0853\tBottom_Loss: 0.0966\tLoss: 0.2236\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0135\tTop_Loss: 0.0415\tBottom_Loss: 0.0419\tLoss: 0.0970\t\n",
      "Subject: 011, n=20 | test_f1: 0.27083 |best_f1: 0.53125\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0165\tTop_Loss: 0.0704\tBottom_Loss: 0.0459\tLoss: 0.1329\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0596\tTop_Loss: 0.1783\tBottom_Loss: 0.0940\tLoss: 0.3319\t\n",
      "Subject: 011, n=20 | test_f1: 0.53125 |best_f1: 0.53125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[84][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1734\tTop_Loss: 0.1985\tBottom_Loss: 0.1408\tLoss: 0.5127\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0119\tTop_Loss: 0.0544\tBottom_Loss: 0.0365\tLoss: 0.1027\t\n",
      "Subject: 011, n=20 | test_f1: 0.39394 |best_f1: 0.53125\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0323\tTop_Loss: 0.1240\tBottom_Loss: 0.0417\tLoss: 0.1979\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0235\tTop_Loss: 0.1042\tBottom_Loss: 0.0484\tLoss: 0.1761\t\n",
      "Subject: 011, n=20 | test_f1: 0.53125 |best_f1: 0.53125\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0128\tTop_Loss: 0.0509\tBottom_Loss: 0.0343\tLoss: 0.0980\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0147\tTop_Loss: 0.0552\tBottom_Loss: 0.0444\tLoss: 0.1142\t\n",
      "Subject: 011, n=20 | test_f1: 0.27083 |best_f1: 0.53125\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0086\tTop_Loss: 0.0626\tBottom_Loss: 0.0370\tLoss: 0.1081\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0327\tTop_Loss: 0.0682\tBottom_Loss: 0.0342\tLoss: 0.1351\t\n",
      "Subject: 011, n=20 | test_f1: 0.3629 |best_f1: 0.53125\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0442\tTop_Loss: 0.1932\tBottom_Loss: 0.0567\tLoss: 0.2941\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0474\tTop_Loss: 0.0573\tBottom_Loss: 0.0553\tLoss: 0.1600\t\n",
      "Subject: 011, n=20 | test_f1: 0.27957 |best_f1: 0.53125\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0124\tTop_Loss: 0.0370\tBottom_Loss: 0.0502\tLoss: 0.0995\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0105\tTop_Loss: 0.0347\tBottom_Loss: 0.0263\tLoss: 0.0715\t\n",
      "Subject: 011, n=20 | test_f1: 0.3629 |best_f1: 0.53125\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0147\tTop_Loss: 0.1120\tBottom_Loss: 0.0254\tLoss: 0.1522\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0072\tTop_Loss: 0.0499\tBottom_Loss: 0.0169\tLoss: 0.0739\t\n",
      "Subject: 011, n=20 | test_f1: 0.39394 |best_f1: 0.53125\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0721\tTop_Loss: 0.1042\tBottom_Loss: 0.0786\tLoss: 0.2550\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0098\tTop_Loss: 0.0257\tBottom_Loss: 0.0239\tLoss: 0.0593\t\n",
      "Subject: 011, n=20 | test_f1: 0.25806 |best_f1: 0.53125\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0241\tTop_Loss: 0.0484\tBottom_Loss: 0.0554\tLoss: 0.1279\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0123\tTop_Loss: 0.0975\tBottom_Loss: 0.0321\tLoss: 0.1419\t\n",
      "Subject: 011, n=20 | test_f1: 0.3629 |best_f1: 0.53125\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0298\tTop_Loss: 0.0675\tBottom_Loss: 0.0595\tLoss: 0.1568\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0078\tTop_Loss: 0.0228\tBottom_Loss: 0.0171\tLoss: 0.0477\t\n",
      "Subject: 011, n=20 | test_f1: 0.53125 |best_f1: 0.53125\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0042\tTop_Loss: 0.0232\tBottom_Loss: 0.0111\tLoss: 0.0385\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0069\tTop_Loss: 0.0200\tBottom_Loss: 0.0135\tLoss: 0.0404\t\n",
      "Subject: 011, n=20 | test_f1: 0.27083 |best_f1: 0.53125\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0066\tTop_Loss: 0.0287\tBottom_Loss: 0.0200\tLoss: 0.0553\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0336\tTop_Loss: 0.0999\tBottom_Loss: 0.0258\tLoss: 0.1593\t\n",
      "Subject: 011, n=20 | test_f1: 0.53125 |best_f1: 0.53125\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0136\tTop_Loss: 0.0429\tBottom_Loss: 0.0442\tLoss: 0.1007\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0081\tTop_Loss: 0.0211\tBottom_Loss: 0.0246\tLoss: 0.0539\t\n",
      "Subject: 011, n=20 | test_f1: 0.53125 |best_f1: 0.53125\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0133\tTop_Loss: 0.0295\tBottom_Loss: 0.0286\tLoss: 0.0713\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0088\tTop_Loss: 0.0240\tBottom_Loss: 0.0458\tLoss: 0.0786\t\n",
      "Subject: 011, n=20 | test_f1: 0.27083 |best_f1: 0.53125\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0059\tTop_Loss: 0.0353\tBottom_Loss: 0.0226\tLoss: 0.0638\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0064\tTop_Loss: 0.0342\tBottom_Loss: 0.0285\tLoss: 0.0691\t\n",
      "Subject: 011, n=20 | test_f1: 0.39394 |best_f1: 0.53125\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0183\tTop_Loss: 0.0323\tBottom_Loss: 0.0483\tLoss: 0.0989\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0161\tTop_Loss: 0.0428\tBottom_Loss: 0.0581\tLoss: 0.1170\t\n",
      "Subject: 011, n=20 | test_f1: 0.53125 |best_f1: 0.53125\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.531\tLabel_Loss: 1.1341\tTop_Loss: 1.6158\tBottom_Loss: 1.2579\tLoss: 4.0078\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.438\tLabel_Loss: 1.2407\tTop_Loss: 1.2591\tBottom_Loss: 1.3064\tLoss: 3.8062\t\n",
      "Subject: 012, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8554\tTop_Loss: 1.0881\tBottom_Loss: 0.8554\tLoss: 2.7988\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.406\tLabel_Loss: 1.0812\tTop_Loss: 1.1995\tBottom_Loss: 1.0140\tLoss: 3.2947\t\n",
      "Subject: 012, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.562\tLabel_Loss: 0.7858\tTop_Loss: 0.9061\tBottom_Loss: 0.8092\tLoss: 2.5011\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.531\tLabel_Loss: 0.9743\tTop_Loss: 1.1516\tBottom_Loss: 0.9488\tLoss: 3.0747\t\n",
      "Subject: 012, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.531\tLabel_Loss: 0.9523\tTop_Loss: 0.8612\tBottom_Loss: 0.9441\tLoss: 2.7576\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7689\tTop_Loss: 0.7417\tBottom_Loss: 0.8955\tLoss: 2.4061\t\n",
      "Subject: 012, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.562\tLabel_Loss: 0.9074\tTop_Loss: 0.9912\tBottom_Loss: 0.8695\tLoss: 2.7680\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7883\tTop_Loss: 0.7409\tBottom_Loss: 0.8226\tLoss: 2.3519\t\n",
      "Subject: 012, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7271\tTop_Loss: 0.8351\tBottom_Loss: 0.9584\tLoss: 2.5206\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8326\tTop_Loss: 0.9060\tBottom_Loss: 0.8426\tLoss: 2.5811\t\n",
      "Subject: 012, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.562\tLabel_Loss: 0.7565\tTop_Loss: 0.7714\tBottom_Loss: 0.7674\tLoss: 2.2953\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.562\tLabel_Loss: 0.8416\tTop_Loss: 1.0068\tBottom_Loss: 0.8990\tLoss: 2.7474\t\n",
      "Subject: 012, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.656\tLabel_Loss: 0.6805\tTop_Loss: 0.8462\tBottom_Loss: 0.8045\tLoss: 2.3312\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.375\tLabel_Loss: 0.9975\tTop_Loss: 1.0360\tBottom_Loss: 0.9957\tLoss: 3.0293\t\n",
      "Subject: 012, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8293\tTop_Loss: 0.8338\tBottom_Loss: 0.9662\tLoss: 2.6293\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.562\tLabel_Loss: 0.9167\tTop_Loss: 1.1770\tBottom_Loss: 0.9883\tLoss: 3.0819\t\n",
      "Subject: 012, n=03 | test_f1: 0.22222 |best_f1: 0.4\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8981\tTop_Loss: 0.8556\tBottom_Loss: 0.8941\tLoss: 2.6479\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.531\tLabel_Loss: 0.9745\tTop_Loss: 0.9936\tBottom_Loss: 0.9685\tLoss: 2.9367\t\n",
      "Subject: 012, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.594\tLabel_Loss: 0.6681\tTop_Loss: 0.7222\tBottom_Loss: 0.8099\tLoss: 2.2002\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4699\tTop_Loss: 0.6913\tBottom_Loss: 0.7044\tLoss: 1.8657\t\n",
      "Subject: 012, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.625\tLabel_Loss: 0.6740\tTop_Loss: 0.6489\tBottom_Loss: 0.6164\tLoss: 1.9393\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7726\tTop_Loss: 0.9055\tBottom_Loss: 0.8990\tLoss: 2.5770\t\n",
      "Subject: 012, n=03 | test_f1: 0.22222 |best_f1: 0.4\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.562\tLabel_Loss: 0.8012\tTop_Loss: 0.7638\tBottom_Loss: 0.7382\tLoss: 2.3031\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5302\tTop_Loss: 0.6275\tBottom_Loss: 0.5928\tLoss: 1.7505\t\n",
      "Subject: 012, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.594\tLabel_Loss: 0.7161\tTop_Loss: 0.8017\tBottom_Loss: 0.6591\tLoss: 2.1769\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4325\tTop_Loss: 0.6228\tBottom_Loss: 0.6360\tLoss: 1.6913\t\n",
      "Subject: 012, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.594\tLabel_Loss: 0.7302\tTop_Loss: 0.8902\tBottom_Loss: 0.7303\tLoss: 2.3507\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6274\tTop_Loss: 0.6448\tBottom_Loss: 0.5479\tLoss: 1.8201\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 012, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.844\tLabel_Loss: 0.5403\tTop_Loss: 0.6420\tBottom_Loss: 0.5547\tLoss: 1.7370\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5399\tTop_Loss: 0.5569\tBottom_Loss: 0.6516\tLoss: 1.7485\t\n",
      "Subject: 012, n=03 | test_f1: 0.22222 |best_f1: 0.4\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5780\tTop_Loss: 0.5426\tBottom_Loss: 0.5352\tLoss: 1.6558\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.875\tLabel_Loss: 0.5402\tTop_Loss: 0.6816\tBottom_Loss: 0.7238\tLoss: 1.9457\t\n",
      "Subject: 012, n=03 | test_f1: 0.22222 |best_f1: 0.4\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6758\tTop_Loss: 1.0474\tBottom_Loss: 0.6375\tLoss: 2.3607\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4064\tTop_Loss: 0.5724\tBottom_Loss: 0.4493\tLoss: 1.4281\t\n",
      "Subject: 012, n=03 | test_f1: 0.22222 |best_f1: 0.4\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3895\tTop_Loss: 0.5386\tBottom_Loss: 0.5376\tLoss: 1.4657\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.719\tLabel_Loss: 0.7663\tTop_Loss: 0.6720\tBottom_Loss: 0.7970\tLoss: 2.2352\t\n",
      "Subject: 012, n=03 | test_f1: 0.22222 |best_f1: 0.4\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.562\tLabel_Loss: 0.8576\tTop_Loss: 0.7123\tBottom_Loss: 0.7603\tLoss: 2.3302\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4821\tTop_Loss: 0.6891\tBottom_Loss: 0.5233\tLoss: 1.6946\t\n",
      "Subject: 012, n=03 | test_f1: 0.33333 |best_f1: 0.4\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3697\tTop_Loss: 0.6135\tBottom_Loss: 0.3661\tLoss: 1.3493\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4150\tTop_Loss: 0.5332\tBottom_Loss: 0.5931\tLoss: 1.5412\t\n",
      "Subject: 012, n=03 | test_f1: 0.22222 |best_f1: 0.4\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.781\tLabel_Loss: 0.6553\tTop_Loss: 0.7533\tBottom_Loss: 0.6925\tLoss: 2.1011\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.750\tLabel_Loss: 0.4519\tTop_Loss: 0.5799\tBottom_Loss: 0.5963\tLoss: 1.6281\t\n",
      "Subject: 012, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3223\tTop_Loss: 0.4694\tBottom_Loss: 0.5570\tLoss: 1.3487\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4789\tTop_Loss: 0.5577\tBottom_Loss: 0.4559\tLoss: 1.4925\t\n",
      "Subject: 012, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5399\tTop_Loss: 0.6162\tBottom_Loss: 0.7193\tLoss: 1.8754\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.844\tLabel_Loss: 0.5012\tTop_Loss: 0.5715\tBottom_Loss: 0.5990\tLoss: 1.6716\t\n",
      "Subject: 012, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.750\tLabel_Loss: 0.4638\tTop_Loss: 0.5912\tBottom_Loss: 0.4602\tLoss: 1.5151\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3426\tTop_Loss: 0.4926\tBottom_Loss: 0.3778\tLoss: 1.2131\t\n",
      "Subject: 012, n=03 | test_f1: 0.33333 |best_f1: 0.4\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3338\tTop_Loss: 0.4816\tBottom_Loss: 0.5394\tLoss: 1.3548\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3635\tTop_Loss: 0.4881\tBottom_Loss: 0.4165\tLoss: 1.2681\t\n",
      "Subject: 012, n=03 | test_f1: 0.33333 |best_f1: 0.4\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3419\tTop_Loss: 0.4507\tBottom_Loss: 0.3711\tLoss: 1.1638\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.688\tLabel_Loss: 0.5103\tTop_Loss: 0.8445\tBottom_Loss: 0.4017\tLoss: 1.7566\t\n",
      "Subject: 012, n=03 | test_f1: 0.22222 |best_f1: 0.4\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3167\tTop_Loss: 0.3260\tBottom_Loss: 0.3290\tLoss: 0.9718\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2322\tTop_Loss: 0.3059\tBottom_Loss: 0.3113\tLoss: 0.8494\t\n",
      "Subject: 012, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3001\tTop_Loss: 0.4720\tBottom_Loss: 0.2678\tLoss: 1.0398\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2258\tTop_Loss: 0.4183\tBottom_Loss: 0.3379\tLoss: 0.9821\t\n",
      "Subject: 012, n=03 | test_f1: 0.22222 |best_f1: 0.4\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3619\tTop_Loss: 0.5486\tBottom_Loss: 0.4717\tLoss: 1.3821\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.844\tLabel_Loss: 0.5047\tTop_Loss: 0.6472\tBottom_Loss: 0.6289\tLoss: 1.7808\t\n",
      "Subject: 012, n=03 | test_f1: 0.22222 |best_f1: 0.4\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3537\tTop_Loss: 0.5297\tBottom_Loss: 0.5180\tLoss: 1.4013\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4399\tTop_Loss: 0.5640\tBottom_Loss: 0.3893\tLoss: 1.3932\t\n",
      "Subject: 012, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3397\tTop_Loss: 0.6619\tBottom_Loss: 0.4680\tLoss: 1.4696\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2515\tTop_Loss: 0.4236\tBottom_Loss: 0.3948\tLoss: 1.0700\t\n",
      "Subject: 012, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.750\tLabel_Loss: 0.3964\tTop_Loss: 0.4271\tBottom_Loss: 0.4047\tLoss: 1.2283\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3027\tTop_Loss: 0.5343\tBottom_Loss: 0.4252\tLoss: 1.2622\t\n",
      "Subject: 012, n=03 | test_f1: 0.22222 |best_f1: 0.4\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2189\tTop_Loss: 0.3207\tBottom_Loss: 0.3286\tLoss: 0.8682\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2270\tTop_Loss: 0.4084\tBottom_Loss: 0.3960\tLoss: 1.0314\t\n",
      "Subject: 012, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3195\tTop_Loss: 0.5139\tBottom_Loss: 0.3344\tLoss: 1.1677\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1969\tTop_Loss: 0.4435\tBottom_Loss: 0.3337\tLoss: 0.9741\t\n",
      "Subject: 012, n=03 | test_f1: 0.33333 |best_f1: 0.4\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2093\tTop_Loss: 0.3622\tBottom_Loss: 0.1710\tLoss: 0.7425\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3361\tTop_Loss: 0.5927\tBottom_Loss: 0.4304\tLoss: 1.3592\t\n",
      "Subject: 012, n=03 | test_f1: 0.22222 |best_f1: 0.4\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2467\tTop_Loss: 0.5049\tBottom_Loss: 0.3543\tLoss: 1.1059\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2153\tTop_Loss: 0.3825\tBottom_Loss: 0.3014\tLoss: 0.8991\t\n",
      "Subject: 012, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3057\tTop_Loss: 0.2839\tBottom_Loss: 0.3830\tLoss: 0.9726\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1822\tTop_Loss: 0.4213\tBottom_Loss: 0.3357\tLoss: 0.9392\t\n",
      "Subject: 012, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1604\tTop_Loss: 0.2323\tBottom_Loss: 0.2786\tLoss: 0.6714\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2781\tTop_Loss: 0.4647\tBottom_Loss: 0.3375\tLoss: 1.0803\t\n",
      "Subject: 012, n=03 | test_f1: 0.22222 |best_f1: 0.4\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1133\tTop_Loss: 0.3390\tBottom_Loss: 0.2588\tLoss: 0.7111\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1457\tTop_Loss: 0.2936\tBottom_Loss: 0.2961\tLoss: 0.7354\t\n",
      "Subject: 012, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0809\tTop_Loss: 0.2746\tBottom_Loss: 0.2002\tLoss: 0.5557\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0970\tTop_Loss: 0.1792\tBottom_Loss: 0.1760\tLoss: 0.4523\t\n",
      "Subject: 012, n=03 | test_f1: 0.22222 |best_f1: 0.4\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3044\tTop_Loss: 0.3918\tBottom_Loss: 0.3507\tLoss: 1.0469\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1897\tTop_Loss: 0.3676\tBottom_Loss: 0.1837\tLoss: 0.7409\t\n",
      "Subject: 012, n=03 | test_f1: 0.33333 |best_f1: 0.4\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1672\tTop_Loss: 0.3281\tBottom_Loss: 0.2423\tLoss: 0.7376\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1668\tTop_Loss: 0.2386\tBottom_Loss: 0.3568\tLoss: 0.7621\t\n",
      "Subject: 012, n=03 | test_f1: 0.0 |best_f1: 0.4\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1756\tTop_Loss: 0.3889\tBottom_Loss: 0.4504\tLoss: 1.0149\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1082\tTop_Loss: 0.3715\tBottom_Loss: 0.1123\tLoss: 0.5920\t\n",
      "Subject: 012, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0738\tTop_Loss: 0.2395\tBottom_Loss: 0.1227\tLoss: 0.4360\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1688\tTop_Loss: 0.2160\tBottom_Loss: 0.1501\tLoss: 0.5348\t\n",
      "Subject: 012, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0880\tTop_Loss: 0.1648\tBottom_Loss: 0.1339\tLoss: 0.3867\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2375\tTop_Loss: 0.3068\tBottom_Loss: 0.2428\tLoss: 0.7871\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 012, n=03 | test_f1: 0.22222 |best_f1: 0.4\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1544\tTop_Loss: 0.1911\tBottom_Loss: 0.2570\tLoss: 0.6025\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0574\tTop_Loss: 0.2185\tBottom_Loss: 0.1723\tLoss: 0.4483\t\n",
      "Subject: 012, n=03 | test_f1: 0.33333 |best_f1: 0.4\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1112\tTop_Loss: 0.2226\tBottom_Loss: 0.1533\tLoss: 0.4871\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1423\tTop_Loss: 0.3641\tBottom_Loss: 0.2239\tLoss: 0.7302\t\n",
      "Subject: 012, n=03 | test_f1: 0.22222 |best_f1: 0.4\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1117\tTop_Loss: 0.3357\tBottom_Loss: 0.1864\tLoss: 0.6338\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1160\tTop_Loss: 0.3732\tBottom_Loss: 0.2154\tLoss: 0.7047\t\n",
      "Subject: 012, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1095\tTop_Loss: 0.2440\tBottom_Loss: 0.1318\tLoss: 0.4852\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1607\tTop_Loss: 0.3257\tBottom_Loss: 0.1626\tLoss: 0.6490\t\n",
      "Subject: 012, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1396\tTop_Loss: 0.2449\tBottom_Loss: 0.1916\tLoss: 0.5762\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0889\tTop_Loss: 0.2872\tBottom_Loss: 0.1047\tLoss: 0.4808\t\n",
      "Subject: 012, n=03 | test_f1: 0.22222 |best_f1: 0.4\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1032\tTop_Loss: 0.3032\tBottom_Loss: 0.1518\tLoss: 0.5581\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0745\tTop_Loss: 0.1766\tBottom_Loss: 0.1868\tLoss: 0.4378\t\n",
      "Subject: 012, n=03 | test_f1: 0.33333 |best_f1: 0.4\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1244\tTop_Loss: 0.2720\tBottom_Loss: 0.1433\tLoss: 0.5397\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0968\tTop_Loss: 0.2457\tBottom_Loss: 0.0936\tLoss: 0.4361\t\n",
      "Subject: 012, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0719\tTop_Loss: 0.1143\tBottom_Loss: 0.1519\tLoss: 0.3381\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0657\tTop_Loss: 0.1898\tBottom_Loss: 0.0911\tLoss: 0.3466\t\n",
      "Subject: 012, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1067\tTop_Loss: 0.2013\tBottom_Loss: 0.1842\tLoss: 0.4922\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1125\tTop_Loss: 0.2141\tBottom_Loss: 0.2576\tLoss: 0.5842\t\n",
      "Subject: 012, n=03 | test_f1: 0.33333 |best_f1: 0.4\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0584\tTop_Loss: 0.1598\tBottom_Loss: 0.1685\tLoss: 0.3866\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0565\tTop_Loss: 0.2424\tBottom_Loss: 0.1088\tLoss: 0.4078\t\n",
      "Subject: 012, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1312\tTop_Loss: 0.3107\tBottom_Loss: 0.1232\tLoss: 0.5652\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1071\tTop_Loss: 0.1643\tBottom_Loss: 0.1548\tLoss: 0.4262\t\n",
      "Subject: 012, n=03 | test_f1: 0.22222 |best_f1: 0.4\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0451\tTop_Loss: 0.2667\tBottom_Loss: 0.0806\tLoss: 0.3924\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1145\tTop_Loss: 0.1912\tBottom_Loss: 0.1872\tLoss: 0.4930\t\n",
      "Subject: 012, n=03 | test_f1: 0.22222 |best_f1: 0.4\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0406\tTop_Loss: 0.1748\tBottom_Loss: 0.1068\tLoss: 0.3223\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1768\tTop_Loss: 0.2604\tBottom_Loss: 0.2630\tLoss: 0.7002\t\n",
      "Subject: 012, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0999\tTop_Loss: 0.2375\tBottom_Loss: 0.2231\tLoss: 0.5605\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0592\tTop_Loss: 0.1456\tBottom_Loss: 0.1568\tLoss: 0.3616\t\n",
      "Subject: 012, n=03 | test_f1: 0.33333 |best_f1: 0.4\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0486\tTop_Loss: 0.2184\tBottom_Loss: 0.0813\tLoss: 0.3483\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0835\tTop_Loss: 0.2238\tBottom_Loss: 0.1458\tLoss: 0.4530\t\n",
      "Subject: 012, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0553\tTop_Loss: 0.2014\tBottom_Loss: 0.0809\tLoss: 0.3376\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0356\tTop_Loss: 0.1061\tBottom_Loss: 0.0746\tLoss: 0.2163\t\n",
      "Subject: 012, n=03 | test_f1: 0.22222 |best_f1: 0.4\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0586\tTop_Loss: 0.2529\tBottom_Loss: 0.0674\tLoss: 0.3789\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0489\tTop_Loss: 0.1185\tBottom_Loss: 0.0532\tLoss: 0.2207\t\n",
      "Subject: 012, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 0.938\tLabel_Loss: 0.0828\tTop_Loss: 0.1280\tBottom_Loss: 0.0962\tLoss: 0.3070\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0692\tTop_Loss: 0.1262\tBottom_Loss: 0.0884\tLoss: 0.2838\t\n",
      "Subject: 012, n=03 | test_f1: 0.0 |best_f1: 0.4\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0714\tTop_Loss: 0.1697\tBottom_Loss: 0.0729\tLoss: 0.3139\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0288\tTop_Loss: 0.0930\tBottom_Loss: 0.0869\tLoss: 0.2087\t\n",
      "Subject: 012, n=03 | test_f1: 0.22222 |best_f1: 0.4\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0472\tTop_Loss: 0.1164\tBottom_Loss: 0.1126\tLoss: 0.2762\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0322\tTop_Loss: 0.0946\tBottom_Loss: 0.0451\tLoss: 0.1720\t\n",
      "Subject: 012, n=03 | test_f1: 0.33333 |best_f1: 0.4\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0716\tTop_Loss: 0.1897\tBottom_Loss: 0.1109\tLoss: 0.3722\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0525\tTop_Loss: 0.1596\tBottom_Loss: 0.1093\tLoss: 0.3214\t\n",
      "Subject: 012, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0266\tTop_Loss: 0.1618\tBottom_Loss: 0.0215\tLoss: 0.2099\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0860\tTop_Loss: 0.1446\tBottom_Loss: 0.0970\tLoss: 0.3276\t\n",
      "Subject: 012, n=03 | test_f1: 0.22222 |best_f1: 0.4\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0207\tTop_Loss: 0.1642\tBottom_Loss: 0.0404\tLoss: 0.2253\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0725\tTop_Loss: 0.1539\tBottom_Loss: 0.2105\tLoss: 0.4369\t\n",
      "Subject: 012, n=03 | test_f1: 0.22222 |best_f1: 0.4\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0250\tTop_Loss: 0.0988\tBottom_Loss: 0.0727\tLoss: 0.1965\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0436\tTop_Loss: 0.1377\tBottom_Loss: 0.0892\tLoss: 0.2705\t\n",
      "Subject: 012, n=03 | test_f1: 0.0 |best_f1: 0.4\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0557\tTop_Loss: 0.1241\tBottom_Loss: 0.1326\tLoss: 0.3124\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0454\tTop_Loss: 0.1306\tBottom_Loss: 0.0475\tLoss: 0.2235\t\n",
      "Subject: 012, n=03 | test_f1: 0.22222 |best_f1: 0.4\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0757\tTop_Loss: 0.1666\tBottom_Loss: 0.0946\tLoss: 0.3368\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0666\tTop_Loss: 0.1397\tBottom_Loss: 0.0764\tLoss: 0.2827\t\n",
      "Subject: 012, n=03 | test_f1: 0.33333 |best_f1: 0.4\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0130\tTop_Loss: 0.0399\tBottom_Loss: 0.0684\tLoss: 0.1212\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0499\tTop_Loss: 0.2284\tBottom_Loss: 0.1064\tLoss: 0.3847\t\n",
      "Subject: 012, n=03 | test_f1: 0.33333 |best_f1: 0.4\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0181\tTop_Loss: 0.1535\tBottom_Loss: 0.0237\tLoss: 0.1954\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0438\tTop_Loss: 0.1604\tBottom_Loss: 0.0383\tLoss: 0.2426\t\n",
      "Subject: 012, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0213\tTop_Loss: 0.1250\tBottom_Loss: 0.0300\tLoss: 0.1763\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0270\tTop_Loss: 0.1276\tBottom_Loss: 0.0389\tLoss: 0.1935\t\n",
      "Subject: 012, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0160\tTop_Loss: 0.0914\tBottom_Loss: 0.0473\tLoss: 0.1546\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0201\tTop_Loss: 0.0948\tBottom_Loss: 0.0242\tLoss: 0.1391\t\n",
      "Subject: 012, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0360\tTop_Loss: 0.1222\tBottom_Loss: 0.0783\tLoss: 0.2365\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0134\tTop_Loss: 0.0654\tBottom_Loss: 0.0498\tLoss: 0.1286\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 012, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0349\tTop_Loss: 0.1365\tBottom_Loss: 0.0345\tLoss: 0.2059\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0236\tTop_Loss: 0.0740\tBottom_Loss: 0.0370\tLoss: 0.1346\t\n",
      "Subject: 012, n=03 | test_f1: 0.0 |best_f1: 0.4\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0350\tTop_Loss: 0.1222\tBottom_Loss: 0.0300\tLoss: 0.1871\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0175\tTop_Loss: 0.0644\tBottom_Loss: 0.0435\tLoss: 0.1253\t\n",
      "Subject: 012, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0178\tTop_Loss: 0.0618\tBottom_Loss: 0.0224\tLoss: 0.1020\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0229\tTop_Loss: 0.1187\tBottom_Loss: 0.0338\tLoss: 0.1754\t\n",
      "Subject: 012, n=03 | test_f1: 0.33333 |best_f1: 0.4\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0217\tTop_Loss: 0.0435\tBottom_Loss: 0.0380\tLoss: 0.1032\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0362\tTop_Loss: 0.0739\tBottom_Loss: 0.1614\tLoss: 0.2716\t\n",
      "Subject: 012, n=03 | test_f1: 0.33333 |best_f1: 0.4\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0787\tTop_Loss: 0.1297\tBottom_Loss: 0.0286\tLoss: 0.2370\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0713\tTop_Loss: 0.1898\tBottom_Loss: 0.0874\tLoss: 0.3485\t\n",
      "Subject: 012, n=03 | test_f1: 0.33333 |best_f1: 0.4\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0522\tTop_Loss: 0.0921\tBottom_Loss: 0.0938\tLoss: 0.2381\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1119\tTop_Loss: 0.0944\tBottom_Loss: 0.1084\tLoss: 0.3147\t\n",
      "Subject: 012, n=03 | test_f1: 0.33333 |best_f1: 0.4\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0191\tTop_Loss: 0.0730\tBottom_Loss: 0.0613\tLoss: 0.1534\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0495\tTop_Loss: 0.1703\tBottom_Loss: 0.0577\tLoss: 0.2776\t\n",
      "Subject: 012, n=03 | test_f1: 0.33333 |best_f1: 0.4\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0797\tTop_Loss: 0.1481\tBottom_Loss: 0.1135\tLoss: 0.3413\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0193\tTop_Loss: 0.0836\tBottom_Loss: 0.0265\tLoss: 0.1295\t\n",
      "Subject: 012, n=03 | test_f1: 0.0 |best_f1: 0.4\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0103\tTop_Loss: 0.0656\tBottom_Loss: 0.0665\tLoss: 0.1425\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0193\tTop_Loss: 0.1120\tBottom_Loss: 0.0403\tLoss: 0.1717\t\n",
      "Subject: 012, n=03 | test_f1: 0.22222 |best_f1: 0.4\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0279\tTop_Loss: 0.0552\tBottom_Loss: 0.0311\tLoss: 0.1142\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0090\tTop_Loss: 0.0556\tBottom_Loss: 0.0729\tLoss: 0.1375\t\n",
      "Subject: 012, n=03 | test_f1: 0.22222 |best_f1: 0.4\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0171\tTop_Loss: 0.0471\tBottom_Loss: 0.0286\tLoss: 0.0928\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0185\tTop_Loss: 0.1073\tBottom_Loss: 0.0248\tLoss: 0.1506\t\n",
      "Subject: 012, n=03 | test_f1: 0.22222 |best_f1: 0.4\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0745\tTop_Loss: 0.1643\tBottom_Loss: 0.1178\tLoss: 0.3566\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0312\tTop_Loss: 0.1360\tBottom_Loss: 0.0163\tLoss: 0.1835\t\n",
      "Subject: 012, n=03 | test_f1: 0.33333 |best_f1: 0.4\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0155\tTop_Loss: 0.1176\tBottom_Loss: 0.0249\tLoss: 0.1580\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0230\tTop_Loss: 0.0673\tBottom_Loss: 0.1070\tLoss: 0.1974\t\n",
      "Subject: 012, n=03 | test_f1: 0.33333 |best_f1: 0.4\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0092\tTop_Loss: 0.0480\tBottom_Loss: 0.0224\tLoss: 0.0796\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0489\tTop_Loss: 0.0776\tBottom_Loss: 0.1075\tLoss: 0.2340\t\n",
      "Subject: 012, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0277\tTop_Loss: 0.1739\tBottom_Loss: 0.0585\tLoss: 0.2601\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0325\tTop_Loss: 0.0633\tBottom_Loss: 0.0264\tLoss: 0.1221\t\n",
      "Subject: 012, n=03 | test_f1: 0.22222 |best_f1: 0.4\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0148\tTop_Loss: 0.0376\tBottom_Loss: 0.0366\tLoss: 0.0891\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0086\tTop_Loss: 0.0381\tBottom_Loss: 0.0261\tLoss: 0.0727\t\n",
      "Subject: 012, n=03 | test_f1: 0.33333 |best_f1: 0.4\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0170\tTop_Loss: 0.0258\tBottom_Loss: 0.0256\tLoss: 0.0683\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0149\tTop_Loss: 0.0516\tBottom_Loss: 0.0561\tLoss: 0.1226\t\n",
      "Subject: 012, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0148\tTop_Loss: 0.0721\tBottom_Loss: 0.0220\tLoss: 0.1088\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0062\tTop_Loss: 0.0309\tBottom_Loss: 0.0189\tLoss: 0.0560\t\n",
      "Subject: 012, n=03 | test_f1: 0.33333 |best_f1: 0.4\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0307\tTop_Loss: 0.0497\tBottom_Loss: 0.0967\tLoss: 0.1772\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0065\tTop_Loss: 0.0429\tBottom_Loss: 0.0109\tLoss: 0.0604\t\n",
      "Subject: 012, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0674\tTop_Loss: 0.1005\tBottom_Loss: 0.0782\tLoss: 0.2461\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0211\tTop_Loss: 0.1055\tBottom_Loss: 0.0572\tLoss: 0.1838\t\n",
      "Subject: 012, n=03 | test_f1: 0.33333 |best_f1: 0.4\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0212\tTop_Loss: 0.0654\tBottom_Loss: 0.0182\tLoss: 0.1048\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0064\tTop_Loss: 0.0545\tBottom_Loss: 0.0217\tLoss: 0.0826\t\n",
      "Subject: 012, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0173\tTop_Loss: 0.0878\tBottom_Loss: 0.0375\tLoss: 0.1427\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0047\tTop_Loss: 0.0292\tBottom_Loss: 0.0155\tLoss: 0.0494\t\n",
      "Subject: 012, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0071\tTop_Loss: 0.0435\tBottom_Loss: 0.0383\tLoss: 0.0890\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0127\tTop_Loss: 0.0254\tBottom_Loss: 0.0272\tLoss: 0.0653\t\n",
      "Subject: 012, n=03 | test_f1: 0.22222 |best_f1: 0.4\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.094\tLabel_Loss: 1.7351\tTop_Loss: 1.1484\tBottom_Loss: 1.4585\tLoss: 4.3421\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.375\tLabel_Loss: 1.2783\tTop_Loss: 1.3342\tBottom_Loss: 1.4868\tLoss: 4.0993\t\n",
      "Subject: 013, n=06 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.531\tLabel_Loss: 1.1452\tTop_Loss: 1.1513\tBottom_Loss: 1.1258\tLoss: 3.4223\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.531\tLabel_Loss: 0.9470\tTop_Loss: 0.9852\tBottom_Loss: 1.1099\tLoss: 3.0420\t\n",
      "Subject: 013, n=06 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.594\tLabel_Loss: 0.9590\tTop_Loss: 0.9762\tBottom_Loss: 0.8778\tLoss: 2.8131\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.656\tLabel_Loss: 0.8867\tTop_Loss: 0.8642\tBottom_Loss: 0.9021\tLoss: 2.6530\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.469\tLabel_Loss: 1.0702\tTop_Loss: 0.8780\tBottom_Loss: 0.9712\tLoss: 2.9194\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8458\tTop_Loss: 0.9210\tBottom_Loss: 0.7987\tLoss: 2.5655\t\n",
      "Subject: 013, n=06 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8892\tTop_Loss: 0.9422\tBottom_Loss: 0.9432\tLoss: 2.7745\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.594\tLabel_Loss: 0.7488\tTop_Loss: 0.7579\tBottom_Loss: 0.8602\tLoss: 2.3668\t\n",
      "Subject: 013, n=06 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.562\tLabel_Loss: 0.8280\tTop_Loss: 0.8826\tBottom_Loss: 0.8500\tLoss: 2.5607\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.594\tLabel_Loss: 0.7501\tTop_Loss: 0.7866\tBottom_Loss: 0.9651\tLoss: 2.5018\t\n",
      "Subject: 013, n=06 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8253\tTop_Loss: 0.7385\tBottom_Loss: 0.8852\tLoss: 2.4490\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7350\tTop_Loss: 0.7257\tBottom_Loss: 0.9611\tLoss: 2.4218\t\n",
      "Subject: 013, n=06 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.719\tLabel_Loss: 0.7775\tTop_Loss: 0.7360\tBottom_Loss: 0.8946\tLoss: 2.4081\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7263\tTop_Loss: 0.8512\tBottom_Loss: 0.8941\tLoss: 2.4716\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.656\tLabel_Loss: 0.6981\tTop_Loss: 0.7177\tBottom_Loss: 0.7911\tLoss: 2.2068\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7848\tTop_Loss: 0.8025\tBottom_Loss: 0.7867\tLoss: 2.3740\t\n",
      "Subject: 013, n=06 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7979\tTop_Loss: 0.9090\tBottom_Loss: 0.8981\tLoss: 2.6050\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.625\tLabel_Loss: 0.9168\tTop_Loss: 0.9063\tBottom_Loss: 0.9564\tLoss: 2.7795\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.406\tLabel_Loss: 1.0090\tTop_Loss: 1.0089\tBottom_Loss: 0.9481\tLoss: 2.9660\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7128\tTop_Loss: 0.6645\tBottom_Loss: 0.8444\tLoss: 2.2217\t\n",
      "Subject: 013, n=06 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6635\tTop_Loss: 0.6056\tBottom_Loss: 0.8472\tLoss: 2.1163\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.719\tLabel_Loss: 0.8920\tTop_Loss: 0.9416\tBottom_Loss: 0.9268\tLoss: 2.7603\t\n",
      "Subject: 013, n=06 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4306\tTop_Loss: 0.5959\tBottom_Loss: 0.6189\tLoss: 1.6453\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5996\tTop_Loss: 0.6326\tBottom_Loss: 0.7344\tLoss: 1.9666\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6810\tTop_Loss: 0.5647\tBottom_Loss: 0.7800\tLoss: 2.0257\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.781\tLabel_Loss: 0.6388\tTop_Loss: 0.7361\tBottom_Loss: 0.6442\tLoss: 2.0191\t\n",
      "Subject: 013, n=06 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.750\tLabel_Loss: 0.7126\tTop_Loss: 0.6473\tBottom_Loss: 0.6542\tLoss: 2.0142\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5738\tTop_Loss: 0.6047\tBottom_Loss: 0.7030\tLoss: 1.8815\t\n",
      "Subject: 013, n=06 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6587\tTop_Loss: 0.5699\tBottom_Loss: 0.6376\tLoss: 1.8662\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.719\tLabel_Loss: 0.8060\tTop_Loss: 0.7728\tBottom_Loss: 0.7758\tLoss: 2.3547\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.938\tLabel_Loss: 0.3995\tTop_Loss: 0.4470\tBottom_Loss: 0.6766\tLoss: 1.5231\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.906\tLabel_Loss: 0.4238\tTop_Loss: 0.4685\tBottom_Loss: 0.6629\tLoss: 1.5552\t\n",
      "Subject: 013, n=06 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.656\tLabel_Loss: 0.6533\tTop_Loss: 0.7334\tBottom_Loss: 0.7897\tLoss: 2.1763\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4677\tTop_Loss: 0.5671\tBottom_Loss: 0.6934\tLoss: 1.7282\t\n",
      "Subject: 013, n=06 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6193\tTop_Loss: 0.6931\tBottom_Loss: 0.8542\tLoss: 2.1665\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3950\tTop_Loss: 0.4457\tBottom_Loss: 0.5481\tLoss: 1.3888\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4142\tTop_Loss: 0.5435\tBottom_Loss: 0.5104\tLoss: 1.4681\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6266\tTop_Loss: 0.7419\tBottom_Loss: 0.6531\tLoss: 2.0216\t\n",
      "Subject: 013, n=06 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6208\tTop_Loss: 0.7928\tBottom_Loss: 0.6037\tLoss: 2.0174\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.750\tLabel_Loss: 0.4791\tTop_Loss: 0.6159\tBottom_Loss: 0.6756\tLoss: 1.7706\t\n",
      "Subject: 013, n=06 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4997\tTop_Loss: 0.5642\tBottom_Loss: 0.6108\tLoss: 1.6747\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4914\tTop_Loss: 0.6098\tBottom_Loss: 0.5629\tLoss: 1.6642\t\n",
      "Subject: 013, n=06 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6983\tTop_Loss: 0.5847\tBottom_Loss: 0.9753\tLoss: 2.2584\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 1.000\tLabel_Loss: 0.2146\tTop_Loss: 0.4905\tBottom_Loss: 0.4183\tLoss: 1.1234\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5473\tTop_Loss: 0.6919\tBottom_Loss: 0.4329\tLoss: 1.6721\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4933\tTop_Loss: 0.5712\tBottom_Loss: 0.5430\tLoss: 1.6076\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5155\tTop_Loss: 0.5515\tBottom_Loss: 0.7565\tLoss: 1.8235\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.625\tLabel_Loss: 0.6446\tTop_Loss: 0.7568\tBottom_Loss: 0.8090\tLoss: 2.2104\t\n",
      "Subject: 013, n=06 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5570\tTop_Loss: 0.6625\tBottom_Loss: 0.6279\tLoss: 1.8474\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4340\tTop_Loss: 0.5049\tBottom_Loss: 0.5726\tLoss: 1.5115\t\n",
      "Subject: 013, n=06 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.875\tLabel_Loss: 0.5080\tTop_Loss: 0.6451\tBottom_Loss: 0.6043\tLoss: 1.7575\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2165\tTop_Loss: 0.3886\tBottom_Loss: 0.4105\tLoss: 1.0156\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3813\tTop_Loss: 0.4999\tBottom_Loss: 0.4249\tLoss: 1.3061\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2018\tTop_Loss: 0.3369\tBottom_Loss: 0.2946\tLoss: 0.8333\t\n",
      "Subject: 013, n=06 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4392\tTop_Loss: 0.5541\tBottom_Loss: 0.4350\tLoss: 1.4283\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.906\tLabel_Loss: 0.4929\tTop_Loss: 0.5549\tBottom_Loss: 0.7019\tLoss: 1.7497\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1429\tTop_Loss: 0.2607\tBottom_Loss: 0.3337\tLoss: 0.7373\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2810\tTop_Loss: 0.4658\tBottom_Loss: 0.3174\tLoss: 1.0642\t\n",
      "Subject: 013, n=06 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3458\tTop_Loss: 0.5442\tBottom_Loss: 0.3428\tLoss: 1.2328\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3577\tTop_Loss: 0.6767\tBottom_Loss: 0.5082\tLoss: 1.5427\t\n",
      "Subject: 013, n=06 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2026\tTop_Loss: 0.4346\tBottom_Loss: 0.3049\tLoss: 0.9421\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3539\tTop_Loss: 0.4288\tBottom_Loss: 0.3825\tLoss: 1.1652\t\n",
      "Subject: 013, n=06 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2671\tTop_Loss: 0.4027\tBottom_Loss: 0.4409\tLoss: 1.1107\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3908\tTop_Loss: 0.3887\tBottom_Loss: 0.5932\tLoss: 1.3727\t\n",
      "Subject: 013, n=06 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1371\tTop_Loss: 0.3941\tBottom_Loss: 0.3126\tLoss: 0.8437\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.781\tLabel_Loss: 0.3269\tTop_Loss: 0.3088\tBottom_Loss: 0.4161\tLoss: 1.0519\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2513\tTop_Loss: 0.4025\tBottom_Loss: 0.3606\tLoss: 1.0144\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.938\tLabel_Loss: 0.3376\tTop_Loss: 0.4943\tBottom_Loss: 0.4727\tLoss: 1.3046\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1480\tTop_Loss: 0.4021\tBottom_Loss: 0.2424\tLoss: 0.7925\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3343\tTop_Loss: 0.5414\tBottom_Loss: 0.3299\tLoss: 1.2056\t\n",
      "Subject: 013, n=06 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2699\tTop_Loss: 0.4791\tBottom_Loss: 0.4012\tLoss: 1.1501\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2130\tTop_Loss: 0.3958\tBottom_Loss: 0.3000\tLoss: 0.9088\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1469\tTop_Loss: 0.2964\tBottom_Loss: 0.3279\tLoss: 0.7712\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3261\tTop_Loss: 0.4758\tBottom_Loss: 0.3274\tLoss: 1.1293\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1684\tTop_Loss: 0.2863\tBottom_Loss: 0.2571\tLoss: 0.7118\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1931\tTop_Loss: 0.3408\tBottom_Loss: 0.2517\tLoss: 0.7856\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2111\tTop_Loss: 0.3192\tBottom_Loss: 0.4493\tLoss: 0.9796\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2283\tTop_Loss: 0.3267\tBottom_Loss: 0.3640\tLoss: 0.9191\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2738\tTop_Loss: 0.3668\tBottom_Loss: 0.4620\tLoss: 1.1026\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1456\tTop_Loss: 0.2435\tBottom_Loss: 0.2301\tLoss: 0.6192\t\n",
      "Subject: 013, n=06 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1234\tTop_Loss: 0.2300\tBottom_Loss: 0.2891\tLoss: 0.6426\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2133\tTop_Loss: 0.2962\tBottom_Loss: 0.2883\tLoss: 0.7979\t\n",
      "Subject: 013, n=06 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2782\tTop_Loss: 0.6089\tBottom_Loss: 0.1968\tLoss: 1.0839\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1077\tTop_Loss: 0.2838\tBottom_Loss: 0.1741\tLoss: 0.5656\t\n",
      "Subject: 013, n=06 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1509\tTop_Loss: 0.2980\tBottom_Loss: 0.2136\tLoss: 0.6625\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1168\tTop_Loss: 0.2575\tBottom_Loss: 0.2951\tLoss: 0.6694\t\n",
      "Subject: 013, n=06 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0653\tTop_Loss: 0.2391\tBottom_Loss: 0.1786\tLoss: 0.4830\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1286\tTop_Loss: 0.2026\tBottom_Loss: 0.3001\tLoss: 0.6313\t\n",
      "Subject: 013, n=06 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0790\tTop_Loss: 0.1639\tBottom_Loss: 0.2158\tLoss: 0.4588\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0685\tTop_Loss: 0.2174\tBottom_Loss: 0.3226\tLoss: 0.6086\t\n",
      "Subject: 013, n=06 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1484\tTop_Loss: 0.2984\tBottom_Loss: 0.2189\tLoss: 0.6656\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2270\tTop_Loss: 0.2744\tBottom_Loss: 0.2936\tLoss: 0.7950\t\n",
      "Subject: 013, n=06 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1049\tTop_Loss: 0.2298\tBottom_Loss: 0.2476\tLoss: 0.5823\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1102\tTop_Loss: 0.2409\tBottom_Loss: 0.1608\tLoss: 0.5118\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1914\tTop_Loss: 0.2888\tBottom_Loss: 0.3303\tLoss: 0.8105\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1421\tTop_Loss: 0.2143\tBottom_Loss: 0.2476\tLoss: 0.6041\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1411\tTop_Loss: 0.3308\tBottom_Loss: 0.1700\tLoss: 0.6418\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1291\tTop_Loss: 0.2519\tBottom_Loss: 0.1653\tLoss: 0.5463\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0606\tTop_Loss: 0.2231\tBottom_Loss: 0.1088\tLoss: 0.3924\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0660\tTop_Loss: 0.1480\tBottom_Loss: 0.1529\tLoss: 0.3669\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1102\tTop_Loss: 0.2174\tBottom_Loss: 0.2716\tLoss: 0.5991\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1108\tTop_Loss: 0.3704\tBottom_Loss: 0.2182\tLoss: 0.6995\t\n",
      "Subject: 013, n=06 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1345\tTop_Loss: 0.3136\tBottom_Loss: 0.2005\tLoss: 0.6486\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0925\tTop_Loss: 0.2323\tBottom_Loss: 0.2229\tLoss: 0.5477\t\n",
      "Subject: 013, n=06 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0776\tTop_Loss: 0.3058\tBottom_Loss: 0.1458\tLoss: 0.5291\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0912\tTop_Loss: 0.1755\tBottom_Loss: 0.1426\tLoss: 0.4093\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1865\tTop_Loss: 0.3114\tBottom_Loss: 0.2643\tLoss: 0.7621\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1396\tTop_Loss: 0.1604\tBottom_Loss: 0.1928\tLoss: 0.4928\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0572\tTop_Loss: 0.1434\tBottom_Loss: 0.1393\tLoss: 0.3399\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1304\tTop_Loss: 0.2448\tBottom_Loss: 0.2631\tLoss: 0.6383\t\n",
      "Subject: 013, n=06 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0738\tTop_Loss: 0.1914\tBottom_Loss: 0.1071\tLoss: 0.3723\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1236\tTop_Loss: 0.2639\tBottom_Loss: 0.1512\tLoss: 0.5387\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0515\tTop_Loss: 0.1174\tBottom_Loss: 0.0857\tLoss: 0.2546\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0419\tTop_Loss: 0.1617\tBottom_Loss: 0.1139\tLoss: 0.3174\t\n",
      "Subject: 013, n=06 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0485\tTop_Loss: 0.1405\tBottom_Loss: 0.1257\tLoss: 0.3147\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0550\tTop_Loss: 0.1835\tBottom_Loss: 0.1359\tLoss: 0.3743\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0325\tTop_Loss: 0.1452\tBottom_Loss: 0.0682\tLoss: 0.2459\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0702\tTop_Loss: 0.1708\tBottom_Loss: 0.0696\tLoss: 0.3106\t\n",
      "Subject: 013, n=06 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0650\tTop_Loss: 0.2071\tBottom_Loss: 0.1175\tLoss: 0.3896\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1115\tTop_Loss: 0.2136\tBottom_Loss: 0.1694\tLoss: 0.4946\t\n",
      "Subject: 013, n=06 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0520\tTop_Loss: 0.1237\tBottom_Loss: 0.2317\tLoss: 0.4074\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0912\tTop_Loss: 0.2572\tBottom_Loss: 0.1171\tLoss: 0.4656\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0775\tTop_Loss: 0.1843\tBottom_Loss: 0.2109\tLoss: 0.4727\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1316\tTop_Loss: 0.2049\tBottom_Loss: 0.2391\tLoss: 0.5756\t\n",
      "Subject: 013, n=06 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0227\tTop_Loss: 0.0924\tBottom_Loss: 0.0811\tLoss: 0.1963\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0784\tTop_Loss: 0.1938\tBottom_Loss: 0.1630\tLoss: 0.4351\t\n",
      "Subject: 013, n=06 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0434\tTop_Loss: 0.0785\tBottom_Loss: 0.1448\tLoss: 0.2667\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1040\tTop_Loss: 0.2019\tBottom_Loss: 0.1486\tLoss: 0.4545\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1426\tTop_Loss: 0.2404\tBottom_Loss: 0.1124\tLoss: 0.4955\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0428\tTop_Loss: 0.0834\tBottom_Loss: 0.1348\tLoss: 0.2610\t\n",
      "Subject: 013, n=06 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0453\tTop_Loss: 0.0799\tBottom_Loss: 0.1654\tLoss: 0.2905\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0246\tTop_Loss: 0.0679\tBottom_Loss: 0.0790\tLoss: 0.1715\t\n",
      "Subject: 013, n=06 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0303\tTop_Loss: 0.1125\tBottom_Loss: 0.1451\tLoss: 0.2880\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0730\tTop_Loss: 0.1391\tBottom_Loss: 0.0896\tLoss: 0.3017\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0259\tTop_Loss: 0.0650\tBottom_Loss: 0.0503\tLoss: 0.1412\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0282\tTop_Loss: 0.0680\tBottom_Loss: 0.0598\tLoss: 0.1561\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0851\tTop_Loss: 0.2210\tBottom_Loss: 0.1762\tLoss: 0.4823\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0303\tTop_Loss: 0.0948\tBottom_Loss: 0.0750\tLoss: 0.2001\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0588\tTop_Loss: 0.1227\tBottom_Loss: 0.1383\tLoss: 0.3199\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0291\tTop_Loss: 0.2024\tBottom_Loss: 0.0496\tLoss: 0.2811\t\n",
      "Subject: 013, n=06 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0817\tTop_Loss: 0.1842\tBottom_Loss: 0.1117\tLoss: 0.3776\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0306\tTop_Loss: 0.1814\tBottom_Loss: 0.0757\tLoss: 0.2877\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0166\tTop_Loss: 0.0638\tBottom_Loss: 0.0491\tLoss: 0.1294\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0148\tTop_Loss: 0.0697\tBottom_Loss: 0.0526\tLoss: 0.1371\t\n",
      "Subject: 013, n=06 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0379\tTop_Loss: 0.1001\tBottom_Loss: 0.0589\tLoss: 0.1969\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0238\tTop_Loss: 0.1194\tBottom_Loss: 0.0429\tLoss: 0.1861\t\n",
      "Subject: 013, n=06 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0382\tTop_Loss: 0.0956\tBottom_Loss: 0.0853\tLoss: 0.2191\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0208\tTop_Loss: 0.0886\tBottom_Loss: 0.0682\tLoss: 0.1777\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0106\tTop_Loss: 0.0519\tBottom_Loss: 0.0533\tLoss: 0.1158\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0601\tTop_Loss: 0.1070\tBottom_Loss: 0.1148\tLoss: 0.2820\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0433\tTop_Loss: 0.0554\tBottom_Loss: 0.0412\tLoss: 0.1399\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0116\tTop_Loss: 0.0495\tBottom_Loss: 0.0430\tLoss: 0.1041\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0317\tTop_Loss: 0.0742\tBottom_Loss: 0.0669\tLoss: 0.1727\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1788\tTop_Loss: 0.2961\tBottom_Loss: 0.1525\tLoss: 0.6274\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0452\tTop_Loss: 0.0413\tBottom_Loss: 0.1029\tLoss: 0.1893\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0181\tTop_Loss: 0.0488\tBottom_Loss: 0.0507\tLoss: 0.1176\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0519\tTop_Loss: 0.0610\tBottom_Loss: 0.1016\tLoss: 0.2146\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0584\tTop_Loss: 0.0695\tBottom_Loss: 0.1293\tLoss: 0.2571\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0111\tTop_Loss: 0.0777\tBottom_Loss: 0.0514\tLoss: 0.1402\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0429\tTop_Loss: 0.1126\tBottom_Loss: 0.0536\tLoss: 0.2092\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0267\tTop_Loss: 0.0742\tBottom_Loss: 0.0284\tLoss: 0.1293\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0547\tTop_Loss: 0.0859\tBottom_Loss: 0.1389\tLoss: 0.2795\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0132\tTop_Loss: 0.1134\tBottom_Loss: 0.0363\tLoss: 0.1629\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0130\tTop_Loss: 0.0428\tBottom_Loss: 0.0320\tLoss: 0.0878\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0187\tTop_Loss: 0.0880\tBottom_Loss: 0.0258\tLoss: 0.1326\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0157\tTop_Loss: 0.0758\tBottom_Loss: 0.0729\tLoss: 0.1644\t\n",
      "Subject: 013, n=06 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0165\tTop_Loss: 0.0677\tBottom_Loss: 0.0716\tLoss: 0.1559\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0306\tTop_Loss: 0.0546\tBottom_Loss: 0.0463\tLoss: 0.1314\t\n",
      "Subject: 013, n=06 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0112\tTop_Loss: 0.0790\tBottom_Loss: 0.0212\tLoss: 0.1114\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0138\tTop_Loss: 0.0321\tBottom_Loss: 0.0289\tLoss: 0.0748\t\n",
      "Subject: 013, n=06 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0342\tTop_Loss: 0.0998\tBottom_Loss: 0.0467\tLoss: 0.1806\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0047\tTop_Loss: 0.0318\tBottom_Loss: 0.0330\tLoss: 0.0695\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0155\tTop_Loss: 0.0323\tBottom_Loss: 0.0688\tLoss: 0.1167\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0179\tTop_Loss: 0.0455\tBottom_Loss: 0.0555\tLoss: 0.1189\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0330\tTop_Loss: 0.0981\tBottom_Loss: 0.0661\tLoss: 0.1973\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0213\tTop_Loss: 0.1221\tBottom_Loss: 0.0216\tLoss: 0.1649\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0041\tTop_Loss: 0.0264\tBottom_Loss: 0.0152\tLoss: 0.0458\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0357\tTop_Loss: 0.0587\tBottom_Loss: 0.0978\tLoss: 0.1922\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0066\tTop_Loss: 0.0505\tBottom_Loss: 0.0207\tLoss: 0.0778\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0114\tTop_Loss: 0.0411\tBottom_Loss: 0.0259\tLoss: 0.0784\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0083\tTop_Loss: 0.0313\tBottom_Loss: 0.0287\tLoss: 0.0683\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0536\tTop_Loss: 0.2010\tBottom_Loss: 0.0726\tLoss: 0.3271\t\n",
      "Subject: 013, n=06 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0083\tTop_Loss: 0.0442\tBottom_Loss: 0.0136\tLoss: 0.0661\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0060\tTop_Loss: 0.0407\tBottom_Loss: 0.0307\tLoss: 0.0774\t\n",
      "Subject: 013, n=06 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0210\tTop_Loss: 0.0822\tBottom_Loss: 0.0484\tLoss: 0.1516\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0272\tTop_Loss: 0.0947\tBottom_Loss: 0.1149\tLoss: 0.2368\t\n",
      "Subject: 013, n=06 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0183\tTop_Loss: 0.1155\tBottom_Loss: 0.0269\tLoss: 0.1606\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0725\tTop_Loss: 0.1665\tBottom_Loss: 0.0659\tLoss: 0.3048\t\n",
      "Subject: 013, n=06 | test_f1: 0.45455 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0117\tTop_Loss: 0.0620\tBottom_Loss: 0.0140\tLoss: 0.0876\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0247\tTop_Loss: 0.0612\tBottom_Loss: 0.0763\tLoss: 0.1622\t\n",
      "Subject: 013, n=06 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0435\tTop_Loss: 0.1102\tBottom_Loss: 0.1303\tLoss: 0.2840\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0049\tTop_Loss: 0.0358\tBottom_Loss: 0.0190\tLoss: 0.0598\t\n",
      "Subject: 013, n=06 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0040\tTop_Loss: 0.0178\tBottom_Loss: 0.0172\tLoss: 0.0390\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0141\tTop_Loss: 0.0722\tBottom_Loss: 0.0386\tLoss: 0.1248\t\n",
      "Subject: 013, n=06 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0057\tTop_Loss: 0.0190\tBottom_Loss: 0.0194\tLoss: 0.0441\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0179\tTop_Loss: 0.0337\tBottom_Loss: 0.1150\tLoss: 0.1666\t\n",
      "Subject: 013, n=06 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0051\tTop_Loss: 0.0569\tBottom_Loss: 0.0138\tLoss: 0.0757\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0389\tTop_Loss: 0.0299\tBottom_Loss: 0.1114\tLoss: 0.1802\t\n",
      "Subject: 013, n=06 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.375\tLabel_Loss: 1.2742\tTop_Loss: 1.4120\tBottom_Loss: 1.2277\tLoss: 3.9138\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.469\tLabel_Loss: 1.1097\tTop_Loss: 1.2236\tBottom_Loss: 1.1156\tLoss: 3.4490\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 014, n=10 | test_f1: 0.11111 |best_f1: 0.11111\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7712\tTop_Loss: 0.8606\tBottom_Loss: 0.9375\tLoss: 2.5693\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.500\tLabel_Loss: 0.9758\tTop_Loss: 0.9749\tBottom_Loss: 1.0408\tLoss: 2.9915\t\n",
      "Subject: 014, n=10 | test_f1: 0.11111 |best_f1: 0.11111\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.500\tLabel_Loss: 1.1370\tTop_Loss: 1.3032\tBottom_Loss: 0.9331\tLoss: 3.3732\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.594\tLabel_Loss: 0.9307\tTop_Loss: 1.0720\tBottom_Loss: 0.9077\tLoss: 2.9104\t\n",
      "Subject: 014, n=10 | test_f1: 0.11111 |best_f1: 0.11111\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8459\tTop_Loss: 0.8362\tBottom_Loss: 0.8353\tLoss: 2.5175\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.531\tLabel_Loss: 0.9645\tTop_Loss: 0.9300\tBottom_Loss: 1.0747\tLoss: 2.9693\t\n",
      "Subject: 014, n=10 | test_f1: 0.11111 |best_f1: 0.11111\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8110\tTop_Loss: 0.9232\tBottom_Loss: 0.9341\tLoss: 2.6682\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7054\tTop_Loss: 0.8559\tBottom_Loss: 0.7338\tLoss: 2.2951\t\n",
      "Subject: 014, n=10 | test_f1: 0.11111 |best_f1: 0.11111\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.719\tLabel_Loss: 0.7906\tTop_Loss: 0.9473\tBottom_Loss: 0.7455\tLoss: 2.4834\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.656\tLabel_Loss: 0.8659\tTop_Loss: 0.9884\tBottom_Loss: 1.0038\tLoss: 2.8581\t\n",
      "Subject: 014, n=10 | test_f1: 0.11111 |best_f1: 0.11111\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7653\tTop_Loss: 0.8214\tBottom_Loss: 0.8335\tLoss: 2.4202\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7768\tTop_Loss: 1.0013\tBottom_Loss: 0.9772\tLoss: 2.7552\t\n",
      "Subject: 014, n=10 | test_f1: 0.11111 |best_f1: 0.11111\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.562\tLabel_Loss: 0.8355\tTop_Loss: 0.7995\tBottom_Loss: 0.9434\tLoss: 2.5784\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.625\tLabel_Loss: 0.6916\tTop_Loss: 1.0455\tBottom_Loss: 0.7871\tLoss: 2.5241\t\n",
      "Subject: 014, n=10 | test_f1: 0.12121 |best_f1: 0.12121\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8006\tTop_Loss: 0.9180\tBottom_Loss: 0.9060\tLoss: 2.6247\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7645\tTop_Loss: 0.9216\tBottom_Loss: 0.8019\tLoss: 2.4880\t\n",
      "Subject: 014, n=10 | test_f1: 0.11111 |best_f1: 0.12121\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7639\tTop_Loss: 0.8486\tBottom_Loss: 0.8920\tLoss: 2.5045\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.688\tLabel_Loss: 0.8335\tTop_Loss: 0.6937\tBottom_Loss: 0.7450\tLoss: 2.2722\t\n",
      "Subject: 014, n=10 | test_f1: 0.11111 |best_f1: 0.12121\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7980\tTop_Loss: 0.8625\tBottom_Loss: 0.7859\tLoss: 2.4464\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6360\tTop_Loss: 0.7304\tBottom_Loss: 0.8774\tLoss: 2.2438\t\n",
      "Subject: 014, n=10 | test_f1: 0.11111 |best_f1: 0.12121\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6412\tTop_Loss: 0.6179\tBottom_Loss: 0.6064\tLoss: 1.8654\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8488\tTop_Loss: 0.8681\tBottom_Loss: 1.0589\tLoss: 2.7758\t\n",
      "Subject: 014, n=10 | test_f1: 0.11111 |best_f1: 0.12121\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6556\tTop_Loss: 0.6441\tBottom_Loss: 0.6855\tLoss: 1.9852\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.562\tLabel_Loss: 0.8467\tTop_Loss: 0.7551\tBottom_Loss: 0.8095\tLoss: 2.4113\t\n",
      "Subject: 014, n=10 | test_f1: 0.11111 |best_f1: 0.12121\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5292\tTop_Loss: 0.6843\tBottom_Loss: 0.5882\tLoss: 1.8017\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5686\tTop_Loss: 0.6931\tBottom_Loss: 0.7204\tLoss: 1.9821\t\n",
      "Subject: 014, n=10 | test_f1: 0.066667 |best_f1: 0.12121\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6792\tTop_Loss: 0.8220\tBottom_Loss: 0.7476\tLoss: 2.2487\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.594\tLabel_Loss: 0.9246\tTop_Loss: 0.9608\tBottom_Loss: 0.9607\tLoss: 2.8461\t\n",
      "Subject: 014, n=10 | test_f1: 0.31481 |best_f1: 0.31481\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.844\tLabel_Loss: 0.5433\tTop_Loss: 0.8834\tBottom_Loss: 0.6117\tLoss: 2.0384\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.844\tLabel_Loss: 0.5719\tTop_Loss: 0.6988\tBottom_Loss: 0.7124\tLoss: 1.9831\t\n",
      "Subject: 014, n=10 | test_f1: 0.11111 |best_f1: 0.31481\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3756\tTop_Loss: 0.5138\tBottom_Loss: 0.4564\tLoss: 1.3458\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6377\tTop_Loss: 0.7396\tBottom_Loss: 0.7745\tLoss: 2.1517\t\n",
      "Subject: 014, n=10 | test_f1: 0.12121 |best_f1: 0.31481\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5485\tTop_Loss: 0.6373\tBottom_Loss: 0.8008\tLoss: 1.9866\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5958\tTop_Loss: 0.7730\tBottom_Loss: 0.6335\tLoss: 2.0023\t\n",
      "Subject: 014, n=10 | test_f1: 0.45455 |best_f1: 0.45455\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4273\tTop_Loss: 0.4836\tBottom_Loss: 0.5577\tLoss: 1.4686\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6040\tTop_Loss: 0.7124\tBottom_Loss: 0.7234\tLoss: 2.0398\t\n",
      "Subject: 014, n=10 | test_f1: 0.16667 |best_f1: 0.45455\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4549\tTop_Loss: 0.6579\tBottom_Loss: 0.5414\tLoss: 1.6542\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5979\tTop_Loss: 0.5789\tBottom_Loss: 0.6257\tLoss: 1.8024\t\n",
      "Subject: 014, n=10 | test_f1: 0.20455 |best_f1: 0.45455\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6112\tTop_Loss: 0.6740\tBottom_Loss: 0.5682\tLoss: 1.8534\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.688\tLabel_Loss: 0.4976\tTop_Loss: 0.6784\tBottom_Loss: 0.5646\tLoss: 1.7406\t\n",
      "Subject: 014, n=10 | test_f1: 0.3 |best_f1: 0.45455\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.781\tLabel_Loss: 0.6002\tTop_Loss: 0.8102\tBottom_Loss: 0.5210\tLoss: 1.9315\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2578\tTop_Loss: 0.4514\tBottom_Loss: 0.4450\tLoss: 1.1542\t\n",
      "Subject: 014, n=10 | test_f1: 0.48148 |best_f1: 0.48148\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2758\tTop_Loss: 0.4098\tBottom_Loss: 0.4172\tLoss: 1.1027\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7478\tTop_Loss: 1.0474\tBottom_Loss: 0.7378\tLoss: 2.5330\t\n",
      "Subject: 014, n=10 | test_f1: 0.35556 |best_f1: 0.48148\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4792\tTop_Loss: 0.5880\tBottom_Loss: 0.5661\tLoss: 1.6334\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4486\tTop_Loss: 0.4660\tBottom_Loss: 0.7474\tLoss: 1.6619\t\n",
      "Subject: 014, n=10 | test_f1: 0.060606 |best_f1: 0.48148\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3598\tTop_Loss: 0.4567\tBottom_Loss: 0.4322\tLoss: 1.2486\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2752\tTop_Loss: 0.3392\tBottom_Loss: 0.3601\tLoss: 0.9744\t\n",
      "Subject: 014, n=10 | test_f1: 0.11111 |best_f1: 0.48148\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3322\tTop_Loss: 0.4686\tBottom_Loss: 0.5751\tLoss: 1.3759\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4762\tTop_Loss: 0.6640\tBottom_Loss: 0.5137\tLoss: 1.6539\t\n",
      "Subject: 014, n=10 | test_f1: 0.11111 |best_f1: 0.48148\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3147\tTop_Loss: 0.5447\tBottom_Loss: 0.4444\tLoss: 1.3038\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3132\tTop_Loss: 0.5368\tBottom_Loss: 0.5218\tLoss: 1.3718\t\n",
      "Subject: 014, n=10 | test_f1: 0.4 |best_f1: 0.48148\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2764\tTop_Loss: 0.4224\tBottom_Loss: 0.4499\tLoss: 1.1487\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3477\tTop_Loss: 0.4254\tBottom_Loss: 0.4682\tLoss: 1.2413\t\n",
      "Subject: 014, n=10 | test_f1: 0.35556 |best_f1: 0.48148\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4845\tTop_Loss: 0.6219\tBottom_Loss: 0.4434\tLoss: 1.5497\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1568\tTop_Loss: 0.4986\tBottom_Loss: 0.2281\tLoss: 0.8835\t\n",
      "Subject: 014, n=10 | test_f1: 0.45455 |best_f1: 0.48148\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3291\tTop_Loss: 0.4364\tBottom_Loss: 0.4544\tLoss: 1.2199\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3557\tTop_Loss: 0.5027\tBottom_Loss: 0.4520\tLoss: 1.3104\t\n",
      "Subject: 014, n=10 | test_f1: 0.55 |best_f1: 0.55\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2898\tTop_Loss: 0.6623\tBottom_Loss: 0.3842\tLoss: 1.3363\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2973\tTop_Loss: 0.4565\tBottom_Loss: 0.4128\tLoss: 1.1665\t\n",
      "Subject: 014, n=10 | test_f1: 0.35556 |best_f1: 0.55\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3814\tTop_Loss: 0.5203\tBottom_Loss: 0.3555\tLoss: 1.2572\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1545\tTop_Loss: 0.2379\tBottom_Loss: 0.3254\tLoss: 0.7178\t\n",
      "Subject: 014, n=10 | test_f1: 0.14074 |best_f1: 0.55\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2589\tTop_Loss: 0.3292\tBottom_Loss: 0.3622\tLoss: 0.9503\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2265\tTop_Loss: 0.4510\tBottom_Loss: 0.3960\tLoss: 1.0734\t\n",
      "Subject: 014, n=10 | test_f1: 0.11111 |best_f1: 0.55\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1410\tTop_Loss: 0.2488\tBottom_Loss: 0.2032\tLoss: 0.5930\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.938\tLabel_Loss: 0.3171\tTop_Loss: 0.5730\tBottom_Loss: 0.3747\tLoss: 1.2648\t\n",
      "Subject: 014, n=10 | test_f1: 0.20455 |best_f1: 0.55\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1987\tTop_Loss: 0.2922\tBottom_Loss: 0.4079\tLoss: 0.8989\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2181\tTop_Loss: 0.4197\tBottom_Loss: 0.4382\tLoss: 1.0759\t\n",
      "Subject: 014, n=10 | test_f1: 0.14815 |best_f1: 0.55\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2702\tTop_Loss: 0.4767\tBottom_Loss: 0.3896\tLoss: 1.1365\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2550\tTop_Loss: 0.4499\tBottom_Loss: 0.2048\tLoss: 0.9097\t\n",
      "Subject: 014, n=10 | test_f1: 0.48148 |best_f1: 0.55\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2913\tTop_Loss: 0.4406\tBottom_Loss: 0.2868\tLoss: 1.0187\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1557\tTop_Loss: 0.4020\tBottom_Loss: 0.1836\tLoss: 0.7414\t\n",
      "Subject: 014, n=10 | test_f1: 0.28148 |best_f1: 0.55\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1130\tTop_Loss: 0.2636\tBottom_Loss: 0.1913\tLoss: 0.5678\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2699\tTop_Loss: 0.6059\tBottom_Loss: 0.3363\tLoss: 1.2120\t\n",
      "Subject: 014, n=10 | test_f1: 0.12121 |best_f1: 0.55\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1870\tTop_Loss: 0.3957\tBottom_Loss: 0.2503\tLoss: 0.8330\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2656\tTop_Loss: 0.3564\tBottom_Loss: 0.3208\tLoss: 0.9428\t\n",
      "Subject: 014, n=10 | test_f1: 0.45455 |best_f1: 0.55\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2324\tTop_Loss: 0.4462\tBottom_Loss: 0.3493\tLoss: 1.0279\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1765\tTop_Loss: 0.3140\tBottom_Loss: 0.2055\tLoss: 0.6960\t\n",
      "Subject: 014, n=10 | test_f1: 0.55 |best_f1: 0.55\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1712\tTop_Loss: 0.4370\tBottom_Loss: 0.2579\tLoss: 0.8661\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2129\tTop_Loss: 0.2398\tBottom_Loss: 0.3832\tLoss: 0.8360\t\n",
      "Subject: 014, n=10 | test_f1: 0.12121 |best_f1: 0.55\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0690\tTop_Loss: 0.3100\tBottom_Loss: 0.1909\tLoss: 0.5699\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1247\tTop_Loss: 0.3068\tBottom_Loss: 0.1987\tLoss: 0.6302\t\n",
      "Subject: 014, n=10 | test_f1: 0.4 |best_f1: 0.55\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2080\tTop_Loss: 0.3830\tBottom_Loss: 0.2874\tLoss: 0.8783\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2512\tTop_Loss: 0.3348\tBottom_Loss: 0.3474\tLoss: 0.9334\t\n",
      "Subject: 014, n=10 | test_f1: 0.55 |best_f1: 0.55\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1749\tTop_Loss: 0.3672\tBottom_Loss: 0.2375\tLoss: 0.7796\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1474\tTop_Loss: 0.3000\tBottom_Loss: 0.2900\tLoss: 0.7374\t\n",
      "Subject: 014, n=10 | test_f1: 0.3 |best_f1: 0.55\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0758\tTop_Loss: 0.1555\tBottom_Loss: 0.1512\tLoss: 0.3825\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0876\tTop_Loss: 0.2441\tBottom_Loss: 0.1274\tLoss: 0.4591\t\n",
      "Subject: 014, n=10 | test_f1: 0.48148 |best_f1: 0.55\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1345\tTop_Loss: 0.1783\tBottom_Loss: 0.2985\tLoss: 0.6113\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1864\tTop_Loss: 0.4306\tBottom_Loss: 0.2550\tLoss: 0.8721\t\n",
      "Subject: 014, n=10 | test_f1: 0.4 |best_f1: 0.55\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0803\tTop_Loss: 0.3086\tBottom_Loss: 0.0910\tLoss: 0.4799\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0437\tTop_Loss: 0.2633\tBottom_Loss: 0.0771\tLoss: 0.3842\t\n",
      "Subject: 014, n=10 | test_f1: 0.55 |best_f1: 0.55\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1297\tTop_Loss: 0.4317\tBottom_Loss: 0.2629\tLoss: 0.8243\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0712\tTop_Loss: 0.1588\tBottom_Loss: 0.1728\tLoss: 0.4028\t\n",
      "Subject: 014, n=10 | test_f1: 0.4 |best_f1: 0.55\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0646\tTop_Loss: 0.1526\tBottom_Loss: 0.1454\tLoss: 0.3626\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1212\tTop_Loss: 0.3367\tBottom_Loss: 0.1709\tLoss: 0.6287\t\n",
      "Subject: 014, n=10 | test_f1: 0.45455 |best_f1: 0.55\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0580\tTop_Loss: 0.2583\tBottom_Loss: 0.0950\tLoss: 0.4114\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0731\tTop_Loss: 0.1602\tBottom_Loss: 0.1604\tLoss: 0.3937\t\n",
      "Subject: 014, n=10 | test_f1: 0.45455 |best_f1: 0.55\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0806\tTop_Loss: 0.2090\tBottom_Loss: 0.2348\tLoss: 0.5244\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0691\tTop_Loss: 0.1748\tBottom_Loss: 0.1553\tLoss: 0.3993\t\n",
      "Subject: 014, n=10 | test_f1: 0.45455 |best_f1: 0.55\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1125\tTop_Loss: 0.1591\tBottom_Loss: 0.1658\tLoss: 0.4374\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1170\tTop_Loss: 0.2181\tBottom_Loss: 0.2813\tLoss: 0.6165\t\n",
      "Subject: 014, n=10 | test_f1: 0.060606 |best_f1: 0.55\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0319\tTop_Loss: 0.1479\tBottom_Loss: 0.0825\tLoss: 0.2623\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0751\tTop_Loss: 0.1191\tBottom_Loss: 0.2157\tLoss: 0.4098\t\n",
      "Subject: 014, n=10 | test_f1: 0.45455 |best_f1: 0.55\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1340\tTop_Loss: 0.1697\tBottom_Loss: 0.2712\tLoss: 0.5749\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0960\tTop_Loss: 0.2605\tBottom_Loss: 0.1426\tLoss: 0.4991\t\n",
      "Subject: 014, n=10 | test_f1: 0.4 |best_f1: 0.55\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0943\tTop_Loss: 0.1393\tBottom_Loss: 0.1562\tLoss: 0.3899\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0896\tTop_Loss: 0.1319\tBottom_Loss: 0.1249\tLoss: 0.3465\t\n",
      "Subject: 014, n=10 | test_f1: 0.48148 |best_f1: 0.55\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1271\tTop_Loss: 0.2061\tBottom_Loss: 0.1769\tLoss: 0.5101\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0746\tTop_Loss: 0.2865\tBottom_Loss: 0.0822\tLoss: 0.4432\t\n",
      "Subject: 014, n=10 | test_f1: 0.11111 |best_f1: 0.55\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0544\tTop_Loss: 0.1899\tBottom_Loss: 0.1565\tLoss: 0.4007\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1192\tTop_Loss: 0.2265\tBottom_Loss: 0.2160\tLoss: 0.5616\t\n",
      "Subject: 014, n=10 | test_f1: 0.45455 |best_f1: 0.55\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0648\tTop_Loss: 0.2191\tBottom_Loss: 0.1882\tLoss: 0.4721\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0365\tTop_Loss: 0.1056\tBottom_Loss: 0.0935\tLoss: 0.2355\t\n",
      "Subject: 014, n=10 | test_f1: 0.4 |best_f1: 0.55\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0662\tTop_Loss: 0.2310\tBottom_Loss: 0.1366\tLoss: 0.4338\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0776\tTop_Loss: 0.1281\tBottom_Loss: 0.1556\tLoss: 0.3613\t\n",
      "Subject: 014, n=10 | test_f1: 0.11111 |best_f1: 0.55\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0628\tTop_Loss: 0.1660\tBottom_Loss: 0.1979\tLoss: 0.4267\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0458\tTop_Loss: 0.1399\tBottom_Loss: 0.1082\tLoss: 0.2939\t\n",
      "Subject: 014, n=10 | test_f1: 0.55 |best_f1: 0.55\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0475\tTop_Loss: 0.1662\tBottom_Loss: 0.0693\tLoss: 0.2829\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1055\tTop_Loss: 0.3257\tBottom_Loss: 0.0946\tLoss: 0.5258\t\n",
      "Subject: 014, n=10 | test_f1: 0.12121 |best_f1: 0.55\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0498\tTop_Loss: 0.1837\tBottom_Loss: 0.0723\tLoss: 0.3057\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0368\tTop_Loss: 0.0903\tBottom_Loss: 0.0915\tLoss: 0.2185\t\n",
      "Subject: 014, n=10 | test_f1: 0.37963 |best_f1: 0.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[62][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0681\tTop_Loss: 0.1475\tBottom_Loss: 0.1465\tLoss: 0.3621\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0902\tTop_Loss: 0.1246\tBottom_Loss: 0.1641\tLoss: 0.3788\t\n",
      "Subject: 014, n=10 | test_f1: 0.11111 |best_f1: 0.55\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0301\tTop_Loss: 0.0845\tBottom_Loss: 0.1070\tLoss: 0.2215\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0621\tTop_Loss: 0.1623\tBottom_Loss: 0.0654\tLoss: 0.2898\t\n",
      "Subject: 014, n=10 | test_f1: 0.48148 |best_f1: 0.55\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0293\tTop_Loss: 0.1240\tBottom_Loss: 0.0714\tLoss: 0.2247\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0408\tTop_Loss: 0.1138\tBottom_Loss: 0.1139\tLoss: 0.2685\t\n",
      "Subject: 014, n=10 | test_f1: 0.55 |best_f1: 0.55\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0636\tTop_Loss: 0.1223\tBottom_Loss: 0.0986\tLoss: 0.2845\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0494\tTop_Loss: 0.1247\tBottom_Loss: 0.1532\tLoss: 0.3273\t\n",
      "Subject: 014, n=10 | test_f1: 0.060606 |best_f1: 0.55\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0201\tTop_Loss: 0.0503\tBottom_Loss: 0.0716\tLoss: 0.1420\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0381\tTop_Loss: 0.0843\tBottom_Loss: 0.1010\tLoss: 0.2234\t\n",
      "Subject: 014, n=10 | test_f1: 0.4 |best_f1: 0.55\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0852\tTop_Loss: 0.1966\tBottom_Loss: 0.1380\tLoss: 0.4197\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0410\tTop_Loss: 0.0575\tBottom_Loss: 0.1167\tLoss: 0.2151\t\n",
      "Subject: 014, n=10 | test_f1: 0.4 |best_f1: 0.55\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0735\tTop_Loss: 0.1816\tBottom_Loss: 0.1089\tLoss: 0.3641\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0502\tTop_Loss: 0.1273\tBottom_Loss: 0.0914\tLoss: 0.2689\t\n",
      "Subject: 014, n=10 | test_f1: 0.21667 |best_f1: 0.55\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0522\tTop_Loss: 0.0961\tBottom_Loss: 0.0853\tLoss: 0.2336\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0132\tTop_Loss: 0.0438\tBottom_Loss: 0.0815\tLoss: 0.1384\t\n",
      "Subject: 014, n=10 | test_f1: 0.11111 |best_f1: 0.55\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0491\tTop_Loss: 0.0885\tBottom_Loss: 0.0542\tLoss: 0.1918\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0446\tTop_Loss: 0.1169\tBottom_Loss: 0.0660\tLoss: 0.2275\t\n",
      "Subject: 014, n=10 | test_f1: 0.060606 |best_f1: 0.55\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0221\tTop_Loss: 0.0989\tBottom_Loss: 0.0387\tLoss: 0.1597\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0303\tTop_Loss: 0.0876\tBottom_Loss: 0.0891\tLoss: 0.2070\t\n",
      "Subject: 014, n=10 | test_f1: 0.45455 |best_f1: 0.55\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0192\tTop_Loss: 0.0586\tBottom_Loss: 0.0390\tLoss: 0.1168\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0249\tTop_Loss: 0.1294\tBottom_Loss: 0.0599\tLoss: 0.2142\t\n",
      "Subject: 014, n=10 | test_f1: 0.45455 |best_f1: 0.55\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0704\tTop_Loss: 0.1342\tBottom_Loss: 0.1285\tLoss: 0.3331\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0223\tTop_Loss: 0.0699\tBottom_Loss: 0.0546\tLoss: 0.1469\t\n",
      "Subject: 014, n=10 | test_f1: 0.55 |best_f1: 0.55\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0139\tTop_Loss: 0.0557\tBottom_Loss: 0.0408\tLoss: 0.1104\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1104\tTop_Loss: 0.1607\tBottom_Loss: 0.1142\tLoss: 0.3853\t\n",
      "Subject: 014, n=10 | test_f1: 0.55 |best_f1: 0.55\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0358\tTop_Loss: 0.1392\tBottom_Loss: 0.0340\tLoss: 0.2089\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0512\tTop_Loss: 0.1161\tBottom_Loss: 0.0623\tLoss: 0.2296\t\n",
      "Subject: 014, n=10 | test_f1: 0.45455 |best_f1: 0.55\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0445\tTop_Loss: 0.0574\tBottom_Loss: 0.0779\tLoss: 0.1799\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0423\tTop_Loss: 0.0680\tBottom_Loss: 0.1278\tLoss: 0.2381\t\n",
      "Subject: 014, n=10 | test_f1: 0.45455 |best_f1: 0.55\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0459\tTop_Loss: 0.0394\tBottom_Loss: 0.0745\tLoss: 0.1597\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0555\tTop_Loss: 0.0680\tBottom_Loss: 0.0839\tLoss: 0.2073\t\n",
      "Subject: 014, n=10 | test_f1: 0.28148 |best_f1: 0.55\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0333\tTop_Loss: 0.1044\tBottom_Loss: 0.0739\tLoss: 0.2115\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0249\tTop_Loss: 0.1250\tBottom_Loss: 0.0353\tLoss: 0.1853\t\n",
      "Subject: 014, n=10 | test_f1: 0.55 |best_f1: 0.55\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0203\tTop_Loss: 0.0621\tBottom_Loss: 0.1081\tLoss: 0.1904\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0129\tTop_Loss: 0.0758\tBottom_Loss: 0.0368\tLoss: 0.1254\t\n",
      "Subject: 014, n=10 | test_f1: 0.060606 |best_f1: 0.55\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0344\tTop_Loss: 0.0814\tBottom_Loss: 0.0871\tLoss: 0.2029\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0097\tTop_Loss: 0.0707\tBottom_Loss: 0.0195\tLoss: 0.0999\t\n",
      "Subject: 014, n=10 | test_f1: 0.28148 |best_f1: 0.55\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0084\tTop_Loss: 0.0322\tBottom_Loss: 0.0364\tLoss: 0.0770\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0161\tTop_Loss: 0.0838\tBottom_Loss: 0.0175\tLoss: 0.1174\t\n",
      "Subject: 014, n=10 | test_f1: 0.4 |best_f1: 0.55\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0216\tTop_Loss: 0.0776\tBottom_Loss: 0.0391\tLoss: 0.1383\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0063\tTop_Loss: 0.0456\tBottom_Loss: 0.0159\tLoss: 0.0678\t\n",
      "Subject: 014, n=10 | test_f1: 0.20455 |best_f1: 0.55\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0487\tTop_Loss: 0.1544\tBottom_Loss: 0.0649\tLoss: 0.2680\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0220\tTop_Loss: 0.0745\tBottom_Loss: 0.1134\tLoss: 0.2099\t\n",
      "Subject: 014, n=10 | test_f1: 0.11111 |best_f1: 0.55\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0095\tTop_Loss: 0.0281\tBottom_Loss: 0.0354\tLoss: 0.0731\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0158\tTop_Loss: 0.0601\tBottom_Loss: 0.0281\tLoss: 0.1040\t\n",
      "Subject: 014, n=10 | test_f1: 0.11111 |best_f1: 0.55\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0127\tTop_Loss: 0.0291\tBottom_Loss: 0.0517\tLoss: 0.0935\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0425\tTop_Loss: 0.1176\tBottom_Loss: 0.1195\tLoss: 0.2796\t\n",
      "Subject: 014, n=10 | test_f1: 0.060606 |best_f1: 0.55\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0147\tTop_Loss: 0.0314\tBottom_Loss: 0.0377\tLoss: 0.0838\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0103\tTop_Loss: 0.0207\tBottom_Loss: 0.0233\tLoss: 0.0542\t\n",
      "Subject: 014, n=10 | test_f1: 0.48148 |best_f1: 0.55\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0297\tTop_Loss: 0.1014\tBottom_Loss: 0.0476\tLoss: 0.1786\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0428\tTop_Loss: 0.1621\tBottom_Loss: 0.0555\tLoss: 0.2604\t\n",
      "Subject: 014, n=10 | test_f1: 0.48148 |best_f1: 0.55\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0089\tTop_Loss: 0.0273\tBottom_Loss: 0.0235\tLoss: 0.0597\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0183\tTop_Loss: 0.0488\tBottom_Loss: 0.0391\tLoss: 0.1062\t\n",
      "Subject: 014, n=10 | test_f1: 0.37963 |best_f1: 0.55\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0191\tTop_Loss: 0.0780\tBottom_Loss: 0.0265\tLoss: 0.1237\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0066\tTop_Loss: 0.0239\tBottom_Loss: 0.0202\tLoss: 0.0508\t\n",
      "Subject: 014, n=10 | test_f1: 0.37963 |best_f1: 0.55\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0120\tTop_Loss: 0.0279\tBottom_Loss: 0.0467\tLoss: 0.0866\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0347\tTop_Loss: 0.0572\tBottom_Loss: 0.0701\tLoss: 0.1620\t\n",
      "Subject: 014, n=10 | test_f1: 0.4 |best_f1: 0.55\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0226\tTop_Loss: 0.0552\tBottom_Loss: 0.0298\tLoss: 0.1077\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0154\tTop_Loss: 0.0822\tBottom_Loss: 0.0361\tLoss: 0.1336\t\n",
      "Subject: 014, n=10 | test_f1: 0.45455 |best_f1: 0.55\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0460\tTop_Loss: 0.0413\tBottom_Loss: 0.0403\tLoss: 0.1276\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0896\tTop_Loss: 0.0682\tBottom_Loss: 0.0886\tLoss: 0.2465\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 014, n=10 | test_f1: 0.14074 |best_f1: 0.55\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0066\tTop_Loss: 0.0378\tBottom_Loss: 0.0154\tLoss: 0.0598\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0501\tTop_Loss: 0.0303\tBottom_Loss: 0.0546\tLoss: 0.1349\t\n",
      "Subject: 014, n=10 | test_f1: 0.060606 |best_f1: 0.55\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0077\tTop_Loss: 0.0435\tBottom_Loss: 0.0159\tLoss: 0.0671\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0450\tTop_Loss: 0.0827\tBottom_Loss: 0.0451\tLoss: 0.1728\t\n",
      "Subject: 014, n=10 | test_f1: 0.45455 |best_f1: 0.55\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0093\tTop_Loss: 0.0423\tBottom_Loss: 0.0248\tLoss: 0.0764\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0081\tTop_Loss: 0.0263\tBottom_Loss: 0.0180\tLoss: 0.0523\t\n",
      "Subject: 014, n=10 | test_f1: 0.55 |best_f1: 0.55\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0110\tTop_Loss: 0.0289\tBottom_Loss: 0.0280\tLoss: 0.0679\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0082\tTop_Loss: 0.0443\tBottom_Loss: 0.0288\tLoss: 0.0813\t\n",
      "Subject: 014, n=10 | test_f1: 0.060606 |best_f1: 0.55\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0257\tTop_Loss: 0.0585\tBottom_Loss: 0.0203\tLoss: 0.1044\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0098\tTop_Loss: 0.0394\tBottom_Loss: 0.0281\tLoss: 0.0772\t\n",
      "Subject: 014, n=10 | test_f1: 0.35556 |best_f1: 0.55\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0120\tTop_Loss: 0.0708\tBottom_Loss: 0.0134\tLoss: 0.0961\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0051\tTop_Loss: 0.0262\tBottom_Loss: 0.0159\tLoss: 0.0472\t\n",
      "Subject: 014, n=10 | test_f1: 0.45455 |best_f1: 0.55\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0046\tTop_Loss: 0.0195\tBottom_Loss: 0.0112\tLoss: 0.0353\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0055\tTop_Loss: 0.0216\tBottom_Loss: 0.0150\tLoss: 0.0421\t\n",
      "Subject: 014, n=10 | test_f1: 0.48148 |best_f1: 0.55\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.312\tLabel_Loss: 1.2416\tTop_Loss: 1.0847\tBottom_Loss: 1.1065\tLoss: 3.4328\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.312\tLabel_Loss: 1.0635\tTop_Loss: 1.1204\tBottom_Loss: 1.5350\tLoss: 3.7189\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8856\tTop_Loss: 1.0207\tBottom_Loss: 1.0873\tLoss: 2.9936\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.406\tLabel_Loss: 1.2261\tTop_Loss: 1.1347\tBottom_Loss: 1.1892\tLoss: 3.5499\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.688\tLabel_Loss: 0.8078\tTop_Loss: 0.9805\tBottom_Loss: 0.7849\tLoss: 2.5732\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.469\tLabel_Loss: 1.1653\tTop_Loss: 1.1110\tBottom_Loss: 1.0905\tLoss: 3.3668\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.688\tLabel_Loss: 0.8228\tTop_Loss: 0.8742\tBottom_Loss: 0.9498\tLoss: 2.6468\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.531\tLabel_Loss: 1.0093\tTop_Loss: 0.8865\tBottom_Loss: 0.9963\tLoss: 2.8921\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.469\tLabel_Loss: 1.0421\tTop_Loss: 0.9554\tBottom_Loss: 0.9795\tLoss: 2.9769\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8844\tTop_Loss: 0.9586\tBottom_Loss: 0.9150\tLoss: 2.7580\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.531\tLabel_Loss: 0.9454\tTop_Loss: 0.9670\tBottom_Loss: 0.8234\tLoss: 2.7358\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7566\tTop_Loss: 0.8083\tBottom_Loss: 0.9346\tLoss: 2.4995\t\n",
      "Subject: 015, n=03 | test_f1: 0.0 |best_f1: 0.4\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.656\tLabel_Loss: 0.6688\tTop_Loss: 0.7916\tBottom_Loss: 0.8338\tLoss: 2.2942\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7888\tTop_Loss: 1.0247\tBottom_Loss: 0.8643\tLoss: 2.6779\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.562\tLabel_Loss: 0.9247\tTop_Loss: 0.7324\tBottom_Loss: 0.8817\tLoss: 2.5388\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6917\tTop_Loss: 0.8530\tBottom_Loss: 0.8903\tLoss: 2.4351\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8735\tTop_Loss: 0.8533\tBottom_Loss: 1.0827\tLoss: 2.8096\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.500\tLabel_Loss: 0.8776\tTop_Loss: 0.9936\tBottom_Loss: 0.8846\tLoss: 2.7558\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7152\tTop_Loss: 0.8257\tBottom_Loss: 1.0251\tLoss: 2.5660\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7256\tTop_Loss: 0.8217\tBottom_Loss: 0.7725\tLoss: 2.3198\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.688\tLabel_Loss: 0.8239\tTop_Loss: 0.8918\tBottom_Loss: 1.0492\tLoss: 2.7649\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6094\tTop_Loss: 0.8961\tBottom_Loss: 0.7833\tLoss: 2.2888\t\n",
      "Subject: 015, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.562\tLabel_Loss: 0.7660\tTop_Loss: 0.7694\tBottom_Loss: 0.8554\tLoss: 2.3908\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.688\tLabel_Loss: 0.5710\tTop_Loss: 0.6913\tBottom_Loss: 0.7209\tLoss: 1.9832\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7586\tTop_Loss: 0.7414\tBottom_Loss: 0.8995\tLoss: 2.3994\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.781\tLabel_Loss: 0.7036\tTop_Loss: 0.7107\tBottom_Loss: 0.8295\tLoss: 2.2438\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6182\tTop_Loss: 0.7016\tBottom_Loss: 0.8026\tLoss: 2.1223\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.719\tLabel_Loss: 0.5882\tTop_Loss: 0.7038\tBottom_Loss: 0.9300\tLoss: 2.2219\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5494\tTop_Loss: 0.5902\tBottom_Loss: 0.5745\tLoss: 1.7140\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5986\tTop_Loss: 0.6187\tBottom_Loss: 0.6421\tLoss: 1.8594\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6962\tTop_Loss: 0.6778\tBottom_Loss: 0.6874\tLoss: 2.0615\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4274\tTop_Loss: 0.6034\tBottom_Loss: 0.6270\tLoss: 1.6579\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5563\tTop_Loss: 0.6216\tBottom_Loss: 0.6317\tLoss: 1.8097\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8414\tTop_Loss: 0.9524\tBottom_Loss: 0.7272\tLoss: 2.5211\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6339\tTop_Loss: 0.6196\tBottom_Loss: 0.5969\tLoss: 1.8504\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5051\tTop_Loss: 0.5911\tBottom_Loss: 0.6489\tLoss: 1.7451\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6038\tTop_Loss: 0.6572\tBottom_Loss: 0.9069\tLoss: 2.1680\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4710\tTop_Loss: 0.5812\tBottom_Loss: 0.5689\tLoss: 1.6211\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4876\tTop_Loss: 0.6086\tBottom_Loss: 0.4917\tLoss: 1.5879\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.781\tLabel_Loss: 0.6306\tTop_Loss: 0.5555\tBottom_Loss: 0.4964\tLoss: 1.6826\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6800\tTop_Loss: 0.7460\tBottom_Loss: 0.7321\tLoss: 2.1581\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3844\tTop_Loss: 0.4770\tBottom_Loss: 0.5636\tLoss: 1.4251\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4918\tTop_Loss: 0.7471\tBottom_Loss: 0.7830\tLoss: 2.0218\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3989\tTop_Loss: 0.5720\tBottom_Loss: 0.5521\tLoss: 1.5231\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3392\tTop_Loss: 0.4798\tBottom_Loss: 0.4843\tLoss: 1.3033\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3579\tTop_Loss: 0.4524\tBottom_Loss: 0.4222\tLoss: 1.2324\t\n",
      "Subject: 015, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4364\tTop_Loss: 0.6016\tBottom_Loss: 0.6680\tLoss: 1.7060\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4100\tTop_Loss: 0.4528\tBottom_Loss: 0.4989\tLoss: 1.3616\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 015, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3719\tTop_Loss: 0.3782\tBottom_Loss: 0.5300\tLoss: 1.2801\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4078\tTop_Loss: 0.5504\tBottom_Loss: 0.4167\tLoss: 1.3749\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3444\tTop_Loss: 0.4776\tBottom_Loss: 0.6274\tLoss: 1.4493\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3920\tTop_Loss: 0.6845\tBottom_Loss: 0.4369\tLoss: 1.5133\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2758\tTop_Loss: 0.4653\tBottom_Loss: 0.4437\tLoss: 1.1848\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2378\tTop_Loss: 0.3658\tBottom_Loss: 0.5119\tLoss: 1.1154\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3853\tTop_Loss: 0.5214\tBottom_Loss: 0.5394\tLoss: 1.4461\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2629\tTop_Loss: 0.4256\tBottom_Loss: 0.4279\tLoss: 1.1165\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3761\tTop_Loss: 0.4582\tBottom_Loss: 0.5059\tLoss: 1.3402\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1826\tTop_Loss: 0.3958\tBottom_Loss: 0.2694\tLoss: 0.8479\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3843\tTop_Loss: 0.5412\tBottom_Loss: 0.4472\tLoss: 1.3726\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3067\tTop_Loss: 0.5515\tBottom_Loss: 0.4668\tLoss: 1.3251\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2824\tTop_Loss: 0.5336\tBottom_Loss: 0.2712\tLoss: 1.0872\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2800\tTop_Loss: 0.5181\tBottom_Loss: 0.2998\tLoss: 1.0979\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3107\tTop_Loss: 0.4364\tBottom_Loss: 0.3873\tLoss: 1.1344\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2888\tTop_Loss: 0.3303\tBottom_Loss: 0.4857\tLoss: 1.1049\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3658\tTop_Loss: 0.5374\tBottom_Loss: 0.3808\tLoss: 1.2839\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.875\tLabel_Loss: 0.1721\tTop_Loss: 0.3325\tBottom_Loss: 0.4137\tLoss: 0.9182\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2053\tTop_Loss: 0.3519\tBottom_Loss: 0.3090\tLoss: 0.8662\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1778\tTop_Loss: 0.3237\tBottom_Loss: 0.3288\tLoss: 0.8304\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2967\tTop_Loss: 0.5624\tBottom_Loss: 0.3074\tLoss: 1.1666\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1786\tTop_Loss: 0.3206\tBottom_Loss: 0.2705\tLoss: 0.7697\t\n",
      "Subject: 015, n=03 | test_f1: 0.25 |best_f1: 0.4\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2712\tTop_Loss: 0.3479\tBottom_Loss: 0.3365\tLoss: 0.9555\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3053\tTop_Loss: 0.5248\tBottom_Loss: 0.4386\tLoss: 1.2686\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1303\tTop_Loss: 0.3146\tBottom_Loss: 0.2865\tLoss: 0.7314\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2632\tTop_Loss: 0.5252\tBottom_Loss: 0.4563\tLoss: 1.2447\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2389\tTop_Loss: 0.3604\tBottom_Loss: 0.2839\tLoss: 0.8832\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0750\tTop_Loss: 0.2271\tBottom_Loss: 0.2306\tLoss: 0.5326\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1411\tTop_Loss: 0.3845\tBottom_Loss: 0.2623\tLoss: 0.7880\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3511\tTop_Loss: 0.4353\tBottom_Loss: 0.3585\tLoss: 1.1448\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1485\tTop_Loss: 0.3505\tBottom_Loss: 0.2629\tLoss: 0.7619\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2314\tTop_Loss: 0.3549\tBottom_Loss: 0.3335\tLoss: 0.9199\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2474\tTop_Loss: 0.4344\tBottom_Loss: 0.4346\tLoss: 1.1164\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2594\tTop_Loss: 0.3579\tBottom_Loss: 0.3320\tLoss: 0.9493\t\n",
      "Subject: 015, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2168\tTop_Loss: 0.3079\tBottom_Loss: 0.2802\tLoss: 0.8049\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1637\tTop_Loss: 0.2908\tBottom_Loss: 0.1945\tLoss: 0.6490\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1249\tTop_Loss: 0.2803\tBottom_Loss: 0.2804\tLoss: 0.6855\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2369\tTop_Loss: 0.3803\tBottom_Loss: 0.4214\tLoss: 1.0386\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1159\tTop_Loss: 0.2853\tBottom_Loss: 0.2651\tLoss: 0.6663\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2016\tTop_Loss: 0.3167\tBottom_Loss: 0.3608\tLoss: 0.8792\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1380\tTop_Loss: 0.3411\tBottom_Loss: 0.1267\tLoss: 0.6059\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0560\tTop_Loss: 0.1389\tBottom_Loss: 0.1785\tLoss: 0.3734\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.844\tLabel_Loss: 0.2408\tTop_Loss: 0.3698\tBottom_Loss: 0.2509\tLoss: 0.8615\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1519\tTop_Loss: 0.2552\tBottom_Loss: 0.2589\tLoss: 0.6660\t\n",
      "Subject: 015, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2374\tTop_Loss: 0.3106\tBottom_Loss: 0.3265\tLoss: 0.8745\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1836\tTop_Loss: 0.2367\tBottom_Loss: 0.3007\tLoss: 0.7210\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1455\tTop_Loss: 0.1872\tBottom_Loss: 0.1985\tLoss: 0.5313\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1217\tTop_Loss: 0.1414\tBottom_Loss: 0.1672\tLoss: 0.4303\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1743\tTop_Loss: 0.2184\tBottom_Loss: 0.2710\tLoss: 0.6637\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1472\tTop_Loss: 0.2968\tBottom_Loss: 0.2050\tLoss: 0.6490\t\n",
      "Subject: 015, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1820\tTop_Loss: 0.2166\tBottom_Loss: 0.3783\tLoss: 0.7770\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1846\tTop_Loss: 0.3157\tBottom_Loss: 0.1424\tLoss: 0.6427\t\n",
      "Subject: 015, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1862\tTop_Loss: 0.1946\tBottom_Loss: 0.2590\tLoss: 0.6399\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0756\tTop_Loss: 0.1970\tBottom_Loss: 0.1466\tLoss: 0.4191\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0971\tTop_Loss: 0.2466\tBottom_Loss: 0.2105\tLoss: 0.5543\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1029\tTop_Loss: 0.2447\tBottom_Loss: 0.1365\tLoss: 0.4841\t\n",
      "Subject: 015, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1475\tTop_Loss: 0.3001\tBottom_Loss: 0.2353\tLoss: 0.6829\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0877\tTop_Loss: 0.2823\tBottom_Loss: 0.1583\tLoss: 0.5283\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0859\tTop_Loss: 0.3481\tBottom_Loss: 0.1572\tLoss: 0.5912\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1028\tTop_Loss: 0.1984\tBottom_Loss: 0.1250\tLoss: 0.4263\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1316\tTop_Loss: 0.2076\tBottom_Loss: 0.3138\tLoss: 0.6530\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0847\tTop_Loss: 0.1427\tBottom_Loss: 0.1919\tLoss: 0.4193\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0891\tTop_Loss: 0.2044\tBottom_Loss: 0.1777\tLoss: 0.4711\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1237\tTop_Loss: 0.2482\tBottom_Loss: 0.2373\tLoss: 0.6092\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1211\tTop_Loss: 0.1722\tBottom_Loss: 0.2361\tLoss: 0.5294\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0705\tTop_Loss: 0.1823\tBottom_Loss: 0.1656\tLoss: 0.4184\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1596\tTop_Loss: 0.3227\tBottom_Loss: 0.1610\tLoss: 0.6434\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1382\tTop_Loss: 0.1984\tBottom_Loss: 0.2375\tLoss: 0.5742\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0376\tTop_Loss: 0.1258\tBottom_Loss: 0.0727\tLoss: 0.2362\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0673\tTop_Loss: 0.2746\tBottom_Loss: 0.1218\tLoss: 0.4637\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0716\tTop_Loss: 0.1475\tBottom_Loss: 0.1402\tLoss: 0.3593\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0252\tTop_Loss: 0.0922\tBottom_Loss: 0.0939\tLoss: 0.2112\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0399\tTop_Loss: 0.1054\tBottom_Loss: 0.0937\tLoss: 0.2389\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0714\tTop_Loss: 0.1412\tBottom_Loss: 0.0682\tLoss: 0.2809\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0899\tTop_Loss: 0.2620\tBottom_Loss: 0.1018\tLoss: 0.4537\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0469\tTop_Loss: 0.1454\tBottom_Loss: 0.1171\tLoss: 0.3094\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0645\tTop_Loss: 0.1290\tBottom_Loss: 0.1443\tLoss: 0.3378\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0505\tTop_Loss: 0.2372\tBottom_Loss: 0.1202\tLoss: 0.4078\t\n",
      "Subject: 015, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0222\tTop_Loss: 0.0904\tBottom_Loss: 0.0583\tLoss: 0.1709\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0908\tTop_Loss: 0.1552\tBottom_Loss: 0.1099\tLoss: 0.3559\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0372\tTop_Loss: 0.0838\tBottom_Loss: 0.0705\tLoss: 0.1915\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0762\tTop_Loss: 0.1193\tBottom_Loss: 0.1196\tLoss: 0.3151\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0556\tTop_Loss: 0.0610\tBottom_Loss: 0.1302\tLoss: 0.2467\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0711\tTop_Loss: 0.1185\tBottom_Loss: 0.1471\tLoss: 0.3366\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0323\tTop_Loss: 0.0884\tBottom_Loss: 0.0614\tLoss: 0.1821\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0273\tTop_Loss: 0.1376\tBottom_Loss: 0.0663\tLoss: 0.2313\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1188\tTop_Loss: 0.1568\tBottom_Loss: 0.1591\tLoss: 0.4348\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0203\tTop_Loss: 0.0667\tBottom_Loss: 0.0556\tLoss: 0.1426\t\n",
      "Subject: 015, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0512\tTop_Loss: 0.1290\tBottom_Loss: 0.1116\tLoss: 0.2919\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0367\tTop_Loss: 0.0696\tBottom_Loss: 0.0815\tLoss: 0.1878\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0217\tTop_Loss: 0.0689\tBottom_Loss: 0.0848\tLoss: 0.1755\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0295\tTop_Loss: 0.1082\tBottom_Loss: 0.0570\tLoss: 0.1947\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0321\tTop_Loss: 0.1124\tBottom_Loss: 0.0491\tLoss: 0.1937\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0526\tTop_Loss: 0.1682\tBottom_Loss: 0.1181\tLoss: 0.3389\t\n",
      "Subject: 015, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0735\tTop_Loss: 0.1589\tBottom_Loss: 0.0987\tLoss: 0.3311\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0232\tTop_Loss: 0.1124\tBottom_Loss: 0.0799\tLoss: 0.2155\t\n",
      "Subject: 015, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0239\tTop_Loss: 0.0878\tBottom_Loss: 0.1121\tLoss: 0.2238\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0187\tTop_Loss: 0.1610\tBottom_Loss: 0.0345\tLoss: 0.2142\t\n",
      "Subject: 015, n=03 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0415\tTop_Loss: 0.1572\tBottom_Loss: 0.0899\tLoss: 0.2886\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0370\tTop_Loss: 0.0924\tBottom_Loss: 0.0892\tLoss: 0.2186\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0298\tTop_Loss: 0.1972\tBottom_Loss: 0.0909\tLoss: 0.3179\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0138\tTop_Loss: 0.0837\tBottom_Loss: 0.0432\tLoss: 0.1406\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0302\tTop_Loss: 0.1159\tBottom_Loss: 0.0624\tLoss: 0.2085\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0130\tTop_Loss: 0.0449\tBottom_Loss: 0.0685\tLoss: 0.1263\t\n",
      "Subject: 015, n=03 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0134\tTop_Loss: 0.0502\tBottom_Loss: 0.0547\tLoss: 0.1183\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0378\tTop_Loss: 0.1411\tBottom_Loss: 0.0756\tLoss: 0.2545\t\n",
      "Subject: 015, n=03 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0127\tTop_Loss: 0.0377\tBottom_Loss: 0.0455\tLoss: 0.0959\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0295\tTop_Loss: 0.0762\tBottom_Loss: 0.0859\tLoss: 0.1916\t\n",
      "Subject: 015, n=03 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0233\tTop_Loss: 0.0971\tBottom_Loss: 0.0359\tLoss: 0.1562\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0387\tTop_Loss: 0.0899\tBottom_Loss: 0.1009\tLoss: 0.2296\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0342\tTop_Loss: 0.0770\tBottom_Loss: 0.0607\tLoss: 0.1719\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0251\tTop_Loss: 0.0981\tBottom_Loss: 0.0538\tLoss: 0.1771\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 0.938\tLabel_Loss: 0.0926\tTop_Loss: 0.1460\tBottom_Loss: 0.1807\tLoss: 0.4193\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0109\tTop_Loss: 0.0677\tBottom_Loss: 0.0245\tLoss: 0.1032\t\n",
      "Subject: 015, n=03 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0602\tTop_Loss: 0.0687\tBottom_Loss: 0.0666\tLoss: 0.1955\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0183\tTop_Loss: 0.1219\tBottom_Loss: 0.0492\tLoss: 0.1894\t\n",
      "Subject: 015, n=03 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0633\tTop_Loss: 0.1154\tBottom_Loss: 0.0748\tLoss: 0.2534\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0243\tTop_Loss: 0.0590\tBottom_Loss: 0.1061\tLoss: 0.1893\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0687\tTop_Loss: 0.1463\tBottom_Loss: 0.1390\tLoss: 0.3539\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0094\tTop_Loss: 0.0957\tBottom_Loss: 0.0298\tLoss: 0.1349\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0150\tTop_Loss: 0.0642\tBottom_Loss: 0.0614\tLoss: 0.1406\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0097\tTop_Loss: 0.0445\tBottom_Loss: 0.0368\tLoss: 0.0910\t\n",
      "Subject: 015, n=03 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0089\tTop_Loss: 0.0304\tBottom_Loss: 0.0540\tLoss: 0.0932\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0235\tTop_Loss: 0.0717\tBottom_Loss: 0.0481\tLoss: 0.1433\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0538\tTop_Loss: 0.0352\tBottom_Loss: 0.0446\tLoss: 0.1337\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0086\tTop_Loss: 0.0485\tBottom_Loss: 0.0270\tLoss: 0.0841\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0151\tTop_Loss: 0.0288\tBottom_Loss: 0.0434\tLoss: 0.0874\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0461\tTop_Loss: 0.0906\tBottom_Loss: 0.1089\tLoss: 0.2456\t\n",
      "Subject: 015, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0114\tTop_Loss: 0.0584\tBottom_Loss: 0.0497\tLoss: 0.1195\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0389\tTop_Loss: 0.0733\tBottom_Loss: 0.0715\tLoss: 0.1837\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0124\tTop_Loss: 0.0536\tBottom_Loss: 0.0157\tLoss: 0.0818\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0089\tTop_Loss: 0.0344\tBottom_Loss: 0.0234\tLoss: 0.0667\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0190\tTop_Loss: 0.0448\tBottom_Loss: 0.0740\tLoss: 0.1378\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0131\tTop_Loss: 0.0191\tBottom_Loss: 0.0359\tLoss: 0.0680\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0229\tTop_Loss: 0.1012\tBottom_Loss: 0.0365\tLoss: 0.1606\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0119\tTop_Loss: 0.0480\tBottom_Loss: 0.0236\tLoss: 0.0835\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0440\tTop_Loss: 0.0759\tBottom_Loss: 0.0247\tLoss: 0.1446\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0294\tTop_Loss: 0.0560\tBottom_Loss: 0.1244\tLoss: 0.2098\t\n",
      "Subject: 015, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0057\tTop_Loss: 0.0281\tBottom_Loss: 0.0187\tLoss: 0.0525\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0059\tTop_Loss: 0.0308\tBottom_Loss: 0.0173\tLoss: 0.0540\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0087\tTop_Loss: 0.0307\tBottom_Loss: 0.0233\tLoss: 0.0626\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0055\tTop_Loss: 0.0282\tBottom_Loss: 0.0196\tLoss: 0.0533\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0370\tTop_Loss: 0.0432\tBottom_Loss: 0.0472\tLoss: 0.1273\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0257\tTop_Loss: 0.0430\tBottom_Loss: 0.0241\tLoss: 0.0928\t\n",
      "Subject: 015, n=03 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0033\tTop_Loss: 0.0178\tBottom_Loss: 0.0170\tLoss: 0.0381\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0059\tTop_Loss: 0.0193\tBottom_Loss: 0.0220\tLoss: 0.0471\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0183\tTop_Loss: 0.0587\tBottom_Loss: 0.0512\tLoss: 0.1282\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0070\tTop_Loss: 0.0361\tBottom_Loss: 0.0171\tLoss: 0.0602\t\n",
      "Subject: 015, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0353\tTop_Loss: 0.0478\tBottom_Loss: 0.0237\tLoss: 0.1068\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0061\tTop_Loss: 0.0220\tBottom_Loss: 0.0215\tLoss: 0.0496\t\n",
      "Subject: 015, n=03 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0176\tTop_Loss: 0.0621\tBottom_Loss: 0.0325\tLoss: 0.1122\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0072\tTop_Loss: 0.0296\tBottom_Loss: 0.0302\tLoss: 0.0670\t\n",
      "Subject: 015, n=03 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.312\tLabel_Loss: 1.3306\tTop_Loss: 1.6382\tBottom_Loss: 1.2843\tLoss: 4.2532\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.500\tLabel_Loss: 0.9888\tTop_Loss: 1.0339\tBottom_Loss: 1.1124\tLoss: 3.1351\t\n",
      "Subject: 016, n=05 | test_f1: 0.19048 |best_f1: 0.19048\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8519\tTop_Loss: 1.0001\tBottom_Loss: 1.0285\tLoss: 2.8805\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.594\tLabel_Loss: 0.9332\tTop_Loss: 0.9795\tBottom_Loss: 0.9601\tLoss: 2.8728\t\n",
      "Subject: 016, n=05 | test_f1: 0.19048 |best_f1: 0.19048\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8425\tTop_Loss: 0.8559\tBottom_Loss: 0.9184\tLoss: 2.6169\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.406\tLabel_Loss: 1.2602\tTop_Loss: 1.2387\tBottom_Loss: 1.3117\tLoss: 3.8106\t\n",
      "Subject: 016, n=05 | test_f1: 0.55556 |best_f1: 0.55556\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.438\tLabel_Loss: 1.0333\tTop_Loss: 0.9924\tBottom_Loss: 1.0389\tLoss: 3.0646\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.594\tLabel_Loss: 1.0215\tTop_Loss: 1.1003\tBottom_Loss: 1.1782\tLoss: 3.3000\t\n",
      "Subject: 016, n=05 | test_f1: 0.19048 |best_f1: 0.55556\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8350\tTop_Loss: 0.7912\tBottom_Loss: 0.8796\tLoss: 2.5058\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.562\tLabel_Loss: 0.8275\tTop_Loss: 0.9191\tBottom_Loss: 1.0923\tLoss: 2.8388\t\n",
      "Subject: 016, n=05 | test_f1: 0.19048 |best_f1: 0.55556\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.469\tLabel_Loss: 0.9135\tTop_Loss: 0.9003\tBottom_Loss: 0.9483\tLoss: 2.7621\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.531\tLabel_Loss: 0.9781\tTop_Loss: 0.8959\tBottom_Loss: 0.8853\tLoss: 2.7592\t\n",
      "Subject: 016, n=05 | test_f1: 0.55556 |best_f1: 0.55556\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6558\tTop_Loss: 0.6518\tBottom_Loss: 0.8428\tLoss: 2.1504\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.438\tLabel_Loss: 0.9953\tTop_Loss: 1.0135\tBottom_Loss: 1.0247\tLoss: 3.0335\t\n",
      "Subject: 016, n=05 | test_f1: 0.19048 |best_f1: 0.55556\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.656\tLabel_Loss: 0.6876\tTop_Loss: 0.8323\tBottom_Loss: 0.8507\tLoss: 2.3706\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.812\tLabel_Loss: 0.6009\tTop_Loss: 0.6838\tBottom_Loss: 0.7530\tLoss: 2.0376\t\n",
      "Subject: 016, n=05 | test_f1: 0.19048 |best_f1: 0.55556\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8018\tTop_Loss: 0.9158\tBottom_Loss: 0.9117\tLoss: 2.6293\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8902\tTop_Loss: 0.8492\tBottom_Loss: 0.9369\tLoss: 2.6763\t\n",
      "Subject: 016, n=05 | test_f1: 0.55556 |best_f1: 0.55556\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.531\tLabel_Loss: 0.8033\tTop_Loss: 0.7136\tBottom_Loss: 0.8634\tLoss: 2.3803\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7349\tTop_Loss: 0.8065\tBottom_Loss: 0.7661\tLoss: 2.3074\t\n",
      "Subject: 016, n=05 | test_f1: 0.48889 |best_f1: 0.55556\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8286\tTop_Loss: 0.8669\tBottom_Loss: 0.8594\tLoss: 2.5549\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7830\tTop_Loss: 0.7361\tBottom_Loss: 0.8855\tLoss: 2.4046\t\n",
      "Subject: 016, n=05 | test_f1: 0.19048 |best_f1: 0.55556\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4791\tTop_Loss: 0.7128\tBottom_Loss: 0.6149\tLoss: 1.8068\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.781\tLabel_Loss: 0.6117\tTop_Loss: 0.7712\tBottom_Loss: 0.7916\tLoss: 2.1746\t\n",
      "Subject: 016, n=05 | test_f1: 0.19048 |best_f1: 0.55556\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7489\tTop_Loss: 0.7336\tBottom_Loss: 0.7776\tLoss: 2.2602\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.719\tLabel_Loss: 0.7121\tTop_Loss: 0.8053\tBottom_Loss: 0.8752\tLoss: 2.3926\t\n",
      "Subject: 016, n=05 | test_f1: 0.19048 |best_f1: 0.55556\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5974\tTop_Loss: 0.8504\tBottom_Loss: 0.8340\tLoss: 2.2817\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6007\tTop_Loss: 0.6295\tBottom_Loss: 0.5982\tLoss: 1.8285\t\n",
      "Subject: 016, n=05 | test_f1: 0.19048 |best_f1: 0.55556\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6282\tTop_Loss: 0.6904\tBottom_Loss: 0.7266\tLoss: 2.0452\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6601\tTop_Loss: 0.6240\tBottom_Loss: 0.9006\tLoss: 2.1847\t\n",
      "Subject: 016, n=05 | test_f1: 0.22222 |best_f1: 0.55556\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.625\tLabel_Loss: 0.6050\tTop_Loss: 0.6146\tBottom_Loss: 0.6059\tLoss: 1.8255\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.906\tLabel_Loss: 0.4275\tTop_Loss: 0.5457\tBottom_Loss: 0.6767\tLoss: 1.6499\t\n",
      "Subject: 016, n=05 | test_f1: 0.55556 |best_f1: 0.55556\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7091\tTop_Loss: 0.6762\tBottom_Loss: 0.7949\tLoss: 2.1802\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4922\tTop_Loss: 0.6051\tBottom_Loss: 0.6158\tLoss: 1.7131\t\n",
      "Subject: 016, n=05 | test_f1: 0.19048 |best_f1: 0.55556\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.750\tLabel_Loss: 0.4998\tTop_Loss: 0.5845\tBottom_Loss: 0.5552\tLoss: 1.6395\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4191\tTop_Loss: 0.5037\tBottom_Loss: 0.5111\tLoss: 1.4338\t\n",
      "Subject: 016, n=05 | test_f1: 0.19048 |best_f1: 0.55556\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3849\tTop_Loss: 0.4475\tBottom_Loss: 0.5215\tLoss: 1.3539\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.688\tLabel_Loss: 0.5721\tTop_Loss: 0.7874\tBottom_Loss: 0.5548\tLoss: 1.9144\t\n",
      "Subject: 016, n=05 | test_f1: 0.19048 |best_f1: 0.55556\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4490\tTop_Loss: 0.4779\tBottom_Loss: 0.6978\tLoss: 1.6248\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.531\tLabel_Loss: 0.7913\tTop_Loss: 0.7984\tBottom_Loss: 0.7447\tLoss: 2.3344\t\n",
      "Subject: 016, n=05 | test_f1: 0.55556 |best_f1: 0.55556\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6362\tTop_Loss: 0.5300\tBottom_Loss: 0.6568\tLoss: 1.8230\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.656\tLabel_Loss: 0.8052\tTop_Loss: 0.7150\tBottom_Loss: 0.8375\tLoss: 2.3577\t\n",
      "Subject: 016, n=05 | test_f1: 0.22222 |best_f1: 0.55556\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4737\tTop_Loss: 0.6855\tBottom_Loss: 0.6518\tLoss: 1.8110\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2552\tTop_Loss: 0.4936\tBottom_Loss: 0.3252\tLoss: 1.0740\t\n",
      "Subject: 016, n=05 | test_f1: 0.55556 |best_f1: 0.55556\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.844\tLabel_Loss: 0.5405\tTop_Loss: 0.7618\tBottom_Loss: 0.6618\tLoss: 1.9641\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3443\tTop_Loss: 0.4967\tBottom_Loss: 0.3913\tLoss: 1.2323\t\n",
      "Subject: 016, n=05 | test_f1: 0.22222 |best_f1: 0.55556\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4833\tTop_Loss: 0.5589\tBottom_Loss: 0.6332\tLoss: 1.6754\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.688\tLabel_Loss: 0.5930\tTop_Loss: 0.5254\tBottom_Loss: 0.8152\tLoss: 1.9335\t\n",
      "Subject: 016, n=05 | test_f1: 0.19048 |best_f1: 0.55556\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3657\tTop_Loss: 0.4812\tBottom_Loss: 0.3713\tLoss: 1.2181\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4011\tTop_Loss: 0.5184\tBottom_Loss: 0.4664\tLoss: 1.3859\t\n",
      "Subject: 016, n=05 | test_f1: 0.48889 |best_f1: 0.55556\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3314\tTop_Loss: 0.4125\tBottom_Loss: 0.4432\tLoss: 1.1871\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3500\tTop_Loss: 0.5204\tBottom_Loss: 0.5024\tLoss: 1.3727\t\n",
      "Subject: 016, n=05 | test_f1: 0.55556 |best_f1: 0.55556\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3647\tTop_Loss: 0.4554\tBottom_Loss: 0.3887\tLoss: 1.2088\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5713\tTop_Loss: 0.5959\tBottom_Loss: 0.6679\tLoss: 1.8350\t\n",
      "Subject: 016, n=05 | test_f1: 0.11111 |best_f1: 0.55556\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4001\tTop_Loss: 0.5021\tBottom_Loss: 0.6695\tLoss: 1.5717\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3310\tTop_Loss: 0.5040\tBottom_Loss: 0.3992\tLoss: 1.2341\t\n",
      "Subject: 016, n=05 | test_f1: 0.19048 |best_f1: 0.55556\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.781\tLabel_Loss: 0.3450\tTop_Loss: 0.4171\tBottom_Loss: 0.5380\tLoss: 1.3002\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5500\tTop_Loss: 0.4665\tBottom_Loss: 0.6021\tLoss: 1.6186\t\n",
      "Subject: 016, n=05 | test_f1: 0.55556 |best_f1: 0.55556\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3624\tTop_Loss: 0.4882\tBottom_Loss: 0.3981\tLoss: 1.2487\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4787\tTop_Loss: 0.5173\tBottom_Loss: 0.6380\tLoss: 1.6340\t\n",
      "Subject: 016, n=05 | test_f1: 0.19048 |best_f1: 0.55556\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4094\tTop_Loss: 0.5760\tBottom_Loss: 0.4152\tLoss: 1.4006\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4987\tTop_Loss: 0.5101\tBottom_Loss: 0.5064\tLoss: 1.5152\t\n",
      "Subject: 016, n=05 | test_f1: 0.11111 |best_f1: 0.55556\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2475\tTop_Loss: 0.3164\tBottom_Loss: 0.3256\tLoss: 0.8896\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3888\tTop_Loss: 0.4768\tBottom_Loss: 0.4094\tLoss: 1.2750\t\n",
      "Subject: 016, n=05 | test_f1: 0.11111 |best_f1: 0.55556\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3220\tTop_Loss: 0.4052\tBottom_Loss: 0.4832\tLoss: 1.2104\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4151\tTop_Loss: 0.4505\tBottom_Loss: 0.4526\tLoss: 1.3182\t\n",
      "Subject: 016, n=05 | test_f1: 0.48889 |best_f1: 0.55556\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3928\tTop_Loss: 0.4976\tBottom_Loss: 0.3382\tLoss: 1.2286\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2835\tTop_Loss: 0.4263\tBottom_Loss: 0.3643\tLoss: 1.0741\t\n",
      "Subject: 016, n=05 | test_f1: 0.48889 |best_f1: 0.55556\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2032\tTop_Loss: 0.2129\tBottom_Loss: 0.2992\tLoss: 0.7152\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2547\tTop_Loss: 0.4269\tBottom_Loss: 0.3508\tLoss: 1.0324\t\n",
      "Subject: 016, n=05 | test_f1: 0.19048 |best_f1: 0.55556\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2569\tTop_Loss: 0.4215\tBottom_Loss: 0.3671\tLoss: 1.0455\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2549\tTop_Loss: 0.4005\tBottom_Loss: 0.3197\tLoss: 0.9751\t\n",
      "Subject: 016, n=05 | test_f1: 0.48889 |best_f1: 0.55556\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3036\tTop_Loss: 0.4573\tBottom_Loss: 0.2676\tLoss: 1.0286\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3591\tTop_Loss: 0.5025\tBottom_Loss: 0.4033\tLoss: 1.2649\t\n",
      "Subject: 016, n=05 | test_f1: 0.5 |best_f1: 0.55556\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2981\tTop_Loss: 0.4387\tBottom_Loss: 0.2722\tLoss: 1.0090\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1752\tTop_Loss: 0.2373\tBottom_Loss: 0.2960\tLoss: 0.7086\t\n",
      "Subject: 016, n=05 | test_f1: 0.48889 |best_f1: 0.55556\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1840\tTop_Loss: 0.2393\tBottom_Loss: 0.3322\tLoss: 0.7554\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.781\tLabel_Loss: 0.3984\tTop_Loss: 0.5123\tBottom_Loss: 0.5623\tLoss: 1.4730\t\n",
      "Subject: 016, n=05 | test_f1: 0.19048 |best_f1: 0.55556\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2690\tTop_Loss: 0.4835\tBottom_Loss: 0.3231\tLoss: 1.0756\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1536\tTop_Loss: 0.2572\tBottom_Loss: 0.2661\tLoss: 0.6769\t\n",
      "Subject: 016, n=05 | test_f1: 0.13333 |best_f1: 0.55556\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2429\tTop_Loss: 0.3724\tBottom_Loss: 0.2543\tLoss: 0.8697\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2787\tTop_Loss: 0.3081\tBottom_Loss: 0.4144\tLoss: 1.0012\t\n",
      "Subject: 016, n=05 | test_f1: 0.22222 |best_f1: 0.55556\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2596\tTop_Loss: 0.4279\tBottom_Loss: 0.3150\tLoss: 1.0026\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1929\tTop_Loss: 0.3348\tBottom_Loss: 0.2720\tLoss: 0.7997\t\n",
      "Subject: 016, n=05 | test_f1: 0.33333 |best_f1: 0.55556\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.938\tLabel_Loss: 0.3040\tTop_Loss: 0.3438\tBottom_Loss: 0.2841\tLoss: 0.9320\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0908\tTop_Loss: 0.2167\tBottom_Loss: 0.2302\tLoss: 0.5377\t\n",
      "Subject: 016, n=05 | test_f1: 0.48889 |best_f1: 0.55556\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1356\tTop_Loss: 0.2700\tBottom_Loss: 0.1985\tLoss: 0.6042\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2478\tTop_Loss: 0.4552\tBottom_Loss: 0.2613\tLoss: 0.9644\t\n",
      "Subject: 016, n=05 | test_f1: 0.19048 |best_f1: 0.55556\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2094\tTop_Loss: 0.2075\tBottom_Loss: 0.1879\tLoss: 0.6049\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1848\tTop_Loss: 0.4243\tBottom_Loss: 0.2568\tLoss: 0.8659\t\n",
      "Subject: 016, n=05 | test_f1: 0.35556 |best_f1: 0.55556\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0467\tTop_Loss: 0.2242\tBottom_Loss: 0.2063\tLoss: 0.4773\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1903\tTop_Loss: 0.4018\tBottom_Loss: 0.2804\tLoss: 0.8725\t\n",
      "Subject: 016, n=05 | test_f1: 0.55556 |best_f1: 0.55556\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1720\tTop_Loss: 0.3233\tBottom_Loss: 0.2755\tLoss: 0.7707\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0977\tTop_Loss: 0.1876\tBottom_Loss: 0.3124\tLoss: 0.5977\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 016, n=05 | test_f1: 0.55556 |best_f1: 0.55556\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1473\tTop_Loss: 0.1930\tBottom_Loss: 0.2784\tLoss: 0.6187\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2268\tTop_Loss: 0.3260\tBottom_Loss: 0.2496\tLoss: 0.8023\t\n",
      "Subject: 016, n=05 | test_f1: 0.19048 |best_f1: 0.55556\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1127\tTop_Loss: 0.2295\tBottom_Loss: 0.1841\tLoss: 0.5263\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0771\tTop_Loss: 0.2111\tBottom_Loss: 0.0979\tLoss: 0.3861\t\n",
      "Subject: 016, n=05 | test_f1: 0.26667 |best_f1: 0.55556\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1164\tTop_Loss: 0.3608\tBottom_Loss: 0.1767\tLoss: 0.6539\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0844\tTop_Loss: 0.2464\tBottom_Loss: 0.1798\tLoss: 0.5106\t\n",
      "Subject: 016, n=05 | test_f1: 0.48889 |best_f1: 0.55556\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0648\tTop_Loss: 0.1271\tBottom_Loss: 0.2443\tLoss: 0.4362\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0777\tTop_Loss: 0.1656\tBottom_Loss: 0.1306\tLoss: 0.3739\t\n",
      "Subject: 016, n=05 | test_f1: 0.35556 |best_f1: 0.55556\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1734\tTop_Loss: 0.4179\tBottom_Loss: 0.3428\tLoss: 0.9341\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1057\tTop_Loss: 0.1781\tBottom_Loss: 0.2152\tLoss: 0.4990\t\n",
      "Subject: 016, n=05 | test_f1: 0.35556 |best_f1: 0.55556\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0730\tTop_Loss: 0.2373\tBottom_Loss: 0.2479\tLoss: 0.5582\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0459\tTop_Loss: 0.1829\tBottom_Loss: 0.0855\tLoss: 0.3144\t\n",
      "Subject: 016, n=05 | test_f1: 0.48889 |best_f1: 0.55556\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1029\tTop_Loss: 0.1733\tBottom_Loss: 0.1854\tLoss: 0.4616\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1328\tTop_Loss: 0.1786\tBottom_Loss: 0.2664\tLoss: 0.5779\t\n",
      "Subject: 016, n=05 | test_f1: 0.48889 |best_f1: 0.55556\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1160\tTop_Loss: 0.1969\tBottom_Loss: 0.1862\tLoss: 0.4991\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0891\tTop_Loss: 0.2382\tBottom_Loss: 0.2179\tLoss: 0.5452\t\n",
      "Subject: 016, n=05 | test_f1: 0.13333 |best_f1: 0.55556\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0488\tTop_Loss: 0.1088\tBottom_Loss: 0.1713\tLoss: 0.3289\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0900\tTop_Loss: 0.2448\tBottom_Loss: 0.1018\tLoss: 0.4366\t\n",
      "Subject: 016, n=05 | test_f1: 0.13333 |best_f1: 0.55556\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0993\tTop_Loss: 0.2243\tBottom_Loss: 0.1788\tLoss: 0.5024\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1125\tTop_Loss: 0.2604\tBottom_Loss: 0.1880\tLoss: 0.5609\t\n",
      "Subject: 016, n=05 | test_f1: 0.48889 |best_f1: 0.55556\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0632\tTop_Loss: 0.0912\tBottom_Loss: 0.2096\tLoss: 0.3641\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1198\tTop_Loss: 0.1783\tBottom_Loss: 0.2139\tLoss: 0.5121\t\n",
      "Subject: 016, n=05 | test_f1: 0.19048 |best_f1: 0.55556\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0641\tTop_Loss: 0.1111\tBottom_Loss: 0.0984\tLoss: 0.2736\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1105\tTop_Loss: 0.1645\tBottom_Loss: 0.1490\tLoss: 0.4240\t\n",
      "Subject: 016, n=05 | test_f1: 0.22222 |best_f1: 0.55556\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1197\tTop_Loss: 0.1392\tBottom_Loss: 0.1555\tLoss: 0.4144\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0430\tTop_Loss: 0.1051\tBottom_Loss: 0.1331\tLoss: 0.2812\t\n",
      "Subject: 016, n=05 | test_f1: 0.48889 |best_f1: 0.55556\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0852\tTop_Loss: 0.1364\tBottom_Loss: 0.1822\tLoss: 0.4039\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0332\tTop_Loss: 0.0667\tBottom_Loss: 0.0882\tLoss: 0.1881\t\n",
      "Subject: 016, n=05 | test_f1: 0.48889 |best_f1: 0.55556\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1232\tTop_Loss: 0.1593\tBottom_Loss: 0.1289\tLoss: 0.4114\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0876\tTop_Loss: 0.1592\tBottom_Loss: 0.1534\tLoss: 0.4002\t\n",
      "Subject: 016, n=05 | test_f1: 0.33333 |best_f1: 0.55556\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0722\tTop_Loss: 0.1342\tBottom_Loss: 0.1525\tLoss: 0.3588\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0574\tTop_Loss: 0.1466\tBottom_Loss: 0.0782\tLoss: 0.2823\t\n",
      "Subject: 016, n=05 | test_f1: 0.82222 |best_f1: 0.82222\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1411\tTop_Loss: 0.1111\tBottom_Loss: 0.4286\tLoss: 0.6807\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0693\tTop_Loss: 0.1136\tBottom_Loss: 0.1365\tLoss: 0.3193\t\n",
      "Subject: 016, n=05 | test_f1: 0.19048 |best_f1: 0.82222\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0304\tTop_Loss: 0.0930\tBottom_Loss: 0.0635\tLoss: 0.1870\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0282\tTop_Loss: 0.1111\tBottom_Loss: 0.0978\tLoss: 0.2371\t\n",
      "Subject: 016, n=05 | test_f1: 0.33333 |best_f1: 0.82222\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0113\tTop_Loss: 0.0523\tBottom_Loss: 0.0656\tLoss: 0.1292\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0491\tTop_Loss: 0.1309\tBottom_Loss: 0.0999\tLoss: 0.2799\t\n",
      "Subject: 016, n=05 | test_f1: 0.55556 |best_f1: 0.82222\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0748\tTop_Loss: 0.2709\tBottom_Loss: 0.2727\tLoss: 0.6185\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0340\tTop_Loss: 0.0868\tBottom_Loss: 0.0917\tLoss: 0.2125\t\n",
      "Subject: 016, n=05 | test_f1: 0.55556 |best_f1: 0.82222\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0448\tTop_Loss: 0.0979\tBottom_Loss: 0.1294\tLoss: 0.2721\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1264\tTop_Loss: 0.1533\tBottom_Loss: 0.1208\tLoss: 0.4005\t\n",
      "Subject: 016, n=05 | test_f1: 0.48889 |best_f1: 0.82222\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0546\tTop_Loss: 0.1566\tBottom_Loss: 0.1041\tLoss: 0.3152\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0621\tTop_Loss: 0.1506\tBottom_Loss: 0.1013\tLoss: 0.3140\t\n",
      "Subject: 016, n=05 | test_f1: 0.48889 |best_f1: 0.82222\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0343\tTop_Loss: 0.0542\tBottom_Loss: 0.1351\tLoss: 0.2236\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0459\tTop_Loss: 0.0978\tBottom_Loss: 0.0742\tLoss: 0.2179\t\n",
      "Subject: 016, n=05 | test_f1: 0.55556 |best_f1: 0.82222\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0474\tTop_Loss: 0.1901\tBottom_Loss: 0.0758\tLoss: 0.3133\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0417\tTop_Loss: 0.1047\tBottom_Loss: 0.1343\tLoss: 0.2806\t\n",
      "Subject: 016, n=05 | test_f1: 0.19048 |best_f1: 0.82222\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0139\tTop_Loss: 0.0625\tBottom_Loss: 0.0351\tLoss: 0.1114\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0493\tTop_Loss: 0.0710\tBottom_Loss: 0.1714\tLoss: 0.2918\t\n",
      "Subject: 016, n=05 | test_f1: 0.55556 |best_f1: 0.82222\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0993\tTop_Loss: 0.2083\tBottom_Loss: 0.1046\tLoss: 0.4122\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0637\tTop_Loss: 0.2048\tBottom_Loss: 0.0776\tLoss: 0.3460\t\n",
      "Subject: 016, n=05 | test_f1: 0.22222 |best_f1: 0.82222\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0302\tTop_Loss: 0.0590\tBottom_Loss: 0.0548\tLoss: 0.1441\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0289\tTop_Loss: 0.0585\tBottom_Loss: 0.0700\tLoss: 0.1574\t\n",
      "Subject: 016, n=05 | test_f1: 0.48889 |best_f1: 0.82222\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0152\tTop_Loss: 0.0553\tBottom_Loss: 0.0493\tLoss: 0.1198\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0257\tTop_Loss: 0.0613\tBottom_Loss: 0.0506\tLoss: 0.1377\t\n",
      "Subject: 016, n=05 | test_f1: 0.55556 |best_f1: 0.82222\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0162\tTop_Loss: 0.0618\tBottom_Loss: 0.0373\tLoss: 0.1152\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0309\tTop_Loss: 0.0854\tBottom_Loss: 0.0427\tLoss: 0.1590\t\n",
      "Subject: 016, n=05 | test_f1: 0.55556 |best_f1: 0.82222\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0312\tTop_Loss: 0.0754\tBottom_Loss: 0.0701\tLoss: 0.1767\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0192\tTop_Loss: 0.0576\tBottom_Loss: 0.0449\tLoss: 0.1217\t\n",
      "Subject: 016, n=05 | test_f1: 0.19048 |best_f1: 0.82222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0322\tTop_Loss: 0.0487\tBottom_Loss: 0.0790\tLoss: 0.1600\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1667\tTop_Loss: 0.1514\tBottom_Loss: 0.1855\tLoss: 0.5036\t\n",
      "Subject: 016, n=05 | test_f1: 0.55556 |best_f1: 0.82222\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0427\tTop_Loss: 0.0854\tBottom_Loss: 0.1141\tLoss: 0.2422\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0395\tTop_Loss: 0.0371\tBottom_Loss: 0.0676\tLoss: 0.1442\t\n",
      "Subject: 016, n=05 | test_f1: 0.22222 |best_f1: 0.82222\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0214\tTop_Loss: 0.0362\tBottom_Loss: 0.0418\tLoss: 0.0995\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0173\tTop_Loss: 0.1051\tBottom_Loss: 0.0394\tLoss: 0.1618\t\n",
      "Subject: 016, n=05 | test_f1: 0.22222 |best_f1: 0.82222\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0217\tTop_Loss: 0.0465\tBottom_Loss: 0.0846\tLoss: 0.1528\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0223\tTop_Loss: 0.1036\tBottom_Loss: 0.0292\tLoss: 0.1551\t\n",
      "Subject: 016, n=05 | test_f1: 0.22222 |best_f1: 0.82222\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0400\tTop_Loss: 0.0684\tBottom_Loss: 0.0428\tLoss: 0.1512\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0223\tTop_Loss: 0.0551\tBottom_Loss: 0.0511\tLoss: 0.1285\t\n",
      "Subject: 016, n=05 | test_f1: 0.55556 |best_f1: 0.82222\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0369\tTop_Loss: 0.1089\tBottom_Loss: 0.0756\tLoss: 0.2214\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0214\tTop_Loss: 0.0788\tBottom_Loss: 0.0774\tLoss: 0.1776\t\n",
      "Subject: 016, n=05 | test_f1: 0.22222 |best_f1: 0.82222\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0370\tTop_Loss: 0.0794\tBottom_Loss: 0.0739\tLoss: 0.1903\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0281\tTop_Loss: 0.0647\tBottom_Loss: 0.0882\tLoss: 0.1811\t\n",
      "Subject: 016, n=05 | test_f1: 0.55556 |best_f1: 0.82222\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0292\tTop_Loss: 0.0459\tBottom_Loss: 0.0329\tLoss: 0.1080\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0505\tTop_Loss: 0.1084\tBottom_Loss: 0.0482\tLoss: 0.2071\t\n",
      "Subject: 016, n=05 | test_f1: 0.48889 |best_f1: 0.82222\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0086\tTop_Loss: 0.0291\tBottom_Loss: 0.0442\tLoss: 0.0819\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0070\tTop_Loss: 0.0474\tBottom_Loss: 0.0139\tLoss: 0.0683\t\n",
      "Subject: 016, n=05 | test_f1: 0.33333 |best_f1: 0.82222\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0075\tTop_Loss: 0.0293\tBottom_Loss: 0.0432\tLoss: 0.0799\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0161\tTop_Loss: 0.0555\tBottom_Loss: 0.0269\tLoss: 0.0985\t\n",
      "Subject: 016, n=05 | test_f1: 0.55556 |best_f1: 0.82222\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0079\tTop_Loss: 0.0455\tBottom_Loss: 0.0184\tLoss: 0.0719\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0153\tTop_Loss: 0.1044\tBottom_Loss: 0.0324\tLoss: 0.1521\t\n",
      "Subject: 016, n=05 | test_f1: 0.35556 |best_f1: 0.82222\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0330\tTop_Loss: 0.0241\tBottom_Loss: 0.1680\tLoss: 0.2250\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0072\tTop_Loss: 0.0256\tBottom_Loss: 0.0177\tLoss: 0.0506\t\n",
      "Subject: 016, n=05 | test_f1: 0.13333 |best_f1: 0.82222\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0153\tTop_Loss: 0.0538\tBottom_Loss: 0.0299\tLoss: 0.0991\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0955\tTop_Loss: 0.2499\tBottom_Loss: 0.0632\tLoss: 0.4085\t\n",
      "Subject: 016, n=05 | test_f1: 0.55556 |best_f1: 0.82222\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0083\tTop_Loss: 0.0267\tBottom_Loss: 0.0278\tLoss: 0.0628\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0089\tTop_Loss: 0.0559\tBottom_Loss: 0.0286\tLoss: 0.0934\t\n",
      "Subject: 016, n=05 | test_f1: 0.13333 |best_f1: 0.82222\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0109\tTop_Loss: 0.0272\tBottom_Loss: 0.0265\tLoss: 0.0646\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0079\tTop_Loss: 0.0324\tBottom_Loss: 0.0225\tLoss: 0.0627\t\n",
      "Subject: 016, n=05 | test_f1: 0.55556 |best_f1: 0.82222\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0088\tTop_Loss: 0.0375\tBottom_Loss: 0.0471\tLoss: 0.0934\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0185\tTop_Loss: 0.0462\tBottom_Loss: 0.0606\tLoss: 0.1254\t\n",
      "Subject: 016, n=05 | test_f1: 0.19048 |best_f1: 0.82222\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0092\tTop_Loss: 0.0539\tBottom_Loss: 0.0273\tLoss: 0.0904\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0100\tTop_Loss: 0.0158\tBottom_Loss: 0.0346\tLoss: 0.0604\t\n",
      "Subject: 016, n=05 | test_f1: 0.19048 |best_f1: 0.82222\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0137\tTop_Loss: 0.0667\tBottom_Loss: 0.0221\tLoss: 0.1025\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0056\tTop_Loss: 0.0192\tBottom_Loss: 0.0193\tLoss: 0.0441\t\n",
      "Subject: 016, n=05 | test_f1: 0.48889 |best_f1: 0.82222\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0114\tTop_Loss: 0.0243\tBottom_Loss: 0.0376\tLoss: 0.0733\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0309\tTop_Loss: 0.0344\tBottom_Loss: 0.0213\tLoss: 0.0867\t\n",
      "Subject: 016, n=05 | test_f1: 0.22222 |best_f1: 0.82222\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0149\tTop_Loss: 0.0235\tBottom_Loss: 0.0450\tLoss: 0.0834\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0058\tTop_Loss: 0.0374\tBottom_Loss: 0.0162\tLoss: 0.0594\t\n",
      "Subject: 016, n=05 | test_f1: 0.33333 |best_f1: 0.82222\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0091\tTop_Loss: 0.0264\tBottom_Loss: 0.0408\tLoss: 0.0763\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0046\tTop_Loss: 0.0151\tBottom_Loss: 0.0103\tLoss: 0.0299\t\n",
      "Subject: 016, n=05 | test_f1: 0.55556 |best_f1: 0.82222\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0085\tTop_Loss: 0.0321\tBottom_Loss: 0.0281\tLoss: 0.0687\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0060\tTop_Loss: 0.0479\tBottom_Loss: 0.0079\tLoss: 0.0617\t\n",
      "Subject: 016, n=05 | test_f1: 0.33333 |best_f1: 0.82222\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0052\tTop_Loss: 0.0160\tBottom_Loss: 0.0210\tLoss: 0.0422\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0201\tTop_Loss: 0.0315\tBottom_Loss: 0.0289\tLoss: 0.0805\t\n",
      "Subject: 016, n=05 | test_f1: 0.13333 |best_f1: 0.82222\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.156\tLabel_Loss: 2.1344\tTop_Loss: 1.6625\tBottom_Loss: 2.3474\tLoss: 6.1442\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.594\tLabel_Loss: 0.9971\tTop_Loss: 1.3419\tBottom_Loss: 1.2344\tLoss: 3.5734\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.375\tLabel_Loss: 1.1696\tTop_Loss: 1.1413\tBottom_Loss: 1.2393\tLoss: 3.5501\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.500\tLabel_Loss: 1.1881\tTop_Loss: 1.0142\tBottom_Loss: 1.1164\tLoss: 3.3186\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.500\tLabel_Loss: 1.0451\tTop_Loss: 1.1090\tBottom_Loss: 1.0707\tLoss: 3.2247\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.719\tLabel_Loss: 0.8287\tTop_Loss: 0.9212\tBottom_Loss: 0.8502\tLoss: 2.6000\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.656\tLabel_Loss: 0.9819\tTop_Loss: 1.0462\tBottom_Loss: 0.9696\tLoss: 2.9977\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7998\tTop_Loss: 0.7156\tBottom_Loss: 0.7962\tLoss: 2.3117\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.656\tLabel_Loss: 0.8107\tTop_Loss: 0.7788\tBottom_Loss: 0.7396\tLoss: 2.3291\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.469\tLabel_Loss: 1.0272\tTop_Loss: 1.0648\tBottom_Loss: 0.9927\tLoss: 3.0847\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.438\tLabel_Loss: 1.2545\tTop_Loss: 1.0263\tBottom_Loss: 1.1024\tLoss: 3.3832\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.438\tLabel_Loss: 0.9465\tTop_Loss: 0.8120\tBottom_Loss: 0.9421\tLoss: 2.7007\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.531\tLabel_Loss: 0.8522\tTop_Loss: 1.0330\tBottom_Loss: 0.8254\tLoss: 2.7106\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.656\tLabel_Loss: 0.8437\tTop_Loss: 0.9925\tBottom_Loss: 0.8850\tLoss: 2.7212\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.594\tLabel_Loss: 0.9103\tTop_Loss: 0.9631\tBottom_Loss: 0.7608\tLoss: 2.6342\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.500\tLabel_Loss: 1.0140\tTop_Loss: 0.8631\tBottom_Loss: 1.1395\tLoss: 3.0167\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.562\tLabel_Loss: 0.8483\tTop_Loss: 0.8292\tBottom_Loss: 0.8346\tLoss: 2.5121\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.688\tLabel_Loss: 0.9466\tTop_Loss: 0.9392\tBottom_Loss: 0.8547\tLoss: 2.7405\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7050\tTop_Loss: 0.7800\tBottom_Loss: 0.9582\tLoss: 2.4432\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7202\tTop_Loss: 0.8166\tBottom_Loss: 0.7065\tLoss: 2.2433\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7775\tTop_Loss: 0.8556\tBottom_Loss: 0.8044\tLoss: 2.4375\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5507\tTop_Loss: 0.8174\tBottom_Loss: 0.7700\tLoss: 2.1381\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.781\tLabel_Loss: 0.7450\tTop_Loss: 0.7365\tBottom_Loss: 0.6836\tLoss: 2.1651\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5702\tTop_Loss: 0.5044\tBottom_Loss: 0.6218\tLoss: 1.6964\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.500\tLabel_Loss: 0.8936\tTop_Loss: 1.0139\tBottom_Loss: 1.0049\tLoss: 2.9124\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5793\tTop_Loss: 0.5807\tBottom_Loss: 0.6716\tLoss: 1.8316\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5104\tTop_Loss: 0.6058\tBottom_Loss: 0.7348\tLoss: 1.8511\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.656\tLabel_Loss: 0.6565\tTop_Loss: 0.7294\tBottom_Loss: 0.7858\tLoss: 2.1717\t\n",
      "Subject: 017, n=04 | test_f1: 0.33333 |best_f1: 0.42857\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.656\tLabel_Loss: 0.8244\tTop_Loss: 0.7419\tBottom_Loss: 0.7837\tLoss: 2.3499\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.656\tLabel_Loss: 0.6381\tTop_Loss: 0.7217\tBottom_Loss: 0.7744\tLoss: 2.1343\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.719\tLabel_Loss: 0.8767\tTop_Loss: 0.9193\tBottom_Loss: 0.9512\tLoss: 2.7472\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.656\tLabel_Loss: 0.6965\tTop_Loss: 0.8813\tBottom_Loss: 0.5839\tLoss: 2.1617\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.656\tLabel_Loss: 0.6766\tTop_Loss: 0.6389\tBottom_Loss: 0.6560\tLoss: 1.9715\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4646\tTop_Loss: 0.6181\tBottom_Loss: 0.8276\tLoss: 1.9103\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6575\tTop_Loss: 0.6302\tBottom_Loss: 0.6771\tLoss: 1.9647\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7426\tTop_Loss: 0.7417\tBottom_Loss: 0.8419\tLoss: 2.3262\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.906\tLabel_Loss: 0.5785\tTop_Loss: 0.6813\tBottom_Loss: 0.9237\tLoss: 2.1834\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.688\tLabel_Loss: 0.4855\tTop_Loss: 0.6553\tBottom_Loss: 0.5261\tLoss: 1.6668\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4960\tTop_Loss: 0.6835\tBottom_Loss: 0.6142\tLoss: 1.7937\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5479\tTop_Loss: 0.5894\tBottom_Loss: 0.7155\tLoss: 1.8529\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.719\tLabel_Loss: 0.4439\tTop_Loss: 0.5518\tBottom_Loss: 0.4904\tLoss: 1.4861\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6373\tTop_Loss: 0.7974\tBottom_Loss: 0.5729\tLoss: 2.0075\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4387\tTop_Loss: 0.5465\tBottom_Loss: 0.4638\tLoss: 1.4489\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.688\tLabel_Loss: 0.5909\tTop_Loss: 0.7196\tBottom_Loss: 0.6645\tLoss: 1.9750\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5564\tTop_Loss: 0.6017\tBottom_Loss: 0.6505\tLoss: 1.8087\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4140\tTop_Loss: 0.4147\tBottom_Loss: 0.5961\tLoss: 1.4248\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4020\tTop_Loss: 0.4965\tBottom_Loss: 0.4404\tLoss: 1.3389\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5918\tTop_Loss: 0.6227\tBottom_Loss: 0.5924\tLoss: 1.8070\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4487\tTop_Loss: 0.5604\tBottom_Loss: 0.5214\tLoss: 1.5305\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4857\tTop_Loss: 0.6119\tBottom_Loss: 0.6778\tLoss: 1.7755\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5819\tTop_Loss: 0.6359\tBottom_Loss: 0.5431\tLoss: 1.7608\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4106\tTop_Loss: 0.6398\tBottom_Loss: 0.4717\tLoss: 1.5221\t\n",
      "Subject: 017, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.750\tLabel_Loss: 0.4999\tTop_Loss: 0.7079\tBottom_Loss: 0.4315\tLoss: 1.6393\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4887\tTop_Loss: 0.6282\tBottom_Loss: 0.5809\tLoss: 1.6979\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3388\tTop_Loss: 0.5042\tBottom_Loss: 0.4456\tLoss: 1.2886\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4350\tTop_Loss: 0.5850\tBottom_Loss: 0.5255\tLoss: 1.5456\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1869\tTop_Loss: 0.2447\tBottom_Loss: 0.4590\tLoss: 0.8906\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2241\tTop_Loss: 0.3510\tBottom_Loss: 0.3977\tLoss: 0.9728\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4201\tTop_Loss: 0.3980\tBottom_Loss: 0.5377\tLoss: 1.3558\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5234\tTop_Loss: 0.6205\tBottom_Loss: 0.7285\tLoss: 1.8724\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4307\tTop_Loss: 0.5089\tBottom_Loss: 0.6107\tLoss: 1.5504\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2134\tTop_Loss: 0.3570\tBottom_Loss: 0.4637\tLoss: 1.0340\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.719\tLabel_Loss: 0.4671\tTop_Loss: 0.4962\tBottom_Loss: 0.5065\tLoss: 1.4697\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3487\tTop_Loss: 0.4697\tBottom_Loss: 0.4894\tLoss: 1.3078\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2434\tTop_Loss: 0.3629\tBottom_Loss: 0.3484\tLoss: 0.9547\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3754\tTop_Loss: 0.5381\tBottom_Loss: 0.5913\tLoss: 1.5048\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2728\tTop_Loss: 0.3893\tBottom_Loss: 0.3561\tLoss: 1.0181\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2971\tTop_Loss: 0.5058\tBottom_Loss: 0.3386\tLoss: 1.1415\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2002\tTop_Loss: 0.3036\tBottom_Loss: 0.3683\tLoss: 0.8721\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2024\tTop_Loss: 0.3821\tBottom_Loss: 0.2722\tLoss: 0.8567\t\n",
      "Subject: 017, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3567\tTop_Loss: 0.6780\tBottom_Loss: 0.3353\tLoss: 1.3700\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3082\tTop_Loss: 0.5029\tBottom_Loss: 0.2662\tLoss: 1.0773\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2248\tTop_Loss: 0.3848\tBottom_Loss: 0.3765\tLoss: 0.9862\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2943\tTop_Loss: 0.3488\tBottom_Loss: 0.4006\tLoss: 1.0437\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1278\tTop_Loss: 0.3312\tBottom_Loss: 0.2146\tLoss: 0.6735\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1517\tTop_Loss: 0.2712\tBottom_Loss: 0.3041\tLoss: 0.7270\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1705\tTop_Loss: 0.2968\tBottom_Loss: 0.2910\tLoss: 0.7583\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1439\tTop_Loss: 0.2893\tBottom_Loss: 0.4212\tLoss: 0.8544\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1113\tTop_Loss: 0.2445\tBottom_Loss: 0.1753\tLoss: 0.5310\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0744\tTop_Loss: 0.2113\tBottom_Loss: 0.1776\tLoss: 0.4633\t\n",
      "Subject: 017, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1151\tTop_Loss: 0.2732\tBottom_Loss: 0.1988\tLoss: 0.5871\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2341\tTop_Loss: 0.2105\tBottom_Loss: 0.3274\tLoss: 0.7721\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2512\tTop_Loss: 0.3775\tBottom_Loss: 0.3156\tLoss: 0.9443\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1472\tTop_Loss: 0.2946\tBottom_Loss: 0.2307\tLoss: 0.6726\t\n",
      "Subject: 017, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1552\tTop_Loss: 0.2408\tBottom_Loss: 0.2335\tLoss: 0.6294\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3472\tTop_Loss: 0.3851\tBottom_Loss: 0.4276\tLoss: 1.1599\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2223\tTop_Loss: 0.3140\tBottom_Loss: 0.4129\tLoss: 0.9492\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2782\tTop_Loss: 0.3689\tBottom_Loss: 0.3866\tLoss: 1.0336\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0953\tTop_Loss: 0.1790\tBottom_Loss: 0.1902\tLoss: 0.4644\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0861\tTop_Loss: 0.2619\tBottom_Loss: 0.2632\tLoss: 0.6113\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2392\tTop_Loss: 0.3462\tBottom_Loss: 0.2245\tLoss: 0.8099\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1287\tTop_Loss: 0.2325\tBottom_Loss: 0.2129\tLoss: 0.5740\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1191\tTop_Loss: 0.2666\tBottom_Loss: 0.1675\tLoss: 0.5532\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1017\tTop_Loss: 0.2466\tBottom_Loss: 0.1307\tLoss: 0.4790\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0983\tTop_Loss: 0.1915\tBottom_Loss: 0.1498\tLoss: 0.4396\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1500\tTop_Loss: 0.4028\tBottom_Loss: 0.2391\tLoss: 0.7919\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2033\tTop_Loss: 0.2850\tBottom_Loss: 0.3546\tLoss: 0.8430\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1212\tTop_Loss: 0.2152\tBottom_Loss: 0.2430\tLoss: 0.5794\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3636\tTop_Loss: 0.4459\tBottom_Loss: 0.4144\tLoss: 1.2239\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1321\tTop_Loss: 0.1594\tBottom_Loss: 0.4883\tLoss: 0.7797\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0444\tTop_Loss: 0.1474\tBottom_Loss: 0.1646\tLoss: 0.3564\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0497\tTop_Loss: 0.1184\tBottom_Loss: 0.0709\tLoss: 0.2390\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0380\tTop_Loss: 0.1717\tBottom_Loss: 0.1809\tLoss: 0.3906\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1153\tTop_Loss: 0.1681\tBottom_Loss: 0.2472\tLoss: 0.5306\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0782\tTop_Loss: 0.1952\tBottom_Loss: 0.2019\tLoss: 0.4753\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1441\tTop_Loss: 0.2735\tBottom_Loss: 0.2117\tLoss: 0.6293\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1048\tTop_Loss: 0.2141\tBottom_Loss: 0.2490\tLoss: 0.5679\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0604\tTop_Loss: 0.1410\tBottom_Loss: 0.1221\tLoss: 0.3236\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0914\tTop_Loss: 0.2620\tBottom_Loss: 0.2150\tLoss: 0.5684\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0707\tTop_Loss: 0.2367\tBottom_Loss: 0.1507\tLoss: 0.4580\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0285\tTop_Loss: 0.1362\tBottom_Loss: 0.0730\tLoss: 0.2377\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0482\tTop_Loss: 0.1064\tBottom_Loss: 0.1792\tLoss: 0.3338\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0702\tTop_Loss: 0.1650\tBottom_Loss: 0.1731\tLoss: 0.4083\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0345\tTop_Loss: 0.1369\tBottom_Loss: 0.1254\tLoss: 0.2968\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1000\tTop_Loss: 0.2196\tBottom_Loss: 0.1416\tLoss: 0.4612\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0748\tTop_Loss: 0.1791\tBottom_Loss: 0.1082\tLoss: 0.3621\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0971\tTop_Loss: 0.1938\tBottom_Loss: 0.1844\tLoss: 0.4754\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1278\tTop_Loss: 0.2893\tBottom_Loss: 0.1674\tLoss: 0.5845\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0500\tTop_Loss: 0.1654\tBottom_Loss: 0.0988\tLoss: 0.3142\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0498\tTop_Loss: 0.1705\tBottom_Loss: 0.2471\tLoss: 0.4674\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0902\tTop_Loss: 0.1377\tBottom_Loss: 0.1809\tLoss: 0.4088\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1078\tTop_Loss: 0.2634\tBottom_Loss: 0.1811\tLoss: 0.5524\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0831\tTop_Loss: 0.1828\tBottom_Loss: 0.1851\tLoss: 0.4510\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1345\tTop_Loss: 0.2676\tBottom_Loss: 0.1869\tLoss: 0.5889\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0555\tTop_Loss: 0.1664\tBottom_Loss: 0.1146\tLoss: 0.3365\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0451\tTop_Loss: 0.1799\tBottom_Loss: 0.1414\tLoss: 0.3665\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0369\tTop_Loss: 0.1234\tBottom_Loss: 0.0607\tLoss: 0.2210\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1043\tTop_Loss: 0.2757\tBottom_Loss: 0.1587\tLoss: 0.5387\t\n",
      "Subject: 017, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0397\tTop_Loss: 0.1392\tBottom_Loss: 0.0640\tLoss: 0.2429\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0511\tTop_Loss: 0.1377\tBottom_Loss: 0.1001\tLoss: 0.2890\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0486\tTop_Loss: 0.1215\tBottom_Loss: 0.1032\tLoss: 0.2733\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0510\tTop_Loss: 0.1253\tBottom_Loss: 0.1179\tLoss: 0.2942\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0563\tTop_Loss: 0.1803\tBottom_Loss: 0.0964\tLoss: 0.3330\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0657\tTop_Loss: 0.1972\tBottom_Loss: 0.1060\tLoss: 0.3690\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0638\tTop_Loss: 0.1453\tBottom_Loss: 0.2037\tLoss: 0.4129\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0520\tTop_Loss: 0.1189\tBottom_Loss: 0.1240\tLoss: 0.2948\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0485\tTop_Loss: 0.1085\tBottom_Loss: 0.0998\tLoss: 0.2568\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0324\tTop_Loss: 0.1209\tBottom_Loss: 0.0583\tLoss: 0.2116\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0270\tTop_Loss: 0.1093\tBottom_Loss: 0.1112\tLoss: 0.2474\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0202\tTop_Loss: 0.0752\tBottom_Loss: 0.0563\tLoss: 0.1517\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1297\tTop_Loss: 0.1466\tBottom_Loss: 0.1928\tLoss: 0.4691\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0538\tTop_Loss: 0.0969\tBottom_Loss: 0.0911\tLoss: 0.2418\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0230\tTop_Loss: 0.1166\tBottom_Loss: 0.0577\tLoss: 0.1973\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0733\tTop_Loss: 0.1021\tBottom_Loss: 0.1043\tLoss: 0.2798\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0504\tTop_Loss: 0.2150\tBottom_Loss: 0.0720\tLoss: 0.3373\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0361\tTop_Loss: 0.0441\tBottom_Loss: 0.1033\tLoss: 0.1835\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0313\tTop_Loss: 0.0723\tBottom_Loss: 0.1405\tLoss: 0.2441\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0816\tTop_Loss: 0.1705\tBottom_Loss: 0.0729\tLoss: 0.3251\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0176\tTop_Loss: 0.0402\tBottom_Loss: 0.0661\tLoss: 0.1239\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0142\tTop_Loss: 0.0622\tBottom_Loss: 0.0538\tLoss: 0.1302\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1305\tTop_Loss: 0.2227\tBottom_Loss: 0.2457\tLoss: 0.5989\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0539\tTop_Loss: 0.1895\tBottom_Loss: 0.0474\tLoss: 0.2907\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0089\tTop_Loss: 0.0521\tBottom_Loss: 0.0581\tLoss: 0.1191\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0649\tTop_Loss: 0.1762\tBottom_Loss: 0.1197\tLoss: 0.3609\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0087\tTop_Loss: 0.0493\tBottom_Loss: 0.0467\tLoss: 0.1047\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0296\tTop_Loss: 0.0433\tBottom_Loss: 0.0895\tLoss: 0.1624\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0231\tTop_Loss: 0.0551\tBottom_Loss: 0.0752\tLoss: 0.1535\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1021\tTop_Loss: 0.1071\tBottom_Loss: 0.1219\tLoss: 0.3312\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0216\tTop_Loss: 0.0679\tBottom_Loss: 0.0601\tLoss: 0.1496\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1226\tTop_Loss: 0.2942\tBottom_Loss: 0.0939\tLoss: 0.5107\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0913\tTop_Loss: 0.0561\tBottom_Loss: 0.2255\tLoss: 0.3728\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0116\tTop_Loss: 0.0921\tBottom_Loss: 0.0464\tLoss: 0.1501\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0198\tTop_Loss: 0.0498\tBottom_Loss: 0.0572\tLoss: 0.1269\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0241\tTop_Loss: 0.0712\tBottom_Loss: 0.0545\tLoss: 0.1497\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0155\tTop_Loss: 0.0504\tBottom_Loss: 0.0624\tLoss: 0.1283\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0499\tTop_Loss: 0.0611\tBottom_Loss: 0.0836\tLoss: 0.1946\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0180\tTop_Loss: 0.0698\tBottom_Loss: 0.0539\tLoss: 0.1418\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0309\tTop_Loss: 0.1769\tBottom_Loss: 0.0723\tLoss: 0.2801\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0171\tTop_Loss: 0.0713\tBottom_Loss: 0.0399\tLoss: 0.1283\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0141\tTop_Loss: 0.0515\tBottom_Loss: 0.0375\tLoss: 0.1031\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0232\tTop_Loss: 0.0379\tBottom_Loss: 0.0663\tLoss: 0.1275\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0094\tTop_Loss: 0.0405\tBottom_Loss: 0.0229\tLoss: 0.0728\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0200\tTop_Loss: 0.0677\tBottom_Loss: 0.0606\tLoss: 0.1483\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0118\tTop_Loss: 0.0443\tBottom_Loss: 0.0297\tLoss: 0.0859\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0110\tTop_Loss: 0.0327\tBottom_Loss: 0.0247\tLoss: 0.0684\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0076\tTop_Loss: 0.0253\tBottom_Loss: 0.0247\tLoss: 0.0576\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0160\tTop_Loss: 0.0589\tBottom_Loss: 0.0307\tLoss: 0.1057\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0638\tTop_Loss: 0.0713\tBottom_Loss: 0.0651\tLoss: 0.2002\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0141\tTop_Loss: 0.0336\tBottom_Loss: 0.0404\tLoss: 0.0881\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0116\tTop_Loss: 0.0292\tBottom_Loss: 0.0234\tLoss: 0.0643\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0147\tTop_Loss: 0.0382\tBottom_Loss: 0.0491\tLoss: 0.1021\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0293\tTop_Loss: 0.0570\tBottom_Loss: 0.0357\tLoss: 0.1221\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0340\tTop_Loss: 0.0695\tBottom_Loss: 0.0540\tLoss: 0.1575\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0132\tTop_Loss: 0.0367\tBottom_Loss: 0.0222\tLoss: 0.0721\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0100\tTop_Loss: 0.0511\tBottom_Loss: 0.0359\tLoss: 0.0971\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0047\tTop_Loss: 0.0248\tBottom_Loss: 0.0307\tLoss: 0.0601\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0829\tTop_Loss: 0.0916\tBottom_Loss: 0.0721\tLoss: 0.2467\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0152\tTop_Loss: 0.0313\tBottom_Loss: 0.1437\tLoss: 0.1901\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0127\tTop_Loss: 0.0783\tBottom_Loss: 0.0334\tLoss: 0.1244\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0418\tTop_Loss: 0.0508\tBottom_Loss: 0.1248\tLoss: 0.2174\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0196\tTop_Loss: 0.0891\tBottom_Loss: 0.0314\tLoss: 0.1401\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0284\tTop_Loss: 0.1204\tBottom_Loss: 0.0395\tLoss: 0.1884\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0115\tTop_Loss: 0.0660\tBottom_Loss: 0.0299\tLoss: 0.1074\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0586\tTop_Loss: 0.1641\tBottom_Loss: 0.0694\tLoss: 0.2920\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1151\tTop_Loss: 0.1721\tBottom_Loss: 0.1699\tLoss: 0.4571\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0116\tTop_Loss: 0.0353\tBottom_Loss: 0.0175\tLoss: 0.0644\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0160\tTop_Loss: 0.0556\tBottom_Loss: 0.0715\tLoss: 0.1431\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0284\tTop_Loss: 0.0375\tBottom_Loss: 0.0815\tLoss: 0.1474\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0172\tTop_Loss: 0.0664\tBottom_Loss: 0.0338\tLoss: 0.1174\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0637\tTop_Loss: 0.0769\tBottom_Loss: 0.1501\tLoss: 0.2907\t\n",
      "Subject: 017, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.406\tLabel_Loss: 1.2504\tTop_Loss: 1.3579\tBottom_Loss: 1.2138\tLoss: 3.8221\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.531\tLabel_Loss: 1.1878\tTop_Loss: 1.0770\tBottom_Loss: 1.3439\tLoss: 3.6087\t\n",
      "Subject: 018, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.469\tLabel_Loss: 1.1591\tTop_Loss: 1.1709\tBottom_Loss: 1.2374\tLoss: 3.5673\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.344\tLabel_Loss: 1.1784\tTop_Loss: 0.9473\tBottom_Loss: 1.2009\tLoss: 3.3266\t\n",
      "Subject: 018, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.469\tLabel_Loss: 0.9516\tTop_Loss: 0.9871\tBottom_Loss: 0.9709\tLoss: 2.9095\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8962\tTop_Loss: 0.8809\tBottom_Loss: 1.0081\tLoss: 2.7852\t\n",
      "Subject: 018, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8539\tTop_Loss: 0.9007\tBottom_Loss: 0.8123\tLoss: 2.5668\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8791\tTop_Loss: 1.0418\tBottom_Loss: 0.9859\tLoss: 2.9068\t\n",
      "Subject: 018, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.781\tLabel_Loss: 0.6712\tTop_Loss: 0.7771\tBottom_Loss: 0.7043\tLoss: 2.1527\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8799\tTop_Loss: 0.9218\tBottom_Loss: 0.9683\tLoss: 2.7701\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8140\tTop_Loss: 1.1095\tBottom_Loss: 0.8932\tLoss: 2.8167\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8836\tTop_Loss: 0.8665\tBottom_Loss: 0.9697\tLoss: 2.7198\t\n",
      "Subject: 018, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7991\tTop_Loss: 0.8299\tBottom_Loss: 1.0575\tLoss: 2.6865\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8190\tTop_Loss: 0.9422\tBottom_Loss: 0.7415\tLoss: 2.5028\t\n",
      "Subject: 018, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8628\tTop_Loss: 0.8213\tBottom_Loss: 0.8412\tLoss: 2.5253\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.531\tLabel_Loss: 0.9694\tTop_Loss: 0.8163\tBottom_Loss: 0.9104\tLoss: 2.6961\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7768\tTop_Loss: 0.8545\tBottom_Loss: 0.8372\tLoss: 2.4685\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.562\tLabel_Loss: 0.8423\tTop_Loss: 0.9152\tBottom_Loss: 0.8924\tLoss: 2.6498\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5960\tTop_Loss: 0.7068\tBottom_Loss: 0.6570\tLoss: 1.9598\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.594\tLabel_Loss: 0.7522\tTop_Loss: 0.7070\tBottom_Loss: 0.6461\tLoss: 2.1054\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7825\tTop_Loss: 0.7932\tBottom_Loss: 0.8820\tLoss: 2.4577\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.688\tLabel_Loss: 0.8820\tTop_Loss: 1.2030\tBottom_Loss: 0.8351\tLoss: 2.9201\t\n",
      "Subject: 018, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7455\tTop_Loss: 0.7502\tBottom_Loss: 0.8200\tLoss: 2.3157\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.656\tLabel_Loss: 0.8016\tTop_Loss: 0.6710\tBottom_Loss: 0.8175\tLoss: 2.2901\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5989\tTop_Loss: 0.6768\tBottom_Loss: 0.8578\tLoss: 2.1334\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7166\tTop_Loss: 1.0928\tBottom_Loss: 0.8768\tLoss: 2.6862\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6808\tTop_Loss: 0.7195\tBottom_Loss: 0.8872\tLoss: 2.2875\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6310\tTop_Loss: 0.7115\tBottom_Loss: 0.8529\tLoss: 2.1955\t\n",
      "Subject: 018, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6084\tTop_Loss: 0.6439\tBottom_Loss: 0.6875\tLoss: 1.9399\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.562\tLabel_Loss: 0.7753\tTop_Loss: 0.8068\tBottom_Loss: 0.8323\tLoss: 2.4144\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4221\tTop_Loss: 0.5987\tBottom_Loss: 0.7443\tLoss: 1.7651\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6473\tTop_Loss: 0.6169\tBottom_Loss: 0.8521\tLoss: 2.1162\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5121\tTop_Loss: 0.6101\tBottom_Loss: 0.6631\tLoss: 1.7853\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.500\tLabel_Loss: 1.0132\tTop_Loss: 1.1642\tBottom_Loss: 0.8400\tLoss: 3.0173\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4755\tTop_Loss: 0.5231\tBottom_Loss: 0.6055\tLoss: 1.6041\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5379\tTop_Loss: 0.7279\tBottom_Loss: 0.7367\tLoss: 2.0025\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3831\tTop_Loss: 0.6247\tBottom_Loss: 0.4335\tLoss: 1.4413\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5780\tTop_Loss: 0.8446\tBottom_Loss: 0.6041\tLoss: 2.0268\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3448\tTop_Loss: 0.3957\tBottom_Loss: 0.5740\tLoss: 1.3144\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3771\tTop_Loss: 0.4797\tBottom_Loss: 0.6053\tLoss: 1.4621\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4754\tTop_Loss: 0.6132\tBottom_Loss: 0.6746\tLoss: 1.7632\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5099\tTop_Loss: 0.5896\tBottom_Loss: 0.6233\tLoss: 1.7227\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2803\tTop_Loss: 0.5370\tBottom_Loss: 0.4785\tLoss: 1.2958\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.938\tLabel_Loss: 0.3178\tTop_Loss: 0.5546\tBottom_Loss: 0.4656\tLoss: 1.3379\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3948\tTop_Loss: 0.5213\tBottom_Loss: 0.4899\tLoss: 1.4060\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4568\tTop_Loss: 0.5531\tBottom_Loss: 0.5648\tLoss: 1.5747\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4385\tTop_Loss: 0.8421\tBottom_Loss: 0.6310\tLoss: 1.9116\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.750\tLabel_Loss: 0.4385\tTop_Loss: 0.6240\tBottom_Loss: 0.5785\tLoss: 1.6411\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4413\tTop_Loss: 0.6173\tBottom_Loss: 0.5064\tLoss: 1.5650\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3849\tTop_Loss: 0.7199\tBottom_Loss: 0.4561\tLoss: 1.5609\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4558\tTop_Loss: 0.4933\tBottom_Loss: 0.5885\tLoss: 1.5377\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4611\tTop_Loss: 0.6129\tBottom_Loss: 0.6958\tLoss: 1.7698\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2947\tTop_Loss: 0.4893\tBottom_Loss: 0.4417\tLoss: 1.2258\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3651\tTop_Loss: 0.5808\tBottom_Loss: 0.4710\tLoss: 1.4170\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3046\tTop_Loss: 0.3950\tBottom_Loss: 0.3599\tLoss: 1.0596\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3808\tTop_Loss: 0.6521\tBottom_Loss: 0.3455\tLoss: 1.3785\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2887\tTop_Loss: 0.5799\tBottom_Loss: 0.3477\tLoss: 1.2162\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2589\tTop_Loss: 0.5413\tBottom_Loss: 0.4176\tLoss: 1.2178\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1913\tTop_Loss: 0.4287\tBottom_Loss: 0.3189\tLoss: 0.9389\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3048\tTop_Loss: 0.3575\tBottom_Loss: 0.4514\tLoss: 1.1137\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2321\tTop_Loss: 0.4072\tBottom_Loss: 0.3758\tLoss: 1.0151\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3288\tTop_Loss: 0.4508\tBottom_Loss: 0.4222\tLoss: 1.2018\t\n",
      "Subject: 018, n=03 | test_f1: 0.0 |best_f1: 0.4\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2236\tTop_Loss: 0.3663\tBottom_Loss: 0.4116\tLoss: 1.0015\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.750\tLabel_Loss: 0.4683\tTop_Loss: 0.5836\tBottom_Loss: 0.6037\tLoss: 1.6556\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2566\tTop_Loss: 0.4312\tBottom_Loss: 0.4228\tLoss: 1.1106\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3557\tTop_Loss: 0.4434\tBottom_Loss: 0.4718\tLoss: 1.2710\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 1.000\tLabel_Loss: 0.2253\tTop_Loss: 0.4758\tBottom_Loss: 0.2827\tLoss: 0.9838\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2046\tTop_Loss: 0.3985\tBottom_Loss: 0.3757\tLoss: 0.9788\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1910\tTop_Loss: 0.4639\tBottom_Loss: 0.3863\tLoss: 1.0412\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3150\tTop_Loss: 0.5133\tBottom_Loss: 0.6534\tLoss: 1.4817\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2087\tTop_Loss: 0.3423\tBottom_Loss: 0.3914\tLoss: 0.9424\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2706\tTop_Loss: 0.4846\tBottom_Loss: 0.2888\tLoss: 1.0440\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3020\tTop_Loss: 0.4280\tBottom_Loss: 0.5322\tLoss: 1.2621\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2805\tTop_Loss: 0.3812\tBottom_Loss: 0.3570\tLoss: 1.0187\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2343\tTop_Loss: 0.5183\tBottom_Loss: 0.3302\tLoss: 1.0828\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3228\tTop_Loss: 0.4311\tBottom_Loss: 0.3901\tLoss: 1.1441\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.781\tLabel_Loss: 0.3551\tTop_Loss: 0.4996\tBottom_Loss: 0.5411\tLoss: 1.3958\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2888\tTop_Loss: 0.4822\tBottom_Loss: 0.5119\tLoss: 1.2828\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1372\tTop_Loss: 0.1949\tBottom_Loss: 0.2437\tLoss: 0.5758\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1720\tTop_Loss: 0.3651\tBottom_Loss: 0.2714\tLoss: 0.8086\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2676\tTop_Loss: 0.3253\tBottom_Loss: 0.3912\tLoss: 0.9841\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1696\tTop_Loss: 0.2506\tBottom_Loss: 0.2492\tLoss: 0.6694\t\n",
      "Subject: 018, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1993\tTop_Loss: 0.3096\tBottom_Loss: 0.2554\tLoss: 0.7643\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2519\tTop_Loss: 0.5733\tBottom_Loss: 0.2284\tLoss: 1.0536\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1811\tTop_Loss: 0.3550\tBottom_Loss: 0.3261\tLoss: 0.8622\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1403\tTop_Loss: 0.2775\tBottom_Loss: 0.2328\tLoss: 0.6505\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1621\tTop_Loss: 0.4250\tBottom_Loss: 0.1539\tLoss: 0.7409\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.875\tLabel_Loss: 0.1971\tTop_Loss: 0.3800\tBottom_Loss: 0.2190\tLoss: 0.7961\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1264\tTop_Loss: 0.2433\tBottom_Loss: 0.1972\tLoss: 0.5669\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1049\tTop_Loss: 0.2544\tBottom_Loss: 0.1668\tLoss: 0.5260\t\n",
      "Subject: 018, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1385\tTop_Loss: 0.2442\tBottom_Loss: 0.2545\tLoss: 0.6372\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1859\tTop_Loss: 0.4174\tBottom_Loss: 0.1954\tLoss: 0.7987\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1200\tTop_Loss: 0.3455\tBottom_Loss: 0.3379\tLoss: 0.8034\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2124\tTop_Loss: 0.2870\tBottom_Loss: 0.3125\tLoss: 0.8120\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1511\tTop_Loss: 0.3159\tBottom_Loss: 0.2505\tLoss: 0.7176\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1667\tTop_Loss: 0.4146\tBottom_Loss: 0.2091\tLoss: 0.7904\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0901\tTop_Loss: 0.1953\tBottom_Loss: 0.1572\tLoss: 0.4426\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1568\tTop_Loss: 0.3743\tBottom_Loss: 0.2832\tLoss: 0.8143\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0821\tTop_Loss: 0.1134\tBottom_Loss: 0.1727\tLoss: 0.3682\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0736\tTop_Loss: 0.2208\tBottom_Loss: 0.1405\tLoss: 0.4349\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1659\tTop_Loss: 0.2590\tBottom_Loss: 0.2099\tLoss: 0.6348\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1540\tTop_Loss: 0.3205\tBottom_Loss: 0.2462\tLoss: 0.7207\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0978\tTop_Loss: 0.2364\tBottom_Loss: 0.2512\tLoss: 0.5855\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0580\tTop_Loss: 0.1647\tBottom_Loss: 0.1304\tLoss: 0.3531\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0597\tTop_Loss: 0.2405\tBottom_Loss: 0.1727\tLoss: 0.4728\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0655\tTop_Loss: 0.2454\tBottom_Loss: 0.1241\tLoss: 0.4350\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2198\tTop_Loss: 0.2486\tBottom_Loss: 0.2797\tLoss: 0.7480\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0738\tTop_Loss: 0.2783\tBottom_Loss: 0.0970\tLoss: 0.4490\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0495\tTop_Loss: 0.1277\tBottom_Loss: 0.1233\tLoss: 0.3005\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1201\tTop_Loss: 0.1260\tBottom_Loss: 0.3303\tLoss: 0.5763\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0392\tTop_Loss: 0.1282\tBottom_Loss: 0.1095\tLoss: 0.2770\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0788\tTop_Loss: 0.2194\tBottom_Loss: 0.1460\tLoss: 0.4442\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0569\tTop_Loss: 0.2906\tBottom_Loss: 0.0744\tLoss: 0.4219\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0945\tTop_Loss: 0.2184\tBottom_Loss: 0.2083\tLoss: 0.5212\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0724\tTop_Loss: 0.2548\tBottom_Loss: 0.1225\tLoss: 0.4496\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0707\tTop_Loss: 0.1409\tBottom_Loss: 0.1732\tLoss: 0.3848\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0438\tTop_Loss: 0.0913\tBottom_Loss: 0.0713\tLoss: 0.2064\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0933\tTop_Loss: 0.2395\tBottom_Loss: 0.1488\tLoss: 0.4816\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0798\tTop_Loss: 0.1811\tBottom_Loss: 0.1296\tLoss: 0.3905\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0587\tTop_Loss: 0.1266\tBottom_Loss: 0.0792\tLoss: 0.2645\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 0.938\tLabel_Loss: 0.0906\tTop_Loss: 0.2922\tBottom_Loss: 0.0846\tLoss: 0.4673\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1967\tTop_Loss: 0.3462\tBottom_Loss: 0.1924\tLoss: 0.7353\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0615\tTop_Loss: 0.2710\tBottom_Loss: 0.1076\tLoss: 0.4400\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0704\tTop_Loss: 0.1907\tBottom_Loss: 0.2093\tLoss: 0.4703\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1503\tTop_Loss: 0.2850\tBottom_Loss: 0.1633\tLoss: 0.5986\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0548\tTop_Loss: 0.1997\tBottom_Loss: 0.1187\tLoss: 0.3732\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1018\tTop_Loss: 0.1681\tBottom_Loss: 0.2608\tLoss: 0.5307\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0728\tTop_Loss: 0.1822\tBottom_Loss: 0.1539\tLoss: 0.4089\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0354\tTop_Loss: 0.1832\tBottom_Loss: 0.0639\tLoss: 0.2826\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0426\tTop_Loss: 0.2179\tBottom_Loss: 0.0656\tLoss: 0.3261\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0622\tTop_Loss: 0.1303\tBottom_Loss: 0.1484\tLoss: 0.3409\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0589\tTop_Loss: 0.0775\tBottom_Loss: 0.1218\tLoss: 0.2582\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0852\tTop_Loss: 0.0668\tBottom_Loss: 0.2013\tLoss: 0.3533\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0329\tTop_Loss: 0.1999\tBottom_Loss: 0.0557\tLoss: 0.2886\t\n",
      "Subject: 018, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0480\tTop_Loss: 0.1309\tBottom_Loss: 0.0608\tLoss: 0.2397\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0279\tTop_Loss: 0.1380\tBottom_Loss: 0.0373\tLoss: 0.2031\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0570\tTop_Loss: 0.1902\tBottom_Loss: 0.1397\tLoss: 0.3868\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0454\tTop_Loss: 0.1176\tBottom_Loss: 0.1342\tLoss: 0.2972\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.4\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0726\tTop_Loss: 0.0655\tBottom_Loss: 0.1214\tLoss: 0.2595\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0295\tTop_Loss: 0.1165\tBottom_Loss: 0.0978\tLoss: 0.2438\t\n",
      "Subject: 018, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0348\tTop_Loss: 0.2075\tBottom_Loss: 0.0649\tLoss: 0.3073\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0843\tTop_Loss: 0.0718\tBottom_Loss: 0.0897\tLoss: 0.2458\t\n",
      "Subject: 018, n=03 | test_f1: 0.55556 |best_f1: 0.55556\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1496\tTop_Loss: 0.2432\tBottom_Loss: 0.1698\tLoss: 0.5626\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0364\tTop_Loss: 0.0718\tBottom_Loss: 0.1233\tLoss: 0.2315\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.55556\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0230\tTop_Loss: 0.1438\tBottom_Loss: 0.0693\tLoss: 0.2361\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0423\tTop_Loss: 0.0949\tBottom_Loss: 0.0594\tLoss: 0.1967\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.55556\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0587\tTop_Loss: 0.1609\tBottom_Loss: 0.1068\tLoss: 0.3264\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0892\tTop_Loss: 0.1051\tBottom_Loss: 0.2557\tLoss: 0.4500\t\n",
      "Subject: 018, n=03 | test_f1: 0.4 |best_f1: 0.55556\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0180\tTop_Loss: 0.0864\tBottom_Loss: 0.0415\tLoss: 0.1459\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0763\tTop_Loss: 0.1496\tBottom_Loss: 0.1372\tLoss: 0.3631\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.55556\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1044\tTop_Loss: 0.0886\tBottom_Loss: 0.0948\tLoss: 0.2878\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0143\tTop_Loss: 0.0473\tBottom_Loss: 0.0583\tLoss: 0.1199\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.55556\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0214\tTop_Loss: 0.0847\tBottom_Loss: 0.0354\tLoss: 0.1414\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0218\tTop_Loss: 0.0931\tBottom_Loss: 0.0422\tLoss: 0.1571\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.55556\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0332\tTop_Loss: 0.1301\tBottom_Loss: 0.0702\tLoss: 0.2335\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0106\tTop_Loss: 0.0558\tBottom_Loss: 0.0475\tLoss: 0.1139\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.55556\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0297\tTop_Loss: 0.0399\tBottom_Loss: 0.0639\tLoss: 0.1335\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0211\tTop_Loss: 0.1014\tBottom_Loss: 0.0804\tLoss: 0.2030\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.55556\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0386\tTop_Loss: 0.1968\tBottom_Loss: 0.0366\tLoss: 0.2720\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0229\tTop_Loss: 0.0617\tBottom_Loss: 0.0778\tLoss: 0.1624\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.55556\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0431\tTop_Loss: 0.1410\tBottom_Loss: 0.0849\tLoss: 0.2689\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0085\tTop_Loss: 0.1017\tBottom_Loss: 0.0272\tLoss: 0.1374\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.55556\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0730\tTop_Loss: 0.1589\tBottom_Loss: 0.1857\tLoss: 0.4176\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0125\tTop_Loss: 0.0875\tBottom_Loss: 0.0252\tLoss: 0.1251\t\n",
      "Subject: 018, n=03 | test_f1: 0.4 |best_f1: 0.55556\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0460\tTop_Loss: 0.1147\tBottom_Loss: 0.0501\tLoss: 0.2107\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0272\tTop_Loss: 0.1151\tBottom_Loss: 0.0391\tLoss: 0.1814\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.55556\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0148\tTop_Loss: 0.0391\tBottom_Loss: 0.0356\tLoss: 0.0896\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0200\tTop_Loss: 0.1017\tBottom_Loss: 0.0329\tLoss: 0.1545\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.55556\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0133\tTop_Loss: 0.0361\tBottom_Loss: 0.0590\tLoss: 0.1084\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0175\tTop_Loss: 0.0662\tBottom_Loss: 0.0463\tLoss: 0.1300\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.55556\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0072\tTop_Loss: 0.0355\tBottom_Loss: 0.0354\tLoss: 0.0781\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0255\tTop_Loss: 0.0441\tBottom_Loss: 0.0798\tLoss: 0.1495\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.55556\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0095\tTop_Loss: 0.0330\tBottom_Loss: 0.0263\tLoss: 0.0688\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0030\tTop_Loss: 0.0377\tBottom_Loss: 0.0113\tLoss: 0.0520\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.55556\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0126\tTop_Loss: 0.0318\tBottom_Loss: 0.0389\tLoss: 0.0833\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0053\tTop_Loss: 0.0308\tBottom_Loss: 0.0278\tLoss: 0.0639\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.55556\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0205\tTop_Loss: 0.0523\tBottom_Loss: 0.0269\tLoss: 0.0997\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0090\tTop_Loss: 0.0848\tBottom_Loss: 0.0244\tLoss: 0.1181\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.55556\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0408\tTop_Loss: 0.1517\tBottom_Loss: 0.0554\tLoss: 0.2479\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0538\tTop_Loss: 0.1769\tBottom_Loss: 0.0894\tLoss: 0.3201\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.55556\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0236\tTop_Loss: 0.0301\tBottom_Loss: 0.0879\tLoss: 0.1416\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0206\tTop_Loss: 0.0823\tBottom_Loss: 0.0335\tLoss: 0.1364\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.55556\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0132\tTop_Loss: 0.0578\tBottom_Loss: 0.0751\tLoss: 0.1460\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0165\tTop_Loss: 0.0984\tBottom_Loss: 0.0264\tLoss: 0.1412\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.55556\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0072\tTop_Loss: 0.0321\tBottom_Loss: 0.0427\tLoss: 0.0820\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0067\tTop_Loss: 0.0394\tBottom_Loss: 0.0227\tLoss: 0.0688\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.55556\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0616\tTop_Loss: 0.0401\tBottom_Loss: 0.1094\tLoss: 0.2111\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0197\tTop_Loss: 0.0535\tBottom_Loss: 0.0303\tLoss: 0.1034\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.55556\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0231\tTop_Loss: 0.0322\tBottom_Loss: 0.0493\tLoss: 0.1046\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0170\tTop_Loss: 0.0643\tBottom_Loss: 0.0357\tLoss: 0.1171\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.55556\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0178\tTop_Loss: 0.0694\tBottom_Loss: 0.0390\tLoss: 0.1263\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0089\tTop_Loss: 0.0305\tBottom_Loss: 0.0231\tLoss: 0.0626\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.55556\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0104\tTop_Loss: 0.0348\tBottom_Loss: 0.0372\tLoss: 0.0823\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0075\tTop_Loss: 0.0234\tBottom_Loss: 0.0195\tLoss: 0.0504\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.55556\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 0.938\tLabel_Loss: 0.0640\tTop_Loss: 0.1305\tBottom_Loss: 0.0625\tLoss: 0.2570\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0072\tTop_Loss: 0.0373\tBottom_Loss: 0.0235\tLoss: 0.0679\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.55556\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0066\tTop_Loss: 0.0148\tBottom_Loss: 0.0362\tLoss: 0.0576\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0234\tTop_Loss: 0.0841\tBottom_Loss: 0.0339\tLoss: 0.1415\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.55556\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0524\tTop_Loss: 0.0660\tBottom_Loss: 0.2052\tLoss: 0.3235\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0115\tTop_Loss: 0.1279\tBottom_Loss: 0.0273\tLoss: 0.1667\t\n",
      "Subject: 018, n=03 | test_f1: 0.16667 |best_f1: 0.55556\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.344\tLabel_Loss: 1.2269\tTop_Loss: 1.5117\tBottom_Loss: 1.4922\tLoss: 4.2307\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.562\tLabel_Loss: 1.1155\tTop_Loss: 1.0789\tBottom_Loss: 1.1163\tLoss: 3.3107\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7876\tTop_Loss: 0.9840\tBottom_Loss: 0.8449\tLoss: 2.6166\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.469\tLabel_Loss: 1.0661\tTop_Loss: 0.8667\tBottom_Loss: 0.9058\tLoss: 2.8387\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.594\tLabel_Loss: 1.0065\tTop_Loss: 0.9135\tBottom_Loss: 0.9463\tLoss: 2.8662\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8893\tTop_Loss: 0.9570\tBottom_Loss: 1.0187\tLoss: 2.8650\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.500\tLabel_Loss: 0.9293\tTop_Loss: 0.8729\tBottom_Loss: 0.8864\tLoss: 2.6886\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8101\tTop_Loss: 0.7256\tBottom_Loss: 0.8208\tLoss: 2.3565\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.875\tLabel_Loss: 0.5178\tTop_Loss: 0.6798\tBottom_Loss: 0.6457\tLoss: 1.8433\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8952\tTop_Loss: 0.7162\tBottom_Loss: 0.9591\tLoss: 2.5705\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.562\tLabel_Loss: 0.7940\tTop_Loss: 0.9277\tBottom_Loss: 1.0135\tLoss: 2.7352\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7488\tTop_Loss: 0.7248\tBottom_Loss: 0.6790\tLoss: 2.1526\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8468\tTop_Loss: 0.9088\tBottom_Loss: 0.6813\tLoss: 2.4369\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.406\tLabel_Loss: 1.0352\tTop_Loss: 0.9084\tBottom_Loss: 1.0193\tLoss: 2.9629\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.531\tLabel_Loss: 0.9940\tTop_Loss: 0.9559\tBottom_Loss: 1.0516\tLoss: 3.0016\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7352\tTop_Loss: 0.7451\tBottom_Loss: 0.8395\tLoss: 2.3198\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.594\tLabel_Loss: 0.7900\tTop_Loss: 0.7972\tBottom_Loss: 0.7141\tLoss: 2.3013\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5846\tTop_Loss: 0.7154\tBottom_Loss: 0.7201\tLoss: 2.0202\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.656\tLabel_Loss: 0.8732\tTop_Loss: 0.9558\tBottom_Loss: 0.8922\tLoss: 2.7213\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7220\tTop_Loss: 0.8280\tBottom_Loss: 0.9095\tLoss: 2.4594\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5585\tTop_Loss: 0.7863\tBottom_Loss: 0.5963\tLoss: 1.9411\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5811\tTop_Loss: 0.6442\tBottom_Loss: 0.7678\tLoss: 1.9931\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5923\tTop_Loss: 0.5830\tBottom_Loss: 0.6016\tLoss: 1.7769\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.719\tLabel_Loss: 0.7045\tTop_Loss: 0.7605\tBottom_Loss: 0.7991\tLoss: 2.2641\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5661\tTop_Loss: 0.8319\tBottom_Loss: 0.5689\tLoss: 1.9670\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.656\tLabel_Loss: 0.6783\tTop_Loss: 0.6836\tBottom_Loss: 0.6944\tLoss: 2.0563\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4896\tTop_Loss: 0.6723\tBottom_Loss: 0.5356\tLoss: 1.6975\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.656\tLabel_Loss: 0.6739\tTop_Loss: 0.8134\tBottom_Loss: 0.7053\tLoss: 2.1925\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.656\tLabel_Loss: 0.5902\tTop_Loss: 0.7211\tBottom_Loss: 0.6190\tLoss: 1.9304\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5759\tTop_Loss: 0.8273\tBottom_Loss: 0.6334\tLoss: 2.0365\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4595\tTop_Loss: 0.7622\tBottom_Loss: 0.5021\tLoss: 1.7238\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6786\tTop_Loss: 0.8098\tBottom_Loss: 0.8469\tLoss: 2.3353\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.750\tLabel_Loss: 0.4992\tTop_Loss: 0.6230\tBottom_Loss: 0.6237\tLoss: 1.7459\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.719\tLabel_Loss: 0.5836\tTop_Loss: 0.6843\tBottom_Loss: 0.6439\tLoss: 1.9118\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3684\tTop_Loss: 0.4973\tBottom_Loss: 0.4179\tLoss: 1.2835\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5183\tTop_Loss: 0.5232\tBottom_Loss: 0.5519\tLoss: 1.5935\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5079\tTop_Loss: 0.5511\tBottom_Loss: 0.5648\tLoss: 1.6238\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6024\tTop_Loss: 0.7552\tBottom_Loss: 0.6824\tLoss: 2.0400\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5423\tTop_Loss: 0.6467\tBottom_Loss: 0.6797\tLoss: 1.8687\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7016\tTop_Loss: 0.8592\tBottom_Loss: 0.6359\tLoss: 2.1967\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4087\tTop_Loss: 0.6189\tBottom_Loss: 0.4075\tLoss: 1.4351\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5249\tTop_Loss: 0.6217\tBottom_Loss: 0.6812\tLoss: 1.8278\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4694\tTop_Loss: 0.6098\tBottom_Loss: 0.5345\tLoss: 1.6137\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.719\tLabel_Loss: 0.5900\tTop_Loss: 0.6611\tBottom_Loss: 0.7129\tLoss: 1.9640\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3865\tTop_Loss: 0.6212\tBottom_Loss: 0.5082\tLoss: 1.5159\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3306\tTop_Loss: 0.4577\tBottom_Loss: 0.4412\tLoss: 1.2295\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3364\tTop_Loss: 0.4160\tBottom_Loss: 0.3219\tLoss: 1.0743\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.781\tLabel_Loss: 0.6087\tTop_Loss: 0.6844\tBottom_Loss: 0.4639\tLoss: 1.7570\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3984\tTop_Loss: 0.6501\tBottom_Loss: 0.6351\tLoss: 1.6837\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4431\tTop_Loss: 0.6110\tBottom_Loss: 0.4437\tLoss: 1.4977\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.938\tLabel_Loss: 0.3170\tTop_Loss: 0.4709\tBottom_Loss: 0.4448\tLoss: 1.2326\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.781\tLabel_Loss: 0.3751\tTop_Loss: 0.5349\tBottom_Loss: 0.4371\tLoss: 1.3471\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3304\tTop_Loss: 0.5612\tBottom_Loss: 0.4142\tLoss: 1.3059\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.875\tLabel_Loss: 0.5500\tTop_Loss: 0.6724\tBottom_Loss: 0.6721\tLoss: 1.8945\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4901\tTop_Loss: 0.7232\tBottom_Loss: 0.5019\tLoss: 1.7152\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3352\tTop_Loss: 0.5786\tBottom_Loss: 0.4542\tLoss: 1.3679\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2449\tTop_Loss: 0.4447\tBottom_Loss: 0.4313\tLoss: 1.1209\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6634\tTop_Loss: 0.5890\tBottom_Loss: 0.5830\tLoss: 1.8354\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2261\tTop_Loss: 0.3835\tBottom_Loss: 0.3484\tLoss: 0.9580\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3836\tTop_Loss: 0.6000\tBottom_Loss: 0.4292\tLoss: 1.4128\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3723\tTop_Loss: 0.4167\tBottom_Loss: 0.4750\tLoss: 1.2640\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2004\tTop_Loss: 0.4604\tBottom_Loss: 0.2343\tLoss: 0.8951\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2613\tTop_Loss: 0.5375\tBottom_Loss: 0.5087\tLoss: 1.3075\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.750\tLabel_Loss: 0.4144\tTop_Loss: 0.6290\tBottom_Loss: 0.5018\tLoss: 1.5452\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.938\tLabel_Loss: 0.3059\tTop_Loss: 0.3810\tBottom_Loss: 0.3373\tLoss: 1.0242\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3723\tTop_Loss: 0.5875\tBottom_Loss: 0.5181\tLoss: 1.4779\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2459\tTop_Loss: 0.4314\tBottom_Loss: 0.3144\tLoss: 0.9917\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2363\tTop_Loss: 0.5497\tBottom_Loss: 0.3082\tLoss: 1.0942\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3325\tTop_Loss: 0.5106\tBottom_Loss: 0.4102\tLoss: 1.2533\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1505\tTop_Loss: 0.3513\tBottom_Loss: 0.2292\tLoss: 0.7310\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1943\tTop_Loss: 0.4031\tBottom_Loss: 0.2421\tLoss: 0.8395\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1204\tTop_Loss: 0.3775\tBottom_Loss: 0.2522\tLoss: 0.7501\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2095\tTop_Loss: 0.3833\tBottom_Loss: 0.3134\tLoss: 0.9062\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.938\tLabel_Loss: 0.3106\tTop_Loss: 0.4368\tBottom_Loss: 0.4207\tLoss: 1.1681\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1607\tTop_Loss: 0.4230\tBottom_Loss: 0.2111\tLoss: 0.7948\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2438\tTop_Loss: 0.4422\tBottom_Loss: 0.2360\tLoss: 0.9220\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1535\tTop_Loss: 0.3441\tBottom_Loss: 0.2114\tLoss: 0.7090\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2535\tTop_Loss: 0.5379\tBottom_Loss: 0.3258\tLoss: 1.1172\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1614\tTop_Loss: 0.2418\tBottom_Loss: 0.4013\tLoss: 0.8045\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2247\tTop_Loss: 0.4286\tBottom_Loss: 0.4119\tLoss: 1.0652\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1922\tTop_Loss: 0.3162\tBottom_Loss: 0.3689\tLoss: 0.8773\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2996\tTop_Loss: 0.4027\tBottom_Loss: 0.3408\tLoss: 1.0430\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1927\tTop_Loss: 0.3216\tBottom_Loss: 0.3188\tLoss: 0.8331\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1251\tTop_Loss: 0.4327\tBottom_Loss: 0.2988\tLoss: 0.8566\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1557\tTop_Loss: 0.3081\tBottom_Loss: 0.1990\tLoss: 0.6628\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1470\tTop_Loss: 0.2445\tBottom_Loss: 0.2012\tLoss: 0.5928\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2187\tTop_Loss: 0.4544\tBottom_Loss: 0.2401\tLoss: 0.9131\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1589\tTop_Loss: 0.3000\tBottom_Loss: 0.3202\tLoss: 0.7791\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1302\tTop_Loss: 0.2812\tBottom_Loss: 0.2086\tLoss: 0.6201\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2267\tTop_Loss: 0.4539\tBottom_Loss: 0.3742\tLoss: 1.0548\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1627\tTop_Loss: 0.3882\tBottom_Loss: 0.1817\tLoss: 0.7325\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1734\tTop_Loss: 0.3071\tBottom_Loss: 0.1583\tLoss: 0.6387\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0853\tTop_Loss: 0.2442\tBottom_Loss: 0.1089\tLoss: 0.4384\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0785\tTop_Loss: 0.2399\tBottom_Loss: 0.1417\tLoss: 0.4601\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1327\tTop_Loss: 0.4737\tBottom_Loss: 0.1591\tLoss: 0.7655\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1107\tTop_Loss: 0.3309\tBottom_Loss: 0.2273\tLoss: 0.6689\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1268\tTop_Loss: 0.2755\tBottom_Loss: 0.2233\tLoss: 0.6256\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0950\tTop_Loss: 0.3432\tBottom_Loss: 0.1748\tLoss: 0.6131\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1497\tTop_Loss: 0.3473\tBottom_Loss: 0.1488\tLoss: 0.6458\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1251\tTop_Loss: 0.2846\tBottom_Loss: 0.1265\tLoss: 0.5361\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0674\tTop_Loss: 0.1983\tBottom_Loss: 0.1185\tLoss: 0.3843\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1160\tTop_Loss: 0.2398\tBottom_Loss: 0.1842\tLoss: 0.5400\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0700\tTop_Loss: 0.1894\tBottom_Loss: 0.1368\tLoss: 0.3962\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0812\tTop_Loss: 0.2426\tBottom_Loss: 0.1112\tLoss: 0.4350\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1053\tTop_Loss: 0.2654\tBottom_Loss: 0.2422\tLoss: 0.6129\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1286\tTop_Loss: 0.2871\tBottom_Loss: 0.1825\tLoss: 0.5981\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0748\tTop_Loss: 0.2206\tBottom_Loss: 0.1919\tLoss: 0.4873\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0958\tTop_Loss: 0.1532\tBottom_Loss: 0.1983\tLoss: 0.4473\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0876\tTop_Loss: 0.2913\tBottom_Loss: 0.1032\tLoss: 0.4821\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0714\tTop_Loss: 0.1960\tBottom_Loss: 0.1362\tLoss: 0.4036\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1298\tTop_Loss: 0.2555\tBottom_Loss: 0.1429\tLoss: 0.5282\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1132\tTop_Loss: 0.2406\tBottom_Loss: 0.1879\tLoss: 0.5417\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0997\tTop_Loss: 0.2969\tBottom_Loss: 0.1860\tLoss: 0.5826\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2048\tTop_Loss: 0.2223\tBottom_Loss: 0.3016\tLoss: 0.7287\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0720\tTop_Loss: 0.1531\tBottom_Loss: 0.1156\tLoss: 0.3406\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0761\tTop_Loss: 0.2193\tBottom_Loss: 0.1026\tLoss: 0.3979\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1052\tTop_Loss: 0.2305\tBottom_Loss: 0.1575\tLoss: 0.4932\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1187\tTop_Loss: 0.2445\tBottom_Loss: 0.1578\tLoss: 0.5211\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1027\tTop_Loss: 0.1950\tBottom_Loss: 0.2071\tLoss: 0.5049\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0411\tTop_Loss: 0.1745\tBottom_Loss: 0.0875\tLoss: 0.3031\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1415\tTop_Loss: 0.2626\tBottom_Loss: 0.1244\tLoss: 0.5284\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0633\tTop_Loss: 0.1469\tBottom_Loss: 0.1277\tLoss: 0.3378\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0712\tTop_Loss: 0.1821\tBottom_Loss: 0.1039\tLoss: 0.3571\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0415\tTop_Loss: 0.1538\tBottom_Loss: 0.0777\tLoss: 0.2730\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0513\tTop_Loss: 0.1934\tBottom_Loss: 0.1342\tLoss: 0.3788\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0597\tTop_Loss: 0.2082\tBottom_Loss: 0.1111\tLoss: 0.3791\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0472\tTop_Loss: 0.1646\tBottom_Loss: 0.1181\tLoss: 0.3299\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0757\tTop_Loss: 0.1833\tBottom_Loss: 0.1061\tLoss: 0.3650\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0551\tTop_Loss: 0.2937\tBottom_Loss: 0.0647\tLoss: 0.4135\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0511\tTop_Loss: 0.1560\tBottom_Loss: 0.0962\tLoss: 0.3032\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0717\tTop_Loss: 0.1517\tBottom_Loss: 0.0739\tLoss: 0.2973\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0683\tTop_Loss: 0.1930\tBottom_Loss: 0.1910\tLoss: 0.4522\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1098\tTop_Loss: 0.3483\tBottom_Loss: 0.1453\tLoss: 0.6034\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0223\tTop_Loss: 0.0834\tBottom_Loss: 0.0861\tLoss: 0.1918\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0981\tTop_Loss: 0.2993\tBottom_Loss: 0.1488\tLoss: 0.5463\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0540\tTop_Loss: 0.1789\tBottom_Loss: 0.1171\tLoss: 0.3500\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0403\tTop_Loss: 0.1389\tBottom_Loss: 0.1082\tLoss: 0.2874\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0230\tTop_Loss: 0.1094\tBottom_Loss: 0.0677\tLoss: 0.2001\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0335\tTop_Loss: 0.1215\tBottom_Loss: 0.0819\tLoss: 0.2369\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0174\tTop_Loss: 0.0540\tBottom_Loss: 0.0462\tLoss: 0.1176\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0215\tTop_Loss: 0.0890\tBottom_Loss: 0.0574\tLoss: 0.1679\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0380\tTop_Loss: 0.1372\tBottom_Loss: 0.0611\tLoss: 0.2363\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0507\tTop_Loss: 0.1708\tBottom_Loss: 0.0752\tLoss: 0.2967\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0351\tTop_Loss: 0.2294\tBottom_Loss: 0.0702\tLoss: 0.3347\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0473\tTop_Loss: 0.1707\tBottom_Loss: 0.0667\tLoss: 0.2847\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1185\tTop_Loss: 0.2297\tBottom_Loss: 0.1506\tLoss: 0.4988\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0175\tTop_Loss: 0.0971\tBottom_Loss: 0.0347\tLoss: 0.1493\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0096\tTop_Loss: 0.0631\tBottom_Loss: 0.0502\tLoss: 0.1229\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0577\tTop_Loss: 0.1061\tBottom_Loss: 0.1192\tLoss: 0.2830\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0643\tTop_Loss: 0.1642\tBottom_Loss: 0.0788\tLoss: 0.3072\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0311\tTop_Loss: 0.0898\tBottom_Loss: 0.0339\tLoss: 0.1548\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1083\tTop_Loss: 0.1607\tBottom_Loss: 0.1264\tLoss: 0.3954\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0310\tTop_Loss: 0.1873\tBottom_Loss: 0.0586\tLoss: 0.2769\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0434\tTop_Loss: 0.1245\tBottom_Loss: 0.0943\tLoss: 0.2622\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0196\tTop_Loss: 0.0809\tBottom_Loss: 0.0620\tLoss: 0.1625\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1107\tTop_Loss: 0.1555\tBottom_Loss: 0.1770\tLoss: 0.4432\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0165\tTop_Loss: 0.0520\tBottom_Loss: 0.0408\tLoss: 0.1093\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0198\tTop_Loss: 0.1324\tBottom_Loss: 0.0504\tLoss: 0.2026\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0184\tTop_Loss: 0.0977\tBottom_Loss: 0.0440\tLoss: 0.1602\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0362\tTop_Loss: 0.1580\tBottom_Loss: 0.1058\tLoss: 0.3001\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0217\tTop_Loss: 0.0914\tBottom_Loss: 0.0856\tLoss: 0.1987\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0768\tTop_Loss: 0.1510\tBottom_Loss: 0.0856\tLoss: 0.3133\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0077\tTop_Loss: 0.0471\tBottom_Loss: 0.0246\tLoss: 0.0793\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0414\tTop_Loss: 0.1419\tBottom_Loss: 0.0832\tLoss: 0.2664\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0183\tTop_Loss: 0.0675\tBottom_Loss: 0.0486\tLoss: 0.1344\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0169\tTop_Loss: 0.0784\tBottom_Loss: 0.0631\tLoss: 0.1584\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0361\tTop_Loss: 0.1346\tBottom_Loss: 0.0229\tLoss: 0.1936\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0185\tTop_Loss: 0.0666\tBottom_Loss: 0.0644\tLoss: 0.1495\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1990\tTop_Loss: 0.1641\tBottom_Loss: 0.2157\tLoss: 0.5788\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0075\tTop_Loss: 0.0662\tBottom_Loss: 0.0291\tLoss: 0.1028\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[85][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0608\tTop_Loss: 0.0524\tBottom_Loss: 0.0998\tLoss: 0.2130\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0885\tTop_Loss: 0.1451\tBottom_Loss: 0.1760\tLoss: 0.4096\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0202\tTop_Loss: 0.0807\tBottom_Loss: 0.0301\tLoss: 0.1310\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0140\tTop_Loss: 0.0513\tBottom_Loss: 0.0336\tLoss: 0.0989\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0130\tTop_Loss: 0.0767\tBottom_Loss: 0.0302\tLoss: 0.1199\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0247\tTop_Loss: 0.1533\tBottom_Loss: 0.0374\tLoss: 0.2154\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0168\tTop_Loss: 0.0609\tBottom_Loss: 0.0361\tLoss: 0.1138\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0151\tTop_Loss: 0.1217\tBottom_Loss: 0.0315\tLoss: 0.1683\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0097\tTop_Loss: 0.0604\tBottom_Loss: 0.0498\tLoss: 0.1199\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0130\tTop_Loss: 0.1012\tBottom_Loss: 0.0197\tLoss: 0.1339\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0152\tTop_Loss: 0.0621\tBottom_Loss: 0.0246\tLoss: 0.1019\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0236\tTop_Loss: 0.1257\tBottom_Loss: 0.0267\tLoss: 0.1761\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0210\tTop_Loss: 0.0824\tBottom_Loss: 0.0420\tLoss: 0.1455\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0155\tTop_Loss: 0.0706\tBottom_Loss: 0.0336\tLoss: 0.1197\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0389\tTop_Loss: 0.0552\tBottom_Loss: 0.1058\tLoss: 0.1999\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0147\tTop_Loss: 0.1105\tBottom_Loss: 0.0161\tLoss: 0.1413\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0375\tTop_Loss: 0.1245\tBottom_Loss: 0.0567\tLoss: 0.2186\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0063\tTop_Loss: 0.0301\tBottom_Loss: 0.0226\tLoss: 0.0591\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0073\tTop_Loss: 0.0776\tBottom_Loss: 0.0190\tLoss: 0.1038\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0214\tTop_Loss: 0.0343\tBottom_Loss: 0.0447\tLoss: 0.1004\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0210\tTop_Loss: 0.0354\tBottom_Loss: 0.0496\tLoss: 0.1060\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0229\tTop_Loss: 0.0516\tBottom_Loss: 0.0494\tLoss: 0.1238\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0053\tTop_Loss: 0.0382\tBottom_Loss: 0.0175\tLoss: 0.0610\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0053\tTop_Loss: 0.0287\tBottom_Loss: 0.0169\tLoss: 0.0508\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0281\tTop_Loss: 0.0721\tBottom_Loss: 0.0547\tLoss: 0.1549\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0035\tTop_Loss: 0.0226\tBottom_Loss: 0.0102\tLoss: 0.0363\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0134\tTop_Loss: 0.0465\tBottom_Loss: 0.0619\tLoss: 0.1218\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0177\tTop_Loss: 0.0516\tBottom_Loss: 0.0250\tLoss: 0.0942\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0389\tTop_Loss: 0.0394\tBottom_Loss: 0.0403\tLoss: 0.1186\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0055\tTop_Loss: 0.0378\tBottom_Loss: 0.0186\tLoss: 0.0619\t\n",
      "Subject: 019, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.500\tLabel_Loss: 1.1520\tTop_Loss: 1.4812\tBottom_Loss: 1.2901\tLoss: 3.9233\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.625\tLabel_Loss: 0.9664\tTop_Loss: 0.7748\tBottom_Loss: 1.1078\tLoss: 2.8491\t\n",
      "Subject: 02, n=09 | test_f1: 0.50909 |best_f1: 0.50909\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.438\tLabel_Loss: 1.0412\tTop_Loss: 1.1997\tBottom_Loss: 1.2181\tLoss: 3.4590\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8948\tTop_Loss: 1.1133\tBottom_Loss: 0.8549\tLoss: 2.8630\t\n",
      "Subject: 02, n=09 | test_f1: 0.20513 |best_f1: 0.50909\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.594\tLabel_Loss: 1.0324\tTop_Loss: 0.9554\tBottom_Loss: 1.1031\tLoss: 3.0908\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.531\tLabel_Loss: 1.0158\tTop_Loss: 0.9680\tBottom_Loss: 1.0096\tLoss: 2.9933\t\n",
      "Subject: 02, n=09 | test_f1: 0.22222 |best_f1: 0.50909\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.656\tLabel_Loss: 0.8589\tTop_Loss: 1.1718\tBottom_Loss: 0.9416\tLoss: 2.9724\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.594\tLabel_Loss: 0.7997\tTop_Loss: 0.8270\tBottom_Loss: 0.8050\tLoss: 2.4318\t\n",
      "Subject: 02, n=09 | test_f1: 0.16667 |best_f1: 0.50909\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.562\tLabel_Loss: 1.0085\tTop_Loss: 0.7772\tBottom_Loss: 1.0881\tLoss: 2.8738\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.562\tLabel_Loss: 0.9567\tTop_Loss: 0.9345\tBottom_Loss: 0.8151\tLoss: 2.7064\t\n",
      "Subject: 02, n=09 | test_f1: 0.37576 |best_f1: 0.50909\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.562\tLabel_Loss: 1.0095\tTop_Loss: 0.8137\tBottom_Loss: 1.0346\tLoss: 2.8579\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.531\tLabel_Loss: 0.7953\tTop_Loss: 0.8257\tBottom_Loss: 0.7841\tLoss: 2.4051\t\n",
      "Subject: 02, n=09 | test_f1: 0.2381 |best_f1: 0.50909\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.500\tLabel_Loss: 0.8899\tTop_Loss: 0.8086\tBottom_Loss: 0.9934\tLoss: 2.6919\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.656\tLabel_Loss: 0.8140\tTop_Loss: 0.8356\tBottom_Loss: 0.9461\tLoss: 2.5957\t\n",
      "Subject: 02, n=09 | test_f1: 0.12121 |best_f1: 0.50909\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7855\tTop_Loss: 0.8977\tBottom_Loss: 0.8289\tLoss: 2.5121\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6744\tTop_Loss: 0.8236\tBottom_Loss: 0.6586\tLoss: 2.1566\t\n",
      "Subject: 02, n=09 | test_f1: 0.18182 |best_f1: 0.50909\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6481\tTop_Loss: 0.5940\tBottom_Loss: 0.7897\tLoss: 2.0318\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.594\tLabel_Loss: 0.9592\tTop_Loss: 0.8772\tBottom_Loss: 1.0479\tLoss: 2.8842\t\n",
      "Subject: 02, n=09 | test_f1: 0.3 |best_f1: 0.50909\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5846\tTop_Loss: 0.6704\tBottom_Loss: 0.7249\tLoss: 1.9800\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6554\tTop_Loss: 0.7741\tBottom_Loss: 0.8746\tLoss: 2.3042\t\n",
      "Subject: 02, n=09 | test_f1: 0.14815 |best_f1: 0.50909\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.844\tLabel_Loss: 0.5825\tTop_Loss: 0.6509\tBottom_Loss: 0.7568\tLoss: 1.9902\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7642\tTop_Loss: 0.6660\tBottom_Loss: 0.9259\tLoss: 2.3561\t\n",
      "Subject: 02, n=09 | test_f1: 0.3 |best_f1: 0.50909\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.625\tLabel_Loss: 0.6724\tTop_Loss: 0.8232\tBottom_Loss: 0.8043\tLoss: 2.2999\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5346\tTop_Loss: 0.5601\tBottom_Loss: 0.4890\tLoss: 1.5837\t\n",
      "Subject: 02, n=09 | test_f1: 0.11111 |best_f1: 0.50909\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4501\tTop_Loss: 0.5710\tBottom_Loss: 0.6645\tLoss: 1.6855\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.656\tLabel_Loss: 0.6452\tTop_Loss: 0.8739\tBottom_Loss: 0.7170\tLoss: 2.2361\t\n",
      "Subject: 02, n=09 | test_f1: 0.35556 |best_f1: 0.50909\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5986\tTop_Loss: 0.7553\tBottom_Loss: 0.6939\tLoss: 2.0478\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.719\tLabel_Loss: 0.7032\tTop_Loss: 0.7161\tBottom_Loss: 0.8394\tLoss: 2.2587\t\n",
      "Subject: 02, n=09 | test_f1: 0.22857 |best_f1: 0.50909\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6895\tTop_Loss: 0.6905\tBottom_Loss: 0.7069\tLoss: 2.0869\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.594\tLabel_Loss: 0.7085\tTop_Loss: 0.7719\tBottom_Loss: 0.7324\tLoss: 2.2127\t\n",
      "Subject: 02, n=09 | test_f1: 0.4 |best_f1: 0.50909\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.875\tLabel_Loss: 0.5170\tTop_Loss: 0.6566\tBottom_Loss: 0.6594\tLoss: 1.8329\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6108\tTop_Loss: 0.6793\tBottom_Loss: 0.7282\tLoss: 2.0183\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 02, n=09 | test_f1: 0.12121 |best_f1: 0.50909\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3707\tTop_Loss: 0.4906\tBottom_Loss: 0.5825\tLoss: 1.4437\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5474\tTop_Loss: 0.6991\tBottom_Loss: 0.5754\tLoss: 1.8218\t\n",
      "Subject: 02, n=09 | test_f1: 0.25 |best_f1: 0.50909\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.938\tLabel_Loss: 0.3477\tTop_Loss: 0.5041\tBottom_Loss: 0.5949\tLoss: 1.4468\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.656\tLabel_Loss: 0.6177\tTop_Loss: 0.6793\tBottom_Loss: 0.6915\tLoss: 1.9884\t\n",
      "Subject: 02, n=09 | test_f1: 0.16667 |best_f1: 0.50909\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2955\tTop_Loss: 0.3721\tBottom_Loss: 0.5222\tLoss: 1.1899\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3666\tTop_Loss: 0.4601\tBottom_Loss: 0.3995\tLoss: 1.2262\t\n",
      "Subject: 02, n=09 | test_f1: 0.18182 |best_f1: 0.50909\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3545\tTop_Loss: 0.4657\tBottom_Loss: 0.5312\tLoss: 1.3514\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5651\tTop_Loss: 0.4521\tBottom_Loss: 0.7044\tLoss: 1.7217\t\n",
      "Subject: 02, n=09 | test_f1: 0.074074 |best_f1: 0.50909\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6216\tTop_Loss: 0.7161\tBottom_Loss: 0.5594\tLoss: 1.8972\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.781\tLabel_Loss: 0.6744\tTop_Loss: 0.6744\tBottom_Loss: 0.9420\tLoss: 2.2908\t\n",
      "Subject: 02, n=09 | test_f1: 0.44444 |best_f1: 0.50909\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4291\tTop_Loss: 0.4534\tBottom_Loss: 0.5794\tLoss: 1.4620\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4964\tTop_Loss: 0.5319\tBottom_Loss: 0.5672\tLoss: 1.5955\t\n",
      "Subject: 02, n=09 | test_f1: 0.13333 |best_f1: 0.50909\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3469\tTop_Loss: 0.5398\tBottom_Loss: 0.5301\tLoss: 1.4168\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3687\tTop_Loss: 0.4755\tBottom_Loss: 0.4383\tLoss: 1.2824\t\n",
      "Subject: 02, n=09 | test_f1: 0.21667 |best_f1: 0.50909\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3873\tTop_Loss: 0.5497\tBottom_Loss: 0.4047\tLoss: 1.3417\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.906\tLabel_Loss: 0.4158\tTop_Loss: 0.4978\tBottom_Loss: 0.3942\tLoss: 1.3078\t\n",
      "Subject: 02, n=09 | test_f1: 0.27778 |best_f1: 0.50909\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.719\tLabel_Loss: 0.7048\tTop_Loss: 0.7502\tBottom_Loss: 0.6006\tLoss: 2.0556\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.625\tLabel_Loss: 0.6804\tTop_Loss: 0.8472\tBottom_Loss: 0.8863\tLoss: 2.4138\t\n",
      "Subject: 02, n=09 | test_f1: 0.35556 |best_f1: 0.50909\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2332\tTop_Loss: 0.3524\tBottom_Loss: 0.3310\tLoss: 0.9166\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3519\tTop_Loss: 0.5072\tBottom_Loss: 0.3936\tLoss: 1.2527\t\n",
      "Subject: 02, n=09 | test_f1: 0.32381 |best_f1: 0.50909\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3655\tTop_Loss: 0.4052\tBottom_Loss: 0.5123\tLoss: 1.2830\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3045\tTop_Loss: 0.6038\tBottom_Loss: 0.3851\tLoss: 1.2934\t\n",
      "Subject: 02, n=09 | test_f1: 0.21667 |best_f1: 0.50909\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2575\tTop_Loss: 0.5349\tBottom_Loss: 0.3243\tLoss: 1.1167\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3991\tTop_Loss: 0.6709\tBottom_Loss: 0.4159\tLoss: 1.4858\t\n",
      "Subject: 02, n=09 | test_f1: 0.21667 |best_f1: 0.50909\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2444\tTop_Loss: 0.4379\tBottom_Loss: 0.3397\tLoss: 1.0220\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4481\tTop_Loss: 0.4001\tBottom_Loss: 0.5729\tLoss: 1.4211\t\n",
      "Subject: 02, n=09 | test_f1: 0.28148 |best_f1: 0.50909\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5501\tTop_Loss: 0.8197\tBottom_Loss: 0.7526\tLoss: 2.1224\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4709\tTop_Loss: 0.5586\tBottom_Loss: 0.6385\tLoss: 1.6680\t\n",
      "Subject: 02, n=09 | test_f1: 0.16667 |best_f1: 0.50909\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3653\tTop_Loss: 0.3619\tBottom_Loss: 0.5243\tLoss: 1.2515\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2248\tTop_Loss: 0.4486\tBottom_Loss: 0.5556\tLoss: 1.2290\t\n",
      "Subject: 02, n=09 | test_f1: 0.13333 |best_f1: 0.50909\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1916\tTop_Loss: 0.3749\tBottom_Loss: 0.2841\tLoss: 0.8507\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2817\tTop_Loss: 0.4239\tBottom_Loss: 0.4804\tLoss: 1.1860\t\n",
      "Subject: 02, n=09 | test_f1: 0.22857 |best_f1: 0.50909\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.844\tLabel_Loss: 0.2720\tTop_Loss: 0.4148\tBottom_Loss: 0.3164\tLoss: 1.0032\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1870\tTop_Loss: 0.2734\tBottom_Loss: 0.2558\tLoss: 0.7162\t\n",
      "Subject: 02, n=09 | test_f1: 0.3 |best_f1: 0.50909\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2656\tTop_Loss: 0.3795\tBottom_Loss: 0.3350\tLoss: 0.9801\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3158\tTop_Loss: 0.4228\tBottom_Loss: 0.3877\tLoss: 1.1262\t\n",
      "Subject: 02, n=09 | test_f1: 0.22222 |best_f1: 0.50909\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3766\tTop_Loss: 0.5758\tBottom_Loss: 0.3389\tLoss: 1.2912\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1701\tTop_Loss: 0.4407\tBottom_Loss: 0.3311\tLoss: 0.9418\t\n",
      "Subject: 02, n=09 | test_f1: 0.3 |best_f1: 0.50909\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2818\tTop_Loss: 0.3689\tBottom_Loss: 0.4074\tLoss: 1.0581\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2945\tTop_Loss: 0.4189\tBottom_Loss: 0.4492\tLoss: 1.1625\t\n",
      "Subject: 02, n=09 | test_f1: 0.20513 |best_f1: 0.50909\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.750\tLabel_Loss: 0.4763\tTop_Loss: 0.5186\tBottom_Loss: 0.7363\tLoss: 1.7312\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1665\tTop_Loss: 0.3662\tBottom_Loss: 0.2584\tLoss: 0.7911\t\n",
      "Subject: 02, n=09 | test_f1: 0.36667 |best_f1: 0.50909\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2359\tTop_Loss: 0.2645\tBottom_Loss: 0.3017\tLoss: 0.8021\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1570\tTop_Loss: 0.2829\tBottom_Loss: 0.3314\tLoss: 0.7713\t\n",
      "Subject: 02, n=09 | test_f1: 0.22222 |best_f1: 0.50909\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3151\tTop_Loss: 0.4283\tBottom_Loss: 0.4356\tLoss: 1.1790\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3720\tTop_Loss: 0.5864\tBottom_Loss: 0.3628\tLoss: 1.3213\t\n",
      "Subject: 02, n=09 | test_f1: 0.38889 |best_f1: 0.50909\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2175\tTop_Loss: 0.3225\tBottom_Loss: 0.3758\tLoss: 0.9157\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2469\tTop_Loss: 0.3637\tBottom_Loss: 0.2998\tLoss: 0.9104\t\n",
      "Subject: 02, n=09 | test_f1: 0.41481 |best_f1: 0.50909\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1538\tTop_Loss: 0.2778\tBottom_Loss: 0.2853\tLoss: 0.7170\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2965\tTop_Loss: 0.4840\tBottom_Loss: 0.4525\tLoss: 1.2329\t\n",
      "Subject: 02, n=09 | test_f1: 0.28148 |best_f1: 0.50909\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2757\tTop_Loss: 0.3614\tBottom_Loss: 0.3520\tLoss: 0.9891\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1981\tTop_Loss: 0.4161\tBottom_Loss: 0.3987\tLoss: 1.0129\t\n",
      "Subject: 02, n=09 | test_f1: 0.52525 |best_f1: 0.52525\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2017\tTop_Loss: 0.3375\tBottom_Loss: 0.2270\tLoss: 0.7662\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1286\tTop_Loss: 0.2826\tBottom_Loss: 0.3470\tLoss: 0.7582\t\n",
      "Subject: 02, n=09 | test_f1: 0.31746 |best_f1: 0.52525\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1774\tTop_Loss: 0.2075\tBottom_Loss: 0.4218\tLoss: 0.8067\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2868\tTop_Loss: 0.3315\tBottom_Loss: 0.4031\tLoss: 1.0214\t\n",
      "Subject: 02, n=09 | test_f1: 0.33333 |best_f1: 0.52525\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1756\tTop_Loss: 0.3586\tBottom_Loss: 0.2150\tLoss: 0.7492\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0993\tTop_Loss: 0.2270\tBottom_Loss: 0.2456\tLoss: 0.5720\t\n",
      "Subject: 02, n=09 | test_f1: 0.4127 |best_f1: 0.52525\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1376\tTop_Loss: 0.2480\tBottom_Loss: 0.1880\tLoss: 0.5736\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1985\tTop_Loss: 0.2578\tBottom_Loss: 0.2475\tLoss: 0.7039\t\n",
      "Subject: 02, n=09 | test_f1: 0.3 |best_f1: 0.52525\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0995\tTop_Loss: 0.2899\tBottom_Loss: 0.1948\tLoss: 0.5843\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1469\tTop_Loss: 0.3362\tBottom_Loss: 0.1771\tLoss: 0.6602\t\n",
      "Subject: 02, n=09 | test_f1: 0.37576 |best_f1: 0.52525\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1192\tTop_Loss: 0.2385\tBottom_Loss: 0.2416\tLoss: 0.5994\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0973\tTop_Loss: 0.2516\tBottom_Loss: 0.1977\tLoss: 0.5466\t\n",
      "Subject: 02, n=09 | test_f1: 0.16667 |best_f1: 0.52525\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0897\tTop_Loss: 0.1413\tBottom_Loss: 0.2118\tLoss: 0.4428\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0791\tTop_Loss: 0.2914\tBottom_Loss: 0.1236\tLoss: 0.4940\t\n",
      "Subject: 02, n=09 | test_f1: 0.35556 |best_f1: 0.52525\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0844\tTop_Loss: 0.2503\tBottom_Loss: 0.1774\tLoss: 0.5120\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1323\tTop_Loss: 0.3900\tBottom_Loss: 0.2131\tLoss: 0.7354\t\n",
      "Subject: 02, n=09 | test_f1: 0.3 |best_f1: 0.52525\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1206\tTop_Loss: 0.2195\tBottom_Loss: 0.1803\tLoss: 0.5204\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0577\tTop_Loss: 0.2055\tBottom_Loss: 0.1014\tLoss: 0.3646\t\n",
      "Subject: 02, n=09 | test_f1: 0.18182 |best_f1: 0.52525\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0695\tTop_Loss: 0.2363\tBottom_Loss: 0.1086\tLoss: 0.4143\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0947\tTop_Loss: 0.1816\tBottom_Loss: 0.2398\tLoss: 0.5160\t\n",
      "Subject: 02, n=09 | test_f1: 0.52222 |best_f1: 0.52525\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1286\tTop_Loss: 0.2122\tBottom_Loss: 0.1362\tLoss: 0.4770\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1369\tTop_Loss: 0.2837\tBottom_Loss: 0.1722\tLoss: 0.5928\t\n",
      "Subject: 02, n=09 | test_f1: 0.16667 |best_f1: 0.52525\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0535\tTop_Loss: 0.1051\tBottom_Loss: 0.1999\tLoss: 0.3585\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0436\tTop_Loss: 0.1426\tBottom_Loss: 0.1345\tLoss: 0.3207\t\n",
      "Subject: 02, n=09 | test_f1: 0.18182 |best_f1: 0.52525\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0683\tTop_Loss: 0.2079\tBottom_Loss: 0.1434\tLoss: 0.4196\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0928\tTop_Loss: 0.1741\tBottom_Loss: 0.2107\tLoss: 0.4775\t\n",
      "Subject: 02, n=09 | test_f1: 0.44444 |best_f1: 0.52525\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0951\tTop_Loss: 0.2264\tBottom_Loss: 0.1864\tLoss: 0.5078\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1560\tTop_Loss: 0.1513\tBottom_Loss: 0.2760\tLoss: 0.5833\t\n",
      "Subject: 02, n=09 | test_f1: 0.3 |best_f1: 0.52525\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0719\tTop_Loss: 0.2075\tBottom_Loss: 0.0826\tLoss: 0.3621\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0579\tTop_Loss: 0.1851\tBottom_Loss: 0.1396\tLoss: 0.3826\t\n",
      "Subject: 02, n=09 | test_f1: 0.4127 |best_f1: 0.52525\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0541\tTop_Loss: 0.1393\tBottom_Loss: 0.0945\tLoss: 0.2878\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1307\tTop_Loss: 0.2034\tBottom_Loss: 0.2632\tLoss: 0.5972\t\n",
      "Subject: 02, n=09 | test_f1: 0.3 |best_f1: 0.52525\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1126\tTop_Loss: 0.1664\tBottom_Loss: 0.1743\tLoss: 0.4533\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0767\tTop_Loss: 0.1963\tBottom_Loss: 0.1224\tLoss: 0.3954\t\n",
      "Subject: 02, n=09 | test_f1: 0.21667 |best_f1: 0.52525\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1579\tTop_Loss: 0.1848\tBottom_Loss: 0.2205\tLoss: 0.5632\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0846\tTop_Loss: 0.1469\tBottom_Loss: 0.1100\tLoss: 0.3415\t\n",
      "Subject: 02, n=09 | test_f1: 0.25 |best_f1: 0.52525\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1135\tTop_Loss: 0.2119\tBottom_Loss: 0.2829\tLoss: 0.6083\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0727\tTop_Loss: 0.1253\tBottom_Loss: 0.1006\tLoss: 0.2987\t\n",
      "Subject: 02, n=09 | test_f1: 0.22857 |best_f1: 0.52525\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0229\tTop_Loss: 0.1116\tBottom_Loss: 0.0716\tLoss: 0.2061\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0582\tTop_Loss: 0.1697\tBottom_Loss: 0.0943\tLoss: 0.3221\t\n",
      "Subject: 02, n=09 | test_f1: 0.33333 |best_f1: 0.52525\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0916\tTop_Loss: 0.1731\tBottom_Loss: 0.1492\tLoss: 0.4140\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0554\tTop_Loss: 0.1733\tBottom_Loss: 0.1107\tLoss: 0.3394\t\n",
      "Subject: 02, n=09 | test_f1: 0.18182 |best_f1: 0.52525\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1351\tTop_Loss: 0.2139\tBottom_Loss: 0.2281\tLoss: 0.5770\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0209\tTop_Loss: 0.0631\tBottom_Loss: 0.0829\tLoss: 0.1669\t\n",
      "Subject: 02, n=09 | test_f1: 0.22222 |best_f1: 0.52525\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0449\tTop_Loss: 0.1541\tBottom_Loss: 0.1662\tLoss: 0.3652\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0304\tTop_Loss: 0.1804\tBottom_Loss: 0.0972\tLoss: 0.3080\t\n",
      "Subject: 02, n=09 | test_f1: 0.31746 |best_f1: 0.52525\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1155\tTop_Loss: 0.1749\tBottom_Loss: 0.0881\tLoss: 0.3785\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0244\tTop_Loss: 0.0679\tBottom_Loss: 0.1057\tLoss: 0.1979\t\n",
      "Subject: 02, n=09 | test_f1: 0.33333 |best_f1: 0.52525\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0510\tTop_Loss: 0.1430\tBottom_Loss: 0.0999\tLoss: 0.2939\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0266\tTop_Loss: 0.0610\tBottom_Loss: 0.1363\tLoss: 0.2239\t\n",
      "Subject: 02, n=09 | test_f1: 0.33333 |best_f1: 0.52525\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0664\tTop_Loss: 0.1218\tBottom_Loss: 0.1282\tLoss: 0.3164\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0227\tTop_Loss: 0.1034\tBottom_Loss: 0.0688\tLoss: 0.1948\t\n",
      "Subject: 02, n=09 | test_f1: 0.28148 |best_f1: 0.52525\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0365\tTop_Loss: 0.0908\tBottom_Loss: 0.0837\tLoss: 0.2110\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0194\tTop_Loss: 0.0747\tBottom_Loss: 0.0531\tLoss: 0.1472\t\n",
      "Subject: 02, n=09 | test_f1: 0.27778 |best_f1: 0.52525\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0272\tTop_Loss: 0.0948\tBottom_Loss: 0.1064\tLoss: 0.2283\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0238\tTop_Loss: 0.1020\tBottom_Loss: 0.0894\tLoss: 0.2152\t\n",
      "Subject: 02, n=09 | test_f1: 0.13333 |best_f1: 0.52525\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0136\tTop_Loss: 0.0930\tBottom_Loss: 0.0591\tLoss: 0.1658\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0613\tTop_Loss: 0.1445\tBottom_Loss: 0.0647\tLoss: 0.2705\t\n",
      "Subject: 02, n=09 | test_f1: 0.34848 |best_f1: 0.52525\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0453\tTop_Loss: 0.1424\tBottom_Loss: 0.0919\tLoss: 0.2796\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0418\tTop_Loss: 0.0833\tBottom_Loss: 0.1426\tLoss: 0.2677\t\n",
      "Subject: 02, n=09 | test_f1: 0.35556 |best_f1: 0.52525\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0315\tTop_Loss: 0.1207\tBottom_Loss: 0.1087\tLoss: 0.2610\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0228\tTop_Loss: 0.0958\tBottom_Loss: 0.0294\tLoss: 0.1479\t\n",
      "Subject: 02, n=09 | test_f1: 0.066667 |best_f1: 0.52525\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0545\tTop_Loss: 0.0969\tBottom_Loss: 0.0906\tLoss: 0.2420\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0265\tTop_Loss: 0.0866\tBottom_Loss: 0.0590\tLoss: 0.1721\t\n",
      "Subject: 02, n=09 | test_f1: 0.48889 |best_f1: 0.52525\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0184\tTop_Loss: 0.0535\tBottom_Loss: 0.0533\tLoss: 0.1252\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0572\tTop_Loss: 0.1586\tBottom_Loss: 0.1021\tLoss: 0.3178\t\n",
      "Subject: 02, n=09 | test_f1: 0.38889 |best_f1: 0.52525\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0404\tTop_Loss: 0.1053\tBottom_Loss: 0.0798\tLoss: 0.2255\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0125\tTop_Loss: 0.0732\tBottom_Loss: 0.0398\tLoss: 0.1256\t\n",
      "Subject: 02, n=09 | test_f1: 0.33333 |best_f1: 0.52525\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0105\tTop_Loss: 0.0267\tBottom_Loss: 0.0424\tLoss: 0.0796\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0458\tTop_Loss: 0.1300\tBottom_Loss: 0.0561\tLoss: 0.2319\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 02, n=09 | test_f1: 0.41111 |best_f1: 0.52525\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0591\tTop_Loss: 0.1203\tBottom_Loss: 0.0387\tLoss: 0.2181\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0181\tTop_Loss: 0.0817\tBottom_Loss: 0.0394\tLoss: 0.1392\t\n",
      "Subject: 02, n=09 | test_f1: 0.28148 |best_f1: 0.52525\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0119\tTop_Loss: 0.0572\tBottom_Loss: 0.0570\tLoss: 0.1260\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0155\tTop_Loss: 0.0912\tBottom_Loss: 0.0305\tLoss: 0.1372\t\n",
      "Subject: 02, n=09 | test_f1: 0.41111 |best_f1: 0.52525\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0064\tTop_Loss: 0.0344\tBottom_Loss: 0.0354\tLoss: 0.0762\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0180\tTop_Loss: 0.0861\tBottom_Loss: 0.0475\tLoss: 0.1516\t\n",
      "Subject: 02, n=09 | test_f1: 0.38889 |best_f1: 0.52525\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1249\tTop_Loss: 0.2200\tBottom_Loss: 0.1133\tLoss: 0.4581\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0288\tTop_Loss: 0.0568\tBottom_Loss: 0.0732\tLoss: 0.1588\t\n",
      "Subject: 02, n=09 | test_f1: 0.51852 |best_f1: 0.52525\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0713\tTop_Loss: 0.1109\tBottom_Loss: 0.1054\tLoss: 0.2875\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0156\tTop_Loss: 0.0594\tBottom_Loss: 0.0625\tLoss: 0.1375\t\n",
      "Subject: 02, n=09 | test_f1: 0.38889 |best_f1: 0.52525\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0274\tTop_Loss: 0.1053\tBottom_Loss: 0.0297\tLoss: 0.1623\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0068\tTop_Loss: 0.0253\tBottom_Loss: 0.0348\tLoss: 0.0668\t\n",
      "Subject: 02, n=09 | test_f1: 0.22857 |best_f1: 0.52525\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0238\tTop_Loss: 0.0758\tBottom_Loss: 0.0654\tLoss: 0.1651\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0166\tTop_Loss: 0.0648\tBottom_Loss: 0.0501\tLoss: 0.1315\t\n",
      "Subject: 02, n=09 | test_f1: 0.51852 |best_f1: 0.52525\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0227\tTop_Loss: 0.0614\tBottom_Loss: 0.0534\tLoss: 0.1375\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0401\tTop_Loss: 0.0936\tBottom_Loss: 0.0643\tLoss: 0.1980\t\n",
      "Subject: 02, n=09 | test_f1: 0.41481 |best_f1: 0.52525\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0163\tTop_Loss: 0.0351\tBottom_Loss: 0.0809\tLoss: 0.1323\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0140\tTop_Loss: 0.0690\tBottom_Loss: 0.0211\tLoss: 0.1041\t\n",
      "Subject: 02, n=09 | test_f1: 0.47222 |best_f1: 0.52525\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0095\tTop_Loss: 0.0274\tBottom_Loss: 0.0360\tLoss: 0.0730\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0131\tTop_Loss: 0.0535\tBottom_Loss: 0.0356\tLoss: 0.1021\t\n",
      "Subject: 02, n=09 | test_f1: 0.35556 |best_f1: 0.52525\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0203\tTop_Loss: 0.0598\tBottom_Loss: 0.0315\tLoss: 0.1116\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0059\tTop_Loss: 0.0464\tBottom_Loss: 0.0220\tLoss: 0.0742\t\n",
      "Subject: 02, n=09 | test_f1: 0.28148 |best_f1: 0.52525\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0131\tTop_Loss: 0.0387\tBottom_Loss: 0.0667\tLoss: 0.1185\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0158\tTop_Loss: 0.0931\tBottom_Loss: 0.0362\tLoss: 0.1451\t\n",
      "Subject: 02, n=09 | test_f1: 0.33333 |best_f1: 0.52525\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0067\tTop_Loss: 0.0276\tBottom_Loss: 0.0268\tLoss: 0.0610\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0112\tTop_Loss: 0.0738\tBottom_Loss: 0.0296\tLoss: 0.1147\t\n",
      "Subject: 02, n=09 | test_f1: 0.52525 |best_f1: 0.52525\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0126\tTop_Loss: 0.0636\tBottom_Loss: 0.0556\tLoss: 0.1319\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0073\tTop_Loss: 0.0271\tBottom_Loss: 0.0608\tLoss: 0.0952\t\n",
      "Subject: 02, n=09 | test_f1: 0.33333 |best_f1: 0.52525\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0086\tTop_Loss: 0.0374\tBottom_Loss: 0.0240\tLoss: 0.0700\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0120\tTop_Loss: 0.0287\tBottom_Loss: 0.0336\tLoss: 0.0743\t\n",
      "Subject: 02, n=09 | test_f1: 0.28148 |best_f1: 0.52525\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0059\tTop_Loss: 0.0168\tBottom_Loss: 0.0167\tLoss: 0.0394\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0306\tTop_Loss: 0.0532\tBottom_Loss: 0.0620\tLoss: 0.1458\t\n",
      "Subject: 02, n=09 | test_f1: 0.4 |best_f1: 0.52525\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0200\tTop_Loss: 0.0377\tBottom_Loss: 0.0230\tLoss: 0.0807\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0072\tTop_Loss: 0.0169\tBottom_Loss: 0.0235\tLoss: 0.0477\t\n",
      "Subject: 02, n=09 | test_f1: 0.28148 |best_f1: 0.52525\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0073\tTop_Loss: 0.0435\tBottom_Loss: 0.0201\tLoss: 0.0709\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0278\tTop_Loss: 0.0989\tBottom_Loss: 0.0383\tLoss: 0.1650\t\n",
      "Subject: 02, n=09 | test_f1: 0.44444 |best_f1: 0.52525\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0146\tTop_Loss: 0.0149\tBottom_Loss: 0.0426\tLoss: 0.0721\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0136\tTop_Loss: 0.0887\tBottom_Loss: 0.0286\tLoss: 0.1309\t\n",
      "Subject: 02, n=09 | test_f1: 0.44444 |best_f1: 0.52525\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0107\tTop_Loss: 0.0419\tBottom_Loss: 0.0338\tLoss: 0.0863\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0049\tTop_Loss: 0.0229\tBottom_Loss: 0.0266\tLoss: 0.0545\t\n",
      "Subject: 02, n=09 | test_f1: 0.3 |best_f1: 0.52525\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0090\tTop_Loss: 0.0179\tBottom_Loss: 0.0177\tLoss: 0.0446\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0034\tTop_Loss: 0.0189\tBottom_Loss: 0.0200\tLoss: 0.0422\t\n",
      "Subject: 02, n=09 | test_f1: 0.33333 |best_f1: 0.52525\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0040\tTop_Loss: 0.0177\tBottom_Loss: 0.0186\tLoss: 0.0403\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0512\tTop_Loss: 0.0856\tBottom_Loss: 0.0790\tLoss: 0.2158\t\n",
      "Subject: 02, n=09 | test_f1: 0.4127 |best_f1: 0.52525\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1134\tTop_Loss: 0.2546\tBottom_Loss: 0.0674\tLoss: 0.4355\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0030\tTop_Loss: 0.0139\tBottom_Loss: 0.0096\tLoss: 0.0264\t\n",
      "Subject: 02, n=09 | test_f1: 0.48889 |best_f1: 0.52525\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.312\tLabel_Loss: 1.3554\tTop_Loss: 1.2580\tBottom_Loss: 1.4664\tLoss: 4.0798\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.344\tLabel_Loss: 1.1614\tTop_Loss: 1.1089\tBottom_Loss: 1.1710\tLoss: 3.4413\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.625\tLabel_Loss: 0.9214\tTop_Loss: 0.9817\tBottom_Loss: 0.9681\tLoss: 2.8712\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.469\tLabel_Loss: 0.9170\tTop_Loss: 0.9411\tBottom_Loss: 1.2229\tLoss: 3.0810\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8842\tTop_Loss: 0.8185\tBottom_Loss: 1.0918\tLoss: 2.7944\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.469\tLabel_Loss: 1.1342\tTop_Loss: 1.0149\tBottom_Loss: 1.1721\tLoss: 3.3212\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8705\tTop_Loss: 0.9483\tBottom_Loss: 0.9710\tLoss: 2.7899\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.562\tLabel_Loss: 0.8571\tTop_Loss: 0.8448\tBottom_Loss: 0.7968\tLoss: 2.4987\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.750\tLabel_Loss: 0.7384\tTop_Loss: 0.9199\tBottom_Loss: 1.0483\tLoss: 2.7066\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.562\tLabel_Loss: 1.0567\tTop_Loss: 0.9057\tBottom_Loss: 0.8862\tLoss: 2.8486\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7397\tTop_Loss: 0.8287\tBottom_Loss: 0.9110\tLoss: 2.4793\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7410\tTop_Loss: 0.9162\tBottom_Loss: 0.9082\tLoss: 2.5654\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7841\tTop_Loss: 0.9659\tBottom_Loss: 0.7856\tLoss: 2.5356\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7956\tTop_Loss: 0.8261\tBottom_Loss: 0.8632\tLoss: 2.4849\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5556\tTop_Loss: 0.6785\tBottom_Loss: 0.6897\tLoss: 1.9237\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.531\tLabel_Loss: 1.0647\tTop_Loss: 1.2748\tBottom_Loss: 0.9832\tLoss: 3.3227\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.531\tLabel_Loss: 0.8832\tTop_Loss: 0.9158\tBottom_Loss: 0.9413\tLoss: 2.7402\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.500\tLabel_Loss: 0.9277\tTop_Loss: 0.9843\tBottom_Loss: 1.0707\tLoss: 2.9827\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.562\tLabel_Loss: 0.7509\tTop_Loss: 0.6829\tBottom_Loss: 0.8066\tLoss: 2.2403\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6722\tTop_Loss: 0.7278\tBottom_Loss: 0.9090\tLoss: 2.3091\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7433\tTop_Loss: 0.9126\tBottom_Loss: 0.8175\tLoss: 2.4734\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4937\tTop_Loss: 0.5203\tBottom_Loss: 0.7627\tLoss: 1.7767\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6278\tTop_Loss: 0.7535\tBottom_Loss: 0.7369\tLoss: 2.1181\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6596\tTop_Loss: 0.6738\tBottom_Loss: 0.7585\tLoss: 2.0919\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5691\tTop_Loss: 0.7429\tBottom_Loss: 0.6522\tLoss: 1.9642\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.688\tLabel_Loss: 0.8307\tTop_Loss: 0.7736\tBottom_Loss: 0.8983\tLoss: 2.5026\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.625\tLabel_Loss: 0.5984\tTop_Loss: 0.6187\tBottom_Loss: 0.8510\tLoss: 2.0681\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4730\tTop_Loss: 0.4471\tBottom_Loss: 0.6475\tLoss: 1.5676\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7012\tTop_Loss: 0.9440\tBottom_Loss: 0.7640\tLoss: 2.4091\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6146\tTop_Loss: 0.6848\tBottom_Loss: 0.7658\tLoss: 2.0652\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5594\tTop_Loss: 0.6448\tBottom_Loss: 0.5871\tLoss: 1.7913\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.562\tLabel_Loss: 0.8701\tTop_Loss: 0.7343\tBottom_Loss: 0.8620\tLoss: 2.4663\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.656\tLabel_Loss: 0.6208\tTop_Loss: 0.6870\tBottom_Loss: 0.8216\tLoss: 2.1294\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6358\tTop_Loss: 0.6390\tBottom_Loss: 0.6531\tLoss: 1.9279\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5156\tTop_Loss: 0.4815\tBottom_Loss: 0.7482\tLoss: 1.7453\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5638\tTop_Loss: 0.7220\tBottom_Loss: 0.6694\tLoss: 1.9552\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6064\tTop_Loss: 0.5651\tBottom_Loss: 0.7228\tLoss: 1.8943\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.562\tLabel_Loss: 0.8102\tTop_Loss: 0.8242\tBottom_Loss: 0.9455\tLoss: 2.5799\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4713\tTop_Loss: 0.5955\tBottom_Loss: 0.6880\tLoss: 1.7548\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6656\tTop_Loss: 0.6029\tBottom_Loss: 0.6919\tLoss: 1.9604\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5956\tTop_Loss: 0.6307\tBottom_Loss: 0.7791\tLoss: 2.0054\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6286\tTop_Loss: 0.5741\tBottom_Loss: 0.9382\tLoss: 2.1409\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5769\tTop_Loss: 0.6063\tBottom_Loss: 0.6128\tLoss: 1.7961\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6150\tTop_Loss: 0.6602\tBottom_Loss: 0.6578\tLoss: 1.9329\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2885\tTop_Loss: 0.5528\tBottom_Loss: 0.3901\tLoss: 1.2315\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.719\tLabel_Loss: 0.5343\tTop_Loss: 0.5614\tBottom_Loss: 0.6931\tLoss: 1.7888\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.906\tLabel_Loss: 0.4072\tTop_Loss: 0.6305\tBottom_Loss: 0.4976\tLoss: 1.5353\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2575\tTop_Loss: 0.3509\tBottom_Loss: 0.4186\tLoss: 1.0270\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4558\tTop_Loss: 0.5008\tBottom_Loss: 0.7146\tLoss: 1.6712\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5807\tTop_Loss: 0.6142\tBottom_Loss: 0.6353\tLoss: 1.8302\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2560\tTop_Loss: 0.4023\tBottom_Loss: 0.3430\tLoss: 1.0013\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3756\tTop_Loss: 0.5640\tBottom_Loss: 0.4389\tLoss: 1.3785\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.906\tLabel_Loss: 0.4193\tTop_Loss: 0.5642\tBottom_Loss: 0.6101\tLoss: 1.5936\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2242\tTop_Loss: 0.4376\tBottom_Loss: 0.4018\tLoss: 1.0636\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3816\tTop_Loss: 0.5049\tBottom_Loss: 0.5842\tLoss: 1.4707\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3752\tTop_Loss: 0.3634\tBottom_Loss: 0.4477\tLoss: 1.1862\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.938\tLabel_Loss: 0.3540\tTop_Loss: 0.5583\tBottom_Loss: 0.5370\tLoss: 1.4494\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2220\tTop_Loss: 0.3368\tBottom_Loss: 0.6665\tLoss: 1.2252\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3873\tTop_Loss: 0.5900\tBottom_Loss: 0.5390\tLoss: 1.5163\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4910\tTop_Loss: 0.5558\tBottom_Loss: 0.5138\tLoss: 1.5605\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2985\tTop_Loss: 0.4172\tBottom_Loss: 0.4167\tLoss: 1.1324\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3665\tTop_Loss: 0.5481\tBottom_Loss: 0.6012\tLoss: 1.5158\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2231\tTop_Loss: 0.2889\tBottom_Loss: 0.4543\tLoss: 0.9663\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3399\tTop_Loss: 0.3528\tBottom_Loss: 0.4375\tLoss: 1.1302\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3049\tTop_Loss: 0.3645\tBottom_Loss: 0.5513\tLoss: 1.2206\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2549\tTop_Loss: 0.4169\tBottom_Loss: 0.3827\tLoss: 1.0545\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2827\tTop_Loss: 0.3768\tBottom_Loss: 0.2790\tLoss: 0.9385\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2835\tTop_Loss: 0.4073\tBottom_Loss: 0.4731\tLoss: 1.1639\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2668\tTop_Loss: 0.4653\tBottom_Loss: 0.4087\tLoss: 1.1408\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2330\tTop_Loss: 0.3997\tBottom_Loss: 0.3179\tLoss: 0.9506\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2476\tTop_Loss: 0.2951\tBottom_Loss: 0.3951\tLoss: 0.9378\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.844\tLabel_Loss: 0.2994\tTop_Loss: 0.4046\tBottom_Loss: 0.3878\tLoss: 1.0918\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1976\tTop_Loss: 0.4071\tBottom_Loss: 0.2782\tLoss: 0.8829\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1818\tTop_Loss: 0.3553\tBottom_Loss: 0.3222\tLoss: 0.8593\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2185\tTop_Loss: 0.3726\tBottom_Loss: 0.3905\tLoss: 0.9817\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2789\tTop_Loss: 0.3477\tBottom_Loss: 0.3912\tLoss: 1.0178\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3372\tTop_Loss: 0.3980\tBottom_Loss: 0.4777\tLoss: 1.2130\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1786\tTop_Loss: 0.2311\tBottom_Loss: 0.4370\tLoss: 0.8467\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3066\tTop_Loss: 0.3024\tBottom_Loss: 0.3869\tLoss: 0.9959\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1487\tTop_Loss: 0.2220\tBottom_Loss: 0.2783\tLoss: 0.6490\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.844\tLabel_Loss: 0.2862\tTop_Loss: 0.3770\tBottom_Loss: 0.4844\tLoss: 1.1476\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1684\tTop_Loss: 0.3349\tBottom_Loss: 0.1963\tLoss: 0.6995\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1035\tTop_Loss: 0.2637\tBottom_Loss: 0.2869\tLoss: 0.6540\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2457\tTop_Loss: 0.4386\tBottom_Loss: 0.3112\tLoss: 0.9954\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3048\tTop_Loss: 0.3919\tBottom_Loss: 0.3223\tLoss: 1.0190\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2279\tTop_Loss: 0.3633\tBottom_Loss: 0.2930\tLoss: 0.8842\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0829\tTop_Loss: 0.2623\tBottom_Loss: 0.2520\tLoss: 0.5971\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1799\tTop_Loss: 0.2239\tBottom_Loss: 0.3643\tLoss: 0.7681\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1176\tTop_Loss: 0.3267\tBottom_Loss: 0.3072\tLoss: 0.7514\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1945\tTop_Loss: 0.2998\tBottom_Loss: 0.4629\tLoss: 0.9572\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1452\tTop_Loss: 0.2444\tBottom_Loss: 0.2437\tLoss: 0.6333\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3029\tTop_Loss: 0.3095\tBottom_Loss: 0.3936\tLoss: 1.0061\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2329\tTop_Loss: 0.3012\tBottom_Loss: 0.3277\tLoss: 0.8618\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0417\tTop_Loss: 0.1486\tBottom_Loss: 0.0907\tLoss: 0.2810\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0813\tTop_Loss: 0.2348\tBottom_Loss: 0.1268\tLoss: 0.4429\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1140\tTop_Loss: 0.2329\tBottom_Loss: 0.2769\tLoss: 0.6237\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1215\tTop_Loss: 0.2560\tBottom_Loss: 0.2167\tLoss: 0.5943\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2484\tTop_Loss: 0.2376\tBottom_Loss: 0.3909\tLoss: 0.8769\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1192\tTop_Loss: 0.2214\tBottom_Loss: 0.2183\tLoss: 0.5589\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1585\tTop_Loss: 0.2278\tBottom_Loss: 0.1943\tLoss: 0.5807\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3143\tTop_Loss: 0.3912\tBottom_Loss: 0.4425\tLoss: 1.1480\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2358\tTop_Loss: 0.2758\tBottom_Loss: 0.2881\tLoss: 0.7997\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1501\tTop_Loss: 0.1994\tBottom_Loss: 0.3015\tLoss: 0.6510\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1186\tTop_Loss: 0.1979\tBottom_Loss: 0.2548\tLoss: 0.5713\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2937\tTop_Loss: 0.4113\tBottom_Loss: 0.3465\tLoss: 1.0515\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2726\tTop_Loss: 0.3683\tBottom_Loss: 0.3183\tLoss: 0.9592\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0495\tTop_Loss: 0.1509\tBottom_Loss: 0.2425\tLoss: 0.4430\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0383\tTop_Loss: 0.1216\tBottom_Loss: 0.1247\tLoss: 0.2846\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0621\tTop_Loss: 0.2150\tBottom_Loss: 0.2013\tLoss: 0.4784\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1643\tTop_Loss: 0.1568\tBottom_Loss: 0.2775\tLoss: 0.5986\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0855\tTop_Loss: 0.3480\tBottom_Loss: 0.1204\tLoss: 0.5540\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0777\tTop_Loss: 0.1858\tBottom_Loss: 0.1765\tLoss: 0.4400\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0351\tTop_Loss: 0.0969\tBottom_Loss: 0.1214\tLoss: 0.2534\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0845\tTop_Loss: 0.1836\tBottom_Loss: 0.1697\tLoss: 0.4377\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1174\tTop_Loss: 0.2794\tBottom_Loss: 0.2121\tLoss: 0.6089\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0446\tTop_Loss: 0.1530\tBottom_Loss: 0.1386\tLoss: 0.3363\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0604\tTop_Loss: 0.1476\tBottom_Loss: 0.2272\tLoss: 0.4352\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1174\tTop_Loss: 0.2913\tBottom_Loss: 0.3117\tLoss: 0.7204\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0806\tTop_Loss: 0.1767\tBottom_Loss: 0.2296\tLoss: 0.4868\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1296\tTop_Loss: 0.2110\tBottom_Loss: 0.2297\tLoss: 0.5704\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0696\tTop_Loss: 0.2473\tBottom_Loss: 0.1671\tLoss: 0.4840\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0428\tTop_Loss: 0.1507\tBottom_Loss: 0.1048\tLoss: 0.2984\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0525\tTop_Loss: 0.1057\tBottom_Loss: 0.1288\tLoss: 0.2870\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1650\tTop_Loss: 0.3118\tBottom_Loss: 0.2174\tLoss: 0.6941\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0539\tTop_Loss: 0.1175\tBottom_Loss: 0.1813\tLoss: 0.3527\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0723\tTop_Loss: 0.1394\tBottom_Loss: 0.1318\tLoss: 0.3436\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0390\tTop_Loss: 0.0845\tBottom_Loss: 0.0883\tLoss: 0.2118\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0479\tTop_Loss: 0.1258\tBottom_Loss: 0.1421\tLoss: 0.3159\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0444\tTop_Loss: 0.1550\tBottom_Loss: 0.0803\tLoss: 0.2797\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0403\tTop_Loss: 0.1375\tBottom_Loss: 0.0848\tLoss: 0.2626\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0723\tTop_Loss: 0.1761\tBottom_Loss: 0.1087\tLoss: 0.3572\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0425\tTop_Loss: 0.1791\tBottom_Loss: 0.0641\tLoss: 0.2856\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0333\tTop_Loss: 0.0746\tBottom_Loss: 0.1715\tLoss: 0.2794\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1193\tTop_Loss: 0.2642\tBottom_Loss: 0.1858\tLoss: 0.5693\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0178\tTop_Loss: 0.0627\tBottom_Loss: 0.0656\tLoss: 0.1462\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0301\tTop_Loss: 0.1382\tBottom_Loss: 0.0544\tLoss: 0.2227\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[68][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1147\tTop_Loss: 0.1362\tBottom_Loss: 0.2053\tLoss: 0.4563\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0154\tTop_Loss: 0.0807\tBottom_Loss: 0.0754\tLoss: 0.1715\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0761\tTop_Loss: 0.2383\tBottom_Loss: 0.0920\tLoss: 0.4065\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0298\tTop_Loss: 0.0739\tBottom_Loss: 0.0677\tLoss: 0.1714\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0205\tTop_Loss: 0.0654\tBottom_Loss: 0.1170\tLoss: 0.2030\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0232\tTop_Loss: 0.0937\tBottom_Loss: 0.0692\tLoss: 0.1861\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0305\tTop_Loss: 0.0651\tBottom_Loss: 0.0957\tLoss: 0.1913\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0236\tTop_Loss: 0.1020\tBottom_Loss: 0.0912\tLoss: 0.2167\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0353\tTop_Loss: 0.0904\tBottom_Loss: 0.2016\tLoss: 0.3273\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0548\tTop_Loss: 0.0539\tBottom_Loss: 0.1497\tLoss: 0.2584\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0242\tTop_Loss: 0.0553\tBottom_Loss: 0.1121\tLoss: 0.1916\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0589\tTop_Loss: 0.1109\tBottom_Loss: 0.0999\tLoss: 0.2697\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1272\tTop_Loss: 0.2473\tBottom_Loss: 0.1735\tLoss: 0.5479\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 0.938\tLabel_Loss: 0.0894\tTop_Loss: 0.1028\tBottom_Loss: 0.1152\tLoss: 0.3074\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0471\tTop_Loss: 0.1659\tBottom_Loss: 0.0960\tLoss: 0.3090\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0653\tTop_Loss: 0.1136\tBottom_Loss: 0.1388\tLoss: 0.3177\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0208\tTop_Loss: 0.0373\tBottom_Loss: 0.0912\tLoss: 0.1492\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0411\tTop_Loss: 0.0549\tBottom_Loss: 0.1414\tLoss: 0.2374\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0143\tTop_Loss: 0.0626\tBottom_Loss: 0.0678\tLoss: 0.1447\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0319\tTop_Loss: 0.1537\tBottom_Loss: 0.0369\tLoss: 0.2225\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0245\tTop_Loss: 0.0577\tBottom_Loss: 0.0423\tLoss: 0.1245\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0286\tTop_Loss: 0.1010\tBottom_Loss: 0.0690\tLoss: 0.1986\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0206\tTop_Loss: 0.0836\tBottom_Loss: 0.0790\tLoss: 0.1833\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0092\tTop_Loss: 0.0396\tBottom_Loss: 0.0959\tLoss: 0.1448\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0213\tTop_Loss: 0.0556\tBottom_Loss: 0.0608\tLoss: 0.1377\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0119\tTop_Loss: 0.0468\tBottom_Loss: 0.0577\tLoss: 0.1163\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0155\tTop_Loss: 0.0225\tBottom_Loss: 0.0874\tLoss: 0.1254\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0191\tTop_Loss: 0.0297\tBottom_Loss: 0.1044\tLoss: 0.1532\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0126\tTop_Loss: 0.0441\tBottom_Loss: 0.0328\tLoss: 0.0896\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0193\tTop_Loss: 0.0483\tBottom_Loss: 0.0805\tLoss: 0.1481\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0123\tTop_Loss: 0.0391\tBottom_Loss: 0.0414\tLoss: 0.0928\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0187\tTop_Loss: 0.0513\tBottom_Loss: 0.1209\tLoss: 0.1909\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0268\tTop_Loss: 0.0754\tBottom_Loss: 0.0291\tLoss: 0.1314\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0460\tTop_Loss: 0.0838\tBottom_Loss: 0.0872\tLoss: 0.2170\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0350\tTop_Loss: 0.0690\tBottom_Loss: 0.0885\tLoss: 0.1925\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0409\tTop_Loss: 0.0512\tBottom_Loss: 0.1042\tLoss: 0.1963\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0238\tTop_Loss: 0.1073\tBottom_Loss: 0.0971\tLoss: 0.2281\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0906\tTop_Loss: 0.1410\tBottom_Loss: 0.0961\tLoss: 0.3277\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0326\tTop_Loss: 0.0339\tBottom_Loss: 0.0612\tLoss: 0.1277\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0088\tTop_Loss: 0.0339\tBottom_Loss: 0.0365\tLoss: 0.0792\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0117\tTop_Loss: 0.0529\tBottom_Loss: 0.0361\tLoss: 0.1007\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0069\tTop_Loss: 0.0221\tBottom_Loss: 0.0266\tLoss: 0.0557\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0079\tTop_Loss: 0.0263\tBottom_Loss: 0.0498\tLoss: 0.0840\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0206\tTop_Loss: 0.0567\tBottom_Loss: 0.0423\tLoss: 0.1196\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0248\tTop_Loss: 0.1016\tBottom_Loss: 0.0411\tLoss: 0.1675\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0292\tTop_Loss: 0.0252\tBottom_Loss: 0.1141\tLoss: 0.1685\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0094\tTop_Loss: 0.0538\tBottom_Loss: 0.0238\tLoss: 0.0870\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0086\tTop_Loss: 0.0651\tBottom_Loss: 0.0482\tLoss: 0.1220\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0049\tTop_Loss: 0.0226\tBottom_Loss: 0.0166\tLoss: 0.0441\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0133\tTop_Loss: 0.0189\tBottom_Loss: 0.0950\tLoss: 0.1272\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0157\tTop_Loss: 0.0440\tBottom_Loss: 0.0344\tLoss: 0.0941\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0163\tTop_Loss: 0.0479\tBottom_Loss: 0.0288\tLoss: 0.0930\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0152\tTop_Loss: 0.0249\tBottom_Loss: 0.0802\tLoss: 0.1202\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0303\tTop_Loss: 0.1145\tBottom_Loss: 0.0470\tLoss: 0.1918\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0107\tTop_Loss: 0.0341\tBottom_Loss: 0.0740\tLoss: 0.1187\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0048\tTop_Loss: 0.0156\tBottom_Loss: 0.0259\tLoss: 0.0464\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0086\tTop_Loss: 0.0202\tBottom_Loss: 0.0582\tLoss: 0.0870\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0123\tTop_Loss: 0.0104\tBottom_Loss: 0.0808\tLoss: 0.1035\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0304\tTop_Loss: 0.0334\tBottom_Loss: 0.0860\tLoss: 0.1497\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0046\tTop_Loss: 0.0214\tBottom_Loss: 0.0164\tLoss: 0.0424\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0120\tTop_Loss: 0.0446\tBottom_Loss: 0.0724\tLoss: 0.1290\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0073\tTop_Loss: 0.0393\tBottom_Loss: 0.0443\tLoss: 0.0909\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0061\tTop_Loss: 0.0153\tBottom_Loss: 0.0436\tLoss: 0.0649\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0256\tTop_Loss: 0.0791\tBottom_Loss: 0.0357\tLoss: 0.1403\t\n",
      "Subject: 020, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.250\tLabel_Loss: 1.6223\tTop_Loss: 1.0683\tBottom_Loss: 1.0781\tLoss: 3.7687\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.375\tLabel_Loss: 1.2009\tTop_Loss: 0.9017\tBottom_Loss: 1.1128\tLoss: 3.2155\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.500\tLabel_Loss: 1.0383\tTop_Loss: 1.1687\tBottom_Loss: 0.8878\tLoss: 3.0948\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.500\tLabel_Loss: 1.1454\tTop_Loss: 1.3362\tBottom_Loss: 1.3028\tLoss: 3.7844\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.531\tLabel_Loss: 1.0320\tTop_Loss: 0.9940\tBottom_Loss: 1.0254\tLoss: 3.0514\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7672\tTop_Loss: 0.8250\tBottom_Loss: 0.8405\tLoss: 2.4327\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.531\tLabel_Loss: 1.0622\tTop_Loss: 1.1534\tBottom_Loss: 0.8893\tLoss: 3.1048\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.656\tLabel_Loss: 0.9347\tTop_Loss: 0.9043\tBottom_Loss: 0.8502\tLoss: 2.6892\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7810\tTop_Loss: 0.8671\tBottom_Loss: 0.8554\tLoss: 2.5036\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.688\tLabel_Loss: 0.8766\tTop_Loss: 0.9869\tBottom_Loss: 1.0525\tLoss: 2.9161\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.531\tLabel_Loss: 0.9302\tTop_Loss: 1.0096\tBottom_Loss: 0.9958\tLoss: 2.9356\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.750\tLabel_Loss: 0.7650\tTop_Loss: 0.8589\tBottom_Loss: 0.9488\tLoss: 2.5727\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.500\tLabel_Loss: 1.0141\tTop_Loss: 0.9870\tBottom_Loss: 1.0530\tLoss: 3.0542\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8372\tTop_Loss: 1.0064\tBottom_Loss: 0.9050\tLoss: 2.7486\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8091\tTop_Loss: 0.8625\tBottom_Loss: 0.7466\tLoss: 2.4182\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.531\tLabel_Loss: 0.7858\tTop_Loss: 0.8634\tBottom_Loss: 0.9703\tLoss: 2.6195\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7864\tTop_Loss: 0.7173\tBottom_Loss: 0.9493\tLoss: 2.4530\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6856\tTop_Loss: 0.7005\tBottom_Loss: 0.7289\tLoss: 2.1150\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.594\tLabel_Loss: 0.6229\tTop_Loss: 0.6602\tBottom_Loss: 0.8061\tLoss: 2.0892\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6433\tTop_Loss: 0.7036\tBottom_Loss: 0.8889\tLoss: 2.2357\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6487\tTop_Loss: 0.6782\tBottom_Loss: 0.7102\tLoss: 2.0371\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7400\tTop_Loss: 0.9494\tBottom_Loss: 0.7194\tLoss: 2.4089\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5750\tTop_Loss: 0.6832\tBottom_Loss: 0.7391\tLoss: 1.9973\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6745\tTop_Loss: 0.6906\tBottom_Loss: 0.6726\tLoss: 2.0376\t\n",
      "Subject: 021, n=02 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6359\tTop_Loss: 0.8988\tBottom_Loss: 0.6688\tLoss: 2.2035\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7636\tTop_Loss: 0.9070\tBottom_Loss: 0.9266\tLoss: 2.5973\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7373\tTop_Loss: 0.8399\tBottom_Loss: 0.8179\tLoss: 2.3951\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6194\tTop_Loss: 0.6426\tBottom_Loss: 0.6999\tLoss: 1.9619\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.625\tLabel_Loss: 0.9661\tTop_Loss: 0.8289\tBottom_Loss: 0.9233\tLoss: 2.7182\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6556\tTop_Loss: 0.7192\tBottom_Loss: 0.7501\tLoss: 2.1249\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6588\tTop_Loss: 0.6595\tBottom_Loss: 0.6448\tLoss: 1.9631\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6058\tTop_Loss: 0.7395\tBottom_Loss: 0.6993\tLoss: 2.0447\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4875\tTop_Loss: 0.5454\tBottom_Loss: 0.4903\tLoss: 1.5232\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.656\tLabel_Loss: 0.5853\tTop_Loss: 0.5569\tBottom_Loss: 0.7658\tLoss: 1.9081\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.781\tLabel_Loss: 0.6036\tTop_Loss: 0.6908\tBottom_Loss: 0.7548\tLoss: 2.0492\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5270\tTop_Loss: 0.5211\tBottom_Loss: 0.7236\tLoss: 1.7717\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7874\tTop_Loss: 0.7689\tBottom_Loss: 0.7742\tLoss: 2.3305\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3852\tTop_Loss: 0.5616\tBottom_Loss: 0.7602\tLoss: 1.7070\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.750\tLabel_Loss: 0.4510\tTop_Loss: 0.5327\tBottom_Loss: 0.6595\tLoss: 1.6432\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5295\tTop_Loss: 0.6084\tBottom_Loss: 0.5845\tLoss: 1.7224\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4613\tTop_Loss: 0.6337\tBottom_Loss: 0.6076\tLoss: 1.7025\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5954\tTop_Loss: 0.6797\tBottom_Loss: 0.7626\tLoss: 2.0377\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3012\tTop_Loss: 0.4118\tBottom_Loss: 0.6740\tLoss: 1.3869\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5477\tTop_Loss: 0.6841\tBottom_Loss: 0.7120\tLoss: 1.9438\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6447\tTop_Loss: 0.6279\tBottom_Loss: 0.6504\tLoss: 1.9230\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.688\tLabel_Loss: 0.5430\tTop_Loss: 0.7379\tBottom_Loss: 0.5734\tLoss: 1.8543\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3820\tTop_Loss: 0.5194\tBottom_Loss: 0.4275\tLoss: 1.3289\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3286\tTop_Loss: 0.4090\tBottom_Loss: 0.6492\tLoss: 1.3868\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4560\tTop_Loss: 0.4083\tBottom_Loss: 0.6216\tLoss: 1.4859\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4379\tTop_Loss: 0.5338\tBottom_Loss: 0.4189\tLoss: 1.3906\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3564\tTop_Loss: 0.5940\tBottom_Loss: 0.6505\tLoss: 1.6009\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3764\tTop_Loss: 0.4166\tBottom_Loss: 0.5319\tLoss: 1.3249\t\n",
      "Subject: 021, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.938\tLabel_Loss: 0.3203\tTop_Loss: 0.4298\tBottom_Loss: 0.5732\tLoss: 1.3233\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4228\tTop_Loss: 0.4230\tBottom_Loss: 0.4828\tLoss: 1.3285\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3831\tTop_Loss: 0.4553\tBottom_Loss: 0.4541\tLoss: 1.2926\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.719\tLabel_Loss: 0.5080\tTop_Loss: 0.5075\tBottom_Loss: 0.6126\tLoss: 1.6281\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2756\tTop_Loss: 0.4067\tBottom_Loss: 0.3384\tLoss: 1.0206\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2917\tTop_Loss: 0.3247\tBottom_Loss: 0.4648\tLoss: 1.0811\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3139\tTop_Loss: 0.4031\tBottom_Loss: 0.3073\tLoss: 1.0242\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3525\tTop_Loss: 0.5635\tBottom_Loss: 0.6260\tLoss: 1.5420\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2676\tTop_Loss: 0.4164\tBottom_Loss: 0.3765\tLoss: 1.0604\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3369\tTop_Loss: 0.4333\tBottom_Loss: 0.5514\tLoss: 1.3217\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1812\tTop_Loss: 0.3849\tBottom_Loss: 0.2892\tLoss: 0.8554\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2185\tTop_Loss: 0.3576\tBottom_Loss: 0.3581\tLoss: 0.9342\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1525\tTop_Loss: 0.3032\tBottom_Loss: 0.3237\tLoss: 0.7793\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2925\tTop_Loss: 0.5887\tBottom_Loss: 0.5385\tLoss: 1.4197\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2709\tTop_Loss: 0.3862\tBottom_Loss: 0.3690\tLoss: 1.0262\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2660\tTop_Loss: 0.4182\tBottom_Loss: 0.4203\tLoss: 1.1045\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2864\tTop_Loss: 0.4996\tBottom_Loss: 0.3364\tLoss: 1.1224\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2432\tTop_Loss: 0.3045\tBottom_Loss: 0.4293\tLoss: 0.9770\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2887\tTop_Loss: 0.4617\tBottom_Loss: 0.3040\tLoss: 1.0543\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2424\tTop_Loss: 0.2618\tBottom_Loss: 0.4142\tLoss: 0.9183\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3875\tTop_Loss: 0.4135\tBottom_Loss: 0.6556\tLoss: 1.4566\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1180\tTop_Loss: 0.2805\tBottom_Loss: 0.2337\tLoss: 0.6322\t\n",
      "Subject: 021, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1737\tTop_Loss: 0.3450\tBottom_Loss: 0.2850\tLoss: 0.8037\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1507\tTop_Loss: 0.3550\tBottom_Loss: 0.3052\tLoss: 0.8110\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1672\tTop_Loss: 0.2417\tBottom_Loss: 0.2866\tLoss: 0.6956\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3061\tTop_Loss: 0.2848\tBottom_Loss: 0.6006\tLoss: 1.1916\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1378\tTop_Loss: 0.2744\tBottom_Loss: 0.2924\tLoss: 0.7047\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.750\tLabel_Loss: 0.3932\tTop_Loss: 0.3182\tBottom_Loss: 0.5366\tLoss: 1.2480\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1363\tTop_Loss: 0.3555\tBottom_Loss: 0.3384\tLoss: 0.8302\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2753\tTop_Loss: 0.2399\tBottom_Loss: 0.4115\tLoss: 0.9268\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2444\tTop_Loss: 0.3408\tBottom_Loss: 0.4686\tLoss: 1.0539\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1824\tTop_Loss: 0.3097\tBottom_Loss: 0.3671\tLoss: 0.8593\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2346\tTop_Loss: 0.3516\tBottom_Loss: 0.3124\tLoss: 0.8986\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2748\tTop_Loss: 0.4227\tBottom_Loss: 0.4365\tLoss: 1.1340\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1403\tTop_Loss: 0.2749\tBottom_Loss: 0.2698\tLoss: 0.6850\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1018\tTop_Loss: 0.1425\tBottom_Loss: 0.2332\tLoss: 0.4775\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2222\tTop_Loss: 0.2612\tBottom_Loss: 0.2766\tLoss: 0.7600\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0971\tTop_Loss: 0.1666\tBottom_Loss: 0.1706\tLoss: 0.4344\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0881\tTop_Loss: 0.2251\tBottom_Loss: 0.3468\tLoss: 0.6600\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0874\tTop_Loss: 0.2420\tBottom_Loss: 0.1404\tLoss: 0.4698\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2056\tTop_Loss: 0.3108\tBottom_Loss: 0.2997\tLoss: 0.8160\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1278\tTop_Loss: 0.3634\tBottom_Loss: 0.1983\tLoss: 0.6896\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0651\tTop_Loss: 0.2111\tBottom_Loss: 0.3020\tLoss: 0.5781\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1720\tTop_Loss: 0.3565\tBottom_Loss: 0.1977\tLoss: 0.7262\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2334\tTop_Loss: 0.2332\tBottom_Loss: 0.5179\tLoss: 0.9845\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1937\tTop_Loss: 0.2340\tBottom_Loss: 0.2760\tLoss: 0.7037\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1329\tTop_Loss: 0.1666\tBottom_Loss: 0.2658\tLoss: 0.5653\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1508\tTop_Loss: 0.2117\tBottom_Loss: 0.2395\tLoss: 0.6019\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1982\tTop_Loss: 0.2648\tBottom_Loss: 0.2948\tLoss: 0.7578\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2448\tTop_Loss: 0.3358\tBottom_Loss: 0.3751\tLoss: 0.9556\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1051\tTop_Loss: 0.1944\tBottom_Loss: 0.1792\tLoss: 0.4787\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1711\tTop_Loss: 0.1739\tBottom_Loss: 0.2373\tLoss: 0.5822\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1665\tTop_Loss: 0.2699\tBottom_Loss: 0.2743\tLoss: 0.7107\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.875\tLabel_Loss: 0.1642\tTop_Loss: 0.2895\tBottom_Loss: 0.1898\tLoss: 0.6434\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0692\tTop_Loss: 0.1490\tBottom_Loss: 0.1301\tLoss: 0.3483\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0590\tTop_Loss: 0.1965\tBottom_Loss: 0.1842\tLoss: 0.4396\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1436\tTop_Loss: 0.2729\tBottom_Loss: 0.1674\tLoss: 0.5839\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0739\tTop_Loss: 0.1995\tBottom_Loss: 0.1536\tLoss: 0.4270\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0660\tTop_Loss: 0.1031\tBottom_Loss: 0.1435\tLoss: 0.3126\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0390\tTop_Loss: 0.1411\tBottom_Loss: 0.0957\tLoss: 0.2758\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1526\tTop_Loss: 0.2320\tBottom_Loss: 0.2786\tLoss: 0.6633\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0992\tTop_Loss: 0.3069\tBottom_Loss: 0.1860\tLoss: 0.5921\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1299\tTop_Loss: 0.1310\tBottom_Loss: 0.2248\tLoss: 0.4857\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0939\tTop_Loss: 0.2725\tBottom_Loss: 0.2417\tLoss: 0.6082\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0994\tTop_Loss: 0.1545\tBottom_Loss: 0.3363\tLoss: 0.5902\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0398\tTop_Loss: 0.1061\tBottom_Loss: 0.1176\tLoss: 0.2635\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1305\tTop_Loss: 0.2918\tBottom_Loss: 0.1190\tLoss: 0.5413\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0708\tTop_Loss: 0.1910\tBottom_Loss: 0.1512\tLoss: 0.4130\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0541\tTop_Loss: 0.0879\tBottom_Loss: 0.1451\tLoss: 0.2872\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0524\tTop_Loss: 0.1039\tBottom_Loss: 0.1980\tLoss: 0.3544\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[61][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1113\tTop_Loss: 0.1921\tBottom_Loss: 0.2264\tLoss: 0.5298\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0632\tTop_Loss: 0.1279\tBottom_Loss: 0.1285\tLoss: 0.3196\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0507\tTop_Loss: 0.0873\tBottom_Loss: 0.1269\tLoss: 0.2648\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0532\tTop_Loss: 0.1883\tBottom_Loss: 0.1111\tLoss: 0.3526\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1682\tTop_Loss: 0.1964\tBottom_Loss: 0.2704\tLoss: 0.6349\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0341\tTop_Loss: 0.0912\tBottom_Loss: 0.0999\tLoss: 0.2253\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0505\tTop_Loss: 0.0933\tBottom_Loss: 0.2023\tLoss: 0.3461\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0650\tTop_Loss: 0.1380\tBottom_Loss: 0.1427\tLoss: 0.3458\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0605\tTop_Loss: 0.2392\tBottom_Loss: 0.1520\tLoss: 0.4517\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0528\tTop_Loss: 0.1570\tBottom_Loss: 0.1044\tLoss: 0.3143\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 0.875\tLabel_Loss: 0.1718\tTop_Loss: 0.3465\tBottom_Loss: 0.2309\tLoss: 0.7492\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0828\tTop_Loss: 0.1072\tBottom_Loss: 0.1801\tLoss: 0.3702\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0325\tTop_Loss: 0.1067\tBottom_Loss: 0.0688\tLoss: 0.2080\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0662\tTop_Loss: 0.1336\tBottom_Loss: 0.1265\tLoss: 0.3263\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0432\tTop_Loss: 0.0951\tBottom_Loss: 0.1399\tLoss: 0.2782\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1184\tTop_Loss: 0.1874\tBottom_Loss: 0.1692\tLoss: 0.4750\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0216\tTop_Loss: 0.0510\tBottom_Loss: 0.1223\tLoss: 0.1949\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0261\tTop_Loss: 0.1276\tBottom_Loss: 0.0678\tLoss: 0.2215\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0365\tTop_Loss: 0.1314\tBottom_Loss: 0.0941\tLoss: 0.2620\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0322\tTop_Loss: 0.0623\tBottom_Loss: 0.0991\tLoss: 0.1936\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0131\tTop_Loss: 0.0487\tBottom_Loss: 0.0388\tLoss: 0.1006\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0289\tTop_Loss: 0.1028\tBottom_Loss: 0.0578\tLoss: 0.1895\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0656\tTop_Loss: 0.2340\tBottom_Loss: 0.1061\tLoss: 0.4056\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0634\tTop_Loss: 0.0927\tBottom_Loss: 0.1013\tLoss: 0.2574\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0475\tTop_Loss: 0.0818\tBottom_Loss: 0.1404\tLoss: 0.2697\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0252\tTop_Loss: 0.0981\tBottom_Loss: 0.0920\tLoss: 0.2153\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0139\tTop_Loss: 0.0360\tBottom_Loss: 0.0532\tLoss: 0.1031\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0620\tTop_Loss: 0.1308\tBottom_Loss: 0.0680\tLoss: 0.2608\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0933\tTop_Loss: 0.0834\tBottom_Loss: 0.1310\tLoss: 0.3077\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0517\tTop_Loss: 0.1261\tBottom_Loss: 0.1667\tLoss: 0.3446\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0143\tTop_Loss: 0.0556\tBottom_Loss: 0.0468\tLoss: 0.1167\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0615\tTop_Loss: 0.0668\tBottom_Loss: 0.1357\tLoss: 0.2640\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0191\tTop_Loss: 0.0712\tBottom_Loss: 0.0444\tLoss: 0.1348\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0137\tTop_Loss: 0.0517\tBottom_Loss: 0.0514\tLoss: 0.1169\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0281\tTop_Loss: 0.0726\tBottom_Loss: 0.0428\tLoss: 0.1435\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 0.938\tLabel_Loss: 0.0672\tTop_Loss: 0.1022\tBottom_Loss: 0.1134\tLoss: 0.2827\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0134\tTop_Loss: 0.0569\tBottom_Loss: 0.0579\tLoss: 0.1282\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0151\tTop_Loss: 0.0513\tBottom_Loss: 0.0566\tLoss: 0.1230\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0249\tTop_Loss: 0.0277\tBottom_Loss: 0.1228\tLoss: 0.1754\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0443\tTop_Loss: 0.1050\tBottom_Loss: 0.0666\tLoss: 0.2159\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0111\tTop_Loss: 0.0438\tBottom_Loss: 0.0346\tLoss: 0.0895\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0384\tTop_Loss: 0.1202\tBottom_Loss: 0.0736\tLoss: 0.2322\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0073\tTop_Loss: 0.0288\tBottom_Loss: 0.0212\tLoss: 0.0574\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0429\tTop_Loss: 0.0685\tBottom_Loss: 0.0608\tLoss: 0.1723\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0464\tTop_Loss: 0.0508\tBottom_Loss: 0.1261\tLoss: 0.2233\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0413\tTop_Loss: 0.1894\tBottom_Loss: 0.0663\tLoss: 0.2971\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0381\tTop_Loss: 0.0378\tBottom_Loss: 0.0832\tLoss: 0.1592\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0219\tTop_Loss: 0.1247\tBottom_Loss: 0.0302\tLoss: 0.1768\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0097\tTop_Loss: 0.0196\tBottom_Loss: 0.0505\tLoss: 0.0798\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0129\tTop_Loss: 0.0591\tBottom_Loss: 0.0371\tLoss: 0.1091\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0271\tTop_Loss: 0.0710\tBottom_Loss: 0.0443\tLoss: 0.1424\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0335\tTop_Loss: 0.0612\tBottom_Loss: 0.0897\tLoss: 0.1844\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0182\tTop_Loss: 0.0522\tBottom_Loss: 0.0273\tLoss: 0.0977\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0083\tTop_Loss: 0.0192\tBottom_Loss: 0.0292\tLoss: 0.0567\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0196\tTop_Loss: 0.0913\tBottom_Loss: 0.0414\tLoss: 0.1524\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0039\tTop_Loss: 0.0292\tBottom_Loss: 0.0219\tLoss: 0.0551\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0267\tTop_Loss: 0.1090\tBottom_Loss: 0.0310\tLoss: 0.1666\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0341\tTop_Loss: 0.0720\tBottom_Loss: 0.0705\tLoss: 0.1766\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0427\tTop_Loss: 0.0487\tBottom_Loss: 0.1107\tLoss: 0.2022\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0063\tTop_Loss: 0.0438\tBottom_Loss: 0.0171\tLoss: 0.0673\t\n",
      "Subject: 021, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0080\tTop_Loss: 0.0384\tBottom_Loss: 0.0339\tLoss: 0.0803\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0072\tTop_Loss: 0.0400\tBottom_Loss: 0.0346\tLoss: 0.0818\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0121\tTop_Loss: 0.0701\tBottom_Loss: 0.0415\tLoss: 0.1237\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0303\tTop_Loss: 0.0843\tBottom_Loss: 0.0338\tLoss: 0.1484\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0156\tTop_Loss: 0.0758\tBottom_Loss: 0.0493\tLoss: 0.1407\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0158\tTop_Loss: 0.0384\tBottom_Loss: 0.0636\tLoss: 0.1178\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0280\tTop_Loss: 0.0248\tBottom_Loss: 0.0859\tLoss: 0.1387\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0065\tTop_Loss: 0.0310\tBottom_Loss: 0.0313\tLoss: 0.0688\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0263\tTop_Loss: 0.0261\tBottom_Loss: 0.0722\tLoss: 0.1246\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0414\tTop_Loss: 0.1141\tBottom_Loss: 0.0579\tLoss: 0.2134\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0515\tTop_Loss: 0.0919\tBottom_Loss: 0.0890\tLoss: 0.2324\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0121\tTop_Loss: 0.0326\tBottom_Loss: 0.0275\tLoss: 0.0723\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0042\tTop_Loss: 0.0143\tBottom_Loss: 0.0183\tLoss: 0.0368\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0212\tTop_Loss: 0.0884\tBottom_Loss: 0.0994\tLoss: 0.2089\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0114\tTop_Loss: 0.0320\tBottom_Loss: 0.0247\tLoss: 0.0680\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0151\tTop_Loss: 0.0431\tBottom_Loss: 0.0645\tLoss: 0.1226\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0268\tTop_Loss: 0.0631\tBottom_Loss: 0.0192\tLoss: 0.1091\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0088\tTop_Loss: 0.0392\tBottom_Loss: 0.0215\tLoss: 0.0696\t\n",
      "Subject: 021, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.562\tLabel_Loss: 1.2647\tTop_Loss: 1.7258\tBottom_Loss: 1.1218\tLoss: 4.1123\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.438\tLabel_Loss: 1.1688\tTop_Loss: 1.1698\tBottom_Loss: 1.1265\tLoss: 3.4652\t\n",
      "Subject: 022, n=05 | test_f1: 0.375 |best_f1: 0.375\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.594\tLabel_Loss: 0.9175\tTop_Loss: 1.0123\tBottom_Loss: 0.9711\tLoss: 2.9009\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.344\tLabel_Loss: 1.0963\tTop_Loss: 1.1576\tBottom_Loss: 1.0998\tLoss: 3.3537\t\n",
      "Subject: 022, n=05 | test_f1: 0.28571 |best_f1: 0.375\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.562\tLabel_Loss: 0.9679\tTop_Loss: 0.9259\tBottom_Loss: 1.1050\tLoss: 2.9988\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.594\tLabel_Loss: 0.9757\tTop_Loss: 0.9836\tBottom_Loss: 1.0231\tLoss: 2.9823\t\n",
      "Subject: 022, n=05 | test_f1: 0.28571 |best_f1: 0.375\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.500\tLabel_Loss: 0.9306\tTop_Loss: 0.7889\tBottom_Loss: 0.8559\tLoss: 2.5754\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.531\tLabel_Loss: 0.9824\tTop_Loss: 0.9656\tBottom_Loss: 0.9166\tLoss: 2.8646\t\n",
      "Subject: 022, n=05 | test_f1: 0.375 |best_f1: 0.375\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.500\tLabel_Loss: 0.8559\tTop_Loss: 0.9023\tBottom_Loss: 0.9494\tLoss: 2.7076\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6654\tTop_Loss: 0.6108\tBottom_Loss: 0.8480\tLoss: 2.1242\t\n",
      "Subject: 022, n=05 | test_f1: 0.375 |best_f1: 0.375\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5921\tTop_Loss: 0.7618\tBottom_Loss: 0.7841\tLoss: 2.1380\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.500\tLabel_Loss: 0.9430\tTop_Loss: 0.9424\tBottom_Loss: 1.0405\tLoss: 2.9259\t\n",
      "Subject: 022, n=05 | test_f1: 0.375 |best_f1: 0.375\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.688\tLabel_Loss: 0.8101\tTop_Loss: 0.6818\tBottom_Loss: 0.8813\tLoss: 2.3732\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7601\tTop_Loss: 0.7192\tBottom_Loss: 0.7198\tLoss: 2.1991\t\n",
      "Subject: 022, n=05 | test_f1: 0.7619 |best_f1: 0.7619\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.562\tLabel_Loss: 0.9377\tTop_Loss: 0.8629\tBottom_Loss: 0.9973\tLoss: 2.7979\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7641\tTop_Loss: 0.9005\tBottom_Loss: 0.8838\tLoss: 2.5485\t\n",
      "Subject: 022, n=05 | test_f1: 0.19048 |best_f1: 0.7619\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6222\tTop_Loss: 0.6884\tBottom_Loss: 0.8808\tLoss: 2.1914\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.500\tLabel_Loss: 0.9093\tTop_Loss: 1.0502\tBottom_Loss: 0.8000\tLoss: 2.7594\t\n",
      "Subject: 022, n=05 | test_f1: 0.22222 |best_f1: 0.7619\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6602\tTop_Loss: 0.5577\tBottom_Loss: 0.6776\tLoss: 1.8956\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8710\tTop_Loss: 0.8261\tBottom_Loss: 0.8869\tLoss: 2.5840\t\n",
      "Subject: 022, n=05 | test_f1: 0.8 |best_f1: 0.8\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6816\tTop_Loss: 0.6835\tBottom_Loss: 0.9498\tLoss: 2.3149\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.500\tLabel_Loss: 1.0879\tTop_Loss: 0.9959\tBottom_Loss: 0.9465\tLoss: 3.0303\t\n",
      "Subject: 022, n=05 | test_f1: 0.55556 |best_f1: 0.8\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7109\tTop_Loss: 0.7364\tBottom_Loss: 0.7210\tLoss: 2.1684\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6752\tTop_Loss: 0.6556\tBottom_Loss: 0.7775\tLoss: 2.1083\t\n",
      "Subject: 022, n=05 | test_f1: 0.7619 |best_f1: 0.8\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.812\tLabel_Loss: 0.6569\tTop_Loss: 0.5551\tBottom_Loss: 0.7104\tLoss: 1.9223\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.625\tLabel_Loss: 0.5944\tTop_Loss: 0.5722\tBottom_Loss: 0.8046\tLoss: 1.9712\t\n",
      "Subject: 022, n=05 | test_f1: 0.28571 |best_f1: 0.8\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6067\tTop_Loss: 0.6157\tBottom_Loss: 0.7166\tLoss: 1.9390\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.594\tLabel_Loss: 0.6950\tTop_Loss: 0.7687\tBottom_Loss: 0.7263\tLoss: 2.1899\t\n",
      "Subject: 022, n=05 | test_f1: 0.7619 |best_f1: 0.8\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.594\tLabel_Loss: 0.7054\tTop_Loss: 0.7330\tBottom_Loss: 0.8612\tLoss: 2.2996\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6405\tTop_Loss: 0.8881\tBottom_Loss: 0.7255\tLoss: 2.2540\t\n",
      "Subject: 022, n=05 | test_f1: 0.8 |best_f1: 0.8\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5927\tTop_Loss: 0.8680\tBottom_Loss: 0.6676\tLoss: 2.1283\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.594\tLabel_Loss: 0.9564\tTop_Loss: 0.9175\tBottom_Loss: 0.8873\tLoss: 2.7611\t\n",
      "Subject: 022, n=05 | test_f1: 0.58333 |best_f1: 0.8\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.562\tLabel_Loss: 0.7522\tTop_Loss: 0.6124\tBottom_Loss: 0.7532\tLoss: 2.1178\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7262\tTop_Loss: 0.6159\tBottom_Loss: 0.8981\tLoss: 2.2402\t\n",
      "Subject: 022, n=05 | test_f1: 0.58333 |best_f1: 0.8\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5684\tTop_Loss: 0.5877\tBottom_Loss: 0.6147\tLoss: 1.7708\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4170\tTop_Loss: 0.5687\tBottom_Loss: 0.7434\tLoss: 1.7291\t\n",
      "Subject: 022, n=05 | test_f1: 0.7619 |best_f1: 0.8\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4811\tTop_Loss: 0.6196\tBottom_Loss: 0.6304\tLoss: 1.7310\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5653\tTop_Loss: 0.6331\tBottom_Loss: 0.6985\tLoss: 1.8969\t\n",
      "Subject: 022, n=05 | test_f1: 0.13333 |best_f1: 0.8\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7067\tTop_Loss: 0.8298\tBottom_Loss: 0.7654\tLoss: 2.3019\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4594\tTop_Loss: 0.6194\tBottom_Loss: 0.6595\tLoss: 1.7384\t\n",
      "Subject: 022, n=05 | test_f1: 0.7619 |best_f1: 0.8\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5533\tTop_Loss: 0.7449\tBottom_Loss: 0.6940\tLoss: 1.9922\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5249\tTop_Loss: 0.6551\tBottom_Loss: 0.5859\tLoss: 1.7659\t\n",
      "Subject: 022, n=05 | test_f1: 0.8 |best_f1: 0.8\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4584\tTop_Loss: 0.5751\tBottom_Loss: 0.6218\tLoss: 1.6552\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5646\tTop_Loss: 0.5357\tBottom_Loss: 0.5642\tLoss: 1.6644\t\n",
      "Subject: 022, n=05 | test_f1: 0.55556 |best_f1: 0.8\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2775\tTop_Loss: 0.4412\tBottom_Loss: 0.3904\tLoss: 1.1091\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3253\tTop_Loss: 0.4679\tBottom_Loss: 0.4579\tLoss: 1.2511\t\n",
      "Subject: 022, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.938\tLabel_Loss: 0.3020\tTop_Loss: 0.3723\tBottom_Loss: 0.3494\tLoss: 1.0237\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.906\tLabel_Loss: 0.4082\tTop_Loss: 0.5717\tBottom_Loss: 0.5574\tLoss: 1.5373\t\n",
      "Subject: 022, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3825\tTop_Loss: 0.6169\tBottom_Loss: 0.5765\tLoss: 1.5759\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.750\tLabel_Loss: 0.4502\tTop_Loss: 0.3977\tBottom_Loss: 0.5706\tLoss: 1.4184\t\n",
      "Subject: 022, n=05 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3490\tTop_Loss: 0.4819\tBottom_Loss: 0.4700\tLoss: 1.3009\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6092\tTop_Loss: 0.5806\tBottom_Loss: 0.5693\tLoss: 1.7591\t\n",
      "Subject: 022, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4752\tTop_Loss: 0.4796\tBottom_Loss: 0.7176\tLoss: 1.6723\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2810\tTop_Loss: 0.4203\tBottom_Loss: 0.4956\tLoss: 1.1968\t\n",
      "Subject: 022, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2014\tTop_Loss: 0.3981\tBottom_Loss: 0.4099\tLoss: 1.0094\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4376\tTop_Loss: 0.3886\tBottom_Loss: 0.5268\tLoss: 1.3529\t\n",
      "Subject: 022, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3079\tTop_Loss: 0.4766\tBottom_Loss: 0.4468\tLoss: 1.2313\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3289\tTop_Loss: 0.4439\tBottom_Loss: 0.3689\tLoss: 1.1417\t\n",
      "Subject: 022, n=05 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4394\tTop_Loss: 0.5186\tBottom_Loss: 0.7236\tLoss: 1.6815\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4455\tTop_Loss: 0.5730\tBottom_Loss: 0.5140\tLoss: 1.5326\t\n",
      "Subject: 022, n=05 | test_f1: 0.58333 |best_f1: 1.0\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2155\tTop_Loss: 0.2798\tBottom_Loss: 0.3295\tLoss: 0.8248\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2150\tTop_Loss: 0.2451\tBottom_Loss: 0.2653\tLoss: 0.7255\t\n",
      "Subject: 022, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1801\tTop_Loss: 0.3130\tBottom_Loss: 0.2614\tLoss: 0.7545\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2838\tTop_Loss: 0.3140\tBottom_Loss: 0.5642\tLoss: 1.1621\t\n",
      "Subject: 022, n=05 | test_f1: 0.8 |best_f1: 1.0\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3348\tTop_Loss: 0.5267\tBottom_Loss: 0.4771\tLoss: 1.3386\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1686\tTop_Loss: 0.3397\tBottom_Loss: 0.3056\tLoss: 0.8139\t\n",
      "Subject: 022, n=05 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2108\tTop_Loss: 0.3835\tBottom_Loss: 0.2861\tLoss: 0.8804\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2484\tTop_Loss: 0.3028\tBottom_Loss: 0.4051\tLoss: 0.9564\t\n",
      "Subject: 022, n=05 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1841\tTop_Loss: 0.3578\tBottom_Loss: 0.2134\tLoss: 0.7553\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3372\tTop_Loss: 0.5849\tBottom_Loss: 0.4644\tLoss: 1.3865\t\n",
      "Subject: 022, n=05 | test_f1: 0.8 |best_f1: 1.0\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1337\tTop_Loss: 0.2978\tBottom_Loss: 0.2349\tLoss: 0.6663\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2279\tTop_Loss: 0.2988\tBottom_Loss: 0.2407\tLoss: 0.7674\t\n",
      "Subject: 022, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2669\tTop_Loss: 0.3560\tBottom_Loss: 0.2180\tLoss: 0.8409\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2025\tTop_Loss: 0.3971\tBottom_Loss: 0.3624\tLoss: 0.9620\t\n",
      "Subject: 022, n=05 | test_f1: 0.58333 |best_f1: 1.0\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0877\tTop_Loss: 0.2457\tBottom_Loss: 0.2165\tLoss: 0.5499\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2234\tTop_Loss: 0.3555\tBottom_Loss: 0.3729\tLoss: 0.9518\t\n",
      "Subject: 022, n=05 | test_f1: 0.58333 |best_f1: 1.0\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2157\tTop_Loss: 0.3662\tBottom_Loss: 0.2796\tLoss: 0.8615\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1806\tTop_Loss: 0.3024\tBottom_Loss: 0.3720\tLoss: 0.8550\t\n",
      "Subject: 022, n=05 | test_f1: 0.8 |best_f1: 1.0\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2144\tTop_Loss: 0.3142\tBottom_Loss: 0.3189\tLoss: 0.8474\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1835\tTop_Loss: 0.3947\tBottom_Loss: 0.3252\tLoss: 0.9033\t\n",
      "Subject: 022, n=05 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1609\tTop_Loss: 0.3410\tBottom_Loss: 0.2385\tLoss: 0.7404\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2276\tTop_Loss: 0.4193\tBottom_Loss: 0.2942\tLoss: 0.9410\t\n",
      "Subject: 022, n=05 | test_f1: 0.48889 |best_f1: 1.0\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2458\tTop_Loss: 0.3539\tBottom_Loss: 0.4224\tLoss: 1.0221\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1590\tTop_Loss: 0.3440\tBottom_Loss: 0.2345\tLoss: 0.7375\t\n",
      "Subject: 022, n=05 | test_f1: 0.58333 |best_f1: 1.0\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2347\tTop_Loss: 0.4042\tBottom_Loss: 0.3016\tLoss: 0.9405\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2321\tTop_Loss: 0.4117\tBottom_Loss: 0.4178\tLoss: 1.0616\t\n",
      "Subject: 022, n=05 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1898\tTop_Loss: 0.4000\tBottom_Loss: 0.2498\tLoss: 0.8396\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1490\tTop_Loss: 0.2228\tBottom_Loss: 0.2018\tLoss: 0.5737\t\n",
      "Subject: 022, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0904\tTop_Loss: 0.2641\tBottom_Loss: 0.1951\tLoss: 0.5495\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0945\tTop_Loss: 0.2702\tBottom_Loss: 0.2455\tLoss: 0.6102\t\n",
      "Subject: 022, n=05 | test_f1: 0.43333 |best_f1: 1.0\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1455\tTop_Loss: 0.2630\tBottom_Loss: 0.3593\tLoss: 0.7678\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1456\tTop_Loss: 0.2158\tBottom_Loss: 0.2701\tLoss: 0.6315\t\n",
      "Subject: 022, n=05 | test_f1: 0.58333 |best_f1: 1.0\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0979\tTop_Loss: 0.1995\tBottom_Loss: 0.1631\tLoss: 0.4605\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1542\tTop_Loss: 0.3669\tBottom_Loss: 0.3005\tLoss: 0.8216\t\n",
      "Subject: 022, n=05 | test_f1: 0.58333 |best_f1: 1.0\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1592\tTop_Loss: 0.2501\tBottom_Loss: 0.2260\tLoss: 0.6353\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1679\tTop_Loss: 0.2818\tBottom_Loss: 0.3136\tLoss: 0.7634\t\n",
      "Subject: 022, n=05 | test_f1: 0.58333 |best_f1: 1.0\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1262\tTop_Loss: 0.2841\tBottom_Loss: 0.1565\tLoss: 0.5668\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0676\tTop_Loss: 0.3398\tBottom_Loss: 0.1307\tLoss: 0.5381\t\n",
      "Subject: 022, n=05 | test_f1: 0.58333 |best_f1: 1.0\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1276\tTop_Loss: 0.3060\tBottom_Loss: 0.2474\tLoss: 0.6810\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1489\tTop_Loss: 0.2189\tBottom_Loss: 0.3114\tLoss: 0.6792\t\n",
      "Subject: 022, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1634\tTop_Loss: 0.2021\tBottom_Loss: 0.2065\tLoss: 0.5720\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1745\tTop_Loss: 0.1972\tBottom_Loss: 0.2200\tLoss: 0.5917\t\n",
      "Subject: 022, n=05 | test_f1: 0.58333 |best_f1: 1.0\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1580\tTop_Loss: 0.2806\tBottom_Loss: 0.2362\tLoss: 0.6747\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0750\tTop_Loss: 0.1675\tBottom_Loss: 0.2422\tLoss: 0.4848\t\n",
      "Subject: 022, n=05 | test_f1: 0.58333 |best_f1: 1.0\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1395\tTop_Loss: 0.2817\tBottom_Loss: 0.1761\tLoss: 0.5973\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1061\tTop_Loss: 0.3216\tBottom_Loss: 0.1905\tLoss: 0.6182\t\n",
      "Subject: 022, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1139\tTop_Loss: 0.1983\tBottom_Loss: 0.1732\tLoss: 0.4854\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1076\tTop_Loss: 0.1870\tBottom_Loss: 0.1772\tLoss: 0.4719\t\n",
      "Subject: 022, n=05 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0476\tTop_Loss: 0.1464\tBottom_Loss: 0.1703\tLoss: 0.3643\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1054\tTop_Loss: 0.3379\tBottom_Loss: 0.1683\tLoss: 0.6116\t\n",
      "Subject: 022, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0949\tTop_Loss: 0.1929\tBottom_Loss: 0.1221\tLoss: 0.4098\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1061\tTop_Loss: 0.2260\tBottom_Loss: 0.2341\tLoss: 0.5662\t\n",
      "Subject: 022, n=05 | test_f1: 0.58333 |best_f1: 1.0\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1282\tTop_Loss: 0.1252\tBottom_Loss: 0.2286\tLoss: 0.4820\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2411\tTop_Loss: 0.3365\tBottom_Loss: 0.3704\tLoss: 0.9480\t\n",
      "Subject: 022, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0933\tTop_Loss: 0.2577\tBottom_Loss: 0.1536\tLoss: 0.5047\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0322\tTop_Loss: 0.0635\tBottom_Loss: 0.1162\tLoss: 0.2119\t\n",
      "Subject: 022, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0989\tTop_Loss: 0.1384\tBottom_Loss: 0.2067\tLoss: 0.4441\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0544\tTop_Loss: 0.1860\tBottom_Loss: 0.1415\tLoss: 0.3818\t\n",
      "Subject: 022, n=05 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0268\tTop_Loss: 0.1364\tBottom_Loss: 0.1073\tLoss: 0.2705\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0535\tTop_Loss: 0.1007\tBottom_Loss: 0.1413\tLoss: 0.2956\t\n",
      "Subject: 022, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0908\tTop_Loss: 0.2302\tBottom_Loss: 0.1556\tLoss: 0.4766\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0458\tTop_Loss: 0.1703\tBottom_Loss: 0.0699\tLoss: 0.2860\t\n",
      "Subject: 022, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0325\tTop_Loss: 0.1125\tBottom_Loss: 0.0814\tLoss: 0.2264\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1359\tTop_Loss: 0.1413\tBottom_Loss: 0.1732\tLoss: 0.4504\t\n",
      "Subject: 022, n=05 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 0.938\tLabel_Loss: 0.0988\tTop_Loss: 0.1354\tBottom_Loss: 0.1790\tLoss: 0.4133\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1476\tTop_Loss: 0.1828\tBottom_Loss: 0.2360\tLoss: 0.5663\t\n",
      "Subject: 022, n=05 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0621\tTop_Loss: 0.1228\tBottom_Loss: 0.1060\tLoss: 0.2909\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0886\tTop_Loss: 0.1748\tBottom_Loss: 0.1366\tLoss: 0.4000\t\n",
      "Subject: 022, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0231\tTop_Loss: 0.1064\tBottom_Loss: 0.0520\tLoss: 0.1816\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0926\tTop_Loss: 0.2465\tBottom_Loss: 0.1813\tLoss: 0.5204\t\n",
      "Subject: 022, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1060\tTop_Loss: 0.1268\tBottom_Loss: 0.1438\tLoss: 0.3766\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0468\tTop_Loss: 0.0742\tBottom_Loss: 0.2066\tLoss: 0.3275\t\n",
      "Subject: 022, n=05 | test_f1: 0.43333 |best_f1: 1.0\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0378\tTop_Loss: 0.0772\tBottom_Loss: 0.0702\tLoss: 0.1852\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0263\tTop_Loss: 0.0713\tBottom_Loss: 0.0899\tLoss: 0.1874\t\n",
      "Subject: 022, n=05 | test_f1: 0.58333 |best_f1: 1.0\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0536\tTop_Loss: 0.1730\tBottom_Loss: 0.0589\tLoss: 0.2855\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0343\tTop_Loss: 0.1583\tBottom_Loss: 0.0617\tLoss: 0.2543\t\n",
      "Subject: 022, n=05 | test_f1: 0.8 |best_f1: 1.0\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0193\tTop_Loss: 0.0654\tBottom_Loss: 0.0324\tLoss: 0.1171\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0288\tTop_Loss: 0.1096\tBottom_Loss: 0.0378\tLoss: 0.1761\t\n",
      "Subject: 022, n=05 | test_f1: 0.58333 |best_f1: 1.0\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0351\tTop_Loss: 0.0825\tBottom_Loss: 0.0907\tLoss: 0.2084\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0283\tTop_Loss: 0.1078\tBottom_Loss: 0.0382\tLoss: 0.1743\t\n",
      "Subject: 022, n=05 | test_f1: 0.58333 |best_f1: 1.0\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0232\tTop_Loss: 0.1440\tBottom_Loss: 0.0607\tLoss: 0.2280\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0545\tTop_Loss: 0.1056\tBottom_Loss: 0.0852\tLoss: 0.2453\t\n",
      "Subject: 022, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1415\tTop_Loss: 0.2840\tBottom_Loss: 0.1876\tLoss: 0.6132\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0336\tTop_Loss: 0.1474\tBottom_Loss: 0.0751\tLoss: 0.2562\t\n",
      "Subject: 022, n=05 | test_f1: 0.58333 |best_f1: 1.0\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0490\tTop_Loss: 0.2314\tBottom_Loss: 0.0672\tLoss: 0.3476\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0853\tTop_Loss: 0.0868\tBottom_Loss: 0.3027\tLoss: 0.4748\t\n",
      "Subject: 022, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 0.938\tLabel_Loss: 0.0812\tTop_Loss: 0.1290\tBottom_Loss: 0.0739\tLoss: 0.2840\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0116\tTop_Loss: 0.0764\tBottom_Loss: 0.0376\tLoss: 0.1256\t\n",
      "Subject: 022, n=05 | test_f1: 0.58333 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0804\tTop_Loss: 0.2022\tBottom_Loss: 0.1086\tLoss: 0.3911\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0287\tTop_Loss: 0.0740\tBottom_Loss: 0.1161\tLoss: 0.2188\t\n",
      "Subject: 022, n=05 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0221\tTop_Loss: 0.1192\tBottom_Loss: 0.0470\tLoss: 0.1883\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0403\tTop_Loss: 0.0708\tBottom_Loss: 0.1976\tLoss: 0.3087\t\n",
      "Subject: 022, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0281\tTop_Loss: 0.1029\tBottom_Loss: 0.0696\tLoss: 0.2005\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0118\tTop_Loss: 0.0274\tBottom_Loss: 0.0548\tLoss: 0.0940\t\n",
      "Subject: 022, n=05 | test_f1: 0.58333 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0639\tTop_Loss: 0.1544\tBottom_Loss: 0.1800\tLoss: 0.3984\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0387\tTop_Loss: 0.0932\tBottom_Loss: 0.0308\tLoss: 0.1627\t\n",
      "Subject: 022, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0288\tTop_Loss: 0.0613\tBottom_Loss: 0.0590\tLoss: 0.1491\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0249\tTop_Loss: 0.0498\tBottom_Loss: 0.0516\tLoss: 0.1262\t\n",
      "Subject: 022, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0077\tTop_Loss: 0.0512\tBottom_Loss: 0.0286\tLoss: 0.0874\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0252\tTop_Loss: 0.0626\tBottom_Loss: 0.0588\tLoss: 0.1465\t\n",
      "Subject: 022, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0166\tTop_Loss: 0.0860\tBottom_Loss: 0.0703\tLoss: 0.1728\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0218\tTop_Loss: 0.0902\tBottom_Loss: 0.0451\tLoss: 0.1571\t\n",
      "Subject: 022, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0199\tTop_Loss: 0.1080\tBottom_Loss: 0.0248\tLoss: 0.1527\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0166\tTop_Loss: 0.0964\tBottom_Loss: 0.0409\tLoss: 0.1539\t\n",
      "Subject: 022, n=05 | test_f1: 0.58333 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1103\tTop_Loss: 0.1504\tBottom_Loss: 0.2183\tLoss: 0.4790\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0129\tTop_Loss: 0.0782\tBottom_Loss: 0.0485\tLoss: 0.1396\t\n",
      "Subject: 022, n=05 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0622\tTop_Loss: 0.0954\tBottom_Loss: 0.0887\tLoss: 0.2463\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0135\tTop_Loss: 0.0414\tBottom_Loss: 0.0489\tLoss: 0.1039\t\n",
      "Subject: 022, n=05 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0287\tTop_Loss: 0.0354\tBottom_Loss: 0.0642\tLoss: 0.1283\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0147\tTop_Loss: 0.0397\tBottom_Loss: 0.0396\tLoss: 0.0940\t\n",
      "Subject: 022, n=05 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0204\tTop_Loss: 0.1032\tBottom_Loss: 0.0455\tLoss: 0.1691\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0088\tTop_Loss: 0.0366\tBottom_Loss: 0.0242\tLoss: 0.0695\t\n",
      "Subject: 022, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1069\tTop_Loss: 0.1442\tBottom_Loss: 0.2652\tLoss: 0.5163\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1362\tTop_Loss: 0.1236\tBottom_Loss: 0.1788\tLoss: 0.4386\t\n",
      "Subject: 022, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0206\tTop_Loss: 0.0753\tBottom_Loss: 0.0399\tLoss: 0.1359\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0244\tTop_Loss: 0.0643\tBottom_Loss: 0.0338\tLoss: 0.1226\t\n",
      "Subject: 022, n=05 | test_f1: 0.58333 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0539\tTop_Loss: 0.0913\tBottom_Loss: 0.0902\tLoss: 0.2354\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0310\tTop_Loss: 0.0412\tBottom_Loss: 0.0918\tLoss: 0.1641\t\n",
      "Subject: 022, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0209\tTop_Loss: 0.0358\tBottom_Loss: 0.0569\tLoss: 0.1136\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0186\tTop_Loss: 0.0448\tBottom_Loss: 0.0468\tLoss: 0.1103\t\n",
      "Subject: 022, n=05 | test_f1: 0.58333 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0185\tTop_Loss: 0.0413\tBottom_Loss: 0.0761\tLoss: 0.1359\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0249\tTop_Loss: 0.0417\tBottom_Loss: 0.0363\tLoss: 0.1030\t\n",
      "Subject: 022, n=05 | test_f1: 0.28571 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0131\tTop_Loss: 0.0767\tBottom_Loss: 0.0335\tLoss: 0.1233\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0314\tTop_Loss: 0.1469\tBottom_Loss: 0.1334\tLoss: 0.3117\t\n",
      "Subject: 022, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0184\tTop_Loss: 0.1398\tBottom_Loss: 0.0254\tLoss: 0.1835\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0200\tTop_Loss: 0.0421\tBottom_Loss: 0.1036\tLoss: 0.1657\t\n",
      "Subject: 022, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0127\tTop_Loss: 0.0493\tBottom_Loss: 0.0273\tLoss: 0.0894\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0164\tTop_Loss: 0.0400\tBottom_Loss: 0.0885\tLoss: 0.1448\t\n",
      "Subject: 022, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0073\tTop_Loss: 0.0280\tBottom_Loss: 0.0286\tLoss: 0.0639\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0074\tTop_Loss: 0.0362\tBottom_Loss: 0.0338\tLoss: 0.0774\t\n",
      "Subject: 022, n=05 | test_f1: 0.58333 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0046\tTop_Loss: 0.0269\tBottom_Loss: 0.0157\tLoss: 0.0472\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0096\tTop_Loss: 0.0386\tBottom_Loss: 0.0304\tLoss: 0.0786\t\n",
      "Subject: 022, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0049\tTop_Loss: 0.0259\tBottom_Loss: 0.0174\tLoss: 0.0483\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0056\tTop_Loss: 0.0342\tBottom_Loss: 0.0185\tLoss: 0.0583\t\n",
      "Subject: 022, n=05 | test_f1: 0.58333 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0324\tTop_Loss: 0.0250\tBottom_Loss: 0.0466\tLoss: 0.1039\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0240\tTop_Loss: 0.0610\tBottom_Loss: 0.0409\tLoss: 0.1259\t\n",
      "Subject: 022, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0048\tTop_Loss: 0.0133\tBottom_Loss: 0.0125\tLoss: 0.0306\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0127\tTop_Loss: 0.0367\tBottom_Loss: 0.0752\tLoss: 0.1246\t\n",
      "Subject: 022, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0101\tTop_Loss: 0.0189\tBottom_Loss: 0.0491\tLoss: 0.0781\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0063\tTop_Loss: 0.0168\tBottom_Loss: 0.0225\tLoss: 0.0456\t\n",
      "Subject: 022, n=05 | test_f1: 0.58333 |best_f1: 1.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.312\tLabel_Loss: 1.4155\tTop_Loss: 1.1286\tBottom_Loss: 2.0550\tLoss: 4.5990\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.562\tLabel_Loss: 1.0407\tTop_Loss: 1.1043\tBottom_Loss: 1.0259\tLoss: 3.1708\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.500\tLabel_Loss: 0.9562\tTop_Loss: 1.0336\tBottom_Loss: 1.1825\tLoss: 3.1723\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.562\tLabel_Loss: 0.9795\tTop_Loss: 1.0244\tBottom_Loss: 0.9108\tLoss: 2.9147\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.625\tLabel_Loss: 0.9100\tTop_Loss: 0.9250\tBottom_Loss: 0.9318\tLoss: 2.7667\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.531\tLabel_Loss: 1.1084\tTop_Loss: 1.0339\tBottom_Loss: 1.1300\tLoss: 3.2722\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.656\tLabel_Loss: 0.8747\tTop_Loss: 0.8628\tBottom_Loss: 0.9914\tLoss: 2.7289\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8955\tTop_Loss: 0.7975\tBottom_Loss: 0.9719\tLoss: 2.6650\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.469\tLabel_Loss: 1.1944\tTop_Loss: 1.3542\tBottom_Loss: 1.1135\tLoss: 3.6621\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.656\tLabel_Loss: 0.8739\tTop_Loss: 0.9754\tBottom_Loss: 0.9049\tLoss: 2.7541\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8072\tTop_Loss: 0.8537\tBottom_Loss: 0.8779\tLoss: 2.5388\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.562\tLabel_Loss: 0.9221\tTop_Loss: 0.8449\tBottom_Loss: 0.9383\tLoss: 2.7052\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.594\tLabel_Loss: 0.9494\tTop_Loss: 0.9420\tBottom_Loss: 0.9958\tLoss: 2.8872\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7389\tTop_Loss: 0.8034\tBottom_Loss: 0.7172\tLoss: 2.2594\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.656\tLabel_Loss: 0.6751\tTop_Loss: 0.7010\tBottom_Loss: 0.8306\tLoss: 2.2068\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.531\tLabel_Loss: 0.9242\tTop_Loss: 0.9843\tBottom_Loss: 1.0688\tLoss: 2.9773\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7405\tTop_Loss: 0.6728\tBottom_Loss: 0.8664\tLoss: 2.2797\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.625\tLabel_Loss: 0.9045\tTop_Loss: 1.0242\tBottom_Loss: 0.8843\tLoss: 2.8130\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6723\tTop_Loss: 0.7579\tBottom_Loss: 0.7015\tLoss: 2.1317\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8419\tTop_Loss: 0.8739\tBottom_Loss: 0.9241\tLoss: 2.6399\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.469\tLabel_Loss: 0.9614\tTop_Loss: 1.0621\tBottom_Loss: 1.0094\tLoss: 3.0329\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7293\tTop_Loss: 0.8437\tBottom_Loss: 0.9238\tLoss: 2.4967\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5183\tTop_Loss: 0.6173\tBottom_Loss: 0.5864\tLoss: 1.7220\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.562\tLabel_Loss: 0.8974\tTop_Loss: 0.7861\tBottom_Loss: 0.8940\tLoss: 2.5775\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.625\tLabel_Loss: 0.9130\tTop_Loss: 0.9529\tBottom_Loss: 0.8907\tLoss: 2.7565\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.656\tLabel_Loss: 0.5932\tTop_Loss: 0.7929\tBottom_Loss: 0.8391\tLoss: 2.2252\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.562\tLabel_Loss: 0.7145\tTop_Loss: 0.8158\tBottom_Loss: 0.8822\tLoss: 2.4125\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.719\tLabel_Loss: 0.5530\tTop_Loss: 0.6574\tBottom_Loss: 0.8321\tLoss: 2.0425\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.688\tLabel_Loss: 0.8124\tTop_Loss: 0.7313\tBottom_Loss: 0.9291\tLoss: 2.4729\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.719\tLabel_Loss: 0.5124\tTop_Loss: 0.6718\tBottom_Loss: 0.6055\tLoss: 1.7896\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6906\tTop_Loss: 0.8301\tBottom_Loss: 0.6011\tLoss: 2.1218\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3440\tTop_Loss: 0.6655\tBottom_Loss: 0.4331\tLoss: 1.4426\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5277\tTop_Loss: 0.6262\tBottom_Loss: 0.6459\tLoss: 1.7998\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4639\tTop_Loss: 0.5929\tBottom_Loss: 0.5547\tLoss: 1.6115\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.875\tLabel_Loss: 0.5066\tTop_Loss: 0.5624\tBottom_Loss: 0.5875\tLoss: 1.6564\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4288\tTop_Loss: 0.6386\tBottom_Loss: 0.5104\tLoss: 1.5778\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4731\tTop_Loss: 0.4858\tBottom_Loss: 0.6291\tLoss: 1.5880\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6568\tTop_Loss: 0.7548\tBottom_Loss: 0.8100\tLoss: 2.2216\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.844\tLabel_Loss: 0.5850\tTop_Loss: 0.8097\tBottom_Loss: 0.5923\tLoss: 1.9870\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6218\tTop_Loss: 0.7219\tBottom_Loss: 0.6969\tLoss: 2.0407\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4783\tTop_Loss: 0.5694\tBottom_Loss: 0.5788\tLoss: 1.6265\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8244\tTop_Loss: 0.8250\tBottom_Loss: 0.8568\tLoss: 2.5061\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4421\tTop_Loss: 0.4656\tBottom_Loss: 0.5562\tLoss: 1.4639\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3696\tTop_Loss: 0.4244\tBottom_Loss: 0.5814\tLoss: 1.3754\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.906\tLabel_Loss: 0.4348\tTop_Loss: 0.5397\tBottom_Loss: 0.5491\tLoss: 1.5236\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.719\tLabel_Loss: 0.5952\tTop_Loss: 0.7170\tBottom_Loss: 0.6656\tLoss: 1.9778\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5904\tTop_Loss: 0.6817\tBottom_Loss: 0.6088\tLoss: 1.8808\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3601\tTop_Loss: 0.4203\tBottom_Loss: 0.4609\tLoss: 1.2413\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4435\tTop_Loss: 0.4735\tBottom_Loss: 0.5996\tLoss: 1.5166\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3668\tTop_Loss: 0.5614\tBottom_Loss: 0.5435\tLoss: 1.4717\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3723\tTop_Loss: 0.5574\tBottom_Loss: 0.4555\tLoss: 1.3852\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.750\tLabel_Loss: 0.7207\tTop_Loss: 0.8300\tBottom_Loss: 0.7479\tLoss: 2.2986\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2830\tTop_Loss: 0.3323\tBottom_Loss: 0.4448\tLoss: 1.0602\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.969\tLabel_Loss: 0.3457\tTop_Loss: 0.4241\tBottom_Loss: 0.4377\tLoss: 1.2074\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3951\tTop_Loss: 0.3930\tBottom_Loss: 0.4861\tLoss: 1.2742\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1495\tTop_Loss: 0.4375\tBottom_Loss: 0.2476\tLoss: 0.8346\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2521\tTop_Loss: 0.3181\tBottom_Loss: 0.4521\tLoss: 1.0223\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3915\tTop_Loss: 0.6545\tBottom_Loss: 0.6120\tLoss: 1.6580\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4065\tTop_Loss: 0.4852\tBottom_Loss: 0.4122\tLoss: 1.3039\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3608\tTop_Loss: 0.4913\tBottom_Loss: 0.3826\tLoss: 1.2346\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3283\tTop_Loss: 0.3711\tBottom_Loss: 0.4886\tLoss: 1.1880\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3647\tTop_Loss: 0.4516\tBottom_Loss: 0.4753\tLoss: 1.2916\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2230\tTop_Loss: 0.4615\tBottom_Loss: 0.2629\tLoss: 0.9473\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2128\tTop_Loss: 0.3888\tBottom_Loss: 0.4133\tLoss: 1.0149\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3707\tTop_Loss: 0.5484\tBottom_Loss: 0.3107\tLoss: 1.2298\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.750\tLabel_Loss: 0.4988\tTop_Loss: 0.5284\tBottom_Loss: 0.4231\tLoss: 1.4502\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3231\tTop_Loss: 0.3329\tBottom_Loss: 0.4901\tLoss: 1.1461\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2130\tTop_Loss: 0.3101\tBottom_Loss: 0.3268\tLoss: 0.8499\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2917\tTop_Loss: 0.5304\tBottom_Loss: 0.3941\tLoss: 1.2163\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2472\tTop_Loss: 0.4466\tBottom_Loss: 0.5194\tLoss: 1.2133\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.844\tLabel_Loss: 0.5064\tTop_Loss: 0.5675\tBottom_Loss: 0.5062\tLoss: 1.5801\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3365\tTop_Loss: 0.4011\tBottom_Loss: 0.4618\tLoss: 1.1993\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2511\tTop_Loss: 0.4168\tBottom_Loss: 0.2943\tLoss: 0.9621\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1678\tTop_Loss: 0.3576\tBottom_Loss: 0.2446\tLoss: 0.7700\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2130\tTop_Loss: 0.3014\tBottom_Loss: 0.3088\tLoss: 0.8233\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3485\tTop_Loss: 0.5602\tBottom_Loss: 0.6111\tLoss: 1.5198\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3022\tTop_Loss: 0.3795\tBottom_Loss: 0.3653\tLoss: 1.0470\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1390\tTop_Loss: 0.3283\tBottom_Loss: 0.2908\tLoss: 0.7580\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2354\tTop_Loss: 0.4144\tBottom_Loss: 0.2701\tLoss: 0.9199\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1995\tTop_Loss: 0.4573\tBottom_Loss: 0.2482\tLoss: 0.9050\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2026\tTop_Loss: 0.3555\tBottom_Loss: 0.4063\tLoss: 0.9644\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3094\tTop_Loss: 0.3348\tBottom_Loss: 0.3168\tLoss: 0.9610\t\n",
      "Subject: 023, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1186\tTop_Loss: 0.2636\tBottom_Loss: 0.2442\tLoss: 0.6264\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.844\tLabel_Loss: 0.2739\tTop_Loss: 0.3239\tBottom_Loss: 0.4195\tLoss: 1.0173\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2168\tTop_Loss: 0.3055\tBottom_Loss: 0.3123\tLoss: 0.8345\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1919\tTop_Loss: 0.2162\tBottom_Loss: 0.2816\tLoss: 0.6897\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1026\tTop_Loss: 0.1840\tBottom_Loss: 0.1946\tLoss: 0.4811\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2521\tTop_Loss: 0.3093\tBottom_Loss: 0.2995\tLoss: 0.8609\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1619\tTop_Loss: 0.4052\tBottom_Loss: 0.2405\tLoss: 0.8076\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1453\tTop_Loss: 0.3079\tBottom_Loss: 0.2000\tLoss: 0.6533\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1182\tTop_Loss: 0.2034\tBottom_Loss: 0.2519\tLoss: 0.5735\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2778\tTop_Loss: 0.5679\tBottom_Loss: 0.2478\tLoss: 1.0935\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0842\tTop_Loss: 0.2915\tBottom_Loss: 0.1827\tLoss: 0.5583\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1628\tTop_Loss: 0.2111\tBottom_Loss: 0.2613\tLoss: 0.6352\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1247\tTop_Loss: 0.3106\tBottom_Loss: 0.2153\tLoss: 0.6506\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.844\tLabel_Loss: 0.2967\tTop_Loss: 0.4489\tBottom_Loss: 0.4169\tLoss: 1.1626\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1596\tTop_Loss: 0.2562\tBottom_Loss: 0.2216\tLoss: 0.6374\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0932\tTop_Loss: 0.1788\tBottom_Loss: 0.2278\tLoss: 0.4998\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1063\tTop_Loss: 0.3956\tBottom_Loss: 0.1563\tLoss: 0.6582\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0808\tTop_Loss: 0.2005\tBottom_Loss: 0.1090\tLoss: 0.3902\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1060\tTop_Loss: 0.1751\tBottom_Loss: 0.2381\tLoss: 0.5192\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1069\tTop_Loss: 0.2754\tBottom_Loss: 0.1838\tLoss: 0.5661\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1619\tTop_Loss: 0.2496\tBottom_Loss: 0.3109\tLoss: 0.7225\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0789\tTop_Loss: 0.2550\tBottom_Loss: 0.1913\tLoss: 0.5253\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0529\tTop_Loss: 0.1959\tBottom_Loss: 0.1154\tLoss: 0.3641\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1767\tTop_Loss: 0.2722\tBottom_Loss: 0.2025\tLoss: 0.6515\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0795\tTop_Loss: 0.2346\tBottom_Loss: 0.1069\tLoss: 0.4210\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1516\tTop_Loss: 0.4137\tBottom_Loss: 0.1215\tLoss: 0.6868\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1298\tTop_Loss: 0.3006\tBottom_Loss: 0.2079\tLoss: 0.6383\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2047\tTop_Loss: 0.2822\tBottom_Loss: 0.3194\tLoss: 0.8063\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0563\tTop_Loss: 0.2326\tBottom_Loss: 0.0729\tLoss: 0.3618\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0866\tTop_Loss: 0.1768\tBottom_Loss: 0.1188\tLoss: 0.3822\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1324\tTop_Loss: 0.2012\tBottom_Loss: 0.2438\tLoss: 0.5774\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1214\tTop_Loss: 0.1371\tBottom_Loss: 0.1623\tLoss: 0.4207\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1180\tTop_Loss: 0.2270\tBottom_Loss: 0.1378\tLoss: 0.4828\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 0.938\tLabel_Loss: 0.0912\tTop_Loss: 0.1823\tBottom_Loss: 0.1454\tLoss: 0.4189\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0475\tTop_Loss: 0.1140\tBottom_Loss: 0.1671\tLoss: 0.3286\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0649\tTop_Loss: 0.1480\tBottom_Loss: 0.1002\tLoss: 0.3131\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0607\tTop_Loss: 0.1543\tBottom_Loss: 0.1460\tLoss: 0.3611\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0910\tTop_Loss: 0.1442\tBottom_Loss: 0.2379\tLoss: 0.4731\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0991\tTop_Loss: 0.1981\tBottom_Loss: 0.1510\tLoss: 0.4482\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0515\tTop_Loss: 0.1419\tBottom_Loss: 0.1365\tLoss: 0.3299\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0566\tTop_Loss: 0.1462\tBottom_Loss: 0.0891\tLoss: 0.2918\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0462\tTop_Loss: 0.1147\tBottom_Loss: 0.0451\tLoss: 0.2060\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0829\tTop_Loss: 0.2215\tBottom_Loss: 0.1125\tLoss: 0.4168\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0671\tTop_Loss: 0.2263\tBottom_Loss: 0.1833\tLoss: 0.4767\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1001\tTop_Loss: 0.1399\tBottom_Loss: 0.1685\tLoss: 0.4085\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0323\tTop_Loss: 0.1132\tBottom_Loss: 0.0919\tLoss: 0.2373\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0993\tTop_Loss: 0.1678\tBottom_Loss: 0.2006\tLoss: 0.4677\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0901\tTop_Loss: 0.3098\tBottom_Loss: 0.0931\tLoss: 0.4929\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0525\tTop_Loss: 0.0725\tBottom_Loss: 0.1448\tLoss: 0.2698\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0603\tTop_Loss: 0.1034\tBottom_Loss: 0.1036\tLoss: 0.2674\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0681\tTop_Loss: 0.1801\tBottom_Loss: 0.1011\tLoss: 0.3493\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0653\tTop_Loss: 0.1082\tBottom_Loss: 0.1311\tLoss: 0.3046\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0620\tTop_Loss: 0.1661\tBottom_Loss: 0.0896\tLoss: 0.3178\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0305\tTop_Loss: 0.0686\tBottom_Loss: 0.0507\tLoss: 0.1499\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0510\tTop_Loss: 0.1570\tBottom_Loss: 0.0732\tLoss: 0.2812\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0447\tTop_Loss: 0.0632\tBottom_Loss: 0.1061\tLoss: 0.2139\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0546\tTop_Loss: 0.0996\tBottom_Loss: 0.1013\tLoss: 0.2555\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0316\tTop_Loss: 0.0495\tBottom_Loss: 0.1041\tLoss: 0.1851\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0560\tTop_Loss: 0.1095\tBottom_Loss: 0.1650\tLoss: 0.3305\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0606\tTop_Loss: 0.0909\tBottom_Loss: 0.1416\tLoss: 0.2931\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0490\tTop_Loss: 0.1540\tBottom_Loss: 0.1252\tLoss: 0.3282\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0496\tTop_Loss: 0.1594\tBottom_Loss: 0.0601\tLoss: 0.2691\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0217\tTop_Loss: 0.0676\tBottom_Loss: 0.0504\tLoss: 0.1396\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0208\tTop_Loss: 0.0982\tBottom_Loss: 0.0483\tLoss: 0.1672\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0479\tTop_Loss: 0.1354\tBottom_Loss: 0.0748\tLoss: 0.2581\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0875\tTop_Loss: 0.1631\tBottom_Loss: 0.1423\tLoss: 0.3929\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0375\tTop_Loss: 0.1223\tBottom_Loss: 0.0404\tLoss: 0.2002\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0969\tTop_Loss: 0.1514\tBottom_Loss: 0.1926\tLoss: 0.4409\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0170\tTop_Loss: 0.0808\tBottom_Loss: 0.0586\tLoss: 0.1564\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0210\tTop_Loss: 0.0434\tBottom_Loss: 0.0655\tLoss: 0.1298\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0617\tTop_Loss: 0.1426\tBottom_Loss: 0.0569\tLoss: 0.2612\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0654\tTop_Loss: 0.1211\tBottom_Loss: 0.0697\tLoss: 0.2561\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0302\tTop_Loss: 0.1351\tBottom_Loss: 0.0659\tLoss: 0.2312\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0188\tTop_Loss: 0.1258\tBottom_Loss: 0.0358\tLoss: 0.1805\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0442\tTop_Loss: 0.1200\tBottom_Loss: 0.1024\tLoss: 0.2667\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0476\tTop_Loss: 0.0651\tBottom_Loss: 0.0643\tLoss: 0.1770\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0180\tTop_Loss: 0.0718\tBottom_Loss: 0.0326\tLoss: 0.1225\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0178\tTop_Loss: 0.0344\tBottom_Loss: 0.0367\tLoss: 0.0889\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0259\tTop_Loss: 0.0809\tBottom_Loss: 0.0373\tLoss: 0.1441\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0218\tTop_Loss: 0.0954\tBottom_Loss: 0.0343\tLoss: 0.1515\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 0.938\tLabel_Loss: 0.0843\tTop_Loss: 0.1148\tBottom_Loss: 0.0663\tLoss: 0.2654\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0166\tTop_Loss: 0.0575\tBottom_Loss: 0.0557\tLoss: 0.1299\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0567\tTop_Loss: 0.0925\tBottom_Loss: 0.0899\tLoss: 0.2391\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0192\tTop_Loss: 0.0859\tBottom_Loss: 0.0336\tLoss: 0.1387\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0644\tTop_Loss: 0.1492\tBottom_Loss: 0.0864\tLoss: 0.3000\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0155\tTop_Loss: 0.0409\tBottom_Loss: 0.0252\tLoss: 0.0817\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0329\tTop_Loss: 0.0456\tBottom_Loss: 0.0602\tLoss: 0.1387\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0491\tTop_Loss: 0.0832\tBottom_Loss: 0.0895\tLoss: 0.2219\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0638\tTop_Loss: 0.0992\tBottom_Loss: 0.0540\tLoss: 0.2170\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0111\tTop_Loss: 0.0535\tBottom_Loss: 0.0285\tLoss: 0.0931\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0179\tTop_Loss: 0.0525\tBottom_Loss: 0.0360\tLoss: 0.1063\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0179\tTop_Loss: 0.0188\tBottom_Loss: 0.0744\tLoss: 0.1112\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0277\tTop_Loss: 0.0788\tBottom_Loss: 0.0681\tLoss: 0.1747\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0080\tTop_Loss: 0.0374\tBottom_Loss: 0.0529\tLoss: 0.0984\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0081\tTop_Loss: 0.0425\tBottom_Loss: 0.0264\tLoss: 0.0770\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0939\tTop_Loss: 0.1226\tBottom_Loss: 0.0996\tLoss: 0.3161\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0076\tTop_Loss: 0.0528\tBottom_Loss: 0.0222\tLoss: 0.0826\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0097\tTop_Loss: 0.0674\tBottom_Loss: 0.0318\tLoss: 0.1089\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0433\tTop_Loss: 0.0855\tBottom_Loss: 0.0467\tLoss: 0.1754\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0222\tTop_Loss: 0.0455\tBottom_Loss: 0.0215\tLoss: 0.0891\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0428\tTop_Loss: 0.0824\tBottom_Loss: 0.1039\tLoss: 0.2291\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0218\tTop_Loss: 0.0242\tBottom_Loss: 0.0606\tLoss: 0.1067\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0133\tTop_Loss: 0.0351\tBottom_Loss: 0.0231\tLoss: 0.0716\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0171\tTop_Loss: 0.0293\tBottom_Loss: 0.0416\tLoss: 0.0880\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0233\tTop_Loss: 0.0367\tBottom_Loss: 0.0321\tLoss: 0.0921\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0165\tTop_Loss: 0.0240\tBottom_Loss: 0.0292\tLoss: 0.0696\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0095\tTop_Loss: 0.0172\tBottom_Loss: 0.0456\tLoss: 0.0722\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0201\tTop_Loss: 0.0507\tBottom_Loss: 0.0557\tLoss: 0.1265\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0072\tTop_Loss: 0.0314\tBottom_Loss: 0.0164\tLoss: 0.0550\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0108\tTop_Loss: 0.0411\tBottom_Loss: 0.0358\tLoss: 0.0877\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0287\tTop_Loss: 0.0780\tBottom_Loss: 0.0713\tLoss: 0.1781\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0388\tTop_Loss: 0.1274\tBottom_Loss: 0.0348\tLoss: 0.2009\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0069\tTop_Loss: 0.0154\tBottom_Loss: 0.0356\tLoss: 0.0579\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0137\tTop_Loss: 0.0437\tBottom_Loss: 0.0329\tLoss: 0.0903\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0089\tTop_Loss: 0.0169\tBottom_Loss: 0.0171\tLoss: 0.0429\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0077\tTop_Loss: 0.0166\tBottom_Loss: 0.0244\tLoss: 0.0487\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0073\tTop_Loss: 0.0237\tBottom_Loss: 0.0262\tLoss: 0.0572\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0388\tTop_Loss: 0.0528\tBottom_Loss: 0.0452\tLoss: 0.1368\t\n",
      "Subject: 023, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.500\tLabel_Loss: 1.0925\tTop_Loss: 1.9751\tBottom_Loss: 1.6243\tLoss: 4.6919\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.500\tLabel_Loss: 1.1767\tTop_Loss: 1.2394\tBottom_Loss: 1.2229\tLoss: 3.6389\t\n",
      "Subject: 024, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.438\tLabel_Loss: 1.0642\tTop_Loss: 0.8479\tBottom_Loss: 0.8746\tLoss: 2.7867\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.469\tLabel_Loss: 1.2142\tTop_Loss: 0.9410\tBottom_Loss: 1.0164\tLoss: 3.1716\t\n",
      "Subject: 024, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.562\tLabel_Loss: 0.8511\tTop_Loss: 1.0180\tBottom_Loss: 1.0497\tLoss: 2.9188\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.625\tLabel_Loss: 0.9449\tTop_Loss: 0.8366\tBottom_Loss: 0.9826\tLoss: 2.7641\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.469\tLabel_Loss: 0.9305\tTop_Loss: 1.1504\tBottom_Loss: 0.9945\tLoss: 3.0754\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.469\tLabel_Loss: 1.0810\tTop_Loss: 0.8539\tBottom_Loss: 0.9342\tLoss: 2.8691\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.719\tLabel_Loss: 0.8358\tTop_Loss: 0.8133\tBottom_Loss: 0.7583\tLoss: 2.4074\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.531\tLabel_Loss: 0.9347\tTop_Loss: 1.0095\tBottom_Loss: 1.0799\tLoss: 3.0242\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6760\tTop_Loss: 0.6569\tBottom_Loss: 0.6689\tLoss: 2.0018\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.625\tLabel_Loss: 0.9196\tTop_Loss: 0.8375\tBottom_Loss: 0.8926\tLoss: 2.6496\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.594\tLabel_Loss: 1.0048\tTop_Loss: 1.0929\tBottom_Loss: 0.9081\tLoss: 3.0058\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7518\tTop_Loss: 0.9760\tBottom_Loss: 0.8104\tLoss: 2.5382\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8437\tTop_Loss: 0.7866\tBottom_Loss: 0.8994\tLoss: 2.5297\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.531\tLabel_Loss: 0.9571\tTop_Loss: 1.1684\tBottom_Loss: 0.9427\tLoss: 3.0682\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6510\tTop_Loss: 0.7278\tBottom_Loss: 0.5990\tLoss: 1.9778\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7867\tTop_Loss: 0.8664\tBottom_Loss: 0.8175\tLoss: 2.4706\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.531\tLabel_Loss: 0.8126\tTop_Loss: 0.8823\tBottom_Loss: 0.9080\tLoss: 2.6029\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7497\tTop_Loss: 0.7899\tBottom_Loss: 0.8165\tLoss: 2.3560\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8124\tTop_Loss: 0.8357\tBottom_Loss: 0.9166\tLoss: 2.5647\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7656\tTop_Loss: 0.7361\tBottom_Loss: 0.7806\tLoss: 2.2823\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7545\tTop_Loss: 0.7394\tBottom_Loss: 0.9965\tLoss: 2.4904\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6096\tTop_Loss: 0.6091\tBottom_Loss: 0.6433\tLoss: 1.8620\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4769\tTop_Loss: 0.5271\tBottom_Loss: 0.7727\tLoss: 1.7766\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6599\tTop_Loss: 0.7962\tBottom_Loss: 0.8398\tLoss: 2.2959\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.844\tLabel_Loss: 0.5501\tTop_Loss: 0.6141\tBottom_Loss: 0.7443\tLoss: 1.9085\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7503\tTop_Loss: 0.6828\tBottom_Loss: 0.6972\tLoss: 2.1302\t\n",
      "Subject: 024, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5379\tTop_Loss: 0.6554\tBottom_Loss: 0.7830\tLoss: 1.9763\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.656\tLabel_Loss: 0.6235\tTop_Loss: 0.6050\tBottom_Loss: 0.7450\tLoss: 1.9735\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7601\tTop_Loss: 0.8228\tBottom_Loss: 0.7970\tLoss: 2.3799\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5591\tTop_Loss: 0.6493\tBottom_Loss: 0.6897\tLoss: 1.8982\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4785\tTop_Loss: 0.6638\tBottom_Loss: 0.5800\tLoss: 1.7223\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4802\tTop_Loss: 0.5428\tBottom_Loss: 0.8168\tLoss: 1.8398\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5653\tTop_Loss: 0.6258\tBottom_Loss: 0.7411\tLoss: 1.9322\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4664\tTop_Loss: 0.3812\tBottom_Loss: 0.5542\tLoss: 1.4017\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4518\tTop_Loss: 0.5739\tBottom_Loss: 0.6507\tLoss: 1.6764\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4609\tTop_Loss: 0.6386\tBottom_Loss: 0.5699\tLoss: 1.6694\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.594\tLabel_Loss: 0.7483\tTop_Loss: 0.8139\tBottom_Loss: 0.7587\tLoss: 2.3208\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4207\tTop_Loss: 0.5520\tBottom_Loss: 0.6624\tLoss: 1.6351\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.688\tLabel_Loss: 0.5547\tTop_Loss: 0.7603\tBottom_Loss: 0.6179\tLoss: 1.9328\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5415\tTop_Loss: 0.5072\tBottom_Loss: 0.6044\tLoss: 1.6532\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4832\tTop_Loss: 0.5871\tBottom_Loss: 0.5525\tLoss: 1.6229\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3701\tTop_Loss: 0.4680\tBottom_Loss: 0.5387\tLoss: 1.3768\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4343\tTop_Loss: 0.5330\tBottom_Loss: 0.5988\tLoss: 1.5661\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.750\tLabel_Loss: 0.4829\tTop_Loss: 0.6445\tBottom_Loss: 0.4867\tLoss: 1.6140\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4821\tTop_Loss: 0.6141\tBottom_Loss: 0.5833\tLoss: 1.6795\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3072\tTop_Loss: 0.4610\tBottom_Loss: 0.4866\tLoss: 1.2549\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4534\tTop_Loss: 0.4999\tBottom_Loss: 0.4590\tLoss: 1.4123\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3315\tTop_Loss: 0.4097\tBottom_Loss: 0.5468\tLoss: 1.2880\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4392\tTop_Loss: 0.6038\tBottom_Loss: 0.5322\tLoss: 1.5752\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.938\tLabel_Loss: 0.3030\tTop_Loss: 0.4581\tBottom_Loss: 0.4025\tLoss: 1.1636\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3287\tTop_Loss: 0.4815\tBottom_Loss: 0.4504\tLoss: 1.2606\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3820\tTop_Loss: 0.5276\tBottom_Loss: 0.3844\tLoss: 1.2939\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4008\tTop_Loss: 0.5398\tBottom_Loss: 0.4853\tLoss: 1.4259\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7152\tTop_Loss: 0.7630\tBottom_Loss: 0.5735\tLoss: 2.0518\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3673\tTop_Loss: 0.4321\tBottom_Loss: 0.4385\tLoss: 1.2378\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3971\tTop_Loss: 0.6085\tBottom_Loss: 0.5298\tLoss: 1.5354\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4044\tTop_Loss: 0.4471\tBottom_Loss: 0.4348\tLoss: 1.2863\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2595\tTop_Loss: 0.3333\tBottom_Loss: 0.4849\tLoss: 1.0776\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4379\tTop_Loss: 0.4801\tBottom_Loss: 0.4773\tLoss: 1.3953\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2599\tTop_Loss: 0.2691\tBottom_Loss: 0.4311\tLoss: 0.9602\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3037\tTop_Loss: 0.4115\tBottom_Loss: 0.5937\tLoss: 1.3090\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4597\tTop_Loss: 0.3525\tBottom_Loss: 0.7261\tLoss: 1.5384\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2707\tTop_Loss: 0.4253\tBottom_Loss: 0.5631\tLoss: 1.2591\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2908\tTop_Loss: 0.4322\tBottom_Loss: 0.3684\tLoss: 1.0913\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3659\tTop_Loss: 0.4701\tBottom_Loss: 0.4378\tLoss: 1.2738\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2161\tTop_Loss: 0.3415\tBottom_Loss: 0.4108\tLoss: 0.9684\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.781\tLabel_Loss: 0.3959\tTop_Loss: 0.5591\tBottom_Loss: 0.5268\tLoss: 1.4817\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2439\tTop_Loss: 0.4800\tBottom_Loss: 0.4189\tLoss: 1.1429\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2838\tTop_Loss: 0.3709\tBottom_Loss: 0.4511\tLoss: 1.1058\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1916\tTop_Loss: 0.3536\tBottom_Loss: 0.2514\tLoss: 0.7966\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1786\tTop_Loss: 0.3038\tBottom_Loss: 0.2060\tLoss: 0.6884\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3199\tTop_Loss: 0.4169\tBottom_Loss: 0.4713\tLoss: 1.2081\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1902\tTop_Loss: 0.3012\tBottom_Loss: 0.2827\tLoss: 0.7741\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2178\tTop_Loss: 0.3534\tBottom_Loss: 0.3015\tLoss: 0.8727\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2300\tTop_Loss: 0.2784\tBottom_Loss: 0.3028\tLoss: 0.8112\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3064\tTop_Loss: 0.4657\tBottom_Loss: 0.3901\tLoss: 1.1623\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2966\tTop_Loss: 0.3845\tBottom_Loss: 0.3423\tLoss: 1.0234\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2259\tTop_Loss: 0.2731\tBottom_Loss: 0.2497\tLoss: 0.7488\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2776\tTop_Loss: 0.3303\tBottom_Loss: 0.3295\tLoss: 0.9373\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2252\tTop_Loss: 0.4497\tBottom_Loss: 0.3642\tLoss: 1.0391\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1014\tTop_Loss: 0.3159\tBottom_Loss: 0.2591\tLoss: 0.6764\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2227\tTop_Loss: 0.5067\tBottom_Loss: 0.3557\tLoss: 1.0852\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.875\tLabel_Loss: 0.1963\tTop_Loss: 0.3733\tBottom_Loss: 0.2685\tLoss: 0.8382\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2117\tTop_Loss: 0.3136\tBottom_Loss: 0.4510\tLoss: 0.9763\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0903\tTop_Loss: 0.1861\tBottom_Loss: 0.1352\tLoss: 0.4116\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1965\tTop_Loss: 0.2050\tBottom_Loss: 0.3261\tLoss: 0.7276\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1620\tTop_Loss: 0.2621\tBottom_Loss: 0.2232\tLoss: 0.6473\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1531\tTop_Loss: 0.2912\tBottom_Loss: 0.3697\tLoss: 0.8139\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1933\tTop_Loss: 0.2413\tBottom_Loss: 0.3422\tLoss: 0.7769\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2965\tTop_Loss: 0.4694\tBottom_Loss: 0.4715\tLoss: 1.2374\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1275\tTop_Loss: 0.2661\tBottom_Loss: 0.3266\tLoss: 0.7201\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1597\tTop_Loss: 0.3171\tBottom_Loss: 0.3269\tLoss: 0.8037\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1681\tTop_Loss: 0.4104\tBottom_Loss: 0.2182\tLoss: 0.7967\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1293\tTop_Loss: 0.2634\tBottom_Loss: 0.1815\tLoss: 0.5742\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1899\tTop_Loss: 0.2792\tBottom_Loss: 0.2035\tLoss: 0.6725\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2043\tTop_Loss: 0.2545\tBottom_Loss: 0.3110\tLoss: 0.7697\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0995\tTop_Loss: 0.2696\tBottom_Loss: 0.1649\tLoss: 0.5339\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0907\tTop_Loss: 0.2731\tBottom_Loss: 0.2848\tLoss: 0.6486\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1441\tTop_Loss: 0.2091\tBottom_Loss: 0.2713\tLoss: 0.6244\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1688\tTop_Loss: 0.2133\tBottom_Loss: 0.2524\tLoss: 0.6345\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1189\tTop_Loss: 0.2093\tBottom_Loss: 0.1992\tLoss: 0.5274\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1007\tTop_Loss: 0.1632\tBottom_Loss: 0.1727\tLoss: 0.4365\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0755\tTop_Loss: 0.1171\tBottom_Loss: 0.1924\tLoss: 0.3850\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1397\tTop_Loss: 0.2357\tBottom_Loss: 0.3276\tLoss: 0.7030\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1113\tTop_Loss: 0.1723\tBottom_Loss: 0.2459\tLoss: 0.5295\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0768\tTop_Loss: 0.1679\tBottom_Loss: 0.1550\tLoss: 0.3997\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0685\tTop_Loss: 0.1461\tBottom_Loss: 0.0747\tLoss: 0.2893\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1189\tTop_Loss: 0.3477\tBottom_Loss: 0.1492\tLoss: 0.6159\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0937\tTop_Loss: 0.2233\tBottom_Loss: 0.1033\tLoss: 0.4204\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0708\tTop_Loss: 0.1950\tBottom_Loss: 0.1348\tLoss: 0.4006\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0552\tTop_Loss: 0.1039\tBottom_Loss: 0.1521\tLoss: 0.3112\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1453\tTop_Loss: 0.2904\tBottom_Loss: 0.1725\tLoss: 0.6082\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0560\tTop_Loss: 0.1954\tBottom_Loss: 0.1033\tLoss: 0.3547\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0717\tTop_Loss: 0.1359\tBottom_Loss: 0.1569\tLoss: 0.3645\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1670\tTop_Loss: 0.2419\tBottom_Loss: 0.1892\tLoss: 0.5981\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1029\tTop_Loss: 0.1497\tBottom_Loss: 0.1182\tLoss: 0.3708\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0826\tTop_Loss: 0.1274\tBottom_Loss: 0.2500\tLoss: 0.4599\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0784\tTop_Loss: 0.1836\tBottom_Loss: 0.1099\tLoss: 0.3719\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0585\tTop_Loss: 0.1203\tBottom_Loss: 0.1268\tLoss: 0.3056\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0663\tTop_Loss: 0.1226\tBottom_Loss: 0.1285\tLoss: 0.3174\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1113\tTop_Loss: 0.2337\tBottom_Loss: 0.1333\tLoss: 0.4783\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0571\tTop_Loss: 0.1117\tBottom_Loss: 0.1059\tLoss: 0.2747\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0675\tTop_Loss: 0.1665\tBottom_Loss: 0.0682\tLoss: 0.3022\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1049\tTop_Loss: 0.1093\tBottom_Loss: 0.0891\tLoss: 0.3032\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1024\tTop_Loss: 0.0982\tBottom_Loss: 0.1726\tLoss: 0.3732\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0724\tTop_Loss: 0.2516\tBottom_Loss: 0.0451\tLoss: 0.3692\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0434\tTop_Loss: 0.1473\tBottom_Loss: 0.0692\tLoss: 0.2599\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0327\tTop_Loss: 0.0823\tBottom_Loss: 0.1489\tLoss: 0.2638\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0815\tTop_Loss: 0.1340\tBottom_Loss: 0.1706\tLoss: 0.3861\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0625\tTop_Loss: 0.1217\tBottom_Loss: 0.1388\tLoss: 0.3230\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1137\tTop_Loss: 0.2455\tBottom_Loss: 0.1994\tLoss: 0.5587\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0580\tTop_Loss: 0.1965\tBottom_Loss: 0.1403\tLoss: 0.3947\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0907\tTop_Loss: 0.1116\tBottom_Loss: 0.1118\tLoss: 0.3141\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1034\tTop_Loss: 0.1906\tBottom_Loss: 0.1855\tLoss: 0.4796\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1095\tTop_Loss: 0.1679\tBottom_Loss: 0.0885\tLoss: 0.3659\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0458\tTop_Loss: 0.0935\tBottom_Loss: 0.1111\tLoss: 0.2504\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0385\tTop_Loss: 0.0862\tBottom_Loss: 0.0841\tLoss: 0.2088\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0245\tTop_Loss: 0.1548\tBottom_Loss: 0.0390\tLoss: 0.2184\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0504\tTop_Loss: 0.1404\tBottom_Loss: 0.1145\tLoss: 0.3054\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0594\tTop_Loss: 0.1196\tBottom_Loss: 0.0707\tLoss: 0.2497\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0209\tTop_Loss: 0.0943\tBottom_Loss: 0.0788\tLoss: 0.1940\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0374\tTop_Loss: 0.0777\tBottom_Loss: 0.0935\tLoss: 0.2086\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0328\tTop_Loss: 0.0733\tBottom_Loss: 0.1033\tLoss: 0.2094\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0325\tTop_Loss: 0.0700\tBottom_Loss: 0.0956\tLoss: 0.1982\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[73][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1294\tTop_Loss: 0.2461\tBottom_Loss: 0.1167\tLoss: 0.4923\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0712\tTop_Loss: 0.1087\tBottom_Loss: 0.1110\tLoss: 0.2909\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0305\tTop_Loss: 0.0957\tBottom_Loss: 0.0548\tLoss: 0.1811\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0204\tTop_Loss: 0.0884\tBottom_Loss: 0.0710\tLoss: 0.1799\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0915\tTop_Loss: 0.1418\tBottom_Loss: 0.1087\tLoss: 0.3420\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0428\tTop_Loss: 0.0748\tBottom_Loss: 0.0662\tLoss: 0.1838\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1211\tTop_Loss: 0.1277\tBottom_Loss: 0.1249\tLoss: 0.3738\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0430\tTop_Loss: 0.1111\tBottom_Loss: 0.0986\tLoss: 0.2527\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0384\tTop_Loss: 0.0481\tBottom_Loss: 0.1194\tLoss: 0.2059\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0515\tTop_Loss: 0.0814\tBottom_Loss: 0.0412\tLoss: 0.1740\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0160\tTop_Loss: 0.0201\tBottom_Loss: 0.0569\tLoss: 0.0930\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0273\tTop_Loss: 0.0838\tBottom_Loss: 0.0618\tLoss: 0.1728\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0594\tTop_Loss: 0.0455\tBottom_Loss: 0.1124\tLoss: 0.2174\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0340\tTop_Loss: 0.1260\tBottom_Loss: 0.0507\tLoss: 0.2107\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0263\tTop_Loss: 0.0442\tBottom_Loss: 0.1506\tLoss: 0.2211\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0503\tTop_Loss: 0.0939\tBottom_Loss: 0.0761\tLoss: 0.2203\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0348\tTop_Loss: 0.1080\tBottom_Loss: 0.0638\tLoss: 0.2066\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0186\tTop_Loss: 0.0459\tBottom_Loss: 0.0556\tLoss: 0.1200\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0176\tTop_Loss: 0.0805\tBottom_Loss: 0.0512\tLoss: 0.1493\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0119\tTop_Loss: 0.0375\tBottom_Loss: 0.0200\tLoss: 0.0695\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0158\tTop_Loss: 0.0558\tBottom_Loss: 0.0249\tLoss: 0.0966\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0191\tTop_Loss: 0.0989\tBottom_Loss: 0.0726\tLoss: 0.1906\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0108\tTop_Loss: 0.0340\tBottom_Loss: 0.0250\tLoss: 0.0698\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0318\tTop_Loss: 0.1034\tBottom_Loss: 0.0675\tLoss: 0.2026\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0209\tTop_Loss: 0.0219\tBottom_Loss: 0.0737\tLoss: 0.1166\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0466\tTop_Loss: 0.0663\tBottom_Loss: 0.1004\tLoss: 0.2134\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0117\tTop_Loss: 0.0319\tBottom_Loss: 0.0301\tLoss: 0.0738\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0262\tTop_Loss: 0.0452\tBottom_Loss: 0.0828\tLoss: 0.1543\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0107\tTop_Loss: 0.0504\tBottom_Loss: 0.0335\tLoss: 0.0947\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0168\tTop_Loss: 0.0561\tBottom_Loss: 0.0145\tLoss: 0.0874\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0147\tTop_Loss: 0.0570\tBottom_Loss: 0.0339\tLoss: 0.1056\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0195\tTop_Loss: 0.0289\tBottom_Loss: 0.0574\tLoss: 0.1059\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0643\tTop_Loss: 0.0782\tBottom_Loss: 0.0588\tLoss: 0.2013\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0106\tTop_Loss: 0.0281\tBottom_Loss: 0.0402\tLoss: 0.0790\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0117\tTop_Loss: 0.0153\tBottom_Loss: 0.0271\tLoss: 0.0541\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0100\tTop_Loss: 0.0378\tBottom_Loss: 0.0394\tLoss: 0.0872\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0365\tTop_Loss: 0.0796\tBottom_Loss: 0.0541\tLoss: 0.1703\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0095\tTop_Loss: 0.0228\tBottom_Loss: 0.0258\tLoss: 0.0580\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0516\tTop_Loss: 0.0689\tBottom_Loss: 0.0777\tLoss: 0.1982\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0355\tTop_Loss: 0.0356\tBottom_Loss: 0.1128\tLoss: 0.1839\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0205\tTop_Loss: 0.0256\tBottom_Loss: 0.0383\tLoss: 0.0844\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0241\tTop_Loss: 0.0361\tBottom_Loss: 0.0662\tLoss: 0.1264\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0199\tTop_Loss: 0.0497\tBottom_Loss: 0.0171\tLoss: 0.0867\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0154\tTop_Loss: 0.1192\tBottom_Loss: 0.0209\tLoss: 0.1554\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0523\tTop_Loss: 0.0752\tBottom_Loss: 0.0862\tLoss: 0.2137\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0100\tTop_Loss: 0.0328\tBottom_Loss: 0.0257\tLoss: 0.0685\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0133\tTop_Loss: 0.0380\tBottom_Loss: 0.0288\tLoss: 0.0801\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0085\tTop_Loss: 0.0134\tBottom_Loss: 0.0186\tLoss: 0.0405\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0180\tTop_Loss: 0.0448\tBottom_Loss: 0.0354\tLoss: 0.0981\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0104\tTop_Loss: 0.0682\tBottom_Loss: 0.0196\tLoss: 0.0983\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0273\tTop_Loss: 0.0279\tBottom_Loss: 0.0545\tLoss: 0.1097\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0193\tTop_Loss: 0.0445\tBottom_Loss: 0.0388\tLoss: 0.1027\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0126\tTop_Loss: 0.0130\tBottom_Loss: 0.0160\tLoss: 0.0416\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0090\tTop_Loss: 0.0297\tBottom_Loss: 0.0227\tLoss: 0.0614\t\n",
      "Subject: 024, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.344\tLabel_Loss: 1.2188\tTop_Loss: 1.2209\tBottom_Loss: 1.2028\tLoss: 3.6425\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.250\tLabel_Loss: 1.4676\tTop_Loss: 1.2938\tBottom_Loss: 1.0563\tLoss: 3.8177\t\n",
      "Subject: 026, n=09 | test_f1: 0.47059 |best_f1: 0.47059\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.500\tLabel_Loss: 1.0905\tTop_Loss: 1.0887\tBottom_Loss: 1.1521\tLoss: 3.3314\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.438\tLabel_Loss: 1.2534\tTop_Loss: 1.1642\tBottom_Loss: 1.1054\tLoss: 3.5230\t\n",
      "Subject: 026, n=09 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.438\tLabel_Loss: 1.0466\tTop_Loss: 0.9361\tBottom_Loss: 0.9520\tLoss: 2.9347\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.375\tLabel_Loss: 1.3389\tTop_Loss: 1.0183\tBottom_Loss: 1.2714\tLoss: 3.6286\t\n",
      "Subject: 026, n=09 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.500\tLabel_Loss: 0.9783\tTop_Loss: 1.0558\tBottom_Loss: 0.9006\tLoss: 2.9347\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8792\tTop_Loss: 0.9484\tBottom_Loss: 0.8922\tLoss: 2.7198\t\n",
      "Subject: 026, n=09 | test_f1: 0.47059 |best_f1: 1.0\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.531\tLabel_Loss: 0.9608\tTop_Loss: 1.2135\tBottom_Loss: 0.8737\tLoss: 3.0480\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.406\tLabel_Loss: 0.9201\tTop_Loss: 0.8786\tBottom_Loss: 0.9483\tLoss: 2.7470\t\n",
      "Subject: 026, n=09 | test_f1: 0.4375 |best_f1: 1.0\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7879\tTop_Loss: 0.8108\tBottom_Loss: 0.9298\tLoss: 2.5285\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.656\tLabel_Loss: 0.6970\tTop_Loss: 0.8585\tBottom_Loss: 0.7949\tLoss: 2.3504\t\n",
      "Subject: 026, n=09 | test_f1: 0.47059 |best_f1: 1.0\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.562\tLabel_Loss: 0.8745\tTop_Loss: 1.0266\tBottom_Loss: 0.8518\tLoss: 2.7528\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.594\tLabel_Loss: 0.7697\tTop_Loss: 0.9231\tBottom_Loss: 0.8788\tLoss: 2.5716\t\n",
      "Subject: 026, n=09 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.688\tLabel_Loss: 0.8438\tTop_Loss: 0.7520\tBottom_Loss: 0.8155\tLoss: 2.4112\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6778\tTop_Loss: 0.8969\tBottom_Loss: 0.7078\tLoss: 2.2825\t\n",
      "Subject: 026, n=09 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6091\tTop_Loss: 0.7363\tBottom_Loss: 0.5442\tLoss: 1.8897\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.531\tLabel_Loss: 0.7809\tTop_Loss: 0.8200\tBottom_Loss: 0.9651\tLoss: 2.5660\t\n",
      "Subject: 026, n=09 | test_f1: 0.29167 |best_f1: 1.0\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.562\tLabel_Loss: 0.8553\tTop_Loss: 0.9326\tBottom_Loss: 0.8313\tLoss: 2.6192\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.781\tLabel_Loss: 0.6344\tTop_Loss: 0.6827\tBottom_Loss: 0.7934\tLoss: 2.1105\t\n",
      "Subject: 026, n=09 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6811\tTop_Loss: 0.6618\tBottom_Loss: 0.9883\tLoss: 2.3312\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7598\tTop_Loss: 0.8373\tBottom_Loss: 0.6524\tLoss: 2.2495\t\n",
      "Subject: 026, n=09 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7051\tTop_Loss: 0.7108\tBottom_Loss: 0.8362\tLoss: 2.2521\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8109\tTop_Loss: 0.8141\tBottom_Loss: 0.8646\tLoss: 2.4896\t\n",
      "Subject: 026, n=09 | test_f1: 0.4375 |best_f1: 1.0\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.531\tLabel_Loss: 0.8269\tTop_Loss: 0.8564\tBottom_Loss: 0.9714\tLoss: 2.6547\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5657\tTop_Loss: 0.6448\tBottom_Loss: 0.6021\tLoss: 1.8125\t\n",
      "Subject: 026, n=09 | test_f1: 0.47059 |best_f1: 1.0\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.562\tLabel_Loss: 0.8363\tTop_Loss: 0.7997\tBottom_Loss: 1.0595\tLoss: 2.6954\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.500\tLabel_Loss: 0.7090\tTop_Loss: 0.7431\tBottom_Loss: 0.6613\tLoss: 2.1133\t\n",
      "Subject: 026, n=09 | test_f1: 0.4375 |best_f1: 1.0\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5874\tTop_Loss: 0.8827\tBottom_Loss: 0.7745\tLoss: 2.2447\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.656\tLabel_Loss: 0.6879\tTop_Loss: 0.7222\tBottom_Loss: 0.6402\tLoss: 2.0503\t\n",
      "Subject: 026, n=09 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6098\tTop_Loss: 0.6883\tBottom_Loss: 0.6422\tLoss: 1.9403\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6319\tTop_Loss: 0.6902\tBottom_Loss: 0.8785\tLoss: 2.2006\t\n",
      "Subject: 026, n=09 | test_f1: 0.47059 |best_f1: 1.0\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4769\tTop_Loss: 0.7101\tBottom_Loss: 0.7777\tLoss: 1.9647\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.781\tLabel_Loss: 0.6781\tTop_Loss: 0.7183\tBottom_Loss: 0.7217\tLoss: 2.1181\t\n",
      "Subject: 026, n=09 | test_f1: 0.2381 |best_f1: 1.0\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7535\tTop_Loss: 1.0020\tBottom_Loss: 0.6383\tLoss: 2.3938\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4415\tTop_Loss: 0.5164\tBottom_Loss: 0.5597\tLoss: 1.5176\t\n",
      "Subject: 026, n=09 | test_f1: 0.29167 |best_f1: 1.0\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4755\tTop_Loss: 0.6479\tBottom_Loss: 0.5693\tLoss: 1.6926\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5704\tTop_Loss: 0.7365\tBottom_Loss: 0.5987\tLoss: 1.9056\t\n",
      "Subject: 026, n=09 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4564\tTop_Loss: 0.6076\tBottom_Loss: 0.4831\tLoss: 1.5471\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3603\tTop_Loss: 0.6000\tBottom_Loss: 0.4951\tLoss: 1.4554\t\n",
      "Subject: 026, n=09 | test_f1: 0.4375 |best_f1: 1.0\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.938\tLabel_Loss: 0.3542\tTop_Loss: 0.4999\tBottom_Loss: 0.6913\tLoss: 1.5454\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.719\tLabel_Loss: 0.5324\tTop_Loss: 0.7688\tBottom_Loss: 0.6723\tLoss: 1.9735\t\n",
      "Subject: 026, n=09 | test_f1: 0.4375 |best_f1: 1.0\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.688\tLabel_Loss: 0.5290\tTop_Loss: 0.6943\tBottom_Loss: 0.7525\tLoss: 1.9758\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3460\tTop_Loss: 0.4407\tBottom_Loss: 0.6139\tLoss: 1.4006\t\n",
      "Subject: 026, n=09 | test_f1: 0.2381 |best_f1: 1.0\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3867\tTop_Loss: 0.4892\tBottom_Loss: 0.4540\tLoss: 1.3299\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5585\tTop_Loss: 0.7450\tBottom_Loss: 0.7580\tLoss: 2.0615\t\n",
      "Subject: 026, n=09 | test_f1: 0.29167 |best_f1: 1.0\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5189\tTop_Loss: 0.6967\tBottom_Loss: 0.6467\tLoss: 1.8623\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6607\tTop_Loss: 0.8374\tBottom_Loss: 0.7637\tLoss: 2.2618\t\n",
      "Subject: 026, n=09 | test_f1: 0.2381 |best_f1: 1.0\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3252\tTop_Loss: 0.4202\tBottom_Loss: 0.3723\tLoss: 1.1177\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3168\tTop_Loss: 0.5233\tBottom_Loss: 0.3587\tLoss: 1.1987\t\n",
      "Subject: 026, n=09 | test_f1: 0.47059 |best_f1: 1.0\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2945\tTop_Loss: 0.4487\tBottom_Loss: 0.4297\tLoss: 1.1730\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4074\tTop_Loss: 0.5448\tBottom_Loss: 0.5513\tLoss: 1.5035\t\n",
      "Subject: 026, n=09 | test_f1: 0.47059 |best_f1: 1.0\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.938\tLabel_Loss: 0.3557\tTop_Loss: 0.5052\tBottom_Loss: 0.4495\tLoss: 1.3104\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6057\tTop_Loss: 0.7398\tBottom_Loss: 0.6870\tLoss: 2.0325\t\n",
      "Subject: 026, n=09 | test_f1: 0.29167 |best_f1: 1.0\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2633\tTop_Loss: 0.4921\tBottom_Loss: 0.3295\tLoss: 1.0849\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4213\tTop_Loss: 0.6954\tBottom_Loss: 0.4329\tLoss: 1.5496\t\n",
      "Subject: 026, n=09 | test_f1: 0.47059 |best_f1: 1.0\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3482\tTop_Loss: 0.5742\tBottom_Loss: 0.5602\tLoss: 1.4826\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2673\tTop_Loss: 0.3712\tBottom_Loss: 0.4391\tLoss: 1.0775\t\n",
      "Subject: 026, n=09 | test_f1: 0.47059 |best_f1: 1.0\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3181\tTop_Loss: 0.3982\tBottom_Loss: 0.3477\tLoss: 1.0640\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2907\tTop_Loss: 0.3057\tBottom_Loss: 0.4769\tLoss: 1.0733\t\n",
      "Subject: 026, n=09 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3549\tTop_Loss: 0.4815\tBottom_Loss: 0.4757\tLoss: 1.3122\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2605\tTop_Loss: 0.3710\tBottom_Loss: 0.3630\tLoss: 0.9944\t\n",
      "Subject: 026, n=09 | test_f1: 0.47059 |best_f1: 1.0\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2702\tTop_Loss: 0.4210\tBottom_Loss: 0.4299\tLoss: 1.1211\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2355\tTop_Loss: 0.3304\tBottom_Loss: 0.3640\tLoss: 0.9299\t\n",
      "Subject: 026, n=09 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2468\tTop_Loss: 0.4716\tBottom_Loss: 0.3773\tLoss: 1.0957\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2552\tTop_Loss: 0.4312\tBottom_Loss: 0.3947\tLoss: 1.0811\t\n",
      "Subject: 026, n=09 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2072\tTop_Loss: 0.3511\tBottom_Loss: 0.3441\tLoss: 0.9024\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.938\tLabel_Loss: 0.3091\tTop_Loss: 0.5422\tBottom_Loss: 0.3191\tLoss: 1.1704\t\n",
      "Subject: 026, n=09 | test_f1: 0.2381 |best_f1: 1.0\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2634\tTop_Loss: 0.5133\tBottom_Loss: 0.3051\tLoss: 1.0818\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2781\tTop_Loss: 0.5918\tBottom_Loss: 0.4191\tLoss: 1.2890\t\n",
      "Subject: 026, n=09 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3249\tTop_Loss: 0.4536\tBottom_Loss: 0.3893\tLoss: 1.1679\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1851\tTop_Loss: 0.3174\tBottom_Loss: 0.4176\tLoss: 0.9201\t\n",
      "Subject: 026, n=09 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1681\tTop_Loss: 0.3466\tBottom_Loss: 0.2292\tLoss: 0.7440\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2688\tTop_Loss: 0.3571\tBottom_Loss: 0.3494\tLoss: 0.9753\t\n",
      "Subject: 026, n=09 | test_f1: 0.47059 |best_f1: 1.0\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2262\tTop_Loss: 0.3575\tBottom_Loss: 0.3328\tLoss: 0.9164\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1658\tTop_Loss: 0.4367\tBottom_Loss: 0.2418\tLoss: 0.8443\t\n",
      "Subject: 026, n=09 | test_f1: 0.47059 |best_f1: 1.0\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3437\tTop_Loss: 0.4195\tBottom_Loss: 0.3678\tLoss: 1.1310\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1506\tTop_Loss: 0.4441\tBottom_Loss: 0.2634\tLoss: 0.8581\t\n",
      "Subject: 026, n=09 | test_f1: 0.20513 |best_f1: 1.0\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2980\tTop_Loss: 0.4157\tBottom_Loss: 0.2912\tLoss: 1.0049\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2271\tTop_Loss: 0.2897\tBottom_Loss: 0.3461\tLoss: 0.8629\t\n",
      "Subject: 026, n=09 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1465\tTop_Loss: 0.2941\tBottom_Loss: 0.1752\tLoss: 0.6159\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0962\tTop_Loss: 0.2729\tBottom_Loss: 0.2172\tLoss: 0.5863\t\n",
      "Subject: 026, n=09 | test_f1: 0.4375 |best_f1: 1.0\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2307\tTop_Loss: 0.4094\tBottom_Loss: 0.4530\tLoss: 1.0930\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1513\tTop_Loss: 0.2084\tBottom_Loss: 0.1664\tLoss: 0.5261\t\n",
      "Subject: 026, n=09 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1495\tTop_Loss: 0.3261\tBottom_Loss: 0.2736\tLoss: 0.7492\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1926\tTop_Loss: 0.3141\tBottom_Loss: 0.3000\tLoss: 0.8067\t\n",
      "Subject: 026, n=09 | test_f1: 0.4375 |best_f1: 1.0\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2099\tTop_Loss: 0.3451\tBottom_Loss: 0.3012\tLoss: 0.8563\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3107\tTop_Loss: 0.4409\tBottom_Loss: 0.3328\tLoss: 1.0844\t\n",
      "Subject: 026, n=09 | test_f1: 0.47059 |best_f1: 1.0\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1924\tTop_Loss: 0.2782\tBottom_Loss: 0.2651\tLoss: 0.7357\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2329\tTop_Loss: 0.3302\tBottom_Loss: 0.3102\tLoss: 0.8733\t\n",
      "Subject: 026, n=09 | test_f1: 0.29167 |best_f1: 1.0\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2793\tTop_Loss: 0.3269\tBottom_Loss: 0.3199\tLoss: 0.9261\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0685\tTop_Loss: 0.1394\tBottom_Loss: 0.1900\tLoss: 0.3978\t\n",
      "Subject: 026, n=09 | test_f1: 0.47059 |best_f1: 1.0\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2119\tTop_Loss: 0.2398\tBottom_Loss: 0.3373\tLoss: 0.7889\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1388\tTop_Loss: 0.3584\tBottom_Loss: 0.1790\tLoss: 0.6761\t\n",
      "Subject: 026, n=09 | test_f1: 0.4375 |best_f1: 1.0\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1549\tTop_Loss: 0.2271\tBottom_Loss: 0.2710\tLoss: 0.6530\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1426\tTop_Loss: 0.2341\tBottom_Loss: 0.2400\tLoss: 0.6166\t\n",
      "Subject: 026, n=09 | test_f1: 0.29167 |best_f1: 1.0\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1198\tTop_Loss: 0.2149\tBottom_Loss: 0.2648\tLoss: 0.5995\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1073\tTop_Loss: 0.2588\tBottom_Loss: 0.1918\tLoss: 0.5579\t\n",
      "Subject: 026, n=09 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1251\tTop_Loss: 0.1678\tBottom_Loss: 0.2422\tLoss: 0.5350\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0904\tTop_Loss: 0.1274\tBottom_Loss: 0.1996\tLoss: 0.4174\t\n",
      "Subject: 026, n=09 | test_f1: 0.29167 |best_f1: 1.0\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1570\tTop_Loss: 0.3086\tBottom_Loss: 0.2422\tLoss: 0.7079\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1052\tTop_Loss: 0.1784\tBottom_Loss: 0.1567\tLoss: 0.4403\t\n",
      "Subject: 026, n=09 | test_f1: 0.47059 |best_f1: 1.0\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0597\tTop_Loss: 0.1494\tBottom_Loss: 0.1376\tLoss: 0.3468\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1027\tTop_Loss: 0.2701\tBottom_Loss: 0.1288\tLoss: 0.5016\t\n",
      "Subject: 026, n=09 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1447\tTop_Loss: 0.3502\tBottom_Loss: 0.1391\tLoss: 0.6340\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1505\tTop_Loss: 0.2747\tBottom_Loss: 0.1889\tLoss: 0.6141\t\n",
      "Subject: 026, n=09 | test_f1: 0.47059 |best_f1: 1.0\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0845\tTop_Loss: 0.2372\tBottom_Loss: 0.1556\tLoss: 0.4774\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1185\tTop_Loss: 0.2684\tBottom_Loss: 0.1920\tLoss: 0.5789\t\n",
      "Subject: 026, n=09 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1324\tTop_Loss: 0.2180\tBottom_Loss: 0.2097\tLoss: 0.5601\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0882\tTop_Loss: 0.2056\tBottom_Loss: 0.1603\tLoss: 0.4541\t\n",
      "Subject: 026, n=09 | test_f1: 0.29167 |best_f1: 1.0\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1658\tTop_Loss: 0.2789\tBottom_Loss: 0.1544\tLoss: 0.5991\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1031\tTop_Loss: 0.1695\tBottom_Loss: 0.1465\tLoss: 0.4191\t\n",
      "Subject: 026, n=09 | test_f1: 0.47059 |best_f1: 1.0\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1468\tTop_Loss: 0.2020\tBottom_Loss: 0.2557\tLoss: 0.6045\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0785\tTop_Loss: 0.1535\tBottom_Loss: 0.2034\tLoss: 0.4354\t\n",
      "Subject: 026, n=09 | test_f1: 0.47059 |best_f1: 1.0\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0472\tTop_Loss: 0.1718\tBottom_Loss: 0.0944\tLoss: 0.3134\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2423\tTop_Loss: 0.3820\tBottom_Loss: 0.3327\tLoss: 0.9571\t\n",
      "Subject: 026, n=09 | test_f1: 0.47059 |best_f1: 1.0\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0481\tTop_Loss: 0.1391\tBottom_Loss: 0.1010\tLoss: 0.2882\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1817\tTop_Loss: 0.2355\tBottom_Loss: 0.1728\tLoss: 0.5899\t\n",
      "Subject: 026, n=09 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0531\tTop_Loss: 0.1665\tBottom_Loss: 0.1011\tLoss: 0.3206\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0682\tTop_Loss: 0.1865\tBottom_Loss: 0.1334\tLoss: 0.3881\t\n",
      "Subject: 026, n=09 | test_f1: 0.4375 |best_f1: 1.0\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0528\tTop_Loss: 0.1460\tBottom_Loss: 0.1713\tLoss: 0.3701\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0866\tTop_Loss: 0.1919\tBottom_Loss: 0.1221\tLoss: 0.4006\t\n",
      "Subject: 026, n=09 | test_f1: 0.47059 |best_f1: 1.0\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0725\tTop_Loss: 0.0892\tBottom_Loss: 0.1711\tLoss: 0.3328\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0431\tTop_Loss: 0.1238\tBottom_Loss: 0.1140\tLoss: 0.2809\t\n",
      "Subject: 026, n=09 | test_f1: 0.29167 |best_f1: 1.0\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1355\tTop_Loss: 0.1999\tBottom_Loss: 0.2144\tLoss: 0.5498\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0346\tTop_Loss: 0.1966\tBottom_Loss: 0.0861\tLoss: 0.3173\t\n",
      "Subject: 026, n=09 | test_f1: 0.47059 |best_f1: 1.0\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0607\tTop_Loss: 0.1041\tBottom_Loss: 0.1274\tLoss: 0.2922\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0725\tTop_Loss: 0.1808\tBottom_Loss: 0.1092\tLoss: 0.3625\t\n",
      "Subject: 026, n=09 | test_f1: 0.47059 |best_f1: 1.0\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0965\tTop_Loss: 0.2521\tBottom_Loss: 0.0664\tLoss: 0.4150\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0344\tTop_Loss: 0.1830\tBottom_Loss: 0.0603\tLoss: 0.2777\t\n",
      "Subject: 026, n=09 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0670\tTop_Loss: 0.1911\tBottom_Loss: 0.1287\tLoss: 0.3868\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1474\tTop_Loss: 0.1544\tBottom_Loss: 0.2561\tLoss: 0.5579\t\n",
      "Subject: 026, n=09 | test_f1: 0.29167 |best_f1: 1.0\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0311\tTop_Loss: 0.1311\tBottom_Loss: 0.0645\tLoss: 0.2267\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[66][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1351\tTop_Loss: 0.1449\tBottom_Loss: 0.1431\tLoss: 0.4232\t\n",
      "Subject: 026, n=09 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0268\tTop_Loss: 0.0629\tBottom_Loss: 0.0615\tLoss: 0.1512\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0588\tTop_Loss: 0.1181\tBottom_Loss: 0.1310\tLoss: 0.3078\t\n",
      "Subject: 026, n=09 | test_f1: 0.4375 |best_f1: 1.0\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0481\tTop_Loss: 0.2571\tBottom_Loss: 0.0577\tLoss: 0.3629\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1536\tTop_Loss: 0.1960\tBottom_Loss: 0.1458\tLoss: 0.4954\t\n",
      "Subject: 026, n=09 | test_f1: 0.2381 |best_f1: 1.0\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0273\tTop_Loss: 0.1018\tBottom_Loss: 0.0439\tLoss: 0.1730\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0403\tTop_Loss: 0.1046\tBottom_Loss: 0.1169\tLoss: 0.2618\t\n",
      "Subject: 026, n=09 | test_f1: 0.29167 |best_f1: 1.0\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0639\tTop_Loss: 0.1447\tBottom_Loss: 0.1129\tLoss: 0.3214\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0489\tTop_Loss: 0.0689\tBottom_Loss: 0.1316\tLoss: 0.2495\t\n",
      "Subject: 026, n=09 | test_f1: 0.29167 |best_f1: 1.0\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0319\tTop_Loss: 0.0670\tBottom_Loss: 0.0902\tLoss: 0.1891\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0466\tTop_Loss: 0.0649\tBottom_Loss: 0.0968\tLoss: 0.2083\t\n",
      "Subject: 026, n=09 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0254\tTop_Loss: 0.0776\tBottom_Loss: 0.0446\tLoss: 0.1476\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0156\tTop_Loss: 0.1056\tBottom_Loss: 0.0515\tLoss: 0.1727\t\n",
      "Subject: 026, n=09 | test_f1: 0.2381 |best_f1: 1.0\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0388\tTop_Loss: 0.0474\tBottom_Loss: 0.1731\tLoss: 0.2593\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0395\tTop_Loss: 0.0699\tBottom_Loss: 0.0945\tLoss: 0.2039\t\n",
      "Subject: 026, n=09 | test_f1: 0.29167 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1022\tTop_Loss: 0.1690\tBottom_Loss: 0.1971\tLoss: 0.4683\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0424\tTop_Loss: 0.0873\tBottom_Loss: 0.0649\tLoss: 0.1947\t\n",
      "Subject: 026, n=09 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0256\tTop_Loss: 0.0434\tBottom_Loss: 0.0644\tLoss: 0.1335\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0329\tTop_Loss: 0.1169\tBottom_Loss: 0.0746\tLoss: 0.2244\t\n",
      "Subject: 026, n=09 | test_f1: 0.47059 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0186\tTop_Loss: 0.0450\tBottom_Loss: 0.0623\tLoss: 0.1260\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0346\tTop_Loss: 0.1740\tBottom_Loss: 0.0835\tLoss: 0.2922\t\n",
      "Subject: 026, n=09 | test_f1: 0.4375 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0312\tTop_Loss: 0.1158\tBottom_Loss: 0.0929\tLoss: 0.2399\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0463\tTop_Loss: 0.0701\tBottom_Loss: 0.1220\tLoss: 0.2384\t\n",
      "Subject: 026, n=09 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0518\tTop_Loss: 0.1205\tBottom_Loss: 0.1143\tLoss: 0.2867\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 0.938\tLabel_Loss: 0.0943\tTop_Loss: 0.1562\tBottom_Loss: 0.1646\tLoss: 0.4151\t\n",
      "Subject: 026, n=09 | test_f1: 0.4375 |best_f1: 1.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0220\tTop_Loss: 0.0608\tBottom_Loss: 0.0441\tLoss: 0.1270\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0169\tTop_Loss: 0.0768\tBottom_Loss: 0.0538\tLoss: 0.1475\t\n",
      "Subject: 026, n=09 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0289\tTop_Loss: 0.0840\tBottom_Loss: 0.0499\tLoss: 0.1628\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0096\tTop_Loss: 0.0303\tBottom_Loss: 0.0392\tLoss: 0.0791\t\n",
      "Subject: 026, n=09 | test_f1: 0.29167 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0307\tTop_Loss: 0.0948\tBottom_Loss: 0.0566\tLoss: 0.1820\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0103\tTop_Loss: 0.0219\tBottom_Loss: 0.0244\tLoss: 0.0566\t\n",
      "Subject: 026, n=09 | test_f1: 0.2381 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0343\tTop_Loss: 0.1111\tBottom_Loss: 0.0852\tLoss: 0.2305\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0145\tTop_Loss: 0.0399\tBottom_Loss: 0.0358\tLoss: 0.0902\t\n",
      "Subject: 026, n=09 | test_f1: 0.47059 |best_f1: 1.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0168\tTop_Loss: 0.0358\tBottom_Loss: 0.0458\tLoss: 0.0984\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0261\tTop_Loss: 0.1194\tBottom_Loss: 0.0554\tLoss: 0.2009\t\n",
      "Subject: 026, n=09 | test_f1: 0.47059 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0414\tTop_Loss: 0.0862\tBottom_Loss: 0.0677\tLoss: 0.1953\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0200\tTop_Loss: 0.0453\tBottom_Loss: 0.0753\tLoss: 0.1406\t\n",
      "Subject: 026, n=09 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0117\tTop_Loss: 0.0396\tBottom_Loss: 0.0504\tLoss: 0.1017\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0077\tTop_Loss: 0.0298\tBottom_Loss: 0.0363\tLoss: 0.0738\t\n",
      "Subject: 026, n=09 | test_f1: 0.4375 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0057\tTop_Loss: 0.0234\tBottom_Loss: 0.0239\tLoss: 0.0530\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0413\tTop_Loss: 0.0930\tBottom_Loss: 0.0963\tLoss: 0.2306\t\n",
      "Subject: 026, n=09 | test_f1: 0.4375 |best_f1: 1.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0179\tTop_Loss: 0.0891\tBottom_Loss: 0.0485\tLoss: 0.1555\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0132\tTop_Loss: 0.0393\tBottom_Loss: 0.0423\tLoss: 0.0947\t\n",
      "Subject: 026, n=09 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0114\tTop_Loss: 0.0555\tBottom_Loss: 0.0282\tLoss: 0.0950\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0123\tTop_Loss: 0.0356\tBottom_Loss: 0.0597\tLoss: 0.1076\t\n",
      "Subject: 026, n=09 | test_f1: 0.47059 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1216\tTop_Loss: 0.1906\tBottom_Loss: 0.1352\tLoss: 0.4475\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0138\tTop_Loss: 0.0471\tBottom_Loss: 0.0484\tLoss: 0.1094\t\n",
      "Subject: 026, n=09 | test_f1: 0.4375 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0576\tTop_Loss: 0.1260\tBottom_Loss: 0.0838\tLoss: 0.2675\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0487\tTop_Loss: 0.0772\tBottom_Loss: 0.0967\tLoss: 0.2226\t\n",
      "Subject: 026, n=09 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0147\tTop_Loss: 0.1023\tBottom_Loss: 0.0290\tLoss: 0.1460\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0081\tTop_Loss: 0.0166\tBottom_Loss: 0.0318\tLoss: 0.0565\t\n",
      "Subject: 026, n=09 | test_f1: 0.47059 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0098\tTop_Loss: 0.0525\tBottom_Loss: 0.0368\tLoss: 0.0991\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0189\tTop_Loss: 0.0689\tBottom_Loss: 0.0305\tLoss: 0.1184\t\n",
      "Subject: 026, n=09 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0147\tTop_Loss: 0.0609\tBottom_Loss: 0.0214\tLoss: 0.0970\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0196\tTop_Loss: 0.0507\tBottom_Loss: 0.0830\tLoss: 0.1534\t\n",
      "Subject: 026, n=09 | test_f1: 0.4375 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0237\tTop_Loss: 0.0488\tBottom_Loss: 0.0680\tLoss: 0.1405\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0119\tTop_Loss: 0.0409\tBottom_Loss: 0.0149\tLoss: 0.0678\t\n",
      "Subject: 026, n=09 | test_f1: 0.2381 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0196\tTop_Loss: 0.0371\tBottom_Loss: 0.0214\tLoss: 0.0781\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0124\tTop_Loss: 0.0417\tBottom_Loss: 0.0265\tLoss: 0.0806\t\n",
      "Subject: 026, n=09 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0158\tTop_Loss: 0.0554\tBottom_Loss: 0.0292\tLoss: 0.1004\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0053\tTop_Loss: 0.0180\tBottom_Loss: 0.0245\tLoss: 0.0478\t\n",
      "Subject: 026, n=09 | test_f1: 0.29167 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0096\tTop_Loss: 0.0178\tBottom_Loss: 0.0485\tLoss: 0.0759\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0052\tTop_Loss: 0.0161\tBottom_Loss: 0.0276\tLoss: 0.0489\t\n",
      "Subject: 026, n=09 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0064\tTop_Loss: 0.0161\tBottom_Loss: 0.0245\tLoss: 0.0470\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0045\tTop_Loss: 0.0131\tBottom_Loss: 0.0180\tLoss: 0.0355\t\n",
      "Subject: 026, n=09 | test_f1: 0.4375 |best_f1: 1.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0138\tTop_Loss: 0.0149\tBottom_Loss: 0.0361\tLoss: 0.0648\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0093\tTop_Loss: 0.0200\tBottom_Loss: 0.0341\tLoss: 0.0634\t\n",
      "Subject: 026, n=09 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.562\tLabel_Loss: 0.9637\tTop_Loss: 1.2642\tBottom_Loss: 1.0683\tLoss: 3.2962\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.469\tLabel_Loss: 1.0673\tTop_Loss: 1.1415\tBottom_Loss: 1.1681\tLoss: 3.3769\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8555\tTop_Loss: 0.9147\tBottom_Loss: 0.9615\tLoss: 2.7317\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.438\tLabel_Loss: 1.1113\tTop_Loss: 1.2205\tBottom_Loss: 1.0887\tLoss: 3.4206\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.500\tLabel_Loss: 1.1270\tTop_Loss: 0.9634\tBottom_Loss: 0.9736\tLoss: 3.0639\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.500\tLabel_Loss: 1.0650\tTop_Loss: 1.1130\tBottom_Loss: 1.0999\tLoss: 3.2779\t\n",
      "Subject: 028, n=03 | test_f1: 0.22222 |best_f1: 0.25\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.531\tLabel_Loss: 0.9662\tTop_Loss: 0.9191\tBottom_Loss: 0.8850\tLoss: 2.7703\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.438\tLabel_Loss: 1.1597\tTop_Loss: 0.9406\tBottom_Loss: 0.8904\tLoss: 2.9906\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6780\tTop_Loss: 0.8594\tBottom_Loss: 0.8081\tLoss: 2.3456\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.719\tLabel_Loss: 0.7757\tTop_Loss: 0.8873\tBottom_Loss: 0.9115\tLoss: 2.5745\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8760\tTop_Loss: 1.0730\tBottom_Loss: 1.1055\tLoss: 3.0545\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.594\tLabel_Loss: 0.9677\tTop_Loss: 1.0919\tBottom_Loss: 0.8858\tLoss: 2.9453\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.594\tLabel_Loss: 0.9831\tTop_Loss: 1.1883\tBottom_Loss: 0.9766\tLoss: 3.1480\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8915\tTop_Loss: 0.8848\tBottom_Loss: 0.8379\tLoss: 2.6142\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8307\tTop_Loss: 0.8541\tBottom_Loss: 0.8887\tLoss: 2.5735\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.656\tLabel_Loss: 0.9046\tTop_Loss: 0.9039\tBottom_Loss: 0.8854\tLoss: 2.6939\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8160\tTop_Loss: 0.7939\tBottom_Loss: 0.9073\tLoss: 2.5172\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.812\tLabel_Loss: 0.6717\tTop_Loss: 0.6803\tBottom_Loss: 0.8377\tLoss: 2.1897\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8708\tTop_Loss: 0.7382\tBottom_Loss: 0.7721\tLoss: 2.3811\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7161\tTop_Loss: 0.8109\tBottom_Loss: 0.8435\tLoss: 2.3705\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.719\tLabel_Loss: 0.7483\tTop_Loss: 1.0407\tBottom_Loss: 0.8141\tLoss: 2.6032\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.594\tLabel_Loss: 0.7399\tTop_Loss: 1.0854\tBottom_Loss: 0.9967\tLoss: 2.8220\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5605\tTop_Loss: 0.6796\tBottom_Loss: 0.8062\tLoss: 2.0464\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.656\tLabel_Loss: 0.6801\tTop_Loss: 0.7553\tBottom_Loss: 0.7125\tLoss: 2.1479\t\n",
      "Subject: 028, n=03 | test_f1: 0.66667 |best_f1: 0.66667\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6635\tTop_Loss: 0.7827\tBottom_Loss: 0.8551\tLoss: 2.3013\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.719\tLabel_Loss: 0.5872\tTop_Loss: 0.9287\tBottom_Loss: 0.7750\tLoss: 2.2910\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6764\tTop_Loss: 0.5977\tBottom_Loss: 0.6891\tLoss: 1.9633\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7194\tTop_Loss: 0.8412\tBottom_Loss: 0.6988\tLoss: 2.2593\t\n",
      "Subject: 028, n=03 | test_f1: 0.66667 |best_f1: 0.66667\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.719\tLabel_Loss: 0.7198\tTop_Loss: 0.8482\tBottom_Loss: 0.8390\tLoss: 2.4069\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.719\tLabel_Loss: 0.5128\tTop_Loss: 0.6100\tBottom_Loss: 0.6734\tLoss: 1.7962\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5948\tTop_Loss: 0.8093\tBottom_Loss: 0.7557\tLoss: 2.1598\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6287\tTop_Loss: 0.7739\tBottom_Loss: 0.7256\tLoss: 2.1283\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5764\tTop_Loss: 0.6179\tBottom_Loss: 0.8614\tLoss: 2.0557\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5703\tTop_Loss: 0.6109\tBottom_Loss: 0.6991\tLoss: 1.8803\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6112\tTop_Loss: 0.6515\tBottom_Loss: 0.7811\tLoss: 2.0438\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.625\tLabel_Loss: 0.6984\tTop_Loss: 0.8644\tBottom_Loss: 0.6821\tLoss: 2.2449\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5631\tTop_Loss: 0.6599\tBottom_Loss: 0.4592\tLoss: 1.6822\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4534\tTop_Loss: 0.5858\tBottom_Loss: 0.5442\tLoss: 1.5834\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5376\tTop_Loss: 0.6943\tBottom_Loss: 0.6171\tLoss: 1.8490\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.594\tLabel_Loss: 0.7154\tTop_Loss: 0.8497\tBottom_Loss: 0.6948\tLoss: 2.2600\t\n",
      "Subject: 028, n=03 | test_f1: 0.66667 |best_f1: 0.66667\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3956\tTop_Loss: 0.6080\tBottom_Loss: 0.4453\tLoss: 1.4489\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4701\tTop_Loss: 0.6987\tBottom_Loss: 0.5555\tLoss: 1.7244\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3744\tTop_Loss: 0.6120\tBottom_Loss: 0.4360\tLoss: 1.4225\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3180\tTop_Loss: 0.4417\tBottom_Loss: 0.5087\tLoss: 1.2684\t\n",
      "Subject: 028, n=03 | test_f1: 0.66667 |best_f1: 0.66667\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3686\tTop_Loss: 0.4699\tBottom_Loss: 0.4241\tLoss: 1.2626\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4215\tTop_Loss: 0.4274\tBottom_Loss: 0.4893\tLoss: 1.3382\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.844\tLabel_Loss: 0.5245\tTop_Loss: 0.5589\tBottom_Loss: 0.4945\tLoss: 1.5779\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4354\tTop_Loss: 0.4658\tBottom_Loss: 0.6460\tLoss: 1.5472\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3533\tTop_Loss: 0.5490\tBottom_Loss: 0.5107\tLoss: 1.4130\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5182\tTop_Loss: 0.5755\tBottom_Loss: 0.4205\tLoss: 1.5142\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.750\tLabel_Loss: 0.3962\tTop_Loss: 0.4109\tBottom_Loss: 0.5519\tLoss: 1.3590\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3760\tTop_Loss: 0.6550\tBottom_Loss: 0.3866\tLoss: 1.4177\t\n",
      "Subject: 028, n=03 | test_f1: 0.66667 |best_f1: 0.66667\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3771\tTop_Loss: 0.4746\tBottom_Loss: 0.5910\tLoss: 1.4426\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2803\tTop_Loss: 0.3757\tBottom_Loss: 0.4073\tLoss: 1.0633\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2423\tTop_Loss: 0.4017\tBottom_Loss: 0.4418\tLoss: 1.0858\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4211\tTop_Loss: 0.6508\tBottom_Loss: 0.4692\tLoss: 1.5412\t\n",
      "Subject: 028, n=03 | test_f1: 0.66667 |best_f1: 0.66667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5181\tTop_Loss: 0.5889\tBottom_Loss: 0.5654\tLoss: 1.6725\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3527\tTop_Loss: 0.5405\tBottom_Loss: 0.5301\tLoss: 1.4233\t\n",
      "Subject: 028, n=03 | test_f1: 0.0 |best_f1: 0.66667\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5900\tTop_Loss: 0.7045\tBottom_Loss: 0.8204\tLoss: 2.1149\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2834\tTop_Loss: 0.4274\tBottom_Loss: 0.4312\tLoss: 1.1420\t\n",
      "Subject: 028, n=03 | test_f1: 0.66667 |best_f1: 0.66667\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3555\tTop_Loss: 0.5002\tBottom_Loss: 0.4178\tLoss: 1.2735\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2178\tTop_Loss: 0.3344\tBottom_Loss: 0.4073\tLoss: 0.9595\t\n",
      "Subject: 028, n=03 | test_f1: 0.0 |best_f1: 0.66667\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3296\tTop_Loss: 0.3956\tBottom_Loss: 0.5710\tLoss: 1.2962\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2627\tTop_Loss: 0.3713\tBottom_Loss: 0.4434\tLoss: 1.0774\t\n",
      "Subject: 028, n=03 | test_f1: 0.66667 |best_f1: 0.66667\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2287\tTop_Loss: 0.3498\tBottom_Loss: 0.3080\tLoss: 0.8865\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4298\tTop_Loss: 0.5303\tBottom_Loss: 0.5048\tLoss: 1.4649\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2851\tTop_Loss: 0.4705\tBottom_Loss: 0.4498\tLoss: 1.2054\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3633\tTop_Loss: 0.4924\tBottom_Loss: 0.4319\tLoss: 1.2877\t\n",
      "Subject: 028, n=03 | test_f1: 0.66667 |best_f1: 0.66667\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4156\tTop_Loss: 0.4620\tBottom_Loss: 0.5426\tLoss: 1.4203\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1698\tTop_Loss: 0.2667\tBottom_Loss: 0.3021\tLoss: 0.7386\t\n",
      "Subject: 028, n=03 | test_f1: 0.66667 |best_f1: 0.66667\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1839\tTop_Loss: 0.3159\tBottom_Loss: 0.3145\tLoss: 0.8143\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3046\tTop_Loss: 0.4932\tBottom_Loss: 0.4790\tLoss: 1.2769\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1714\tTop_Loss: 0.2308\tBottom_Loss: 0.2669\tLoss: 0.6691\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1940\tTop_Loss: 0.3243\tBottom_Loss: 0.2378\tLoss: 0.7561\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1385\tTop_Loss: 0.2208\tBottom_Loss: 0.2246\tLoss: 0.5839\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1797\tTop_Loss: 0.4611\tBottom_Loss: 0.2956\tLoss: 0.9364\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.812\tLabel_Loss: 0.2913\tTop_Loss: 0.3230\tBottom_Loss: 0.3183\tLoss: 0.9326\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2747\tTop_Loss: 0.4628\tBottom_Loss: 0.3670\tLoss: 1.1046\t\n",
      "Subject: 028, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2101\tTop_Loss: 0.3711\tBottom_Loss: 0.3418\tLoss: 0.9230\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1655\tTop_Loss: 0.3382\tBottom_Loss: 0.3136\tLoss: 0.8174\t\n",
      "Subject: 028, n=03 | test_f1: 0.66667 |best_f1: 1.0\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1784\tTop_Loss: 0.3765\tBottom_Loss: 0.3173\tLoss: 0.8721\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2179\tTop_Loss: 0.2775\tBottom_Loss: 0.3433\tLoss: 0.8387\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2230\tTop_Loss: 0.3229\tBottom_Loss: 0.2999\tLoss: 0.8458\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1687\tTop_Loss: 0.3482\tBottom_Loss: 0.1338\tLoss: 0.6507\t\n",
      "Subject: 028, n=03 | test_f1: 0.66667 |best_f1: 1.0\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3115\tTop_Loss: 0.4280\tBottom_Loss: 0.3845\tLoss: 1.1240\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1451\tTop_Loss: 0.3273\tBottom_Loss: 0.1712\tLoss: 0.6436\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1293\tTop_Loss: 0.3136\tBottom_Loss: 0.3336\tLoss: 0.7765\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4428\tTop_Loss: 0.3879\tBottom_Loss: 0.3873\tLoss: 1.2180\t\n",
      "Subject: 028, n=03 | test_f1: 0.66667 |best_f1: 1.0\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2115\tTop_Loss: 0.3787\tBottom_Loss: 0.4176\tLoss: 1.0077\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1251\tTop_Loss: 0.2686\tBottom_Loss: 0.2170\tLoss: 0.6107\t\n",
      "Subject: 028, n=03 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1279\tTop_Loss: 0.2119\tBottom_Loss: 0.1927\tLoss: 0.5325\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1454\tTop_Loss: 0.2830\tBottom_Loss: 0.2111\tLoss: 0.6395\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0739\tTop_Loss: 0.1222\tBottom_Loss: 0.2001\tLoss: 0.3962\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1264\tTop_Loss: 0.2526\tBottom_Loss: 0.1781\tLoss: 0.5571\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1746\tTop_Loss: 0.3051\tBottom_Loss: 0.1227\tLoss: 0.6025\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1416\tTop_Loss: 0.2774\tBottom_Loss: 0.2210\tLoss: 0.6400\t\n",
      "Subject: 028, n=03 | test_f1: 0.66667 |best_f1: 1.0\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1976\tTop_Loss: 0.3006\tBottom_Loss: 0.2868\tLoss: 0.7850\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0789\tTop_Loss: 0.1701\tBottom_Loss: 0.1256\tLoss: 0.3746\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1291\tTop_Loss: 0.2916\tBottom_Loss: 0.1585\tLoss: 0.5791\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1508\tTop_Loss: 0.3398\tBottom_Loss: 0.1253\tLoss: 0.6159\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0886\tTop_Loss: 0.2024\tBottom_Loss: 0.2365\tLoss: 0.5275\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0635\tTop_Loss: 0.2048\tBottom_Loss: 0.1129\tLoss: 0.3813\t\n",
      "Subject: 028, n=03 | test_f1: 0.66667 |best_f1: 1.0\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0713\tTop_Loss: 0.2577\tBottom_Loss: 0.1835\tLoss: 0.5125\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1138\tTop_Loss: 0.2546\tBottom_Loss: 0.1419\tLoss: 0.5104\t\n",
      "Subject: 028, n=03 | test_f1: 0.66667 |best_f1: 1.0\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1009\tTop_Loss: 0.1533\tBottom_Loss: 0.1928\tLoss: 0.4470\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0703\tTop_Loss: 0.2082\tBottom_Loss: 0.1695\tLoss: 0.4481\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0556\tTop_Loss: 0.2058\tBottom_Loss: 0.2095\tLoss: 0.4708\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0487\tTop_Loss: 0.1319\tBottom_Loss: 0.1351\tLoss: 0.3156\t\n",
      "Subject: 028, n=03 | test_f1: 0.66667 |best_f1: 1.0\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0800\tTop_Loss: 0.1462\tBottom_Loss: 0.1473\tLoss: 0.3734\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0553\tTop_Loss: 0.2113\tBottom_Loss: 0.1294\tLoss: 0.3960\t\n",
      "Subject: 028, n=03 | test_f1: 0.66667 |best_f1: 1.0\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1597\tTop_Loss: 0.2057\tBottom_Loss: 0.3135\tLoss: 0.6789\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0432\tTop_Loss: 0.1248\tBottom_Loss: 0.0968\tLoss: 0.2648\t\n",
      "Subject: 028, n=03 | test_f1: 0.66667 |best_f1: 1.0\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1200\tTop_Loss: 0.2243\tBottom_Loss: 0.1861\tLoss: 0.5304\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0803\tTop_Loss: 0.2070\tBottom_Loss: 0.2069\tLoss: 0.4942\t\n",
      "Subject: 028, n=03 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0312\tTop_Loss: 0.0883\tBottom_Loss: 0.1203\tLoss: 0.2398\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0660\tTop_Loss: 0.1450\tBottom_Loss: 0.1196\tLoss: 0.3307\t\n",
      "Subject: 028, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0354\tTop_Loss: 0.1714\tBottom_Loss: 0.1072\tLoss: 0.3140\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0605\tTop_Loss: 0.1497\tBottom_Loss: 0.0562\tLoss: 0.2664\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0810\tTop_Loss: 0.1358\tBottom_Loss: 0.2536\tLoss: 0.4704\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0340\tTop_Loss: 0.1451\tBottom_Loss: 0.0752\tLoss: 0.2543\t\n",
      "Subject: 028, n=03 | test_f1: 0.66667 |best_f1: 1.0\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0351\tTop_Loss: 0.0935\tBottom_Loss: 0.2137\tLoss: 0.3423\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0805\tTop_Loss: 0.3394\tBottom_Loss: 0.0951\tLoss: 0.5150\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0789\tTop_Loss: 0.1369\tBottom_Loss: 0.1008\tLoss: 0.3166\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0600\tTop_Loss: 0.1719\tBottom_Loss: 0.1216\tLoss: 0.3534\t\n",
      "Subject: 028, n=03 | test_f1: 0.66667 |best_f1: 1.0\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1161\tTop_Loss: 0.1667\tBottom_Loss: 0.1366\tLoss: 0.4194\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0372\tTop_Loss: 0.1365\tBottom_Loss: 0.0818\tLoss: 0.2555\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0544\tTop_Loss: 0.3194\tBottom_Loss: 0.1098\tLoss: 0.4835\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0503\tTop_Loss: 0.2045\tBottom_Loss: 0.0727\tLoss: 0.3275\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0822\tTop_Loss: 0.1198\tBottom_Loss: 0.0871\tLoss: 0.2890\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0253\tTop_Loss: 0.0707\tBottom_Loss: 0.1597\tLoss: 0.2557\t\n",
      "Subject: 028, n=03 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0378\tTop_Loss: 0.0725\tBottom_Loss: 0.1157\tLoss: 0.2260\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0403\tTop_Loss: 0.1173\tBottom_Loss: 0.0945\tLoss: 0.2521\t\n",
      "Subject: 028, n=03 | test_f1: 0.66667 |best_f1: 1.0\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0405\tTop_Loss: 0.1155\tBottom_Loss: 0.0970\tLoss: 0.2530\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1607\tTop_Loss: 0.1956\tBottom_Loss: 0.2077\tLoss: 0.5639\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 0.938\tLabel_Loss: 0.0841\tTop_Loss: 0.1127\tBottom_Loss: 0.1065\tLoss: 0.3034\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2058\tTop_Loss: 0.1962\tBottom_Loss: 0.2282\tLoss: 0.6302\t\n",
      "Subject: 028, n=03 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0259\tTop_Loss: 0.0819\tBottom_Loss: 0.0572\tLoss: 0.1651\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0493\tTop_Loss: 0.1010\tBottom_Loss: 0.1321\tLoss: 0.2824\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0377\tTop_Loss: 0.0960\tBottom_Loss: 0.0359\tLoss: 0.1696\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0306\tTop_Loss: 0.0597\tBottom_Loss: 0.0786\tLoss: 0.1690\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0521\tTop_Loss: 0.1274\tBottom_Loss: 0.1202\tLoss: 0.2996\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0161\tTop_Loss: 0.0616\tBottom_Loss: 0.0452\tLoss: 0.1229\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0643\tTop_Loss: 0.1249\tBottom_Loss: 0.1834\tLoss: 0.3726\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0213\tTop_Loss: 0.1421\tBottom_Loss: 0.0431\tLoss: 0.2065\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0096\tTop_Loss: 0.0543\tBottom_Loss: 0.0411\tLoss: 0.1050\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0108\tTop_Loss: 0.0470\tBottom_Loss: 0.0417\tLoss: 0.0996\t\n",
      "Subject: 028, n=03 | test_f1: 0.66667 |best_f1: 1.0\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0194\tTop_Loss: 0.1193\tBottom_Loss: 0.0506\tLoss: 0.1894\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0435\tTop_Loss: 0.1502\tBottom_Loss: 0.0480\tLoss: 0.2417\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0110\tTop_Loss: 0.0673\tBottom_Loss: 0.0461\tLoss: 0.1243\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0529\tTop_Loss: 0.1256\tBottom_Loss: 0.0829\tLoss: 0.2614\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0186\tTop_Loss: 0.0574\tBottom_Loss: 0.0600\tLoss: 0.1361\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0490\tTop_Loss: 0.0834\tBottom_Loss: 0.1160\tLoss: 0.2484\t\n",
      "Subject: 028, n=03 | test_f1: 0.66667 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0165\tTop_Loss: 0.0738\tBottom_Loss: 0.0532\tLoss: 0.1436\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0187\tTop_Loss: 0.0457\tBottom_Loss: 0.0605\tLoss: 0.1249\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0922\tTop_Loss: 0.1068\tBottom_Loss: 0.2037\tLoss: 0.4027\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0493\tTop_Loss: 0.0800\tBottom_Loss: 0.0673\tLoss: 0.1966\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0111\tTop_Loss: 0.0472\tBottom_Loss: 0.0306\tLoss: 0.0890\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0234\tTop_Loss: 0.0803\tBottom_Loss: 0.0459\tLoss: 0.1496\t\n",
      "Subject: 028, n=03 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0155\tTop_Loss: 0.0833\tBottom_Loss: 0.0385\tLoss: 0.1373\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0194\tTop_Loss: 0.1131\tBottom_Loss: 0.0547\tLoss: 0.1872\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0144\tTop_Loss: 0.0689\tBottom_Loss: 0.0245\tLoss: 0.1078\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 0.938\tLabel_Loss: 0.0825\tTop_Loss: 0.1464\tBottom_Loss: 0.0897\tLoss: 0.3187\t\n",
      "Subject: 028, n=03 | test_f1: 0.66667 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0271\tTop_Loss: 0.1436\tBottom_Loss: 0.0357\tLoss: 0.2064\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0112\tTop_Loss: 0.0456\tBottom_Loss: 0.0251\tLoss: 0.0819\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0260\tTop_Loss: 0.1118\tBottom_Loss: 0.0574\tLoss: 0.1952\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0749\tTop_Loss: 0.1627\tBottom_Loss: 0.0922\tLoss: 0.3298\t\n",
      "Subject: 028, n=03 | test_f1: 0.66667 |best_f1: 1.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0103\tTop_Loss: 0.0347\tBottom_Loss: 0.0321\tLoss: 0.0771\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0207\tTop_Loss: 0.1160\tBottom_Loss: 0.0364\tLoss: 0.1731\t\n",
      "Subject: 028, n=03 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0102\tTop_Loss: 0.0524\tBottom_Loss: 0.0194\tLoss: 0.0820\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0130\tTop_Loss: 0.0850\tBottom_Loss: 0.0280\tLoss: 0.1260\t\n",
      "Subject: 028, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0168\tTop_Loss: 0.0957\tBottom_Loss: 0.0248\tLoss: 0.1373\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0130\tTop_Loss: 0.0498\tBottom_Loss: 0.0158\tLoss: 0.0786\t\n",
      "Subject: 028, n=03 | test_f1: 0.66667 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0186\tTop_Loss: 0.0940\tBottom_Loss: 0.0411\tLoss: 0.1537\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0665\tTop_Loss: 0.1403\tBottom_Loss: 0.1121\tLoss: 0.3188\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0070\tTop_Loss: 0.0497\tBottom_Loss: 0.0231\tLoss: 0.0798\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0103\tTop_Loss: 0.0172\tBottom_Loss: 0.0478\tLoss: 0.0752\t\n",
      "Subject: 028, n=03 | test_f1: 0.66667 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0174\tTop_Loss: 0.0726\tBottom_Loss: 0.0427\tLoss: 0.1328\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0416\tTop_Loss: 0.1344\tBottom_Loss: 0.1257\tLoss: 0.3017\t\n",
      "Subject: 028, n=03 | test_f1: 0.66667 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0191\tTop_Loss: 0.0947\tBottom_Loss: 0.0381\tLoss: 0.1519\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0217\tTop_Loss: 0.0575\tBottom_Loss: 0.0413\tLoss: 0.1205\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0203\tTop_Loss: 0.0316\tBottom_Loss: 0.0399\tLoss: 0.0917\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0085\tTop_Loss: 0.0564\tBottom_Loss: 0.0346\tLoss: 0.0994\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0102\tTop_Loss: 0.1012\tBottom_Loss: 0.0259\tLoss: 0.1373\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0110\tTop_Loss: 0.0235\tBottom_Loss: 0.0353\tLoss: 0.0698\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0137\tTop_Loss: 0.0280\tBottom_Loss: 0.0490\tLoss: 0.0907\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0588\tTop_Loss: 0.0793\tBottom_Loss: 0.1297\tLoss: 0.2677\t\n",
      "Subject: 028, n=03 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0108\tTop_Loss: 0.0290\tBottom_Loss: 0.0306\tLoss: 0.0704\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0135\tTop_Loss: 0.0408\tBottom_Loss: 0.0183\tLoss: 0.0726\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0130\tTop_Loss: 0.0451\tBottom_Loss: 0.0252\tLoss: 0.0833\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0233\tTop_Loss: 0.0351\tBottom_Loss: 0.0616\tLoss: 0.1200\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0156\tTop_Loss: 0.0311\tBottom_Loss: 0.0362\tLoss: 0.0828\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0179\tTop_Loss: 0.0461\tBottom_Loss: 0.0308\tLoss: 0.0947\t\n",
      "Subject: 028, n=03 | test_f1: 0.66667 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0273\tTop_Loss: 0.0367\tBottom_Loss: 0.0513\tLoss: 0.1153\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0066\tTop_Loss: 0.0227\tBottom_Loss: 0.0190\tLoss: 0.0482\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0080\tTop_Loss: 0.0226\tBottom_Loss: 0.0272\tLoss: 0.0578\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0082\tTop_Loss: 0.0327\tBottom_Loss: 0.0329\tLoss: 0.0738\t\n",
      "Subject: 028, n=03 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0064\tTop_Loss: 0.0225\tBottom_Loss: 0.0191\tLoss: 0.0481\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0622\tTop_Loss: 0.0348\tBottom_Loss: 0.1576\tLoss: 0.2547\t\n",
      "Subject: 028, n=03 | test_f1: 0.66667 |best_f1: 1.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0027\tTop_Loss: 0.0162\tBottom_Loss: 0.0106\tLoss: 0.0295\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0053\tTop_Loss: 0.0431\tBottom_Loss: 0.0122\tLoss: 0.0606\t\n",
      "Subject: 028, n=03 | test_f1: 0.66667 |best_f1: 1.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.406\tLabel_Loss: 1.1193\tTop_Loss: 1.7806\tBottom_Loss: 1.6235\tLoss: 4.5235\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.500\tLabel_Loss: 1.0831\tTop_Loss: 1.3390\tBottom_Loss: 1.2713\tLoss: 3.6934\t\n",
      "Subject: 03, n=05 | test_f1: 0.19048 |best_f1: 0.19048\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8766\tTop_Loss: 0.9108\tBottom_Loss: 1.0640\tLoss: 2.8514\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.562\tLabel_Loss: 0.9978\tTop_Loss: 0.9250\tBottom_Loss: 0.9270\tLoss: 2.8498\t\n",
      "Subject: 03, n=05 | test_f1: 0.44444 |best_f1: 0.44444\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.562\tLabel_Loss: 1.1563\tTop_Loss: 1.1174\tBottom_Loss: 1.0964\tLoss: 3.3702\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.406\tLabel_Loss: 1.0872\tTop_Loss: 1.0890\tBottom_Loss: 1.0542\tLoss: 3.2304\t\n",
      "Subject: 03, n=05 | test_f1: 0.44444 |best_f1: 0.44444\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.562\tLabel_Loss: 0.9052\tTop_Loss: 0.9632\tBottom_Loss: 0.9212\tLoss: 2.7897\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7605\tTop_Loss: 0.7714\tBottom_Loss: 1.0207\tLoss: 2.5526\t\n",
      "Subject: 03, n=05 | test_f1: 0.44444 |best_f1: 0.44444\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.531\tLabel_Loss: 0.9902\tTop_Loss: 1.1757\tBottom_Loss: 1.2192\tLoss: 3.3852\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.719\tLabel_Loss: 0.7355\tTop_Loss: 0.9007\tBottom_Loss: 0.7810\tLoss: 2.4172\t\n",
      "Subject: 03, n=05 | test_f1: 0.44444 |best_f1: 0.44444\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.562\tLabel_Loss: 0.9036\tTop_Loss: 1.0099\tBottom_Loss: 0.8422\tLoss: 2.7558\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.719\tLabel_Loss: 0.7542\tTop_Loss: 0.9449\tBottom_Loss: 0.8252\tLoss: 2.5244\t\n",
      "Subject: 03, n=05 | test_f1: 0.61905 |best_f1: 0.61905\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.438\tLabel_Loss: 0.9418\tTop_Loss: 1.0521\tBottom_Loss: 1.0151\tLoss: 3.0091\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.594\tLabel_Loss: 0.7512\tTop_Loss: 0.9315\tBottom_Loss: 0.9872\tLoss: 2.6700\t\n",
      "Subject: 03, n=05 | test_f1: 0.44444 |best_f1: 0.61905\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.656\tLabel_Loss: 0.6556\tTop_Loss: 0.8670\tBottom_Loss: 0.6970\tLoss: 2.2195\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.750\tLabel_Loss: 0.7334\tTop_Loss: 0.8318\tBottom_Loss: 0.8223\tLoss: 2.3874\t\n",
      "Subject: 03, n=05 | test_f1: 0.19048 |best_f1: 0.61905\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8085\tTop_Loss: 0.9590\tBottom_Loss: 0.8486\tLoss: 2.6161\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5952\tTop_Loss: 0.7346\tBottom_Loss: 0.7686\tLoss: 2.0984\t\n",
      "Subject: 03, n=05 | test_f1: 0.28571 |best_f1: 0.61905\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7744\tTop_Loss: 0.7411\tBottom_Loss: 0.9267\tLoss: 2.4422\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8573\tTop_Loss: 0.7146\tBottom_Loss: 0.9466\tLoss: 2.5186\t\n",
      "Subject: 03, n=05 | test_f1: 0.13333 |best_f1: 0.61905\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.500\tLabel_Loss: 0.8818\tTop_Loss: 0.9587\tBottom_Loss: 0.7640\tLoss: 2.6045\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8904\tTop_Loss: 0.9013\tBottom_Loss: 0.9400\tLoss: 2.7317\t\n",
      "Subject: 03, n=05 | test_f1: 0.375 |best_f1: 0.61905\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7330\tTop_Loss: 0.9228\tBottom_Loss: 0.8576\tLoss: 2.5134\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8867\tTop_Loss: 0.8520\tBottom_Loss: 1.1205\tLoss: 2.8592\t\n",
      "Subject: 03, n=05 | test_f1: 0.25 |best_f1: 0.61905\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.781\tLabel_Loss: 0.6300\tTop_Loss: 0.6620\tBottom_Loss: 0.8303\tLoss: 2.1223\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7523\tTop_Loss: 0.8289\tBottom_Loss: 0.7885\tLoss: 2.3697\t\n",
      "Subject: 03, n=05 | test_f1: 0.55556 |best_f1: 0.61905\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5909\tTop_Loss: 0.6574\tBottom_Loss: 0.6905\tLoss: 1.9388\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6851\tTop_Loss: 0.8423\tBottom_Loss: 0.8285\tLoss: 2.3559\t\n",
      "Subject: 03, n=05 | test_f1: 0.44444 |best_f1: 0.61905\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5691\tTop_Loss: 0.7131\tBottom_Loss: 0.7300\tLoss: 2.0122\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.812\tLabel_Loss: 0.6326\tTop_Loss: 0.8607\tBottom_Loss: 0.6149\tLoss: 2.1083\t\n",
      "Subject: 03, n=05 | test_f1: 0.61905 |best_f1: 0.61905\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4467\tTop_Loss: 0.6366\tBottom_Loss: 0.5731\tLoss: 1.6564\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.594\tLabel_Loss: 0.7211\tTop_Loss: 0.7538\tBottom_Loss: 0.6160\tLoss: 2.0909\t\n",
      "Subject: 03, n=05 | test_f1: 0.25 |best_f1: 0.61905\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7861\tTop_Loss: 0.8196\tBottom_Loss: 0.6940\tLoss: 2.2998\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7145\tTop_Loss: 0.9175\tBottom_Loss: 0.8716\tLoss: 2.5037\t\n",
      "Subject: 03, n=05 | test_f1: 0.61905 |best_f1: 0.61905\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5729\tTop_Loss: 0.7957\tBottom_Loss: 0.6792\tLoss: 2.0478\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.875\tLabel_Loss: 0.5815\tTop_Loss: 0.7072\tBottom_Loss: 0.8077\tLoss: 2.0963\t\n",
      "Subject: 03, n=05 | test_f1: 0.61905 |best_f1: 0.61905\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7442\tTop_Loss: 0.7102\tBottom_Loss: 0.8596\tLoss: 2.3141\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6416\tTop_Loss: 0.6808\tBottom_Loss: 0.6130\tLoss: 1.9354\t\n",
      "Subject: 03, n=05 | test_f1: 0.25 |best_f1: 0.61905\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5736\tTop_Loss: 0.5544\tBottom_Loss: 0.6464\tLoss: 1.7744\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4826\tTop_Loss: 0.5563\tBottom_Loss: 0.5973\tLoss: 1.6362\t\n",
      "Subject: 03, n=05 | test_f1: 0.61905 |best_f1: 0.61905\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5218\tTop_Loss: 0.5649\tBottom_Loss: 0.6356\tLoss: 1.7223\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3543\tTop_Loss: 0.4803\tBottom_Loss: 0.5788\tLoss: 1.4134\t\n",
      "Subject: 03, n=05 | test_f1: 0.19048 |best_f1: 0.61905\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5107\tTop_Loss: 0.7850\tBottom_Loss: 0.4993\tLoss: 1.7950\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5049\tTop_Loss: 0.6792\tBottom_Loss: 0.5846\tLoss: 1.7687\t\n",
      "Subject: 03, n=05 | test_f1: 0.55556 |best_f1: 0.61905\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4028\tTop_Loss: 0.4162\tBottom_Loss: 0.4197\tLoss: 1.2387\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4054\tTop_Loss: 0.6099\tBottom_Loss: 0.5200\tLoss: 1.5353\t\n",
      "Subject: 03, n=05 | test_f1: 0.25 |best_f1: 0.61905\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4656\tTop_Loss: 0.5454\tBottom_Loss: 0.5831\tLoss: 1.5941\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3734\tTop_Loss: 0.5382\tBottom_Loss: 0.6204\tLoss: 1.5320\t\n",
      "Subject: 03, n=05 | test_f1: 0.19048 |best_f1: 0.61905\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3968\tTop_Loss: 0.4943\tBottom_Loss: 0.4633\tLoss: 1.3544\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3360\tTop_Loss: 0.5568\tBottom_Loss: 0.6051\tLoss: 1.4979\t\n",
      "Subject: 03, n=05 | test_f1: 0.11111 |best_f1: 0.61905\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2513\tTop_Loss: 0.4019\tBottom_Loss: 0.3686\tLoss: 1.0218\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.719\tLabel_Loss: 0.5420\tTop_Loss: 0.6711\tBottom_Loss: 0.6636\tLoss: 1.8767\t\n",
      "Subject: 03, n=05 | test_f1: 0.61905 |best_f1: 0.61905\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3871\tTop_Loss: 0.4230\tBottom_Loss: 0.6383\tLoss: 1.4484\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4295\tTop_Loss: 0.5989\tBottom_Loss: 0.7051\tLoss: 1.7335\t\n",
      "Subject: 03, n=05 | test_f1: 0.19048 |best_f1: 0.61905\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2718\tTop_Loss: 0.4891\tBottom_Loss: 0.5008\tLoss: 1.2616\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3578\tTop_Loss: 0.5015\tBottom_Loss: 0.5486\tLoss: 1.4079\t\n",
      "Subject: 03, n=05 | test_f1: 0.25 |best_f1: 0.61905\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3071\tTop_Loss: 0.3962\tBottom_Loss: 0.4299\tLoss: 1.1332\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3378\tTop_Loss: 0.4993\tBottom_Loss: 0.4367\tLoss: 1.2739\t\n",
      "Subject: 03, n=05 | test_f1: 0.55556 |best_f1: 0.61905\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3378\tTop_Loss: 0.3812\tBottom_Loss: 0.6028\tLoss: 1.3218\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3239\tTop_Loss: 0.4162\tBottom_Loss: 0.7070\tLoss: 1.4471\t\n",
      "Subject: 03, n=05 | test_f1: 0.375 |best_f1: 0.61905\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2216\tTop_Loss: 0.4090\tBottom_Loss: 0.3173\tLoss: 0.9479\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1909\tTop_Loss: 0.3127\tBottom_Loss: 0.2874\tLoss: 0.7910\t\n",
      "Subject: 03, n=05 | test_f1: 0.19048 |best_f1: 0.61905\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3077\tTop_Loss: 0.4582\tBottom_Loss: 0.4450\tLoss: 1.2109\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1843\tTop_Loss: 0.2827\tBottom_Loss: 0.3324\tLoss: 0.7995\t\n",
      "Subject: 03, n=05 | test_f1: 0.25 |best_f1: 0.61905\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2362\tTop_Loss: 0.4113\tBottom_Loss: 0.4787\tLoss: 1.1262\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1766\tTop_Loss: 0.4547\tBottom_Loss: 0.3092\tLoss: 0.9405\t\n",
      "Subject: 03, n=05 | test_f1: 0.375 |best_f1: 0.61905\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2159\tTop_Loss: 0.3024\tBottom_Loss: 0.2824\tLoss: 0.8007\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2259\tTop_Loss: 0.4352\tBottom_Loss: 0.3879\tLoss: 1.0490\t\n",
      "Subject: 03, n=05 | test_f1: 0.25 |best_f1: 0.61905\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3582\tTop_Loss: 0.4140\tBottom_Loss: 0.5178\tLoss: 1.2901\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.719\tLabel_Loss: 0.5117\tTop_Loss: 0.4780\tBottom_Loss: 0.7024\tLoss: 1.6921\t\n",
      "Subject: 03, n=05 | test_f1: 0.3 |best_f1: 0.61905\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1213\tTop_Loss: 0.2833\tBottom_Loss: 0.2458\tLoss: 0.6504\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2172\tTop_Loss: 0.4717\tBottom_Loss: 0.5159\tLoss: 1.2048\t\n",
      "Subject: 03, n=05 | test_f1: 0.19048 |best_f1: 0.61905\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2552\tTop_Loss: 0.4261\tBottom_Loss: 0.3253\tLoss: 1.0066\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2000\tTop_Loss: 0.3764\tBottom_Loss: 0.3205\tLoss: 0.8969\t\n",
      "Subject: 03, n=05 | test_f1: 0.19048 |best_f1: 0.61905\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2001\tTop_Loss: 0.3035\tBottom_Loss: 0.3628\tLoss: 0.8664\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1987\tTop_Loss: 0.4372\tBottom_Loss: 0.2316\tLoss: 0.8676\t\n",
      "Subject: 03, n=05 | test_f1: 0.7619 |best_f1: 0.7619\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1930\tTop_Loss: 0.3080\tBottom_Loss: 0.3222\tLoss: 0.8233\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2001\tTop_Loss: 0.4028\tBottom_Loss: 0.4526\tLoss: 1.0555\t\n",
      "Subject: 03, n=05 | test_f1: 0.375 |best_f1: 0.7619\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1324\tTop_Loss: 0.3298\tBottom_Loss: 0.2782\tLoss: 0.7404\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0879\tTop_Loss: 0.1848\tBottom_Loss: 0.2094\tLoss: 0.4822\t\n",
      "Subject: 03, n=05 | test_f1: 0.19048 |best_f1: 0.7619\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1602\tTop_Loss: 0.3749\tBottom_Loss: 0.2468\tLoss: 0.7819\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1641\tTop_Loss: 0.3504\tBottom_Loss: 0.2698\tLoss: 0.7843\t\n",
      "Subject: 03, n=05 | test_f1: 0.19048 |best_f1: 0.7619\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0776\tTop_Loss: 0.1938\tBottom_Loss: 0.2887\tLoss: 0.5601\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2018\tTop_Loss: 0.3202\tBottom_Loss: 0.3762\tLoss: 0.8982\t\n",
      "Subject: 03, n=05 | test_f1: 0.19048 |best_f1: 0.7619\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3491\tTop_Loss: 0.5436\tBottom_Loss: 0.6032\tLoss: 1.4960\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1135\tTop_Loss: 0.2126\tBottom_Loss: 0.2555\tLoss: 0.5816\t\n",
      "Subject: 03, n=05 | test_f1: 0.11111 |best_f1: 0.7619\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1724\tTop_Loss: 0.2723\tBottom_Loss: 0.2527\tLoss: 0.6974\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1267\tTop_Loss: 0.1733\tBottom_Loss: 0.3322\tLoss: 0.6322\t\n",
      "Subject: 03, n=05 | test_f1: 0.19048 |best_f1: 0.7619\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1743\tTop_Loss: 0.2399\tBottom_Loss: 0.2000\tLoss: 0.6142\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0871\tTop_Loss: 0.2645\tBottom_Loss: 0.2185\tLoss: 0.5702\t\n",
      "Subject: 03, n=05 | test_f1: 0.44444 |best_f1: 0.7619\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1728\tTop_Loss: 0.3690\tBottom_Loss: 0.2899\tLoss: 0.8317\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1937\tTop_Loss: 0.2231\tBottom_Loss: 0.2414\tLoss: 0.6583\t\n",
      "Subject: 03, n=05 | test_f1: 0.61905 |best_f1: 0.7619\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1077\tTop_Loss: 0.2726\tBottom_Loss: 0.2359\tLoss: 0.6163\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1550\tTop_Loss: 0.2019\tBottom_Loss: 0.2820\tLoss: 0.6389\t\n",
      "Subject: 03, n=05 | test_f1: 0.19048 |best_f1: 0.7619\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0998\tTop_Loss: 0.1907\tBottom_Loss: 0.2592\tLoss: 0.5498\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1205\tTop_Loss: 0.2225\tBottom_Loss: 0.2608\tLoss: 0.6037\t\n",
      "Subject: 03, n=05 | test_f1: 0.375 |best_f1: 0.7619\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1102\tTop_Loss: 0.3487\tBottom_Loss: 0.2509\tLoss: 0.7097\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1634\tTop_Loss: 0.3522\tBottom_Loss: 0.1679\tLoss: 0.6836\t\n",
      "Subject: 03, n=05 | test_f1: 0.44444 |best_f1: 0.7619\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0960\tTop_Loss: 0.2233\tBottom_Loss: 0.2458\tLoss: 0.5651\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0761\tTop_Loss: 0.1637\tBottom_Loss: 0.2467\tLoss: 0.4865\t\n",
      "Subject: 03, n=05 | test_f1: 0.19048 |best_f1: 0.7619\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0667\tTop_Loss: 0.2356\tBottom_Loss: 0.1787\tLoss: 0.4809\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2175\tTop_Loss: 0.2809\tBottom_Loss: 0.3271\tLoss: 0.8255\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 03, n=05 | test_f1: 0.19048 |best_f1: 0.7619\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1405\tTop_Loss: 0.1458\tBottom_Loss: 0.2545\tLoss: 0.5408\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1768\tTop_Loss: 0.2756\tBottom_Loss: 0.3185\tLoss: 0.7708\t\n",
      "Subject: 03, n=05 | test_f1: 0.19048 |best_f1: 0.7619\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1074\tTop_Loss: 0.2544\tBottom_Loss: 0.2766\tLoss: 0.6384\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1230\tTop_Loss: 0.1777\tBottom_Loss: 0.2472\tLoss: 0.5480\t\n",
      "Subject: 03, n=05 | test_f1: 0.11111 |best_f1: 0.7619\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0972\tTop_Loss: 0.2596\tBottom_Loss: 0.1325\tLoss: 0.4892\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0699\tTop_Loss: 0.1730\tBottom_Loss: 0.2515\tLoss: 0.4944\t\n",
      "Subject: 03, n=05 | test_f1: 0.19048 |best_f1: 0.7619\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0693\tTop_Loss: 0.2059\tBottom_Loss: 0.1837\tLoss: 0.4589\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0947\tTop_Loss: 0.2666\tBottom_Loss: 0.2101\tLoss: 0.5715\t\n",
      "Subject: 03, n=05 | test_f1: 0.19048 |best_f1: 0.7619\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0655\tTop_Loss: 0.1995\tBottom_Loss: 0.2162\tLoss: 0.4812\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0848\tTop_Loss: 0.1763\tBottom_Loss: 0.2873\tLoss: 0.5483\t\n",
      "Subject: 03, n=05 | test_f1: 0.28571 |best_f1: 0.7619\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1400\tTop_Loss: 0.2874\tBottom_Loss: 0.1922\tLoss: 0.6196\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0856\tTop_Loss: 0.1589\tBottom_Loss: 0.1521\tLoss: 0.3967\t\n",
      "Subject: 03, n=05 | test_f1: 0.19048 |best_f1: 0.7619\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0459\tTop_Loss: 0.1827\tBottom_Loss: 0.1088\tLoss: 0.3374\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1057\tTop_Loss: 0.1927\tBottom_Loss: 0.2570\tLoss: 0.5554\t\n",
      "Subject: 03, n=05 | test_f1: 0.11111 |best_f1: 0.7619\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0348\tTop_Loss: 0.0960\tBottom_Loss: 0.0717\tLoss: 0.2025\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1353\tTop_Loss: 0.2649\tBottom_Loss: 0.2516\tLoss: 0.6518\t\n",
      "Subject: 03, n=05 | test_f1: 0.44444 |best_f1: 0.7619\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0871\tTop_Loss: 0.1736\tBottom_Loss: 0.1277\tLoss: 0.3884\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0743\tTop_Loss: 0.2811\tBottom_Loss: 0.1716\tLoss: 0.5270\t\n",
      "Subject: 03, n=05 | test_f1: 0.28571 |best_f1: 0.7619\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0569\tTop_Loss: 0.0977\tBottom_Loss: 0.1899\tLoss: 0.3446\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0506\tTop_Loss: 0.1493\tBottom_Loss: 0.1398\tLoss: 0.3396\t\n",
      "Subject: 03, n=05 | test_f1: 0.11111 |best_f1: 0.7619\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0570\tTop_Loss: 0.1223\tBottom_Loss: 0.0960\tLoss: 0.2753\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0547\tTop_Loss: 0.1065\tBottom_Loss: 0.2045\tLoss: 0.3657\t\n",
      "Subject: 03, n=05 | test_f1: 0.19048 |best_f1: 0.7619\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0947\tTop_Loss: 0.1241\tBottom_Loss: 0.2914\tLoss: 0.5101\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0335\tTop_Loss: 0.0856\tBottom_Loss: 0.0837\tLoss: 0.2029\t\n",
      "Subject: 03, n=05 | test_f1: 0.55556 |best_f1: 0.7619\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0319\tTop_Loss: 0.1190\tBottom_Loss: 0.1074\tLoss: 0.2584\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0388\tTop_Loss: 0.1979\tBottom_Loss: 0.0725\tLoss: 0.3092\t\n",
      "Subject: 03, n=05 | test_f1: 0.19048 |best_f1: 0.7619\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0560\tTop_Loss: 0.0701\tBottom_Loss: 0.1169\tLoss: 0.2429\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0874\tTop_Loss: 0.1932\tBottom_Loss: 0.1800\tLoss: 0.4606\t\n",
      "Subject: 03, n=05 | test_f1: 0.19048 |best_f1: 0.7619\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1417\tTop_Loss: 0.1885\tBottom_Loss: 0.1623\tLoss: 0.4925\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1114\tTop_Loss: 0.1834\tBottom_Loss: 0.1461\tLoss: 0.4409\t\n",
      "Subject: 03, n=05 | test_f1: 0.11111 |best_f1: 0.7619\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0405\tTop_Loss: 0.0967\tBottom_Loss: 0.0882\tLoss: 0.2254\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0715\tTop_Loss: 0.2145\tBottom_Loss: 0.1703\tLoss: 0.4563\t\n",
      "Subject: 03, n=05 | test_f1: 0.11111 |best_f1: 0.7619\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0592\tTop_Loss: 0.1297\tBottom_Loss: 0.0525\tLoss: 0.2413\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0582\tTop_Loss: 0.1185\tBottom_Loss: 0.1714\tLoss: 0.3481\t\n",
      "Subject: 03, n=05 | test_f1: 0.44444 |best_f1: 0.7619\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0789\tTop_Loss: 0.1565\tBottom_Loss: 0.1262\tLoss: 0.3616\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1332\tTop_Loss: 0.2100\tBottom_Loss: 0.1874\tLoss: 0.5305\t\n",
      "Subject: 03, n=05 | test_f1: 0.44444 |best_f1: 0.7619\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0181\tTop_Loss: 0.0555\tBottom_Loss: 0.0624\tLoss: 0.1360\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1010\tTop_Loss: 0.1522\tBottom_Loss: 0.1396\tLoss: 0.3927\t\n",
      "Subject: 03, n=05 | test_f1: 0.0 |best_f1: 0.7619\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1550\tTop_Loss: 0.1952\tBottom_Loss: 0.1768\tLoss: 0.5270\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0203\tTop_Loss: 0.0696\tBottom_Loss: 0.0714\tLoss: 0.1613\t\n",
      "Subject: 03, n=05 | test_f1: 0.19048 |best_f1: 0.7619\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0379\tTop_Loss: 0.0678\tBottom_Loss: 0.0890\tLoss: 0.1946\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0740\tTop_Loss: 0.0851\tBottom_Loss: 0.1291\tLoss: 0.2882\t\n",
      "Subject: 03, n=05 | test_f1: 0.19048 |best_f1: 0.7619\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0284\tTop_Loss: 0.1325\tBottom_Loss: 0.0596\tLoss: 0.2205\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0500\tTop_Loss: 0.1818\tBottom_Loss: 0.0635\tLoss: 0.2953\t\n",
      "Subject: 03, n=05 | test_f1: 0.19048 |best_f1: 0.7619\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0272\tTop_Loss: 0.1182\tBottom_Loss: 0.0609\tLoss: 0.2063\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0257\tTop_Loss: 0.0623\tBottom_Loss: 0.0922\tLoss: 0.1802\t\n",
      "Subject: 03, n=05 | test_f1: 0.11111 |best_f1: 0.7619\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0258\tTop_Loss: 0.0994\tBottom_Loss: 0.1131\tLoss: 0.2383\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0449\tTop_Loss: 0.1081\tBottom_Loss: 0.1042\tLoss: 0.2572\t\n",
      "Subject: 03, n=05 | test_f1: 0.19048 |best_f1: 0.7619\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0809\tTop_Loss: 0.0875\tBottom_Loss: 0.1178\tLoss: 0.2863\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0230\tTop_Loss: 0.0585\tBottom_Loss: 0.0387\tLoss: 0.1202\t\n",
      "Subject: 03, n=05 | test_f1: 0.11111 |best_f1: 0.7619\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0315\tTop_Loss: 0.0629\tBottom_Loss: 0.0850\tLoss: 0.1794\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0637\tTop_Loss: 0.1059\tBottom_Loss: 0.0887\tLoss: 0.2583\t\n",
      "Subject: 03, n=05 | test_f1: 0.19048 |best_f1: 0.7619\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0192\tTop_Loss: 0.0790\tBottom_Loss: 0.0760\tLoss: 0.1743\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0273\tTop_Loss: 0.0558\tBottom_Loss: 0.0623\tLoss: 0.1454\t\n",
      "Subject: 03, n=05 | test_f1: 0.375 |best_f1: 0.7619\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0327\tTop_Loss: 0.1027\tBottom_Loss: 0.0740\tLoss: 0.2094\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0098\tTop_Loss: 0.0382\tBottom_Loss: 0.0295\tLoss: 0.0774\t\n",
      "Subject: 03, n=05 | test_f1: 0.19048 |best_f1: 0.7619\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0143\tTop_Loss: 0.0355\tBottom_Loss: 0.0456\tLoss: 0.0954\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0564\tTop_Loss: 0.1400\tBottom_Loss: 0.0712\tLoss: 0.2676\t\n",
      "Subject: 03, n=05 | test_f1: 0.19048 |best_f1: 0.7619\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1492\tTop_Loss: 0.1500\tBottom_Loss: 0.2452\tLoss: 0.5444\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0192\tTop_Loss: 0.0480\tBottom_Loss: 0.0620\tLoss: 0.1292\t\n",
      "Subject: 03, n=05 | test_f1: 0.7619 |best_f1: 0.7619\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0155\tTop_Loss: 0.0511\tBottom_Loss: 0.0544\tLoss: 0.1210\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0296\tTop_Loss: 0.0889\tBottom_Loss: 0.0597\tLoss: 0.1782\t\n",
      "Subject: 03, n=05 | test_f1: 0.25 |best_f1: 0.7619\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0163\tTop_Loss: 0.0442\tBottom_Loss: 0.0537\tLoss: 0.1142\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0161\tTop_Loss: 0.1291\tBottom_Loss: 0.0626\tLoss: 0.2078\t\n",
      "Subject: 03, n=05 | test_f1: 0.19048 |best_f1: 0.7619\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0132\tTop_Loss: 0.0651\tBottom_Loss: 0.0538\tLoss: 0.1321\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0290\tTop_Loss: 0.1151\tBottom_Loss: 0.0474\tLoss: 0.1915\t\n",
      "Subject: 03, n=05 | test_f1: 0.375 |best_f1: 0.7619\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0460\tTop_Loss: 0.0460\tBottom_Loss: 0.0898\tLoss: 0.1818\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1307\tTop_Loss: 0.1634\tBottom_Loss: 0.1223\tLoss: 0.4164\t\n",
      "Subject: 03, n=05 | test_f1: 0.11111 |best_f1: 0.7619\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0149\tTop_Loss: 0.0286\tBottom_Loss: 0.0580\tLoss: 0.1015\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0267\tTop_Loss: 0.0661\tBottom_Loss: 0.0805\tLoss: 0.1733\t\n",
      "Subject: 03, n=05 | test_f1: 0.19048 |best_f1: 0.7619\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0307\tTop_Loss: 0.0723\tBottom_Loss: 0.0649\tLoss: 0.1680\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1520\tTop_Loss: 0.1588\tBottom_Loss: 0.0816\tLoss: 0.3924\t\n",
      "Subject: 03, n=05 | test_f1: 0.375 |best_f1: 0.7619\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0156\tTop_Loss: 0.0623\tBottom_Loss: 0.0390\tLoss: 0.1170\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0058\tTop_Loss: 0.0314\tBottom_Loss: 0.0336\tLoss: 0.0707\t\n",
      "Subject: 03, n=05 | test_f1: 0.44444 |best_f1: 0.7619\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0579\tTop_Loss: 0.0457\tBottom_Loss: 0.0993\tLoss: 0.2029\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0065\tTop_Loss: 0.0203\tBottom_Loss: 0.0405\tLoss: 0.0673\t\n",
      "Subject: 03, n=05 | test_f1: 0.44444 |best_f1: 0.7619\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0260\tTop_Loss: 0.1321\tBottom_Loss: 0.0371\tLoss: 0.1952\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0074\tTop_Loss: 0.0390\tBottom_Loss: 0.0315\tLoss: 0.0778\t\n",
      "Subject: 03, n=05 | test_f1: 0.44444 |best_f1: 0.7619\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0162\tTop_Loss: 0.0654\tBottom_Loss: 0.0355\tLoss: 0.1171\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0469\tTop_Loss: 0.1049\tBottom_Loss: 0.1071\tLoss: 0.2589\t\n",
      "Subject: 03, n=05 | test_f1: 0.11111 |best_f1: 0.7619\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0118\tTop_Loss: 0.0381\tBottom_Loss: 0.0275\tLoss: 0.0775\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0149\tTop_Loss: 0.0588\tBottom_Loss: 0.0620\tLoss: 0.1358\t\n",
      "Subject: 03, n=05 | test_f1: 0.19048 |best_f1: 0.7619\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0114\tTop_Loss: 0.0213\tBottom_Loss: 0.0439\tLoss: 0.0766\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0060\tTop_Loss: 0.0190\tBottom_Loss: 0.0335\tLoss: 0.0585\t\n",
      "Subject: 03, n=05 | test_f1: 0.25 |best_f1: 0.7619\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0112\tTop_Loss: 0.0300\tBottom_Loss: 0.0608\tLoss: 0.1021\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0490\tTop_Loss: 0.0860\tBottom_Loss: 0.1277\tLoss: 0.2628\t\n",
      "Subject: 03, n=05 | test_f1: 0.44444 |best_f1: 0.7619\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0081\tTop_Loss: 0.0328\tBottom_Loss: 0.0413\tLoss: 0.0822\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0060\tTop_Loss: 0.0155\tBottom_Loss: 0.0406\tLoss: 0.0620\t\n",
      "Subject: 03, n=05 | test_f1: 0.28571 |best_f1: 0.7619\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0532\tTop_Loss: 0.1638\tBottom_Loss: 0.0381\tLoss: 0.2551\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0152\tTop_Loss: 0.0902\tBottom_Loss: 0.0506\tLoss: 0.1561\t\n",
      "Subject: 03, n=05 | test_f1: 0.19048 |best_f1: 0.7619\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0090\tTop_Loss: 0.0329\tBottom_Loss: 0.0400\tLoss: 0.0819\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0095\tTop_Loss: 0.0242\tBottom_Loss: 0.0316\tLoss: 0.0654\t\n",
      "Subject: 03, n=05 | test_f1: 0.19048 |best_f1: 0.7619\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0351\tTop_Loss: 0.1143\tBottom_Loss: 0.0308\tLoss: 0.1802\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0130\tTop_Loss: 0.0476\tBottom_Loss: 0.0327\tLoss: 0.0933\t\n",
      "Subject: 03, n=05 | test_f1: 0.44444 |best_f1: 0.7619\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0447\tTop_Loss: 0.0397\tBottom_Loss: 0.0815\tLoss: 0.1659\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0398\tTop_Loss: 0.1650\tBottom_Loss: 0.0537\tLoss: 0.2586\t\n",
      "Subject: 03, n=05 | test_f1: 0.58333 |best_f1: 0.7619\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0105\tTop_Loss: 0.0247\tBottom_Loss: 0.0469\tLoss: 0.0821\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0055\tTop_Loss: 0.0252\tBottom_Loss: 0.0388\tLoss: 0.0695\t\n",
      "Subject: 03, n=05 | test_f1: 0.375 |best_f1: 0.7619\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.344\tLabel_Loss: 1.4053\tTop_Loss: 1.1266\tBottom_Loss: 1.6815\tLoss: 4.2135\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.375\tLabel_Loss: 1.1282\tTop_Loss: 1.0605\tBottom_Loss: 1.2221\tLoss: 3.4107\t\n",
      "Subject: 030, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.531\tLabel_Loss: 1.2403\tTop_Loss: 1.0944\tBottom_Loss: 1.0974\tLoss: 3.4321\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.562\tLabel_Loss: 1.0187\tTop_Loss: 1.0176\tBottom_Loss: 1.0398\tLoss: 3.0761\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.594\tLabel_Loss: 0.9462\tTop_Loss: 0.9728\tBottom_Loss: 0.9933\tLoss: 2.9123\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7924\tTop_Loss: 0.7836\tBottom_Loss: 0.8520\tLoss: 2.4280\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.656\tLabel_Loss: 0.9102\tTop_Loss: 0.9310\tBottom_Loss: 0.9540\tLoss: 2.7952\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8310\tTop_Loss: 0.7880\tBottom_Loss: 1.0646\tLoss: 2.6835\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.469\tLabel_Loss: 0.9406\tTop_Loss: 1.0532\tBottom_Loss: 1.0581\tLoss: 3.0520\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.469\tLabel_Loss: 0.9650\tTop_Loss: 0.7485\tBottom_Loss: 0.8467\tLoss: 2.5602\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.594\tLabel_Loss: 0.9215\tTop_Loss: 0.9985\tBottom_Loss: 0.8812\tLoss: 2.8013\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7083\tTop_Loss: 0.9377\tBottom_Loss: 0.8185\tLoss: 2.4644\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6786\tTop_Loss: 0.7318\tBottom_Loss: 0.8532\tLoss: 2.2636\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.406\tLabel_Loss: 0.9086\tTop_Loss: 0.9182\tBottom_Loss: 0.9750\tLoss: 2.8018\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.594\tLabel_Loss: 0.7098\tTop_Loss: 0.7623\tBottom_Loss: 0.7484\tLoss: 2.2205\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6805\tTop_Loss: 0.8640\tBottom_Loss: 0.5962\tLoss: 2.1407\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.875\tLabel_Loss: 0.5067\tTop_Loss: 0.6070\tBottom_Loss: 0.5896\tLoss: 1.7034\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.531\tLabel_Loss: 0.8506\tTop_Loss: 0.8851\tBottom_Loss: 1.0034\tLoss: 2.7391\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6929\tTop_Loss: 0.6435\tBottom_Loss: 0.7258\tLoss: 2.0622\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.719\tLabel_Loss: 0.7790\tTop_Loss: 0.6773\tBottom_Loss: 0.8331\tLoss: 2.2894\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.688\tLabel_Loss: 0.8369\tTop_Loss: 0.8285\tBottom_Loss: 0.8527\tLoss: 2.5181\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6675\tTop_Loss: 0.7541\tBottom_Loss: 0.7491\tLoss: 2.1707\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5772\tTop_Loss: 0.7180\tBottom_Loss: 0.7915\tLoss: 2.0867\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.656\tLabel_Loss: 0.6277\tTop_Loss: 0.6871\tBottom_Loss: 0.7009\tLoss: 2.0157\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.781\tLabel_Loss: 0.6491\tTop_Loss: 0.7684\tBottom_Loss: 0.5777\tLoss: 1.9953\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.719\tLabel_Loss: 0.5816\tTop_Loss: 0.6460\tBottom_Loss: 0.7257\tLoss: 1.9533\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.688\tLabel_Loss: 0.8091\tTop_Loss: 0.7423\tBottom_Loss: 1.0410\tLoss: 2.5925\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6274\tTop_Loss: 0.7005\tBottom_Loss: 0.7500\tLoss: 2.0778\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6009\tTop_Loss: 0.7306\tBottom_Loss: 0.8894\tLoss: 2.2209\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7724\tTop_Loss: 0.7920\tBottom_Loss: 0.7852\tLoss: 2.3496\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.750\tLabel_Loss: 0.4951\tTop_Loss: 0.4926\tBottom_Loss: 0.6161\tLoss: 1.6038\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6162\tTop_Loss: 0.8017\tBottom_Loss: 0.5678\tLoss: 1.9857\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.750\tLabel_Loss: 0.4805\tTop_Loss: 0.5267\tBottom_Loss: 0.6287\tLoss: 1.6359\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8284\tTop_Loss: 0.7570\tBottom_Loss: 0.7989\tLoss: 2.3842\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6194\tTop_Loss: 0.6588\tBottom_Loss: 0.6507\tLoss: 1.9289\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5057\tTop_Loss: 0.6179\tBottom_Loss: 0.6961\tLoss: 1.8197\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6732\tTop_Loss: 0.6216\tBottom_Loss: 0.7238\tLoss: 2.0187\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4364\tTop_Loss: 0.4794\tBottom_Loss: 0.5330\tLoss: 1.4488\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4879\tTop_Loss: 0.6519\tBottom_Loss: 0.5106\tLoss: 1.6504\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5556\tTop_Loss: 0.6299\tBottom_Loss: 0.7786\tLoss: 1.9641\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5388\tTop_Loss: 0.6684\tBottom_Loss: 0.7535\tLoss: 1.9608\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4199\tTop_Loss: 0.4871\tBottom_Loss: 0.5152\tLoss: 1.4221\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3631\tTop_Loss: 0.5761\tBottom_Loss: 0.4998\tLoss: 1.4389\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4355\tTop_Loss: 0.6151\tBottom_Loss: 0.6349\tLoss: 1.6855\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.750\tLabel_Loss: 0.4911\tTop_Loss: 0.5481\tBottom_Loss: 0.5051\tLoss: 1.5443\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5866\tTop_Loss: 0.6013\tBottom_Loss: 0.7145\tLoss: 1.9023\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2856\tTop_Loss: 0.5158\tBottom_Loss: 0.4384\tLoss: 1.2398\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4386\tTop_Loss: 0.6466\tBottom_Loss: 0.5561\tLoss: 1.6414\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2779\tTop_Loss: 0.4567\tBottom_Loss: 0.4795\tLoss: 1.2141\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3418\tTop_Loss: 0.5064\tBottom_Loss: 0.4065\tLoss: 1.2547\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4107\tTop_Loss: 0.4659\tBottom_Loss: 0.4470\tLoss: 1.3236\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4087\tTop_Loss: 0.5013\tBottom_Loss: 0.5139\tLoss: 1.4239\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2727\tTop_Loss: 0.5393\tBottom_Loss: 0.4741\tLoss: 1.2861\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.938\tLabel_Loss: 0.3000\tTop_Loss: 0.3602\tBottom_Loss: 0.4491\tLoss: 1.1093\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2395\tTop_Loss: 0.4344\tBottom_Loss: 0.3897\tLoss: 1.0636\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3201\tTop_Loss: 0.3494\tBottom_Loss: 0.4628\tLoss: 1.1323\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4567\tTop_Loss: 0.4794\tBottom_Loss: 0.5213\tLoss: 1.4575\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.906\tLabel_Loss: 0.4245\tTop_Loss: 0.4910\tBottom_Loss: 0.5822\tLoss: 1.4977\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4419\tTop_Loss: 0.6241\tBottom_Loss: 0.4234\tLoss: 1.4895\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2806\tTop_Loss: 0.3744\tBottom_Loss: 0.5131\tLoss: 1.1681\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1505\tTop_Loss: 0.3736\tBottom_Loss: 0.2469\tLoss: 0.7710\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2560\tTop_Loss: 0.4325\tBottom_Loss: 0.4375\tLoss: 1.1260\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2300\tTop_Loss: 0.3210\tBottom_Loss: 0.4899\tLoss: 1.0410\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4632\tTop_Loss: 0.6131\tBottom_Loss: 0.5920\tLoss: 1.6684\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2305\tTop_Loss: 0.3196\tBottom_Loss: 0.4167\tLoss: 0.9669\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1924\tTop_Loss: 0.3705\tBottom_Loss: 0.3226\tLoss: 0.8855\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2891\tTop_Loss: 0.5810\tBottom_Loss: 0.4274\tLoss: 1.2975\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2892\tTop_Loss: 0.4908\tBottom_Loss: 0.3792\tLoss: 1.1592\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2436\tTop_Loss: 0.3970\tBottom_Loss: 0.2597\tLoss: 0.9003\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2700\tTop_Loss: 0.4793\tBottom_Loss: 0.4706\tLoss: 1.2199\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2046\tTop_Loss: 0.4346\tBottom_Loss: 0.3406\tLoss: 0.9799\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2720\tTop_Loss: 0.5665\tBottom_Loss: 0.3619\tLoss: 1.2003\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3198\tTop_Loss: 0.4767\tBottom_Loss: 0.4346\tLoss: 1.2312\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3805\tTop_Loss: 0.4666\tBottom_Loss: 0.5296\tLoss: 1.3767\t\n",
      "Subject: 030, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2290\tTop_Loss: 0.4369\tBottom_Loss: 0.3039\tLoss: 0.9697\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1555\tTop_Loss: 0.3109\tBottom_Loss: 0.2400\tLoss: 0.7063\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0894\tTop_Loss: 0.2557\tBottom_Loss: 0.2470\tLoss: 0.5921\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1675\tTop_Loss: 0.2787\tBottom_Loss: 0.2778\tLoss: 0.7241\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1814\tTop_Loss: 0.3122\tBottom_Loss: 0.2498\tLoss: 0.7433\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1433\tTop_Loss: 0.2668\tBottom_Loss: 0.3022\tLoss: 0.7123\t\n",
      "Subject: 030, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2974\tTop_Loss: 0.4825\tBottom_Loss: 0.3829\tLoss: 1.1628\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1176\tTop_Loss: 0.2770\tBottom_Loss: 0.2417\tLoss: 0.6363\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1856\tTop_Loss: 0.3775\tBottom_Loss: 0.2052\tLoss: 0.7683\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1794\tTop_Loss: 0.3423\tBottom_Loss: 0.2929\tLoss: 0.8145\t\n",
      "Subject: 030, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2340\tTop_Loss: 0.2843\tBottom_Loss: 0.3648\tLoss: 0.8831\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0942\tTop_Loss: 0.1937\tBottom_Loss: 0.2856\tLoss: 0.5735\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1289\tTop_Loss: 0.2208\tBottom_Loss: 0.3171\tLoss: 0.6668\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1801\tTop_Loss: 0.2414\tBottom_Loss: 0.3135\tLoss: 0.7350\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1018\tTop_Loss: 0.2394\tBottom_Loss: 0.1796\tLoss: 0.5208\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2867\tTop_Loss: 0.4673\tBottom_Loss: 0.3410\tLoss: 1.0950\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1528\tTop_Loss: 0.2691\tBottom_Loss: 0.2869\tLoss: 0.7087\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3162\tTop_Loss: 0.4295\tBottom_Loss: 0.4116\tLoss: 1.1573\t\n",
      "Subject: 030, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1250\tTop_Loss: 0.2930\tBottom_Loss: 0.1235\tLoss: 0.5415\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2422\tTop_Loss: 0.5421\tBottom_Loss: 0.2955\tLoss: 1.0798\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0775\tTop_Loss: 0.1608\tBottom_Loss: 0.2437\tLoss: 0.4820\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1102\tTop_Loss: 0.2567\tBottom_Loss: 0.3007\tLoss: 0.6676\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1667\tTop_Loss: 0.3249\tBottom_Loss: 0.2791\tLoss: 0.7707\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0899\tTop_Loss: 0.2274\tBottom_Loss: 0.1818\tLoss: 0.4992\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1175\tTop_Loss: 0.2115\tBottom_Loss: 0.2188\tLoss: 0.5478\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0478\tTop_Loss: 0.1638\tBottom_Loss: 0.1405\tLoss: 0.3521\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1948\tTop_Loss: 0.1915\tBottom_Loss: 0.2514\tLoss: 0.6377\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1165\tTop_Loss: 0.2288\tBottom_Loss: 0.2488\tLoss: 0.5941\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0996\tTop_Loss: 0.2433\tBottom_Loss: 0.2596\tLoss: 0.6025\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0825\tTop_Loss: 0.1810\tBottom_Loss: 0.1773\tLoss: 0.4407\t\n",
      "Subject: 030, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1118\tTop_Loss: 0.1285\tBottom_Loss: 0.1113\tLoss: 0.3516\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0929\tTop_Loss: 0.2803\tBottom_Loss: 0.2278\tLoss: 0.6010\t\n",
      "Subject: 030, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0775\tTop_Loss: 0.2082\tBottom_Loss: 0.1360\tLoss: 0.4217\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1660\tTop_Loss: 0.3038\tBottom_Loss: 0.1420\tLoss: 0.6118\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0769\tTop_Loss: 0.1678\tBottom_Loss: 0.1723\tLoss: 0.4170\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0595\tTop_Loss: 0.1203\tBottom_Loss: 0.1452\tLoss: 0.3251\t\n",
      "Subject: 030, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1214\tTop_Loss: 0.2815\tBottom_Loss: 0.2421\tLoss: 0.6450\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1313\tTop_Loss: 0.2588\tBottom_Loss: 0.1113\tLoss: 0.5014\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.875\tLabel_Loss: 0.1651\tTop_Loss: 0.2862\tBottom_Loss: 0.1625\tLoss: 0.6138\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1378\tTop_Loss: 0.2792\tBottom_Loss: 0.1263\tLoss: 0.5433\t\n",
      "Subject: 030, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0608\tTop_Loss: 0.1380\tBottom_Loss: 0.1090\tLoss: 0.3078\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1057\tTop_Loss: 0.2341\tBottom_Loss: 0.1253\tLoss: 0.4651\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0939\tTop_Loss: 0.2505\tBottom_Loss: 0.2605\tLoss: 0.6048\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1207\tTop_Loss: 0.1598\tBottom_Loss: 0.1928\tLoss: 0.4732\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0723\tTop_Loss: 0.2623\tBottom_Loss: 0.1609\tLoss: 0.4955\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0406\tTop_Loss: 0.1251\tBottom_Loss: 0.1056\tLoss: 0.2713\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1213\tTop_Loss: 0.2113\tBottom_Loss: 0.2482\tLoss: 0.5808\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0337\tTop_Loss: 0.0779\tBottom_Loss: 0.2106\tLoss: 0.3222\t\n",
      "Subject: 030, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1545\tTop_Loss: 0.1572\tBottom_Loss: 0.2174\tLoss: 0.5292\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0422\tTop_Loss: 0.1788\tBottom_Loss: 0.0780\tLoss: 0.2990\t\n",
      "Subject: 030, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0615\tTop_Loss: 0.1379\tBottom_Loss: 0.1197\tLoss: 0.3191\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0270\tTop_Loss: 0.1283\tBottom_Loss: 0.1003\tLoss: 0.2557\t\n",
      "Subject: 030, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0568\tTop_Loss: 0.2065\tBottom_Loss: 0.1083\tLoss: 0.3716\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1264\tTop_Loss: 0.1572\tBottom_Loss: 0.1231\tLoss: 0.4067\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0487\tTop_Loss: 0.1462\tBottom_Loss: 0.0925\tLoss: 0.2875\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0186\tTop_Loss: 0.1066\tBottom_Loss: 0.0383\tLoss: 0.1635\t\n",
      "Subject: 030, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0424\tTop_Loss: 0.1451\tBottom_Loss: 0.0718\tLoss: 0.2593\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0527\tTop_Loss: 0.0894\tBottom_Loss: 0.1603\tLoss: 0.3024\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0314\tTop_Loss: 0.0708\tBottom_Loss: 0.0542\tLoss: 0.1565\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0502\tTop_Loss: 0.0898\tBottom_Loss: 0.1774\tLoss: 0.3174\t\n",
      "Subject: 030, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0414\tTop_Loss: 0.1987\tBottom_Loss: 0.0996\tLoss: 0.3397\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0518\tTop_Loss: 0.1226\tBottom_Loss: 0.0843\tLoss: 0.2587\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0300\tTop_Loss: 0.1543\tBottom_Loss: 0.0808\tLoss: 0.2651\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0987\tTop_Loss: 0.1400\tBottom_Loss: 0.1705\tLoss: 0.4092\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0282\tTop_Loss: 0.0627\tBottom_Loss: 0.0912\tLoss: 0.1821\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0281\tTop_Loss: 0.1472\tBottom_Loss: 0.0594\tLoss: 0.2347\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0315\tTop_Loss: 0.1014\tBottom_Loss: 0.1361\tLoss: 0.2690\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0599\tTop_Loss: 0.0831\tBottom_Loss: 0.1676\tLoss: 0.3107\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0182\tTop_Loss: 0.0646\tBottom_Loss: 0.0604\tLoss: 0.1432\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0633\tTop_Loss: 0.1321\tBottom_Loss: 0.1019\tLoss: 0.2974\t\n",
      "Subject: 030, n=03 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0512\tTop_Loss: 0.0773\tBottom_Loss: 0.0905\tLoss: 0.2190\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1004\tTop_Loss: 0.1226\tBottom_Loss: 0.0720\tLoss: 0.2950\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0302\tTop_Loss: 0.0666\tBottom_Loss: 0.0789\tLoss: 0.1757\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0733\tTop_Loss: 0.0929\tBottom_Loss: 0.1666\tLoss: 0.3328\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0163\tTop_Loss: 0.0764\tBottom_Loss: 0.0780\tLoss: 0.1706\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0622\tTop_Loss: 0.1379\tBottom_Loss: 0.1385\tLoss: 0.3385\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0156\tTop_Loss: 0.1192\tBottom_Loss: 0.0549\tLoss: 0.1897\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0161\tTop_Loss: 0.0622\tBottom_Loss: 0.0481\tLoss: 0.1263\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0631\tTop_Loss: 0.0733\tBottom_Loss: 0.1381\tLoss: 0.2745\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0446\tTop_Loss: 0.0798\tBottom_Loss: 0.1363\tLoss: 0.2608\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0379\tTop_Loss: 0.0634\tBottom_Loss: 0.1573\tLoss: 0.2585\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0179\tTop_Loss: 0.0812\tBottom_Loss: 0.0893\tLoss: 0.1884\t\n",
      "Subject: 030, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0143\tTop_Loss: 0.0672\tBottom_Loss: 0.0302\tLoss: 0.1117\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0374\tTop_Loss: 0.1127\tBottom_Loss: 0.0592\tLoss: 0.2094\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0733\tTop_Loss: 0.1589\tBottom_Loss: 0.1014\tLoss: 0.3336\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0198\tTop_Loss: 0.0770\tBottom_Loss: 0.0389\tLoss: 0.1357\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0425\tTop_Loss: 0.0918\tBottom_Loss: 0.0722\tLoss: 0.2065\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0180\tTop_Loss: 0.0399\tBottom_Loss: 0.0613\tLoss: 0.1192\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0131\tTop_Loss: 0.0709\tBottom_Loss: 0.0398\tLoss: 0.1237\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0479\tTop_Loss: 0.0857\tBottom_Loss: 0.0858\tLoss: 0.2194\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0331\tTop_Loss: 0.1088\tBottom_Loss: 0.0557\tLoss: 0.1977\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0326\tTop_Loss: 0.0979\tBottom_Loss: 0.0725\tLoss: 0.2030\t\n",
      "Subject: 030, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0155\tTop_Loss: 0.0220\tBottom_Loss: 0.0423\tLoss: 0.0799\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0396\tTop_Loss: 0.0788\tBottom_Loss: 0.0570\tLoss: 0.1753\t\n",
      "Subject: 030, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0175\tTop_Loss: 0.0753\tBottom_Loss: 0.0497\tLoss: 0.1425\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0713\tTop_Loss: 0.1276\tBottom_Loss: 0.0573\tLoss: 0.2562\t\n",
      "Subject: 030, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0076\tTop_Loss: 0.0467\tBottom_Loss: 0.0262\tLoss: 0.0805\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0140\tTop_Loss: 0.0445\tBottom_Loss: 0.0393\tLoss: 0.0978\t\n",
      "Subject: 030, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0123\tTop_Loss: 0.0586\tBottom_Loss: 0.0273\tLoss: 0.0983\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0146\tTop_Loss: 0.0438\tBottom_Loss: 0.0305\tLoss: 0.0889\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0179\tTop_Loss: 0.0501\tBottom_Loss: 0.0817\tLoss: 0.1497\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0132\tTop_Loss: 0.0477\tBottom_Loss: 0.0372\tLoss: 0.0981\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0137\tTop_Loss: 0.0379\tBottom_Loss: 0.0252\tLoss: 0.0767\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0097\tTop_Loss: 0.0682\tBottom_Loss: 0.0273\tLoss: 0.1052\t\n",
      "Subject: 030, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0445\tTop_Loss: 0.0898\tBottom_Loss: 0.0744\tLoss: 0.2087\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0210\tTop_Loss: 0.0305\tBottom_Loss: 0.0561\tLoss: 0.1076\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0182\tTop_Loss: 0.0571\tBottom_Loss: 0.0674\tLoss: 0.1427\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0072\tTop_Loss: 0.0330\tBottom_Loss: 0.0194\tLoss: 0.0595\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0078\tTop_Loss: 0.0375\tBottom_Loss: 0.0203\tLoss: 0.0656\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0194\tTop_Loss: 0.0363\tBottom_Loss: 0.0358\tLoss: 0.0915\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0086\tTop_Loss: 0.0511\tBottom_Loss: 0.0333\tLoss: 0.0930\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0216\tTop_Loss: 0.0396\tBottom_Loss: 0.0276\tLoss: 0.0888\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0122\tTop_Loss: 0.0269\tBottom_Loss: 0.0570\tLoss: 0.0962\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0528\tTop_Loss: 0.1116\tBottom_Loss: 0.2189\tLoss: 0.3834\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0600\tTop_Loss: 0.0734\tBottom_Loss: 0.1274\tLoss: 0.2608\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0061\tTop_Loss: 0.0344\tBottom_Loss: 0.0154\tLoss: 0.0559\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0310\tTop_Loss: 0.0832\tBottom_Loss: 0.0297\tLoss: 0.1439\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0175\tTop_Loss: 0.0888\tBottom_Loss: 0.0638\tLoss: 0.1701\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0244\tTop_Loss: 0.0770\tBottom_Loss: 0.0722\tLoss: 0.1736\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0073\tTop_Loss: 0.0162\tBottom_Loss: 0.0313\tLoss: 0.0549\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0160\tTop_Loss: 0.0501\tBottom_Loss: 0.0983\tLoss: 0.1644\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1252\tTop_Loss: 0.1588\tBottom_Loss: 0.1089\tLoss: 0.3928\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0251\tTop_Loss: 0.0380\tBottom_Loss: 0.0757\tLoss: 0.1389\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0192\tTop_Loss: 0.0389\tBottom_Loss: 0.0407\tLoss: 0.0988\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0105\tTop_Loss: 0.0174\tBottom_Loss: 0.0421\tLoss: 0.0700\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0049\tTop_Loss: 0.0281\tBottom_Loss: 0.0136\tLoss: 0.0466\t\n",
      "Subject: 030, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.312\tLabel_Loss: 1.3545\tTop_Loss: 1.1543\tBottom_Loss: 1.6758\tLoss: 4.1845\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.531\tLabel_Loss: 1.1809\tTop_Loss: 1.1386\tBottom_Loss: 0.9851\tLoss: 3.3047\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.562\tLabel_Loss: 0.8917\tTop_Loss: 1.0227\tBottom_Loss: 0.9718\tLoss: 2.8862\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.531\tLabel_Loss: 0.9635\tTop_Loss: 0.9931\tBottom_Loss: 0.8811\tLoss: 2.8377\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7673\tTop_Loss: 0.9669\tBottom_Loss: 0.7977\tLoss: 2.5319\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.531\tLabel_Loss: 0.8977\tTop_Loss: 0.9972\tBottom_Loss: 0.9651\tLoss: 2.8600\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.375\tLabel_Loss: 1.1975\tTop_Loss: 1.1600\tBottom_Loss: 1.1704\tLoss: 3.5279\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.625\tLabel_Loss: 0.9324\tTop_Loss: 1.0569\tBottom_Loss: 0.9817\tLoss: 2.9711\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8640\tTop_Loss: 0.9173\tBottom_Loss: 0.9152\tLoss: 2.6965\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.531\tLabel_Loss: 0.9520\tTop_Loss: 1.0619\tBottom_Loss: 0.9292\tLoss: 2.9431\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.625\tLabel_Loss: 0.9444\tTop_Loss: 0.9844\tBottom_Loss: 0.9899\tLoss: 2.9186\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8943\tTop_Loss: 0.9431\tBottom_Loss: 1.0423\tLoss: 2.8796\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.469\tLabel_Loss: 0.9350\tTop_Loss: 0.8019\tBottom_Loss: 0.9026\tLoss: 2.6395\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.594\tLabel_Loss: 0.9731\tTop_Loss: 1.0120\tBottom_Loss: 0.8846\tLoss: 2.8697\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.594\tLabel_Loss: 0.9817\tTop_Loss: 0.9215\tBottom_Loss: 0.8861\tLoss: 2.7893\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.594\tLabel_Loss: 0.9273\tTop_Loss: 0.9666\tBottom_Loss: 0.8524\tLoss: 2.7463\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.656\tLabel_Loss: 0.8282\tTop_Loss: 0.8539\tBottom_Loss: 0.9382\tLoss: 2.6202\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6616\tTop_Loss: 1.0586\tBottom_Loss: 0.7369\tLoss: 2.4571\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7280\tTop_Loss: 0.8391\tBottom_Loss: 0.7778\tLoss: 2.3449\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.562\tLabel_Loss: 0.8615\tTop_Loss: 1.0893\tBottom_Loss: 0.8728\tLoss: 2.8236\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.719\tLabel_Loss: 0.7938\tTop_Loss: 0.8839\tBottom_Loss: 0.7216\tLoss: 2.3992\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.719\tLabel_Loss: 0.5665\tTop_Loss: 0.7653\tBottom_Loss: 0.7001\tLoss: 2.0319\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7723\tTop_Loss: 0.7331\tBottom_Loss: 0.7352\tLoss: 2.2406\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6810\tTop_Loss: 0.7447\tBottom_Loss: 0.6729\tLoss: 2.0986\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6954\tTop_Loss: 0.6625\tBottom_Loss: 0.6943\tLoss: 2.0521\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5725\tTop_Loss: 0.6158\tBottom_Loss: 0.7177\tLoss: 1.9060\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.625\tLabel_Loss: 0.6495\tTop_Loss: 0.6785\tBottom_Loss: 0.6756\tLoss: 2.0036\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7329\tTop_Loss: 0.8310\tBottom_Loss: 0.6479\tLoss: 2.2118\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.656\tLabel_Loss: 0.6298\tTop_Loss: 0.7543\tBottom_Loss: 0.5685\tLoss: 1.9526\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4469\tTop_Loss: 0.5246\tBottom_Loss: 0.6748\tLoss: 1.6463\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.656\tLabel_Loss: 0.5978\tTop_Loss: 0.6935\tBottom_Loss: 0.6864\tLoss: 1.9777\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.812\tLabel_Loss: 0.6681\tTop_Loss: 0.7856\tBottom_Loss: 0.6968\tLoss: 2.1505\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5971\tTop_Loss: 0.7051\tBottom_Loss: 0.5789\tLoss: 1.8811\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6174\tTop_Loss: 0.8990\tBottom_Loss: 0.6485\tLoss: 2.1649\t\n",
      "Subject: 031, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5448\tTop_Loss: 0.5268\tBottom_Loss: 0.5476\tLoss: 1.6192\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.719\tLabel_Loss: 0.5630\tTop_Loss: 0.6287\tBottom_Loss: 0.6411\tLoss: 1.8329\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5797\tTop_Loss: 0.7177\tBottom_Loss: 0.6559\tLoss: 1.9533\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.750\tLabel_Loss: 0.7336\tTop_Loss: 0.8985\tBottom_Loss: 0.7188\tLoss: 2.3509\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7601\tTop_Loss: 0.8741\tBottom_Loss: 0.8276\tLoss: 2.4618\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4213\tTop_Loss: 0.7095\tBottom_Loss: 0.5303\tLoss: 1.6611\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6435\tTop_Loss: 0.7248\tBottom_Loss: 0.6983\tLoss: 2.0666\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6120\tTop_Loss: 0.9547\tBottom_Loss: 0.7037\tLoss: 2.2705\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4817\tTop_Loss: 0.6346\tBottom_Loss: 0.5323\tLoss: 1.6486\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3869\tTop_Loss: 0.5155\tBottom_Loss: 0.5308\tLoss: 1.4332\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5024\tTop_Loss: 0.7265\tBottom_Loss: 0.5940\tLoss: 1.8229\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3722\tTop_Loss: 0.6344\tBottom_Loss: 0.5514\tLoss: 1.5580\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4819\tTop_Loss: 0.8092\tBottom_Loss: 0.5218\tLoss: 1.8128\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5366\tTop_Loss: 0.5211\tBottom_Loss: 0.7181\tLoss: 1.7758\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3370\tTop_Loss: 0.6510\tBottom_Loss: 0.3677\tLoss: 1.3556\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6138\tTop_Loss: 0.6229\tBottom_Loss: 0.6970\tLoss: 1.9337\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4294\tTop_Loss: 0.7150\tBottom_Loss: 0.5084\tLoss: 1.6528\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3383\tTop_Loss: 0.4149\tBottom_Loss: 0.3605\tLoss: 1.1137\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.750\tLabel_Loss: 0.4786\tTop_Loss: 0.6205\tBottom_Loss: 0.7141\tLoss: 1.8132\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2796\tTop_Loss: 0.5495\tBottom_Loss: 0.5232\tLoss: 1.3523\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2078\tTop_Loss: 0.4361\tBottom_Loss: 0.3170\tLoss: 0.9609\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2057\tTop_Loss: 0.4849\tBottom_Loss: 0.3263\tLoss: 1.0168\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5448\tTop_Loss: 0.6264\tBottom_Loss: 0.4762\tLoss: 1.6474\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3176\tTop_Loss: 0.5921\tBottom_Loss: 0.4235\tLoss: 1.3332\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2839\tTop_Loss: 0.6196\tBottom_Loss: 0.3323\tLoss: 1.2357\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2528\tTop_Loss: 0.4869\tBottom_Loss: 0.4881\tLoss: 1.2278\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.781\tLabel_Loss: 0.3835\tTop_Loss: 0.5081\tBottom_Loss: 0.4598\tLoss: 1.3514\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3144\tTop_Loss: 0.7450\tBottom_Loss: 0.4692\tLoss: 1.5286\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1594\tTop_Loss: 0.3579\tBottom_Loss: 0.2561\tLoss: 0.7734\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1814\tTop_Loss: 0.3385\tBottom_Loss: 0.3630\tLoss: 0.8829\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2218\tTop_Loss: 0.2847\tBottom_Loss: 0.3696\tLoss: 0.8761\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2122\tTop_Loss: 0.4664\tBottom_Loss: 0.2571\tLoss: 0.9356\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2060\tTop_Loss: 0.3565\tBottom_Loss: 0.4112\tLoss: 0.9737\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3202\tTop_Loss: 0.4183\tBottom_Loss: 0.3891\tLoss: 1.1276\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2484\tTop_Loss: 0.5657\tBottom_Loss: 0.3015\tLoss: 1.1156\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2817\tTop_Loss: 0.3296\tBottom_Loss: 0.3083\tLoss: 0.9196\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1709\tTop_Loss: 0.3273\tBottom_Loss: 0.4274\tLoss: 0.9256\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1618\tTop_Loss: 0.4033\tBottom_Loss: 0.2554\tLoss: 0.8205\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3842\tTop_Loss: 0.4521\tBottom_Loss: 0.5204\tLoss: 1.3567\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1989\tTop_Loss: 0.4945\tBottom_Loss: 0.3012\tLoss: 0.9946\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1837\tTop_Loss: 0.4435\tBottom_Loss: 0.2280\tLoss: 0.8552\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2262\tTop_Loss: 0.5396\tBottom_Loss: 0.3520\tLoss: 1.1178\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1917\tTop_Loss: 0.4322\tBottom_Loss: 0.4532\tLoss: 1.0771\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2975\tTop_Loss: 0.3383\tBottom_Loss: 0.4427\tLoss: 1.0784\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1972\tTop_Loss: 0.4294\tBottom_Loss: 0.2945\tLoss: 0.9211\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2054\tTop_Loss: 0.5081\tBottom_Loss: 0.3019\tLoss: 1.0153\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1433\tTop_Loss: 0.3094\tBottom_Loss: 0.2795\tLoss: 0.7322\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1215\tTop_Loss: 0.2857\tBottom_Loss: 0.1994\tLoss: 0.6066\t\n",
      "Subject: 031, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3710\tTop_Loss: 0.5447\tBottom_Loss: 0.5482\tLoss: 1.4639\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1431\tTop_Loss: 0.3294\tBottom_Loss: 0.2776\tLoss: 0.7501\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1071\tTop_Loss: 0.3198\tBottom_Loss: 0.1737\tLoss: 0.6005\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0930\tTop_Loss: 0.3136\tBottom_Loss: 0.1548\tLoss: 0.5614\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2414\tTop_Loss: 0.3712\tBottom_Loss: 0.2092\tLoss: 0.8218\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1871\tTop_Loss: 0.4162\tBottom_Loss: 0.1583\tLoss: 0.7617\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1017\tTop_Loss: 0.3053\tBottom_Loss: 0.1908\tLoss: 0.5978\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.844\tLabel_Loss: 0.2555\tTop_Loss: 0.3457\tBottom_Loss: 0.2932\tLoss: 0.8944\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1056\tTop_Loss: 0.3149\tBottom_Loss: 0.1872\tLoss: 0.6077\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0639\tTop_Loss: 0.2267\tBottom_Loss: 0.1413\tLoss: 0.4319\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1514\tTop_Loss: 0.3538\tBottom_Loss: 0.2081\tLoss: 0.7133\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2299\tTop_Loss: 0.2826\tBottom_Loss: 0.2896\tLoss: 0.8021\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0933\tTop_Loss: 0.3095\tBottom_Loss: 0.2636\tLoss: 0.6663\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0732\tTop_Loss: 0.2879\tBottom_Loss: 0.0927\tLoss: 0.4538\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1765\tTop_Loss: 0.2609\tBottom_Loss: 0.2847\tLoss: 0.7221\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0644\tTop_Loss: 0.3400\tBottom_Loss: 0.2026\tLoss: 0.6071\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1250\tTop_Loss: 0.2474\tBottom_Loss: 0.1646\tLoss: 0.5370\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0437\tTop_Loss: 0.2494\tBottom_Loss: 0.1429\tLoss: 0.4360\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1690\tTop_Loss: 0.1942\tBottom_Loss: 0.1930\tLoss: 0.5561\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1222\tTop_Loss: 0.2895\tBottom_Loss: 0.1472\tLoss: 0.5589\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0540\tTop_Loss: 0.2702\tBottom_Loss: 0.1102\tLoss: 0.4344\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1186\tTop_Loss: 0.2467\tBottom_Loss: 0.1740\tLoss: 0.5393\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1791\tTop_Loss: 0.2555\tBottom_Loss: 0.2170\tLoss: 0.6516\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0629\tTop_Loss: 0.2642\tBottom_Loss: 0.1335\tLoss: 0.4607\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2133\tTop_Loss: 0.3566\tBottom_Loss: 0.2722\tLoss: 0.8421\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0425\tTop_Loss: 0.1962\tBottom_Loss: 0.1358\tLoss: 0.3745\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0527\tTop_Loss: 0.2880\tBottom_Loss: 0.0837\tLoss: 0.4244\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0657\tTop_Loss: 0.2725\tBottom_Loss: 0.1631\tLoss: 0.5013\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0832\tTop_Loss: 0.1417\tBottom_Loss: 0.2042\tLoss: 0.4291\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0473\tTop_Loss: 0.1939\tBottom_Loss: 0.1006\tLoss: 0.3417\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0553\tTop_Loss: 0.1312\tBottom_Loss: 0.1317\tLoss: 0.3181\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1632\tTop_Loss: 0.3115\tBottom_Loss: 0.2531\tLoss: 0.7278\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1515\tTop_Loss: 0.2443\tBottom_Loss: 0.1765\tLoss: 0.5722\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1263\tTop_Loss: 0.2422\tBottom_Loss: 0.1313\tLoss: 0.4998\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1304\tTop_Loss: 0.2535\tBottom_Loss: 0.1573\tLoss: 0.5413\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1651\tTop_Loss: 0.2608\tBottom_Loss: 0.2291\tLoss: 0.6550\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1598\tTop_Loss: 0.2548\tBottom_Loss: 0.2674\tLoss: 0.6820\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0456\tTop_Loss: 0.1138\tBottom_Loss: 0.1275\tLoss: 0.2868\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0782\tTop_Loss: 0.2366\tBottom_Loss: 0.1821\tLoss: 0.4968\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0378\tTop_Loss: 0.1548\tBottom_Loss: 0.1310\tLoss: 0.3236\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1414\tTop_Loss: 0.1787\tBottom_Loss: 0.2079\tLoss: 0.5280\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1405\tTop_Loss: 0.2974\tBottom_Loss: 0.1422\tLoss: 0.5801\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0975\tTop_Loss: 0.2125\tBottom_Loss: 0.1625\tLoss: 0.4725\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1961\tTop_Loss: 0.2825\tBottom_Loss: 0.1714\tLoss: 0.6501\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1163\tTop_Loss: 0.2316\tBottom_Loss: 0.1614\tLoss: 0.5093\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0463\tTop_Loss: 0.1651\tBottom_Loss: 0.0835\tLoss: 0.2949\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0994\tTop_Loss: 0.2574\tBottom_Loss: 0.1389\tLoss: 0.4957\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2014\tTop_Loss: 0.1750\tBottom_Loss: 0.2365\tLoss: 0.6130\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0255\tTop_Loss: 0.0832\tBottom_Loss: 0.0579\tLoss: 0.1667\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0495\tTop_Loss: 0.1713\tBottom_Loss: 0.1078\tLoss: 0.3285\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2549\tTop_Loss: 0.3993\tBottom_Loss: 0.1879\tLoss: 0.8422\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0357\tTop_Loss: 0.0937\tBottom_Loss: 0.0754\tLoss: 0.2048\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0186\tTop_Loss: 0.0682\tBottom_Loss: 0.0532\tLoss: 0.1399\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0563\tTop_Loss: 0.1757\tBottom_Loss: 0.1008\tLoss: 0.3328\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0332\tTop_Loss: 0.0776\tBottom_Loss: 0.1029\tLoss: 0.2136\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0295\tTop_Loss: 0.0543\tBottom_Loss: 0.0806\tLoss: 0.1644\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0250\tTop_Loss: 0.0724\tBottom_Loss: 0.0481\tLoss: 0.1455\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0376\tTop_Loss: 0.0953\tBottom_Loss: 0.0777\tLoss: 0.2106\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0345\tTop_Loss: 0.1746\tBottom_Loss: 0.0493\tLoss: 0.2584\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0167\tTop_Loss: 0.0757\tBottom_Loss: 0.0279\tLoss: 0.1203\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0628\tTop_Loss: 0.1170\tBottom_Loss: 0.0780\tLoss: 0.2578\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0406\tTop_Loss: 0.0719\tBottom_Loss: 0.0821\tLoss: 0.1946\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0169\tTop_Loss: 0.0760\tBottom_Loss: 0.0330\tLoss: 0.1259\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0134\tTop_Loss: 0.0497\tBottom_Loss: 0.0448\tLoss: 0.1079\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0448\tTop_Loss: 0.1323\tBottom_Loss: 0.0839\tLoss: 0.2610\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0215\tTop_Loss: 0.1056\tBottom_Loss: 0.0500\tLoss: 0.1771\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0365\tTop_Loss: 0.1565\tBottom_Loss: 0.1220\tLoss: 0.3149\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0094\tTop_Loss: 0.1605\tBottom_Loss: 0.0562\tLoss: 0.2262\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0458\tTop_Loss: 0.1330\tBottom_Loss: 0.1056\tLoss: 0.2845\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0180\tTop_Loss: 0.0738\tBottom_Loss: 0.0293\tLoss: 0.1210\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0407\tTop_Loss: 0.1217\tBottom_Loss: 0.0648\tLoss: 0.2272\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0546\tTop_Loss: 0.0851\tBottom_Loss: 0.0929\tLoss: 0.2326\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0141\tTop_Loss: 0.0930\tBottom_Loss: 0.0399\tLoss: 0.1469\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0234\tTop_Loss: 0.0764\tBottom_Loss: 0.0475\tLoss: 0.1474\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0359\tTop_Loss: 0.1559\tBottom_Loss: 0.0864\tLoss: 0.2782\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0158\tTop_Loss: 0.0797\tBottom_Loss: 0.0633\tLoss: 0.1588\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0257\tTop_Loss: 0.1749\tBottom_Loss: 0.0658\tLoss: 0.2664\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0352\tTop_Loss: 0.1182\tBottom_Loss: 0.0836\tLoss: 0.2369\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0484\tTop_Loss: 0.0710\tBottom_Loss: 0.1000\tLoss: 0.2195\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0082\tTop_Loss: 0.1036\tBottom_Loss: 0.0279\tLoss: 0.1397\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0489\tTop_Loss: 0.0594\tBottom_Loss: 0.1711\tLoss: 0.2795\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0540\tTop_Loss: 0.0687\tBottom_Loss: 0.0948\tLoss: 0.2175\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0490\tTop_Loss: 0.0795\tBottom_Loss: 0.0659\tLoss: 0.1944\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0490\tTop_Loss: 0.1455\tBottom_Loss: 0.0745\tLoss: 0.2691\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0263\tTop_Loss: 0.0547\tBottom_Loss: 0.0634\tLoss: 0.1445\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0131\tTop_Loss: 0.0678\tBottom_Loss: 0.0309\tLoss: 0.1118\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0176\tTop_Loss: 0.0759\tBottom_Loss: 0.0330\tLoss: 0.1265\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0120\tTop_Loss: 0.0399\tBottom_Loss: 0.0376\tLoss: 0.0895\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0477\tTop_Loss: 0.0561\tBottom_Loss: 0.0942\tLoss: 0.1980\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0158\tTop_Loss: 0.0424\tBottom_Loss: 0.0451\tLoss: 0.1033\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0094\tTop_Loss: 0.0666\tBottom_Loss: 0.0205\tLoss: 0.0965\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0382\tTop_Loss: 0.1531\tBottom_Loss: 0.0957\tLoss: 0.2871\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0151\tTop_Loss: 0.0516\tBottom_Loss: 0.0325\tLoss: 0.0992\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0100\tTop_Loss: 0.0504\tBottom_Loss: 0.0384\tLoss: 0.0988\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0111\tTop_Loss: 0.0558\tBottom_Loss: 0.0268\tLoss: 0.0937\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0080\tTop_Loss: 0.0268\tBottom_Loss: 0.0229\tLoss: 0.0576\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0123\tTop_Loss: 0.0385\tBottom_Loss: 0.0337\tLoss: 0.0845\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0113\tTop_Loss: 0.0435\tBottom_Loss: 0.0248\tLoss: 0.0796\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0471\tTop_Loss: 0.1264\tBottom_Loss: 0.0313\tLoss: 0.2048\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0092\tTop_Loss: 0.0659\tBottom_Loss: 0.0207\tLoss: 0.0958\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0270\tTop_Loss: 0.0820\tBottom_Loss: 0.0283\tLoss: 0.1372\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0251\tTop_Loss: 0.0489\tBottom_Loss: 0.0808\tLoss: 0.1547\t\n",
      "Subject: 031, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0074\tTop_Loss: 0.0787\tBottom_Loss: 0.0429\tLoss: 0.1289\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0531\tTop_Loss: 0.0766\tBottom_Loss: 0.0863\tLoss: 0.2160\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0089\tTop_Loss: 0.0285\tBottom_Loss: 0.0438\tLoss: 0.0812\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0042\tTop_Loss: 0.0220\tBottom_Loss: 0.0165\tLoss: 0.0427\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0449\tTop_Loss: 0.1133\tBottom_Loss: 0.0588\tLoss: 0.2170\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0238\tTop_Loss: 0.0577\tBottom_Loss: 0.0228\tLoss: 0.1043\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0166\tTop_Loss: 0.0291\tBottom_Loss: 0.0393\tLoss: 0.0850\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0180\tTop_Loss: 0.0499\tBottom_Loss: 0.0719\tLoss: 0.1398\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0061\tTop_Loss: 0.0325\tBottom_Loss: 0.0235\tLoss: 0.0620\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0025\tTop_Loss: 0.0158\tBottom_Loss: 0.0144\tLoss: 0.0327\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0095\tTop_Loss: 0.0269\tBottom_Loss: 0.0217\tLoss: 0.0581\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0257\tTop_Loss: 0.0415\tBottom_Loss: 0.0726\tLoss: 0.1398\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0110\tTop_Loss: 0.0376\tBottom_Loss: 0.0213\tLoss: 0.0698\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1065\tTop_Loss: 0.0654\tBottom_Loss: 0.0406\tLoss: 0.2124\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0115\tTop_Loss: 0.0485\tBottom_Loss: 0.0161\tLoss: 0.0761\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0057\tTop_Loss: 0.0251\tBottom_Loss: 0.0579\tLoss: 0.0887\t\n",
      "Subject: 031, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.375\tLabel_Loss: 1.3105\tTop_Loss: 1.1968\tBottom_Loss: 1.5081\tLoss: 4.0154\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.500\tLabel_Loss: 1.2373\tTop_Loss: 1.2035\tBottom_Loss: 1.2906\tLoss: 3.7314\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7350\tTop_Loss: 1.0601\tBottom_Loss: 0.9708\tLoss: 2.7660\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8813\tTop_Loss: 1.0040\tBottom_Loss: 0.8782\tLoss: 2.7635\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8893\tTop_Loss: 0.9689\tBottom_Loss: 0.9124\tLoss: 2.7706\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.531\tLabel_Loss: 1.1491\tTop_Loss: 0.9756\tBottom_Loss: 0.9928\tLoss: 3.1176\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.531\tLabel_Loss: 1.1023\tTop_Loss: 1.0067\tBottom_Loss: 0.9128\tLoss: 3.0217\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.531\tLabel_Loss: 0.8591\tTop_Loss: 1.1075\tBottom_Loss: 0.7841\tLoss: 2.7507\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.500\tLabel_Loss: 1.0093\tTop_Loss: 1.0602\tBottom_Loss: 1.0284\tLoss: 3.0979\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.688\tLabel_Loss: 0.8739\tTop_Loss: 0.6931\tBottom_Loss: 0.9047\tLoss: 2.4717\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.562\tLabel_Loss: 0.9620\tTop_Loss: 0.9625\tBottom_Loss: 0.9351\tLoss: 2.8596\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.531\tLabel_Loss: 0.8420\tTop_Loss: 0.8988\tBottom_Loss: 0.9066\tLoss: 2.6474\t\n",
      "Subject: 032, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.469\tLabel_Loss: 0.9247\tTop_Loss: 1.0387\tBottom_Loss: 0.8431\tLoss: 2.8065\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8537\tTop_Loss: 0.8814\tBottom_Loss: 1.0730\tLoss: 2.8080\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8191\tTop_Loss: 0.8362\tBottom_Loss: 1.0006\tLoss: 2.6559\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7160\tTop_Loss: 0.6994\tBottom_Loss: 0.9583\tLoss: 2.3737\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4933\tTop_Loss: 0.5538\tBottom_Loss: 0.6347\tLoss: 1.6818\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8621\tTop_Loss: 0.8657\tBottom_Loss: 0.9439\tLoss: 2.6717\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7635\tTop_Loss: 0.8829\tBottom_Loss: 0.7902\tLoss: 2.4366\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.656\tLabel_Loss: 0.8013\tTop_Loss: 0.8323\tBottom_Loss: 0.7911\tLoss: 2.4247\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.344\tLabel_Loss: 1.1160\tTop_Loss: 0.9757\tBottom_Loss: 1.0012\tLoss: 3.0929\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7525\tTop_Loss: 0.7755\tBottom_Loss: 0.8793\tLoss: 2.4072\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7774\tTop_Loss: 0.7568\tBottom_Loss: 0.8476\tLoss: 2.3817\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6526\tTop_Loss: 0.7234\tBottom_Loss: 0.7143\tLoss: 2.0904\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7215\tTop_Loss: 0.6487\tBottom_Loss: 0.6014\tLoss: 1.9715\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5903\tTop_Loss: 0.5700\tBottom_Loss: 0.7688\tLoss: 1.9291\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.688\tLabel_Loss: 0.5842\tTop_Loss: 0.7578\tBottom_Loss: 0.7666\tLoss: 2.1086\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.656\tLabel_Loss: 0.6942\tTop_Loss: 0.8013\tBottom_Loss: 0.5823\tLoss: 2.0778\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.625\tLabel_Loss: 0.6905\tTop_Loss: 0.6690\tBottom_Loss: 0.8311\tLoss: 2.1906\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4733\tTop_Loss: 0.5513\tBottom_Loss: 0.5911\tLoss: 1.6157\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5395\tTop_Loss: 0.6134\tBottom_Loss: 0.7601\tLoss: 1.9131\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.719\tLabel_Loss: 0.5776\tTop_Loss: 0.5775\tBottom_Loss: 0.7341\tLoss: 1.8893\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.844\tLabel_Loss: 0.5777\tTop_Loss: 0.6756\tBottom_Loss: 0.7222\tLoss: 1.9755\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6538\tTop_Loss: 0.6160\tBottom_Loss: 0.7726\tLoss: 2.0424\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.844\tLabel_Loss: 0.5996\tTop_Loss: 0.6265\tBottom_Loss: 0.6800\tLoss: 1.9061\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6264\tTop_Loss: 0.6798\tBottom_Loss: 0.6357\tLoss: 1.9418\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6576\tTop_Loss: 0.6078\tBottom_Loss: 0.8898\tLoss: 2.1551\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.656\tLabel_Loss: 0.6828\tTop_Loss: 0.6142\tBottom_Loss: 0.8053\tLoss: 2.1022\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3720\tTop_Loss: 0.4904\tBottom_Loss: 0.5926\tLoss: 1.4551\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.688\tLabel_Loss: 0.5738\tTop_Loss: 0.8410\tBottom_Loss: 0.7409\tLoss: 2.1557\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4704\tTop_Loss: 0.5680\tBottom_Loss: 0.5904\tLoss: 1.6289\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3055\tTop_Loss: 0.4093\tBottom_Loss: 0.4963\tLoss: 1.2111\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5581\tTop_Loss: 0.6072\tBottom_Loss: 0.6938\tLoss: 1.8591\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4301\tTop_Loss: 0.5233\tBottom_Loss: 0.6077\tLoss: 1.5611\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4678\tTop_Loss: 0.6158\tBottom_Loss: 0.4191\tLoss: 1.5028\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4879\tTop_Loss: 0.8632\tBottom_Loss: 0.5622\tLoss: 1.9133\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5659\tTop_Loss: 0.8100\tBottom_Loss: 0.6210\tLoss: 1.9970\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4152\tTop_Loss: 0.5412\tBottom_Loss: 0.4730\tLoss: 1.4293\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3889\tTop_Loss: 0.4387\tBottom_Loss: 0.6729\tLoss: 1.5004\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3387\tTop_Loss: 0.4928\tBottom_Loss: 0.4619\tLoss: 1.2934\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2836\tTop_Loss: 0.3593\tBottom_Loss: 0.3577\tLoss: 1.0006\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3970\tTop_Loss: 0.5055\tBottom_Loss: 0.6336\tLoss: 1.5362\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5138\tTop_Loss: 0.6380\tBottom_Loss: 0.6160\tLoss: 1.7678\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4097\tTop_Loss: 0.5631\tBottom_Loss: 0.5226\tLoss: 1.4954\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3494\tTop_Loss: 0.5314\tBottom_Loss: 0.4991\tLoss: 1.3799\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3326\tTop_Loss: 0.4371\tBottom_Loss: 0.5030\tLoss: 1.2728\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5321\tTop_Loss: 0.5228\tBottom_Loss: 0.5080\tLoss: 1.5628\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2508\tTop_Loss: 0.4616\tBottom_Loss: 0.3175\tLoss: 1.0298\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.938\tLabel_Loss: 0.3163\tTop_Loss: 0.5986\tBottom_Loss: 0.4179\tLoss: 1.3328\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4258\tTop_Loss: 0.4672\tBottom_Loss: 0.5318\tLoss: 1.4249\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2929\tTop_Loss: 0.4252\tBottom_Loss: 0.4080\tLoss: 1.1262\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2648\tTop_Loss: 0.3885\tBottom_Loss: 0.3346\tLoss: 0.9878\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3012\tTop_Loss: 0.4565\tBottom_Loss: 0.3481\tLoss: 1.1057\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1813\tTop_Loss: 0.3186\tBottom_Loss: 0.3811\tLoss: 0.8810\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3499\tTop_Loss: 0.4987\tBottom_Loss: 0.5319\tLoss: 1.3806\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2527\tTop_Loss: 0.3352\tBottom_Loss: 0.3571\tLoss: 0.9450\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2221\tTop_Loss: 0.3356\tBottom_Loss: 0.4423\tLoss: 1.0000\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1316\tTop_Loss: 0.2265\tBottom_Loss: 0.3065\tLoss: 0.6646\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2814\tTop_Loss: 0.2877\tBottom_Loss: 0.3768\tLoss: 0.9459\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2604\tTop_Loss: 0.4333\tBottom_Loss: 0.4217\tLoss: 1.1153\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.938\tLabel_Loss: 0.3220\tTop_Loss: 0.5100\tBottom_Loss: 0.5000\tLoss: 1.3320\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2629\tTop_Loss: 0.3178\tBottom_Loss: 0.5046\tLoss: 1.0852\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2143\tTop_Loss: 0.3408\tBottom_Loss: 0.3273\tLoss: 0.8824\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2127\tTop_Loss: 0.2851\tBottom_Loss: 0.4783\tLoss: 0.9760\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1006\tTop_Loss: 0.2548\tBottom_Loss: 0.2158\tLoss: 0.5712\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1249\tTop_Loss: 0.2078\tBottom_Loss: 0.4402\tLoss: 0.7728\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3256\tTop_Loss: 0.3300\tBottom_Loss: 0.5859\tLoss: 1.2416\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2309\tTop_Loss: 0.4129\tBottom_Loss: 0.3178\tLoss: 0.9617\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1574\tTop_Loss: 0.2975\tBottom_Loss: 0.2237\tLoss: 0.6786\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2387\tTop_Loss: 0.4129\tBottom_Loss: 0.2938\tLoss: 0.9454\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1841\tTop_Loss: 0.3260\tBottom_Loss: 0.3005\tLoss: 0.8105\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3168\tTop_Loss: 0.5062\tBottom_Loss: 0.4955\tLoss: 1.3186\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1324\tTop_Loss: 0.2462\tBottom_Loss: 0.3638\tLoss: 0.7424\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1916\tTop_Loss: 0.3415\tBottom_Loss: 0.3021\tLoss: 0.8352\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2301\tTop_Loss: 0.3120\tBottom_Loss: 0.3134\tLoss: 0.8555\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.750\tLabel_Loss: 0.3962\tTop_Loss: 0.5602\tBottom_Loss: 0.4434\tLoss: 1.3998\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1689\tTop_Loss: 0.2174\tBottom_Loss: 0.3470\tLoss: 0.7333\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2230\tTop_Loss: 0.3044\tBottom_Loss: 0.3465\tLoss: 0.8739\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2018\tTop_Loss: 0.2619\tBottom_Loss: 0.2695\tLoss: 0.7331\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1082\tTop_Loss: 0.2721\tBottom_Loss: 0.2118\tLoss: 0.5921\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1174\tTop_Loss: 0.2298\tBottom_Loss: 0.2680\tLoss: 0.6152\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1077\tTop_Loss: 0.2061\tBottom_Loss: 0.2529\tLoss: 0.5667\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1363\tTop_Loss: 0.2285\tBottom_Loss: 0.3064\tLoss: 0.6712\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0832\tTop_Loss: 0.1420\tBottom_Loss: 0.1892\tLoss: 0.4143\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1758\tTop_Loss: 0.2301\tBottom_Loss: 0.3704\tLoss: 0.7763\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1236\tTop_Loss: 0.3115\tBottom_Loss: 0.2081\tLoss: 0.6432\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1159\tTop_Loss: 0.2214\tBottom_Loss: 0.1534\tLoss: 0.4907\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0701\tTop_Loss: 0.1346\tBottom_Loss: 0.2356\tLoss: 0.4404\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0773\tTop_Loss: 0.2453\tBottom_Loss: 0.1294\tLoss: 0.4519\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1046\tTop_Loss: 0.3026\tBottom_Loss: 0.1798\tLoss: 0.5870\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0796\tTop_Loss: 0.1976\tBottom_Loss: 0.2418\tLoss: 0.5191\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1284\tTop_Loss: 0.1934\tBottom_Loss: 0.2877\tLoss: 0.6096\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0972\tTop_Loss: 0.1688\tBottom_Loss: 0.2003\tLoss: 0.4663\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1768\tTop_Loss: 0.2779\tBottom_Loss: 0.3650\tLoss: 0.8197\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0688\tTop_Loss: 0.1981\tBottom_Loss: 0.1142\tLoss: 0.3811\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1782\tTop_Loss: 0.2743\tBottom_Loss: 0.2784\tLoss: 0.7310\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1045\tTop_Loss: 0.1654\tBottom_Loss: 0.2099\tLoss: 0.4798\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0736\tTop_Loss: 0.2048\tBottom_Loss: 0.1153\tLoss: 0.3937\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1090\tTop_Loss: 0.2532\tBottom_Loss: 0.2233\tLoss: 0.5855\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0459\tTop_Loss: 0.1866\tBottom_Loss: 0.2081\tLoss: 0.4406\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0387\tTop_Loss: 0.1043\tBottom_Loss: 0.1152\tLoss: 0.2581\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1061\tTop_Loss: 0.1270\tBottom_Loss: 0.2667\tLoss: 0.4998\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.938\tLabel_Loss: 0.0988\tTop_Loss: 0.2097\tBottom_Loss: 0.1690\tLoss: 0.4775\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0315\tTop_Loss: 0.1055\tBottom_Loss: 0.1552\tLoss: 0.2922\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0575\tTop_Loss: 0.2502\tBottom_Loss: 0.2027\tLoss: 0.5104\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0406\tTop_Loss: 0.2032\tBottom_Loss: 0.1112\tLoss: 0.3551\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0544\tTop_Loss: 0.1427\tBottom_Loss: 0.0866\tLoss: 0.2838\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0790\tTop_Loss: 0.1961\tBottom_Loss: 0.0841\tLoss: 0.3592\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0443\tTop_Loss: 0.0935\tBottom_Loss: 0.1716\tLoss: 0.3094\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0564\tTop_Loss: 0.2060\tBottom_Loss: 0.0857\tLoss: 0.3481\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0495\tTop_Loss: 0.1058\tBottom_Loss: 0.1323\tLoss: 0.2876\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0779\tTop_Loss: 0.2299\tBottom_Loss: 0.1488\tLoss: 0.4566\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0276\tTop_Loss: 0.1503\tBottom_Loss: 0.0618\tLoss: 0.2397\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1236\tTop_Loss: 0.1747\tBottom_Loss: 0.2078\tLoss: 0.5061\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 0.875\tLabel_Loss: 0.1862\tTop_Loss: 0.2565\tBottom_Loss: 0.1828\tLoss: 0.6255\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1360\tTop_Loss: 0.2190\tBottom_Loss: 0.1691\tLoss: 0.5242\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[63][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0921\tTop_Loss: 0.1255\tBottom_Loss: 0.1175\tLoss: 0.3351\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0381\tTop_Loss: 0.1669\tBottom_Loss: 0.0504\tLoss: 0.2554\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0387\tTop_Loss: 0.0946\tBottom_Loss: 0.0780\tLoss: 0.2113\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0236\tTop_Loss: 0.1040\tBottom_Loss: 0.0795\tLoss: 0.2071\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0480\tTop_Loss: 0.1393\tBottom_Loss: 0.1108\tLoss: 0.2980\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1262\tTop_Loss: 0.1800\tBottom_Loss: 0.1584\tLoss: 0.4646\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1731\tTop_Loss: 0.2182\tBottom_Loss: 0.3258\tLoss: 0.7171\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0349\tTop_Loss: 0.0916\tBottom_Loss: 0.0842\tLoss: 0.2107\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1103\tTop_Loss: 0.1593\tBottom_Loss: 0.1085\tLoss: 0.3780\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0430\tTop_Loss: 0.1189\tBottom_Loss: 0.0875\tLoss: 0.2494\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1275\tTop_Loss: 0.1632\tBottom_Loss: 0.3012\tLoss: 0.5920\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0533\tTop_Loss: 0.1484\tBottom_Loss: 0.0546\tLoss: 0.2563\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1185\tTop_Loss: 0.1355\tBottom_Loss: 0.1696\tLoss: 0.4236\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0301\tTop_Loss: 0.0803\tBottom_Loss: 0.1049\tLoss: 0.2153\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0110\tTop_Loss: 0.0459\tBottom_Loss: 0.0604\tLoss: 0.1172\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0475\tTop_Loss: 0.0769\tBottom_Loss: 0.1782\tLoss: 0.3026\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0353\tTop_Loss: 0.0538\tBottom_Loss: 0.1358\tLoss: 0.2249\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0764\tTop_Loss: 0.1571\tBottom_Loss: 0.1109\tLoss: 0.3443\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0900\tTop_Loss: 0.1608\tBottom_Loss: 0.1272\tLoss: 0.3780\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0174\tTop_Loss: 0.0491\tBottom_Loss: 0.0644\tLoss: 0.1308\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0164\tTop_Loss: 0.0860\tBottom_Loss: 0.0569\tLoss: 0.1593\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0229\tTop_Loss: 0.0444\tBottom_Loss: 0.0736\tLoss: 0.1408\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0148\tTop_Loss: 0.0575\tBottom_Loss: 0.0525\tLoss: 0.1248\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0165\tTop_Loss: 0.1050\tBottom_Loss: 0.0504\tLoss: 0.1719\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0591\tTop_Loss: 0.1496\tBottom_Loss: 0.1413\tLoss: 0.3500\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0163\tTop_Loss: 0.0642\tBottom_Loss: 0.0289\tLoss: 0.1094\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0090\tTop_Loss: 0.0386\tBottom_Loss: 0.0548\tLoss: 0.1024\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0546\tTop_Loss: 0.0861\tBottom_Loss: 0.0773\tLoss: 0.2181\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0265\tTop_Loss: 0.0526\tBottom_Loss: 0.1507\tLoss: 0.2298\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0187\tTop_Loss: 0.0587\tBottom_Loss: 0.0581\tLoss: 0.1355\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0104\tTop_Loss: 0.0641\tBottom_Loss: 0.0282\tLoss: 0.1027\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0828\tTop_Loss: 0.1329\tBottom_Loss: 0.0838\tLoss: 0.2996\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0111\tTop_Loss: 0.0385\tBottom_Loss: 0.0421\tLoss: 0.0918\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0060\tTop_Loss: 0.0584\tBottom_Loss: 0.0456\tLoss: 0.1101\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0206\tTop_Loss: 0.1365\tBottom_Loss: 0.0372\tLoss: 0.1944\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0251\tTop_Loss: 0.1176\tBottom_Loss: 0.0268\tLoss: 0.1695\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0383\tTop_Loss: 0.0416\tBottom_Loss: 0.0792\tLoss: 0.1592\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0126\tTop_Loss: 0.0473\tBottom_Loss: 0.0699\tLoss: 0.1297\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0164\tTop_Loss: 0.0662\tBottom_Loss: 0.0542\tLoss: 0.1368\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0145\tTop_Loss: 0.0479\tBottom_Loss: 0.0680\tLoss: 0.1303\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0235\tTop_Loss: 0.0488\tBottom_Loss: 0.0876\tLoss: 0.1598\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0148\tTop_Loss: 0.0517\tBottom_Loss: 0.0918\tLoss: 0.1583\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1254\tTop_Loss: 0.1510\tBottom_Loss: 0.1618\tLoss: 0.4382\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0100\tTop_Loss: 0.0195\tBottom_Loss: 0.0504\tLoss: 0.0799\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0246\tTop_Loss: 0.2147\tBottom_Loss: 0.0606\tLoss: 0.2999\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0598\tTop_Loss: 0.1134\tBottom_Loss: 0.0561\tLoss: 0.2293\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0227\tTop_Loss: 0.0656\tBottom_Loss: 0.0300\tLoss: 0.1184\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0149\tTop_Loss: 0.0932\tBottom_Loss: 0.0414\tLoss: 0.1494\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0148\tTop_Loss: 0.0489\tBottom_Loss: 0.0505\tLoss: 0.1143\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0271\tTop_Loss: 0.0835\tBottom_Loss: 0.0661\tLoss: 0.1766\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0245\tTop_Loss: 0.0561\tBottom_Loss: 0.0682\tLoss: 0.1488\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0134\tTop_Loss: 0.0288\tBottom_Loss: 0.0505\tLoss: 0.0927\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0096\tTop_Loss: 0.0546\tBottom_Loss: 0.0410\tLoss: 0.1052\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0086\tTop_Loss: 0.0355\tBottom_Loss: 0.0652\tLoss: 0.1092\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0058\tTop_Loss: 0.0261\tBottom_Loss: 0.0416\tLoss: 0.0735\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0126\tTop_Loss: 0.0650\tBottom_Loss: 0.0632\tLoss: 0.1407\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0203\tTop_Loss: 0.0573\tBottom_Loss: 0.0478\tLoss: 0.1254\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0369\tTop_Loss: 0.0541\tBottom_Loss: 0.0596\tLoss: 0.1506\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0264\tTop_Loss: 0.0921\tBottom_Loss: 0.0364\tLoss: 0.1549\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0213\tTop_Loss: 0.0151\tBottom_Loss: 0.1249\tLoss: 0.1613\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0136\tTop_Loss: 0.0252\tBottom_Loss: 0.0586\tLoss: 0.0975\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0031\tTop_Loss: 0.0146\tBottom_Loss: 0.0204\tLoss: 0.0381\t\n",
      "Subject: 032, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0062\tTop_Loss: 0.0318\tBottom_Loss: 0.0229\tLoss: 0.0610\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0201\tTop_Loss: 0.0849\tBottom_Loss: 0.1029\tLoss: 0.2078\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0050\tTop_Loss: 0.0277\tBottom_Loss: 0.0264\tLoss: 0.0591\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0052\tTop_Loss: 0.0217\tBottom_Loss: 0.0151\tLoss: 0.0420\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0483\tTop_Loss: 0.1146\tBottom_Loss: 0.0487\tLoss: 0.2117\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0207\tTop_Loss: 0.0886\tBottom_Loss: 0.0658\tLoss: 0.1751\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0051\tTop_Loss: 0.0211\tBottom_Loss: 0.0319\tLoss: 0.0581\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0055\tTop_Loss: 0.0142\tBottom_Loss: 0.0377\tLoss: 0.0573\t\n",
      "Subject: 032, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0067\tTop_Loss: 0.0179\tBottom_Loss: 0.0185\tLoss: 0.0430\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0071\tTop_Loss: 0.0223\tBottom_Loss: 0.0636\tLoss: 0.0931\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0125\tTop_Loss: 0.0809\tBottom_Loss: 0.0168\tLoss: 0.1102\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0065\tTop_Loss: 0.0320\tBottom_Loss: 0.0230\tLoss: 0.0615\t\n",
      "Subject: 032, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.344\tLabel_Loss: 1.3697\tTop_Loss: 1.1176\tBottom_Loss: 1.5007\tLoss: 3.9880\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.438\tLabel_Loss: 1.1927\tTop_Loss: 1.0444\tBottom_Loss: 1.2286\tLoss: 3.4656\t\n",
      "Subject: 033, n=05 | test_f1: 0.19048 |best_f1: 0.19048\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.469\tLabel_Loss: 1.0179\tTop_Loss: 0.9861\tBottom_Loss: 1.0645\tLoss: 3.0685\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.438\tLabel_Loss: 1.2355\tTop_Loss: 1.0758\tBottom_Loss: 1.2005\tLoss: 3.5118\t\n",
      "Subject: 033, n=05 | test_f1: 0.44444 |best_f1: 0.44444\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.531\tLabel_Loss: 1.1056\tTop_Loss: 0.9362\tBottom_Loss: 0.8048\tLoss: 2.8467\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.719\tLabel_Loss: 0.7975\tTop_Loss: 0.8338\tBottom_Loss: 0.7453\tLoss: 2.3766\t\n",
      "Subject: 033, n=05 | test_f1: 0.25 |best_f1: 0.44444\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.469\tLabel_Loss: 1.0132\tTop_Loss: 0.8843\tBottom_Loss: 0.8784\tLoss: 2.7759\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.500\tLabel_Loss: 0.9911\tTop_Loss: 1.1562\tBottom_Loss: 0.9383\tLoss: 3.0857\t\n",
      "Subject: 033, n=05 | test_f1: 0.44444 |best_f1: 0.44444\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6771\tTop_Loss: 0.7785\tBottom_Loss: 0.9440\tLoss: 2.3996\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.625\tLabel_Loss: 0.9884\tTop_Loss: 0.8979\tBottom_Loss: 1.0800\tLoss: 2.9662\t\n",
      "Subject: 033, n=05 | test_f1: 0.44444 |best_f1: 0.44444\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6285\tTop_Loss: 0.7042\tBottom_Loss: 0.7767\tLoss: 2.1094\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.500\tLabel_Loss: 0.9579\tTop_Loss: 1.0230\tBottom_Loss: 0.9887\tLoss: 2.9696\t\n",
      "Subject: 033, n=05 | test_f1: 0.44444 |best_f1: 0.44444\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8726\tTop_Loss: 0.8385\tBottom_Loss: 0.9608\tLoss: 2.6719\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6430\tTop_Loss: 0.7083\tBottom_Loss: 0.7957\tLoss: 2.1469\t\n",
      "Subject: 033, n=05 | test_f1: 0.11111 |best_f1: 0.44444\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.719\tLabel_Loss: 0.7667\tTop_Loss: 0.8548\tBottom_Loss: 0.7159\tLoss: 2.3374\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.656\tLabel_Loss: 0.8869\tTop_Loss: 0.9079\tBottom_Loss: 1.0369\tLoss: 2.8317\t\n",
      "Subject: 033, n=05 | test_f1: 0.25 |best_f1: 0.44444\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7227\tTop_Loss: 0.6715\tBottom_Loss: 0.7524\tLoss: 2.1466\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.562\tLabel_Loss: 0.8273\tTop_Loss: 0.7758\tBottom_Loss: 0.9106\tLoss: 2.5138\t\n",
      "Subject: 033, n=05 | test_f1: 0.25 |best_f1: 0.44444\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.562\tLabel_Loss: 0.9306\tTop_Loss: 0.8863\tBottom_Loss: 0.9482\tLoss: 2.7651\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.688\tLabel_Loss: 0.5549\tTop_Loss: 0.7378\tBottom_Loss: 0.6387\tLoss: 1.9314\t\n",
      "Subject: 033, n=05 | test_f1: 0.28571 |best_f1: 0.44444\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.750\tLabel_Loss: 0.7100\tTop_Loss: 0.7520\tBottom_Loss: 0.8250\tLoss: 2.2869\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.625\tLabel_Loss: 0.6600\tTop_Loss: 0.7000\tBottom_Loss: 0.7711\tLoss: 2.1310\t\n",
      "Subject: 033, n=05 | test_f1: 0.19048 |best_f1: 0.44444\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.781\tLabel_Loss: 0.6243\tTop_Loss: 0.6117\tBottom_Loss: 0.6810\tLoss: 1.9170\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.719\tLabel_Loss: 0.7141\tTop_Loss: 0.6314\tBottom_Loss: 0.7981\tLoss: 2.1436\t\n",
      "Subject: 033, n=05 | test_f1: 0.0 |best_f1: 0.44444\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.594\tLabel_Loss: 0.7859\tTop_Loss: 0.7011\tBottom_Loss: 0.8536\tLoss: 2.3407\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.656\tLabel_Loss: 0.6410\tTop_Loss: 0.6277\tBottom_Loss: 0.6656\tLoss: 1.9342\t\n",
      "Subject: 033, n=05 | test_f1: 0.375 |best_f1: 0.44444\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7488\tTop_Loss: 0.7339\tBottom_Loss: 0.6750\tLoss: 2.1577\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7358\tTop_Loss: 0.8275\tBottom_Loss: 0.7123\tLoss: 2.2756\t\n",
      "Subject: 033, n=05 | test_f1: 0.11111 |best_f1: 0.44444\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7420\tTop_Loss: 0.7287\tBottom_Loss: 0.8250\tLoss: 2.2957\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5064\tTop_Loss: 0.6236\tBottom_Loss: 0.5071\tLoss: 1.6371\t\n",
      "Subject: 033, n=05 | test_f1: 0.44444 |best_f1: 0.44444\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5415\tTop_Loss: 0.7502\tBottom_Loss: 0.6665\tLoss: 1.9581\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6640\tTop_Loss: 0.7755\tBottom_Loss: 0.8417\tLoss: 2.2812\t\n",
      "Subject: 033, n=05 | test_f1: 0.44444 |best_f1: 0.44444\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5674\tTop_Loss: 0.5848\tBottom_Loss: 0.6678\tLoss: 1.8200\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.656\tLabel_Loss: 0.6746\tTop_Loss: 0.6693\tBottom_Loss: 0.8403\tLoss: 2.1842\t\n",
      "Subject: 033, n=05 | test_f1: 0.25 |best_f1: 0.44444\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5679\tTop_Loss: 0.6873\tBottom_Loss: 0.6996\tLoss: 1.9548\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.719\tLabel_Loss: 0.5951\tTop_Loss: 0.8163\tBottom_Loss: 0.5795\tLoss: 1.9908\t\n",
      "Subject: 033, n=05 | test_f1: 0.25 |best_f1: 0.44444\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5633\tTop_Loss: 0.6774\tBottom_Loss: 0.5758\tLoss: 1.8165\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5556\tTop_Loss: 0.6618\tBottom_Loss: 0.7850\tLoss: 2.0024\t\n",
      "Subject: 033, n=05 | test_f1: 0.25 |best_f1: 0.44444\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3032\tTop_Loss: 0.5455\tBottom_Loss: 0.4296\tLoss: 1.2783\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6519\tTop_Loss: 0.6425\tBottom_Loss: 0.7094\tLoss: 2.0038\t\n",
      "Subject: 033, n=05 | test_f1: 0.44444 |best_f1: 0.44444\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3472\tTop_Loss: 0.5204\tBottom_Loss: 0.4124\tLoss: 1.2800\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.781\tLabel_Loss: 0.3645\tTop_Loss: 0.5742\tBottom_Loss: 0.3716\tLoss: 1.3103\t\n",
      "Subject: 033, n=05 | test_f1: 0.11111 |best_f1: 0.44444\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4186\tTop_Loss: 0.6395\tBottom_Loss: 0.4718\tLoss: 1.5299\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4610\tTop_Loss: 0.4030\tBottom_Loss: 0.5941\tLoss: 1.4580\t\n",
      "Subject: 033, n=05 | test_f1: 0.44444 |best_f1: 0.44444\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4130\tTop_Loss: 0.5190\tBottom_Loss: 0.4883\tLoss: 1.4203\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4675\tTop_Loss: 0.5078\tBottom_Loss: 0.5770\tLoss: 1.5523\t\n",
      "Subject: 033, n=05 | test_f1: 0.44444 |best_f1: 0.44444\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3156\tTop_Loss: 0.4512\tBottom_Loss: 0.4076\tLoss: 1.1745\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3798\tTop_Loss: 0.5059\tBottom_Loss: 0.4026\tLoss: 1.2882\t\n",
      "Subject: 033, n=05 | test_f1: 0.19048 |best_f1: 0.44444\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4326\tTop_Loss: 0.5542\tBottom_Loss: 0.4796\tLoss: 1.4664\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4083\tTop_Loss: 0.6624\tBottom_Loss: 0.4808\tLoss: 1.5515\t\n",
      "Subject: 033, n=05 | test_f1: 0.19048 |best_f1: 0.44444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5780\tTop_Loss: 0.6965\tBottom_Loss: 0.5901\tLoss: 1.8646\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4474\tTop_Loss: 0.7234\tBottom_Loss: 0.5188\tLoss: 1.6896\t\n",
      "Subject: 033, n=05 | test_f1: 0.25 |best_f1: 0.44444\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4328\tTop_Loss: 0.5286\tBottom_Loss: 0.5291\tLoss: 1.4905\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4125\tTop_Loss: 0.4575\tBottom_Loss: 0.5851\tLoss: 1.4551\t\n",
      "Subject: 033, n=05 | test_f1: 0.11111 |best_f1: 0.44444\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.938\tLabel_Loss: 0.3997\tTop_Loss: 0.5056\tBottom_Loss: 0.4758\tLoss: 1.3811\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3621\tTop_Loss: 0.5518\tBottom_Loss: 0.4649\tLoss: 1.3788\t\n",
      "Subject: 033, n=05 | test_f1: 0.33333 |best_f1: 0.44444\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3790\tTop_Loss: 0.4724\tBottom_Loss: 0.4132\tLoss: 1.2646\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4936\tTop_Loss: 0.6875\tBottom_Loss: 0.6132\tLoss: 1.7942\t\n",
      "Subject: 033, n=05 | test_f1: 0.55556 |best_f1: 0.55556\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2903\tTop_Loss: 0.5321\tBottom_Loss: 0.3427\tLoss: 1.1651\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2788\tTop_Loss: 0.4231\tBottom_Loss: 0.4536\tLoss: 1.1555\t\n",
      "Subject: 033, n=05 | test_f1: 0.19048 |best_f1: 0.55556\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3155\tTop_Loss: 0.4503\tBottom_Loss: 0.4439\tLoss: 1.2097\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3064\tTop_Loss: 0.3939\tBottom_Loss: 0.4153\tLoss: 1.1156\t\n",
      "Subject: 033, n=05 | test_f1: 0.375 |best_f1: 0.55556\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2111\tTop_Loss: 0.3481\tBottom_Loss: 0.3073\tLoss: 0.8665\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3836\tTop_Loss: 0.5442\tBottom_Loss: 0.3993\tLoss: 1.3270\t\n",
      "Subject: 033, n=05 | test_f1: 0.19048 |best_f1: 0.55556\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2331\tTop_Loss: 0.3690\tBottom_Loss: 0.4103\tLoss: 1.0124\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2782\tTop_Loss: 0.4111\tBottom_Loss: 0.3672\tLoss: 1.0566\t\n",
      "Subject: 033, n=05 | test_f1: 0.11111 |best_f1: 0.55556\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2578\tTop_Loss: 0.4590\tBottom_Loss: 0.3393\tLoss: 1.0561\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3072\tTop_Loss: 0.5089\tBottom_Loss: 0.3796\tLoss: 1.1957\t\n",
      "Subject: 033, n=05 | test_f1: 0.3 |best_f1: 0.55556\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1330\tTop_Loss: 0.2338\tBottom_Loss: 0.1982\tLoss: 0.5650\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2148\tTop_Loss: 0.2655\tBottom_Loss: 0.3120\tLoss: 0.7923\t\n",
      "Subject: 033, n=05 | test_f1: 0.19048 |best_f1: 0.55556\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2278\tTop_Loss: 0.5647\tBottom_Loss: 0.3279\tLoss: 1.1205\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1442\tTop_Loss: 0.3530\tBottom_Loss: 0.1985\tLoss: 0.6957\t\n",
      "Subject: 033, n=05 | test_f1: 0.44444 |best_f1: 0.55556\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3304\tTop_Loss: 0.5230\tBottom_Loss: 0.4440\tLoss: 1.2974\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.938\tLabel_Loss: 0.3851\tTop_Loss: 0.6236\tBottom_Loss: 0.4949\tLoss: 1.5036\t\n",
      "Subject: 033, n=05 | test_f1: 0.25 |best_f1: 0.55556\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2188\tTop_Loss: 0.3320\tBottom_Loss: 0.3046\tLoss: 0.8554\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2682\tTop_Loss: 0.4655\tBottom_Loss: 0.4638\tLoss: 1.1975\t\n",
      "Subject: 033, n=05 | test_f1: 0.44444 |best_f1: 0.55556\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1438\tTop_Loss: 0.2512\tBottom_Loss: 0.2415\tLoss: 0.6365\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2710\tTop_Loss: 0.4055\tBottom_Loss: 0.3913\tLoss: 1.0678\t\n",
      "Subject: 033, n=05 | test_f1: 0.19048 |best_f1: 0.55556\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2601\tTop_Loss: 0.2924\tBottom_Loss: 0.3532\tLoss: 0.9057\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1161\tTop_Loss: 0.3589\tBottom_Loss: 0.2547\tLoss: 0.7296\t\n",
      "Subject: 033, n=05 | test_f1: 0.375 |best_f1: 0.55556\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1663\tTop_Loss: 0.3085\tBottom_Loss: 0.3735\tLoss: 0.8484\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1823\tTop_Loss: 0.2937\tBottom_Loss: 0.3192\tLoss: 0.7952\t\n",
      "Subject: 033, n=05 | test_f1: 0.44444 |best_f1: 0.55556\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2063\tTop_Loss: 0.3106\tBottom_Loss: 0.2180\tLoss: 0.7349\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1536\tTop_Loss: 0.3385\tBottom_Loss: 0.2671\tLoss: 0.7592\t\n",
      "Subject: 033, n=05 | test_f1: 0.19048 |best_f1: 0.55556\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1101\tTop_Loss: 0.2609\tBottom_Loss: 0.1455\tLoss: 0.5165\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0970\tTop_Loss: 0.2986\tBottom_Loss: 0.1465\tLoss: 0.5421\t\n",
      "Subject: 033, n=05 | test_f1: 0.7619 |best_f1: 0.7619\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2349\tTop_Loss: 0.3295\tBottom_Loss: 0.3687\tLoss: 0.9331\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2165\tTop_Loss: 0.2272\tBottom_Loss: 0.2729\tLoss: 0.7166\t\n",
      "Subject: 033, n=05 | test_f1: 0.25 |best_f1: 0.7619\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2613\tTop_Loss: 0.4477\tBottom_Loss: 0.3371\tLoss: 1.0461\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1658\tTop_Loss: 0.4336\tBottom_Loss: 0.1841\tLoss: 0.7835\t\n",
      "Subject: 033, n=05 | test_f1: 0.7619 |best_f1: 0.7619\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2993\tTop_Loss: 0.4753\tBottom_Loss: 0.2669\tLoss: 1.0414\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1771\tTop_Loss: 0.3131\tBottom_Loss: 0.3154\tLoss: 0.8056\t\n",
      "Subject: 033, n=05 | test_f1: 0.44444 |best_f1: 0.7619\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1018\tTop_Loss: 0.2698\tBottom_Loss: 0.2744\tLoss: 0.6461\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0866\tTop_Loss: 0.2732\tBottom_Loss: 0.2100\tLoss: 0.5697\t\n",
      "Subject: 033, n=05 | test_f1: 0.35556 |best_f1: 0.7619\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2968\tTop_Loss: 0.4214\tBottom_Loss: 0.4044\tLoss: 1.1227\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1578\tTop_Loss: 0.2756\tBottom_Loss: 0.2318\tLoss: 0.6652\t\n",
      "Subject: 033, n=05 | test_f1: 0.19048 |best_f1: 0.7619\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2259\tTop_Loss: 0.4135\tBottom_Loss: 0.2819\tLoss: 0.9213\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1056\tTop_Loss: 0.1981\tBottom_Loss: 0.1609\tLoss: 0.4646\t\n",
      "Subject: 033, n=05 | test_f1: 0.44444 |best_f1: 0.7619\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1365\tTop_Loss: 0.2657\tBottom_Loss: 0.2113\tLoss: 0.6135\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0983\tTop_Loss: 0.1762\tBottom_Loss: 0.1399\tLoss: 0.4144\t\n",
      "Subject: 033, n=05 | test_f1: 0.44444 |best_f1: 0.7619\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0874\tTop_Loss: 0.3013\tBottom_Loss: 0.1862\tLoss: 0.5749\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2644\tTop_Loss: 0.4361\tBottom_Loss: 0.2511\tLoss: 0.9515\t\n",
      "Subject: 033, n=05 | test_f1: 0.25 |best_f1: 0.7619\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0766\tTop_Loss: 0.1365\tBottom_Loss: 0.2149\tLoss: 0.4280\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2031\tTop_Loss: 0.3420\tBottom_Loss: 0.3308\tLoss: 0.8759\t\n",
      "Subject: 033, n=05 | test_f1: 0.25 |best_f1: 0.7619\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0726\tTop_Loss: 0.2265\tBottom_Loss: 0.1047\tLoss: 0.4038\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1792\tTop_Loss: 0.4774\tBottom_Loss: 0.1605\tLoss: 0.8171\t\n",
      "Subject: 033, n=05 | test_f1: 0.61905 |best_f1: 0.7619\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0581\tTop_Loss: 0.1977\tBottom_Loss: 0.1080\tLoss: 0.3638\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0997\tTop_Loss: 0.2723\tBottom_Loss: 0.1678\tLoss: 0.5398\t\n",
      "Subject: 033, n=05 | test_f1: 0.44444 |best_f1: 0.7619\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0548\tTop_Loss: 0.1707\tBottom_Loss: 0.1033\tLoss: 0.3287\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1008\tTop_Loss: 0.2107\tBottom_Loss: 0.1200\tLoss: 0.4315\t\n",
      "Subject: 033, n=05 | test_f1: 0.7619 |best_f1: 0.7619\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1173\tTop_Loss: 0.2534\tBottom_Loss: 0.2049\tLoss: 0.5755\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[55][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1567\tTop_Loss: 0.3935\tBottom_Loss: 0.2791\tLoss: 0.8293\t\n",
      "Subject: 033, n=05 | test_f1: 0.55556 |best_f1: 0.7619\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2117\tTop_Loss: 0.3146\tBottom_Loss: 0.3371\tLoss: 0.8633\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0996\tTop_Loss: 0.1589\tBottom_Loss: 0.1694\tLoss: 0.4280\t\n",
      "Subject: 033, n=05 | test_f1: 0.7619 |best_f1: 0.7619\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0462\tTop_Loss: 0.1765\tBottom_Loss: 0.1131\tLoss: 0.3359\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0760\tTop_Loss: 0.2527\tBottom_Loss: 0.2060\tLoss: 0.5346\t\n",
      "Subject: 033, n=05 | test_f1: 0.3 |best_f1: 0.7619\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0721\tTop_Loss: 0.2648\tBottom_Loss: 0.1469\tLoss: 0.4837\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1313\tTop_Loss: 0.1501\tBottom_Loss: 0.1869\tLoss: 0.4684\t\n",
      "Subject: 033, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1633\tTop_Loss: 0.2080\tBottom_Loss: 0.2346\tLoss: 0.6059\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0381\tTop_Loss: 0.2293\tBottom_Loss: 0.0605\tLoss: 0.3279\t\n",
      "Subject: 033, n=05 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0738\tTop_Loss: 0.2634\tBottom_Loss: 0.1139\tLoss: 0.4511\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0498\tTop_Loss: 0.1319\tBottom_Loss: 0.1381\tLoss: 0.3198\t\n",
      "Subject: 033, n=05 | test_f1: 0.58333 |best_f1: 1.0\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0253\tTop_Loss: 0.1361\tBottom_Loss: 0.0577\tLoss: 0.2191\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0137\tTop_Loss: 0.0785\tBottom_Loss: 0.0387\tLoss: 0.1309\t\n",
      "Subject: 033, n=05 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1182\tTop_Loss: 0.2094\tBottom_Loss: 0.1065\tLoss: 0.4341\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0546\tTop_Loss: 0.1364\tBottom_Loss: 0.1458\tLoss: 0.3368\t\n",
      "Subject: 033, n=05 | test_f1: 0.58333 |best_f1: 1.0\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2006\tTop_Loss: 0.2995\tBottom_Loss: 0.2264\tLoss: 0.7265\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1045\tTop_Loss: 0.2217\tBottom_Loss: 0.1430\tLoss: 0.4691\t\n",
      "Subject: 033, n=05 | test_f1: 0.28571 |best_f1: 1.0\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0958\tTop_Loss: 0.1962\tBottom_Loss: 0.1761\tLoss: 0.4681\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0371\tTop_Loss: 0.1496\tBottom_Loss: 0.0904\tLoss: 0.2772\t\n",
      "Subject: 033, n=05 | test_f1: 0.58333 |best_f1: 1.0\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0227\tTop_Loss: 0.1745\tBottom_Loss: 0.0406\tLoss: 0.2378\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0253\tTop_Loss: 0.1161\tBottom_Loss: 0.0771\tLoss: 0.2185\t\n",
      "Subject: 033, n=05 | test_f1: 0.35556 |best_f1: 1.0\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0321\tTop_Loss: 0.1022\tBottom_Loss: 0.0573\tLoss: 0.1916\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1618\tTop_Loss: 0.2361\tBottom_Loss: 0.2083\tLoss: 0.6062\t\n",
      "Subject: 033, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0501\tTop_Loss: 0.1723\tBottom_Loss: 0.1086\tLoss: 0.3309\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0703\tTop_Loss: 0.0803\tBottom_Loss: 0.0896\tLoss: 0.2402\t\n",
      "Subject: 033, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0233\tTop_Loss: 0.1374\tBottom_Loss: 0.0697\tLoss: 0.2304\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0655\tTop_Loss: 0.1777\tBottom_Loss: 0.0818\tLoss: 0.3251\t\n",
      "Subject: 033, n=05 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0719\tTop_Loss: 0.1328\tBottom_Loss: 0.1266\tLoss: 0.3313\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0193\tTop_Loss: 0.0674\tBottom_Loss: 0.0702\tLoss: 0.1570\t\n",
      "Subject: 033, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0408\tTop_Loss: 0.0901\tBottom_Loss: 0.0476\tLoss: 0.1784\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0635\tTop_Loss: 0.2007\tBottom_Loss: 0.1304\tLoss: 0.3947\t\n",
      "Subject: 033, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1018\tTop_Loss: 0.1712\tBottom_Loss: 0.1889\tLoss: 0.4618\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0652\tTop_Loss: 0.1288\tBottom_Loss: 0.0916\tLoss: 0.2856\t\n",
      "Subject: 033, n=05 | test_f1: 0.19048 |best_f1: 1.0\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0741\tTop_Loss: 0.2038\tBottom_Loss: 0.1154\tLoss: 0.3933\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0248\tTop_Loss: 0.0765\tBottom_Loss: 0.0716\tLoss: 0.1729\t\n",
      "Subject: 033, n=05 | test_f1: 0.19048 |best_f1: 1.0\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0387\tTop_Loss: 0.1541\tBottom_Loss: 0.0626\tLoss: 0.2554\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0223\tTop_Loss: 0.0831\tBottom_Loss: 0.0502\tLoss: 0.1556\t\n",
      "Subject: 033, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0241\tTop_Loss: 0.1003\tBottom_Loss: 0.0940\tLoss: 0.2183\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0470\tTop_Loss: 0.1252\tBottom_Loss: 0.0922\tLoss: 0.2645\t\n",
      "Subject: 033, n=05 | test_f1: 0.19048 |best_f1: 1.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0513\tTop_Loss: 0.0664\tBottom_Loss: 0.0704\tLoss: 0.1881\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0905\tTop_Loss: 0.1594\tBottom_Loss: 0.1032\tLoss: 0.3531\t\n",
      "Subject: 033, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0192\tTop_Loss: 0.0767\tBottom_Loss: 0.0509\tLoss: 0.1468\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0114\tTop_Loss: 0.0584\tBottom_Loss: 0.0248\tLoss: 0.0946\t\n",
      "Subject: 033, n=05 | test_f1: 0.61905 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0200\tTop_Loss: 0.0674\tBottom_Loss: 0.0593\tLoss: 0.1467\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0260\tTop_Loss: 0.1412\tBottom_Loss: 0.0331\tLoss: 0.2003\t\n",
      "Subject: 033, n=05 | test_f1: 0.19048 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0100\tTop_Loss: 0.0737\tBottom_Loss: 0.0300\tLoss: 0.1137\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0202\tTop_Loss: 0.1289\tBottom_Loss: 0.0441\tLoss: 0.1932\t\n",
      "Subject: 033, n=05 | test_f1: 0.28571 |best_f1: 1.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0411\tTop_Loss: 0.0839\tBottom_Loss: 0.0949\tLoss: 0.2199\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0347\tTop_Loss: 0.0857\tBottom_Loss: 0.0462\tLoss: 0.1667\t\n",
      "Subject: 033, n=05 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0648\tTop_Loss: 0.1108\tBottom_Loss: 0.0611\tLoss: 0.2367\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0169\tTop_Loss: 0.0685\tBottom_Loss: 0.0687\tLoss: 0.1541\t\n",
      "Subject: 033, n=05 | test_f1: 0.61905 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0147\tTop_Loss: 0.0381\tBottom_Loss: 0.0414\tLoss: 0.0942\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0238\tTop_Loss: 0.1001\tBottom_Loss: 0.0553\tLoss: 0.1792\t\n",
      "Subject: 033, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0279\tTop_Loss: 0.0561\tBottom_Loss: 0.1157\tLoss: 0.1997\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0145\tTop_Loss: 0.0913\tBottom_Loss: 0.0298\tLoss: 0.1357\t\n",
      "Subject: 033, n=05 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0106\tTop_Loss: 0.0582\tBottom_Loss: 0.0344\tLoss: 0.1032\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0548\tTop_Loss: 0.0762\tBottom_Loss: 0.0634\tLoss: 0.1944\t\n",
      "Subject: 033, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0192\tTop_Loss: 0.0625\tBottom_Loss: 0.0239\tLoss: 0.1057\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0063\tTop_Loss: 0.0315\tBottom_Loss: 0.0353\tLoss: 0.0730\t\n",
      "Subject: 033, n=05 | test_f1: 0.61905 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0161\tTop_Loss: 0.0538\tBottom_Loss: 0.0422\tLoss: 0.1121\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0074\tTop_Loss: 0.0399\tBottom_Loss: 0.0218\tLoss: 0.0691\t\n",
      "Subject: 033, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0247\tTop_Loss: 0.0480\tBottom_Loss: 0.0319\tLoss: 0.1045\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0083\tTop_Loss: 0.0457\tBottom_Loss: 0.0380\tLoss: 0.0920\t\n",
      "Subject: 033, n=05 | test_f1: 0.35556 |best_f1: 1.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0080\tTop_Loss: 0.0686\tBottom_Loss: 0.0198\tLoss: 0.0964\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0091\tTop_Loss: 0.0530\tBottom_Loss: 0.0236\tLoss: 0.0857\t\n",
      "Subject: 033, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0145\tTop_Loss: 0.1555\tBottom_Loss: 0.0182\tLoss: 0.1882\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0263\tTop_Loss: 0.0540\tBottom_Loss: 0.0587\tLoss: 0.1390\t\n",
      "Subject: 033, n=05 | test_f1: 0.46667 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0101\tTop_Loss: 0.0586\tBottom_Loss: 0.0356\tLoss: 0.1044\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0214\tTop_Loss: 0.0848\tBottom_Loss: 0.0494\tLoss: 0.1556\t\n",
      "Subject: 033, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0109\tTop_Loss: 0.0244\tBottom_Loss: 0.0203\tLoss: 0.0557\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0375\tTop_Loss: 0.0997\tBottom_Loss: 0.0981\tLoss: 0.2352\t\n",
      "Subject: 033, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0115\tTop_Loss: 0.0305\tBottom_Loss: 0.0211\tLoss: 0.0630\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0108\tTop_Loss: 0.0592\tBottom_Loss: 0.0341\tLoss: 0.1040\t\n",
      "Subject: 033, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0039\tTop_Loss: 0.0167\tBottom_Loss: 0.0085\tLoss: 0.0291\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0227\tTop_Loss: 0.1018\tBottom_Loss: 0.0181\tLoss: 0.1425\t\n",
      "Subject: 033, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0103\tTop_Loss: 0.0738\tBottom_Loss: 0.0538\tLoss: 0.1379\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0055\tTop_Loss: 0.0425\tBottom_Loss: 0.0159\tLoss: 0.0639\t\n",
      "Subject: 033, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0062\tTop_Loss: 0.0271\tBottom_Loss: 0.0357\tLoss: 0.0690\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 0.938\tLabel_Loss: 0.0797\tTop_Loss: 0.0708\tBottom_Loss: 0.0968\tLoss: 0.2472\t\n",
      "Subject: 033, n=05 | test_f1: 0.61905 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0203\tTop_Loss: 0.0528\tBottom_Loss: 0.0474\tLoss: 0.1205\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0051\tTop_Loss: 0.0266\tBottom_Loss: 0.0118\tLoss: 0.0435\t\n",
      "Subject: 033, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0105\tTop_Loss: 0.0364\tBottom_Loss: 0.0101\tLoss: 0.0570\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0060\tTop_Loss: 0.0242\tBottom_Loss: 0.0353\tLoss: 0.0654\t\n",
      "Subject: 033, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0032\tTop_Loss: 0.0165\tBottom_Loss: 0.0195\tLoss: 0.0392\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0043\tTop_Loss: 0.0351\tBottom_Loss: 0.0233\tLoss: 0.0627\t\n",
      "Subject: 033, n=05 | test_f1: 0.61905 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0039\tTop_Loss: 0.0227\tBottom_Loss: 0.0369\tLoss: 0.0635\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0446\tTop_Loss: 0.0801\tBottom_Loss: 0.0288\tLoss: 0.1535\t\n",
      "Subject: 033, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0151\tTop_Loss: 0.0512\tBottom_Loss: 0.0301\tLoss: 0.0964\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0051\tTop_Loss: 0.0343\tBottom_Loss: 0.0157\tLoss: 0.0551\t\n",
      "Subject: 033, n=05 | test_f1: 0.61905 |best_f1: 1.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.281\tLabel_Loss: 1.6048\tTop_Loss: 1.7986\tBottom_Loss: 1.1387\tLoss: 4.5421\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.438\tLabel_Loss: 1.1837\tTop_Loss: 1.5057\tBottom_Loss: 1.2585\tLoss: 3.9479\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.469\tLabel_Loss: 1.1523\tTop_Loss: 1.1138\tBottom_Loss: 1.0442\tLoss: 3.3103\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.656\tLabel_Loss: 0.8150\tTop_Loss: 1.0294\tBottom_Loss: 0.9682\tLoss: 2.8125\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.531\tLabel_Loss: 0.9962\tTop_Loss: 1.0357\tBottom_Loss: 1.1609\tLoss: 3.1927\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.500\tLabel_Loss: 1.0942\tTop_Loss: 0.9555\tBottom_Loss: 1.0255\tLoss: 3.0751\t\n",
      "Subject: 034, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.625\tLabel_Loss: 0.9309\tTop_Loss: 0.8607\tBottom_Loss: 0.8598\tLoss: 2.6514\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.438\tLabel_Loss: 1.1126\tTop_Loss: 1.0655\tBottom_Loss: 0.9821\tLoss: 3.1602\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.500\tLabel_Loss: 0.9191\tTop_Loss: 1.0548\tBottom_Loss: 1.0301\tLoss: 3.0040\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.625\tLabel_Loss: 0.9434\tTop_Loss: 0.9703\tBottom_Loss: 1.0885\tLoss: 3.0022\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.562\tLabel_Loss: 0.8809\tTop_Loss: 1.0154\tBottom_Loss: 0.8721\tLoss: 2.7684\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.531\tLabel_Loss: 0.9373\tTop_Loss: 0.9769\tBottom_Loss: 1.2767\tLoss: 3.1910\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.562\tLabel_Loss: 1.0052\tTop_Loss: 0.9539\tBottom_Loss: 0.8949\tLoss: 2.8540\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.562\tLabel_Loss: 0.9513\tTop_Loss: 0.9606\tBottom_Loss: 0.9235\tLoss: 2.8355\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8449\tTop_Loss: 0.7685\tBottom_Loss: 0.9374\tLoss: 2.5507\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5652\tTop_Loss: 0.7508\tBottom_Loss: 0.7519\tLoss: 2.0678\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6777\tTop_Loss: 0.8526\tBottom_Loss: 0.7165\tLoss: 2.2469\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8868\tTop_Loss: 0.8207\tBottom_Loss: 0.9307\tLoss: 2.6382\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.719\tLabel_Loss: 0.7250\tTop_Loss: 0.8153\tBottom_Loss: 0.8465\tLoss: 2.3869\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8651\tTop_Loss: 0.7341\tBottom_Loss: 0.8793\tLoss: 2.4785\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6380\tTop_Loss: 0.6173\tBottom_Loss: 0.7485\tLoss: 2.0038\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7905\tTop_Loss: 0.9274\tBottom_Loss: 0.7617\tLoss: 2.4795\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5691\tTop_Loss: 0.6357\tBottom_Loss: 0.7822\tLoss: 1.9869\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8116\tTop_Loss: 0.7551\tBottom_Loss: 0.7683\tLoss: 2.3351\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.656\tLabel_Loss: 0.8300\tTop_Loss: 0.7996\tBottom_Loss: 0.7799\tLoss: 2.4095\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.781\tLabel_Loss: 0.6612\tTop_Loss: 0.7360\tBottom_Loss: 0.7674\tLoss: 2.1646\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.750\tLabel_Loss: 0.7430\tTop_Loss: 0.9185\tBottom_Loss: 0.8125\tLoss: 2.4739\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7217\tTop_Loss: 0.7434\tBottom_Loss: 0.6280\tLoss: 2.0930\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.719\tLabel_Loss: 0.7199\tTop_Loss: 0.7768\tBottom_Loss: 0.6402\tLoss: 2.1369\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6608\tTop_Loss: 0.6287\tBottom_Loss: 0.8102\tLoss: 2.0997\t\n",
      "Subject: 034, n=03 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5456\tTop_Loss: 0.7907\tBottom_Loss: 0.7546\tLoss: 2.0910\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.656\tLabel_Loss: 0.5980\tTop_Loss: 0.6066\tBottom_Loss: 0.7438\tLoss: 1.9483\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.531\tLabel_Loss: 0.9028\tTop_Loss: 0.8746\tBottom_Loss: 0.7835\tLoss: 2.5609\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7504\tTop_Loss: 0.7625\tBottom_Loss: 0.7645\tLoss: 2.2774\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4072\tTop_Loss: 0.4425\tBottom_Loss: 0.6107\tLoss: 1.4603\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5003\tTop_Loss: 0.6799\tBottom_Loss: 0.6147\tLoss: 1.7949\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4212\tTop_Loss: 0.5280\tBottom_Loss: 0.5788\tLoss: 1.5280\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7356\tTop_Loss: 0.6862\tBottom_Loss: 0.8342\tLoss: 2.2560\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6699\tTop_Loss: 0.7238\tBottom_Loss: 0.7894\tLoss: 2.1832\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4853\tTop_Loss: 0.5455\tBottom_Loss: 0.4714\tLoss: 1.5022\t\n",
      "Subject: 034, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4882\tTop_Loss: 0.5870\tBottom_Loss: 0.4644\tLoss: 1.5396\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.656\tLabel_Loss: 0.5744\tTop_Loss: 0.6298\tBottom_Loss: 0.7985\tLoss: 2.0026\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5339\tTop_Loss: 0.5134\tBottom_Loss: 0.6862\tLoss: 1.7334\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4440\tTop_Loss: 0.6464\tBottom_Loss: 0.4716\tLoss: 1.5620\t\n",
      "Subject: 034, n=03 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4330\tTop_Loss: 0.4710\tBottom_Loss: 0.5263\tLoss: 1.4304\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4078\tTop_Loss: 0.5472\tBottom_Loss: 0.5431\tLoss: 1.4980\t\n",
      "Subject: 034, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3961\tTop_Loss: 0.5747\tBottom_Loss: 0.5008\tLoss: 1.4716\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4645\tTop_Loss: 0.5083\tBottom_Loss: 0.6183\tLoss: 1.5911\t\n",
      "Subject: 034, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3424\tTop_Loss: 0.4703\tBottom_Loss: 0.4077\tLoss: 1.2205\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.688\tLabel_Loss: 0.5180\tTop_Loss: 0.5337\tBottom_Loss: 0.6218\tLoss: 1.6735\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3677\tTop_Loss: 0.6178\tBottom_Loss: 0.4659\tLoss: 1.4513\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3488\tTop_Loss: 0.4200\tBottom_Loss: 0.4799\tLoss: 1.2488\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4063\tTop_Loss: 0.6140\tBottom_Loss: 0.4511\tLoss: 1.4714\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.781\tLabel_Loss: 0.3816\tTop_Loss: 0.6528\tBottom_Loss: 0.4726\tLoss: 1.5069\t\n",
      "Subject: 034, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.938\tLabel_Loss: 0.3105\tTop_Loss: 0.4346\tBottom_Loss: 0.4513\tLoss: 1.1964\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3604\tTop_Loss: 0.7447\tBottom_Loss: 0.5219\tLoss: 1.6269\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3086\tTop_Loss: 0.3879\tBottom_Loss: 0.4775\tLoss: 1.1741\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3619\tTop_Loss: 0.4555\tBottom_Loss: 0.3675\tLoss: 1.1849\t\n",
      "Subject: 034, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2991\tTop_Loss: 0.4544\tBottom_Loss: 0.3651\tLoss: 1.1185\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6107\tTop_Loss: 0.7637\tBottom_Loss: 0.5830\tLoss: 1.9574\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3178\tTop_Loss: 0.5265\tBottom_Loss: 0.4374\tLoss: 1.2818\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4180\tTop_Loss: 0.5918\tBottom_Loss: 0.4952\tLoss: 1.5049\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3237\tTop_Loss: 0.4654\tBottom_Loss: 0.4277\tLoss: 1.2168\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.844\tLabel_Loss: 0.2582\tTop_Loss: 0.4856\tBottom_Loss: 0.3945\tLoss: 1.1382\t\n",
      "Subject: 034, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3647\tTop_Loss: 0.4905\tBottom_Loss: 0.4226\tLoss: 1.2778\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1849\tTop_Loss: 0.3825\tBottom_Loss: 0.2033\tLoss: 0.7707\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3357\tTop_Loss: 0.4173\tBottom_Loss: 0.4338\tLoss: 1.1868\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3488\tTop_Loss: 0.5131\tBottom_Loss: 0.4385\tLoss: 1.3005\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2502\tTop_Loss: 0.4409\tBottom_Loss: 0.3034\tLoss: 0.9945\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2224\tTop_Loss: 0.5232\tBottom_Loss: 0.3312\tLoss: 1.0768\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1516\tTop_Loss: 0.3792\tBottom_Loss: 0.1553\tLoss: 0.6861\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2273\tTop_Loss: 0.5705\tBottom_Loss: 0.2517\tLoss: 1.0494\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1965\tTop_Loss: 0.3939\tBottom_Loss: 0.2928\tLoss: 0.8832\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2322\tTop_Loss: 0.3645\tBottom_Loss: 0.2519\tLoss: 0.8487\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1409\tTop_Loss: 0.3665\tBottom_Loss: 0.2493\tLoss: 0.7567\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1329\tTop_Loss: 0.3608\tBottom_Loss: 0.2079\tLoss: 0.7016\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1986\tTop_Loss: 0.4314\tBottom_Loss: 0.2739\tLoss: 0.9040\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2136\tTop_Loss: 0.4332\tBottom_Loss: 0.3381\tLoss: 0.9849\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1746\tTop_Loss: 0.3508\tBottom_Loss: 0.3263\tLoss: 0.8517\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3301\tTop_Loss: 0.4540\tBottom_Loss: 0.4579\tLoss: 1.2419\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1987\tTop_Loss: 0.3219\tBottom_Loss: 0.4655\tLoss: 0.9860\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2003\tTop_Loss: 0.3131\tBottom_Loss: 0.2470\tLoss: 0.7604\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2367\tTop_Loss: 0.4547\tBottom_Loss: 0.2760\tLoss: 0.9674\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3027\tTop_Loss: 0.4682\tBottom_Loss: 0.3657\tLoss: 1.1367\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1978\tTop_Loss: 0.3546\tBottom_Loss: 0.2527\tLoss: 0.8051\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1611\tTop_Loss: 0.3281\tBottom_Loss: 0.3807\tLoss: 0.8699\t\n",
      "Subject: 034, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0774\tTop_Loss: 0.2056\tBottom_Loss: 0.1540\tLoss: 0.4370\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2046\tTop_Loss: 0.3039\tBottom_Loss: 0.3463\tLoss: 0.8548\t\n",
      "Subject: 034, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1762\tTop_Loss: 0.3500\tBottom_Loss: 0.3115\tLoss: 0.8377\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1630\tTop_Loss: 0.2380\tBottom_Loss: 0.1913\tLoss: 0.5923\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2084\tTop_Loss: 0.2915\tBottom_Loss: 0.2298\tLoss: 0.7297\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1985\tTop_Loss: 0.2745\tBottom_Loss: 0.3057\tLoss: 0.7788\t\n",
      "Subject: 034, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1393\tTop_Loss: 0.2864\tBottom_Loss: 0.2747\tLoss: 0.7003\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1204\tTop_Loss: 0.3086\tBottom_Loss: 0.2023\tLoss: 0.6313\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1738\tTop_Loss: 0.3215\tBottom_Loss: 0.1837\tLoss: 0.6790\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1079\tTop_Loss: 0.2532\tBottom_Loss: 0.1719\tLoss: 0.5329\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1210\tTop_Loss: 0.1964\tBottom_Loss: 0.2364\tLoss: 0.5537\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0610\tTop_Loss: 0.3160\tBottom_Loss: 0.1383\tLoss: 0.5152\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0987\tTop_Loss: 0.1830\tBottom_Loss: 0.2023\tLoss: 0.4841\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0613\tTop_Loss: 0.1773\tBottom_Loss: 0.1783\tLoss: 0.4169\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1682\tTop_Loss: 0.3100\tBottom_Loss: 0.2212\tLoss: 0.6994\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1371\tTop_Loss: 0.2480\tBottom_Loss: 0.1360\tLoss: 0.5210\t\n",
      "Subject: 034, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0867\tTop_Loss: 0.1995\tBottom_Loss: 0.1000\tLoss: 0.3862\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1162\tTop_Loss: 0.3555\tBottom_Loss: 0.1821\tLoss: 0.6538\t\n",
      "Subject: 034, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1168\tTop_Loss: 0.2002\tBottom_Loss: 0.2452\tLoss: 0.5621\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0791\tTop_Loss: 0.1282\tBottom_Loss: 0.1922\tLoss: 0.3995\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1345\tTop_Loss: 0.2189\tBottom_Loss: 0.2491\tLoss: 0.6026\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1338\tTop_Loss: 0.3021\tBottom_Loss: 0.2065\tLoss: 0.6424\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2016\tTop_Loss: 0.3672\tBottom_Loss: 0.3266\tLoss: 0.8954\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1469\tTop_Loss: 0.2979\tBottom_Loss: 0.1487\tLoss: 0.5934\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0926\tTop_Loss: 0.2451\tBottom_Loss: 0.1301\tLoss: 0.4678\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2220\tTop_Loss: 0.2957\tBottom_Loss: 0.3621\tLoss: 0.8798\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1086\tTop_Loss: 0.2059\tBottom_Loss: 0.2226\tLoss: 0.5371\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0557\tTop_Loss: 0.2400\tBottom_Loss: 0.0728\tLoss: 0.3685\t\n",
      "Subject: 034, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0565\tTop_Loss: 0.1634\tBottom_Loss: 0.1027\tLoss: 0.3227\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0503\tTop_Loss: 0.1697\tBottom_Loss: 0.1197\tLoss: 0.3397\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1300\tTop_Loss: 0.3053\tBottom_Loss: 0.1176\tLoss: 0.5530\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0640\tTop_Loss: 0.1976\tBottom_Loss: 0.0858\tLoss: 0.3475\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1612\tTop_Loss: 0.2154\tBottom_Loss: 0.2143\tLoss: 0.5909\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0765\tTop_Loss: 0.2072\tBottom_Loss: 0.1464\tLoss: 0.4301\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0790\tTop_Loss: 0.2163\tBottom_Loss: 0.0868\tLoss: 0.3821\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0675\tTop_Loss: 0.1611\tBottom_Loss: 0.1215\tLoss: 0.3501\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1472\tTop_Loss: 0.2463\tBottom_Loss: 0.1802\tLoss: 0.5737\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0412\tTop_Loss: 0.1215\tBottom_Loss: 0.1200\tLoss: 0.2827\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1021\tTop_Loss: 0.1822\tBottom_Loss: 0.1456\tLoss: 0.4298\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0377\tTop_Loss: 0.2002\tBottom_Loss: 0.0603\tLoss: 0.2982\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0799\tTop_Loss: 0.1344\tBottom_Loss: 0.1468\tLoss: 0.3612\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0320\tTop_Loss: 0.2009\tBottom_Loss: 0.0592\tLoss: 0.2921\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0350\tTop_Loss: 0.1050\tBottom_Loss: 0.0944\tLoss: 0.2344\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0367\tTop_Loss: 0.1136\tBottom_Loss: 0.0632\tLoss: 0.2135\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 0.938\tLabel_Loss: 0.0956\tTop_Loss: 0.2228\tBottom_Loss: 0.1610\tLoss: 0.4794\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0455\tTop_Loss: 0.1823\tBottom_Loss: 0.0575\tLoss: 0.2852\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0320\tTop_Loss: 0.1425\tBottom_Loss: 0.0731\tLoss: 0.2477\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0801\tTop_Loss: 0.0823\tBottom_Loss: 0.1541\tLoss: 0.3164\t\n",
      "Subject: 034, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0835\tTop_Loss: 0.1345\tBottom_Loss: 0.1097\tLoss: 0.3277\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0318\tTop_Loss: 0.1355\tBottom_Loss: 0.0805\tLoss: 0.2478\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0512\tTop_Loss: 0.1396\tBottom_Loss: 0.0565\tLoss: 0.2474\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0313\tTop_Loss: 0.0572\tBottom_Loss: 0.1173\tLoss: 0.2058\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0978\tTop_Loss: 0.2836\tBottom_Loss: 0.1263\tLoss: 0.5076\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0795\tTop_Loss: 0.1445\tBottom_Loss: 0.1208\tLoss: 0.3448\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0496\tTop_Loss: 0.1422\tBottom_Loss: 0.1104\tLoss: 0.3022\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0765\tTop_Loss: 0.2712\tBottom_Loss: 0.0701\tLoss: 0.4178\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0483\tTop_Loss: 0.2145\tBottom_Loss: 0.1435\tLoss: 0.4063\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0125\tTop_Loss: 0.1359\tBottom_Loss: 0.0273\tLoss: 0.1757\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0196\tTop_Loss: 0.0953\tBottom_Loss: 0.0541\tLoss: 0.1689\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0292\tTop_Loss: 0.1095\tBottom_Loss: 0.1090\tLoss: 0.2478\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0181\tTop_Loss: 0.0897\tBottom_Loss: 0.0515\tLoss: 0.1593\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0628\tTop_Loss: 0.1910\tBottom_Loss: 0.0571\tLoss: 0.3108\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0321\tTop_Loss: 0.0924\tBottom_Loss: 0.0518\tLoss: 0.1764\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0268\tTop_Loss: 0.0659\tBottom_Loss: 0.0703\tLoss: 0.1630\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0347\tTop_Loss: 0.1494\tBottom_Loss: 0.0789\tLoss: 0.2629\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0133\tTop_Loss: 0.0745\tBottom_Loss: 0.0401\tLoss: 0.1279\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0372\tTop_Loss: 0.0889\tBottom_Loss: 0.0340\tLoss: 0.1600\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0861\tTop_Loss: 0.1747\tBottom_Loss: 0.1493\tLoss: 0.4101\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0188\tTop_Loss: 0.0864\tBottom_Loss: 0.0513\tLoss: 0.1565\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0709\tTop_Loss: 0.1422\tBottom_Loss: 0.0594\tLoss: 0.2726\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0441\tTop_Loss: 0.1061\tBottom_Loss: 0.0966\tLoss: 0.2468\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0870\tTop_Loss: 0.1208\tBottom_Loss: 0.2031\tLoss: 0.4110\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0311\tTop_Loss: 0.1149\tBottom_Loss: 0.0606\tLoss: 0.2067\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0405\tTop_Loss: 0.1535\tBottom_Loss: 0.0647\tLoss: 0.2588\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[80][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0392\tTop_Loss: 0.0520\tBottom_Loss: 0.1226\tLoss: 0.2138\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0193\tTop_Loss: 0.0575\tBottom_Loss: 0.0338\tLoss: 0.1107\t\n",
      "Subject: 034, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0470\tTop_Loss: 0.0818\tBottom_Loss: 0.0682\tLoss: 0.1970\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0197\tTop_Loss: 0.0595\tBottom_Loss: 0.0380\tLoss: 0.1171\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0343\tTop_Loss: 0.0743\tBottom_Loss: 0.0836\tLoss: 0.1922\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0129\tTop_Loss: 0.0676\tBottom_Loss: 0.0310\tLoss: 0.1115\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0613\tTop_Loss: 0.1280\tBottom_Loss: 0.0985\tLoss: 0.2879\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0404\tTop_Loss: 0.1228\tBottom_Loss: 0.0952\tLoss: 0.2584\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0201\tTop_Loss: 0.1162\tBottom_Loss: 0.0394\tLoss: 0.1757\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 0.938\tLabel_Loss: 0.0837\tTop_Loss: 0.1999\tBottom_Loss: 0.0938\tLoss: 0.3775\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0076\tTop_Loss: 0.0271\tBottom_Loss: 0.0373\tLoss: 0.0720\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0261\tTop_Loss: 0.0351\tBottom_Loss: 0.0609\tLoss: 0.1222\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0107\tTop_Loss: 0.0517\tBottom_Loss: 0.0172\tLoss: 0.0796\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0084\tTop_Loss: 0.0274\tBottom_Loss: 0.0243\tLoss: 0.0601\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0232\tTop_Loss: 0.0630\tBottom_Loss: 0.0830\tLoss: 0.1692\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0154\tTop_Loss: 0.0718\tBottom_Loss: 0.0551\tLoss: 0.1423\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0310\tTop_Loss: 0.1098\tBottom_Loss: 0.0591\tLoss: 0.1998\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0225\tTop_Loss: 0.0908\tBottom_Loss: 0.0483\tLoss: 0.1617\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0211\tTop_Loss: 0.0850\tBottom_Loss: 0.0581\tLoss: 0.1642\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0203\tTop_Loss: 0.0622\tBottom_Loss: 0.0303\tLoss: 0.1128\t\n",
      "Subject: 034, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0128\tTop_Loss: 0.0415\tBottom_Loss: 0.0325\tLoss: 0.0868\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0063\tTop_Loss: 0.0172\tBottom_Loss: 0.0247\tLoss: 0.0482\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0091\tTop_Loss: 0.0342\tBottom_Loss: 0.0286\tLoss: 0.0719\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0415\tTop_Loss: 0.1125\tBottom_Loss: 0.0635\tLoss: 0.2175\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0214\tTop_Loss: 0.0358\tBottom_Loss: 0.0409\tLoss: 0.0981\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0164\tTop_Loss: 0.1265\tBottom_Loss: 0.0157\tLoss: 0.1586\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0060\tTop_Loss: 0.0282\tBottom_Loss: 0.0217\tLoss: 0.0558\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0215\tTop_Loss: 0.0716\tBottom_Loss: 0.0407\tLoss: 0.1338\t\n",
      "Subject: 034, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0131\tTop_Loss: 0.0290\tBottom_Loss: 0.0451\tLoss: 0.0872\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0074\tTop_Loss: 0.0297\tBottom_Loss: 0.0214\tLoss: 0.0584\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0120\tTop_Loss: 0.0313\tBottom_Loss: 0.0389\tLoss: 0.0823\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0507\tTop_Loss: 0.0804\tBottom_Loss: 0.0923\tLoss: 0.2235\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0446\tTop_Loss: 0.1108\tBottom_Loss: 0.1065\tLoss: 0.2619\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0182\tTop_Loss: 0.0927\tBottom_Loss: 0.0258\tLoss: 0.1367\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0103\tTop_Loss: 0.0453\tBottom_Loss: 0.0416\tLoss: 0.0972\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0615\tTop_Loss: 0.0609\tBottom_Loss: 0.1193\tLoss: 0.2417\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0264\tTop_Loss: 0.1439\tBottom_Loss: 0.0291\tLoss: 0.1994\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0213\tTop_Loss: 0.0557\tBottom_Loss: 0.0427\tLoss: 0.1197\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0076\tTop_Loss: 0.0342\tBottom_Loss: 0.0222\tLoss: 0.0641\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0146\tTop_Loss: 0.0627\tBottom_Loss: 0.0271\tLoss: 0.1045\t\n",
      "Subject: 034, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.406\tLabel_Loss: 1.2067\tTop_Loss: 1.1853\tBottom_Loss: 1.8398\tLoss: 4.2317\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.469\tLabel_Loss: 1.2359\tTop_Loss: 1.2800\tBottom_Loss: 1.2173\tLoss: 3.7332\t\n",
      "Subject: 035, n=08 | test_f1: 0.42857 |best_f1: 0.42857\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.375\tLabel_Loss: 1.1566\tTop_Loss: 1.2554\tBottom_Loss: 1.1339\tLoss: 3.5458\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.594\tLabel_Loss: 1.0013\tTop_Loss: 0.9548\tBottom_Loss: 0.9267\tLoss: 2.8828\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.42857\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.500\tLabel_Loss: 1.1052\tTop_Loss: 1.0756\tBottom_Loss: 0.9848\tLoss: 3.1657\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8000\tTop_Loss: 1.0250\tBottom_Loss: 0.8474\tLoss: 2.6724\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.781\tLabel_Loss: 0.7456\tTop_Loss: 0.7539\tBottom_Loss: 0.7587\tLoss: 2.2583\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.531\tLabel_Loss: 1.0586\tTop_Loss: 0.9950\tBottom_Loss: 1.0929\tLoss: 3.1464\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.750\tLabel_Loss: 0.7633\tTop_Loss: 0.7028\tBottom_Loss: 0.9062\tLoss: 2.3724\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.500\tLabel_Loss: 1.0234\tTop_Loss: 0.9312\tBottom_Loss: 1.0397\tLoss: 2.9942\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.500\tLabel_Loss: 0.9364\tTop_Loss: 0.9873\tBottom_Loss: 0.8703\tLoss: 2.7940\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.469\tLabel_Loss: 0.9916\tTop_Loss: 0.9531\tBottom_Loss: 0.9019\tLoss: 2.8466\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7473\tTop_Loss: 0.8632\tBottom_Loss: 0.8088\tLoss: 2.4194\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7828\tTop_Loss: 0.8396\tBottom_Loss: 0.9178\tLoss: 2.5402\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7394\tTop_Loss: 0.7740\tBottom_Loss: 0.7493\tLoss: 2.2626\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.469\tLabel_Loss: 1.0666\tTop_Loss: 1.1215\tBottom_Loss: 1.0703\tLoss: 3.2584\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.656\tLabel_Loss: 0.8358\tTop_Loss: 0.9212\tBottom_Loss: 0.8958\tLoss: 2.6528\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.656\tLabel_Loss: 0.8557\tTop_Loss: 0.8348\tBottom_Loss: 0.8703\tLoss: 2.5609\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.594\tLabel_Loss: 0.7846\tTop_Loss: 0.8704\tBottom_Loss: 0.8717\tLoss: 2.5268\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.562\tLabel_Loss: 0.8031\tTop_Loss: 0.8349\tBottom_Loss: 0.8705\tLoss: 2.5084\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7578\tTop_Loss: 0.8570\tBottom_Loss: 0.9240\tLoss: 2.5387\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.656\tLabel_Loss: 0.8437\tTop_Loss: 0.8518\tBottom_Loss: 0.8745\tLoss: 2.5701\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 035, n=08 | test_f1: 0.22222 |best_f1: 0.46667\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6554\tTop_Loss: 0.8302\tBottom_Loss: 0.7721\tLoss: 2.2578\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6402\tTop_Loss: 0.7059\tBottom_Loss: 0.7541\tLoss: 2.1002\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7115\tTop_Loss: 0.6598\tBottom_Loss: 0.7197\tLoss: 2.0909\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6380\tTop_Loss: 0.7895\tBottom_Loss: 0.8804\tLoss: 2.3079\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.750\tLabel_Loss: 0.7368\tTop_Loss: 0.8577\tBottom_Loss: 0.7910\tLoss: 2.3855\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4844\tTop_Loss: 0.5630\tBottom_Loss: 0.7639\tLoss: 1.8113\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5493\tTop_Loss: 0.7452\tBottom_Loss: 0.7920\tLoss: 2.0864\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7081\tTop_Loss: 0.9654\tBottom_Loss: 0.8379\tLoss: 2.5114\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5793\tTop_Loss: 0.7048\tBottom_Loss: 0.7138\tLoss: 1.9979\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.500\tLabel_Loss: 0.8071\tTop_Loss: 0.9243\tBottom_Loss: 1.0386\tLoss: 2.7700\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4452\tTop_Loss: 0.6891\tBottom_Loss: 0.5364\tLoss: 1.6707\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6633\tTop_Loss: 0.7794\tBottom_Loss: 0.7043\tLoss: 2.1470\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5520\tTop_Loss: 0.6022\tBottom_Loss: 0.7407\tLoss: 1.8950\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.781\tLabel_Loss: 0.6175\tTop_Loss: 0.5609\tBottom_Loss: 0.6861\tLoss: 1.8644\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7004\tTop_Loss: 0.8845\tBottom_Loss: 0.6109\tLoss: 2.1958\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4653\tTop_Loss: 0.6610\tBottom_Loss: 0.5605\tLoss: 1.6867\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5029\tTop_Loss: 0.6100\tBottom_Loss: 0.5276\tLoss: 1.6404\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6001\tTop_Loss: 0.6488\tBottom_Loss: 0.5699\tLoss: 1.8188\t\n",
      "Subject: 035, n=08 | test_f1: 0.25641 |best_f1: 0.46667\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5219\tTop_Loss: 0.7013\tBottom_Loss: 0.6178\tLoss: 1.8410\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3651\tTop_Loss: 0.5252\tBottom_Loss: 0.5624\tLoss: 1.4526\t\n",
      "Subject: 035, n=08 | test_f1: 0.25641 |best_f1: 0.46667\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4916\tTop_Loss: 0.5303\tBottom_Loss: 0.6008\tLoss: 1.6227\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.750\tLabel_Loss: 0.4633\tTop_Loss: 0.6493\tBottom_Loss: 0.6071\tLoss: 1.7197\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4866\tTop_Loss: 0.7026\tBottom_Loss: 0.6439\tLoss: 1.8331\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3941\tTop_Loss: 0.5463\tBottom_Loss: 0.4891\tLoss: 1.4296\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.750\tLabel_Loss: 0.4437\tTop_Loss: 0.5642\tBottom_Loss: 0.5213\tLoss: 1.5292\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2810\tTop_Loss: 0.4661\tBottom_Loss: 0.4261\tLoss: 1.1731\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3129\tTop_Loss: 0.6349\tBottom_Loss: 0.5201\tLoss: 1.4679\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6850\tTop_Loss: 0.8455\tBottom_Loss: 0.6501\tLoss: 2.1807\t\n",
      "Subject: 035, n=08 | test_f1: 0.25641 |best_f1: 0.46667\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2385\tTop_Loss: 0.5929\tBottom_Loss: 0.2971\tLoss: 1.1285\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4214\tTop_Loss: 0.7436\tBottom_Loss: 0.5144\tLoss: 1.6793\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2872\tTop_Loss: 0.5935\tBottom_Loss: 0.4767\tLoss: 1.3574\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4645\tTop_Loss: 0.5644\tBottom_Loss: 0.5478\tLoss: 1.5767\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3596\tTop_Loss: 0.4417\tBottom_Loss: 0.3840\tLoss: 1.1853\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3513\tTop_Loss: 0.4084\tBottom_Loss: 0.4386\tLoss: 1.1984\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3980\tTop_Loss: 0.5496\tBottom_Loss: 0.4411\tLoss: 1.3888\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3022\tTop_Loss: 0.5891\tBottom_Loss: 0.3995\tLoss: 1.2908\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.938\tLabel_Loss: 0.3018\tTop_Loss: 0.5053\tBottom_Loss: 0.3819\tLoss: 1.1890\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3310\tTop_Loss: 0.4534\tBottom_Loss: 0.4662\tLoss: 1.2506\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3784\tTop_Loss: 0.5022\tBottom_Loss: 0.5455\tLoss: 1.4261\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1999\tTop_Loss: 0.3753\tBottom_Loss: 0.3655\tLoss: 0.9406\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2684\tTop_Loss: 0.3503\tBottom_Loss: 0.3422\tLoss: 0.9608\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2442\tTop_Loss: 0.5510\tBottom_Loss: 0.3468\tLoss: 1.1420\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2342\tTop_Loss: 0.4443\tBottom_Loss: 0.3146\tLoss: 0.9931\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2176\tTop_Loss: 0.4015\tBottom_Loss: 0.5111\tLoss: 1.1302\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2471\tTop_Loss: 0.3854\tBottom_Loss: 0.3539\tLoss: 0.9863\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3492\tTop_Loss: 0.4618\tBottom_Loss: 0.4867\tLoss: 1.2976\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1535\tTop_Loss: 0.3601\tBottom_Loss: 0.3100\tLoss: 0.8236\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2973\tTop_Loss: 0.4756\tBottom_Loss: 0.3928\tLoss: 1.1656\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3897\tTop_Loss: 0.4937\tBottom_Loss: 0.5108\tLoss: 1.3942\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2658\tTop_Loss: 0.5806\tBottom_Loss: 0.3274\tLoss: 1.1737\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1163\tTop_Loss: 0.3928\tBottom_Loss: 0.1847\tLoss: 0.6937\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2078\tTop_Loss: 0.5279\tBottom_Loss: 0.2938\tLoss: 1.0295\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2219\tTop_Loss: 0.3390\tBottom_Loss: 0.2865\tLoss: 0.8475\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2483\tTop_Loss: 0.2709\tBottom_Loss: 0.4901\tLoss: 1.0093\t\n",
      "Subject: 035, n=08 | test_f1: 0.25641 |best_f1: 0.46667\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3032\tTop_Loss: 0.3953\tBottom_Loss: 0.4843\tLoss: 1.1828\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2386\tTop_Loss: 0.3498\tBottom_Loss: 0.2634\tLoss: 0.8518\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3420\tTop_Loss: 0.4433\tBottom_Loss: 0.4147\tLoss: 1.2000\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1088\tTop_Loss: 0.1961\tBottom_Loss: 0.2416\tLoss: 0.5465\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1582\tTop_Loss: 0.4246\tBottom_Loss: 0.2790\tLoss: 0.8618\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1602\tTop_Loss: 0.4222\tBottom_Loss: 0.2546\tLoss: 0.8370\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3289\tTop_Loss: 0.3699\tBottom_Loss: 0.4049\tLoss: 1.1037\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1683\tTop_Loss: 0.3803\tBottom_Loss: 0.2878\tLoss: 0.8364\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2466\tTop_Loss: 0.3199\tBottom_Loss: 0.4416\tLoss: 1.0081\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2467\tTop_Loss: 0.5010\tBottom_Loss: 0.3422\tLoss: 1.0899\t\n",
      "Subject: 035, n=08 | test_f1: 0.22222 |best_f1: 0.46667\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2119\tTop_Loss: 0.5115\tBottom_Loss: 0.2581\tLoss: 0.9815\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1196\tTop_Loss: 0.3702\tBottom_Loss: 0.1562\tLoss: 0.6460\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1294\tTop_Loss: 0.3948\tBottom_Loss: 0.1446\tLoss: 0.6689\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0881\tTop_Loss: 0.1799\tBottom_Loss: 0.1609\tLoss: 0.4289\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2001\tTop_Loss: 0.2960\tBottom_Loss: 0.2914\tLoss: 0.7876\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1841\tTop_Loss: 0.3264\tBottom_Loss: 0.3038\tLoss: 0.8144\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1059\tTop_Loss: 0.2441\tBottom_Loss: 0.2231\tLoss: 0.5732\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1485\tTop_Loss: 0.4045\tBottom_Loss: 0.2566\tLoss: 0.8097\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2078\tTop_Loss: 0.2766\tBottom_Loss: 0.2958\tLoss: 0.7802\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1400\tTop_Loss: 0.2613\tBottom_Loss: 0.1917\tLoss: 0.5930\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.844\tLabel_Loss: 0.2883\tTop_Loss: 0.5093\tBottom_Loss: 0.3038\tLoss: 1.1013\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0774\tTop_Loss: 0.3166\tBottom_Loss: 0.1427\tLoss: 0.5367\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0755\tTop_Loss: 0.1544\tBottom_Loss: 0.1968\tLoss: 0.4267\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0944\tTop_Loss: 0.3250\tBottom_Loss: 0.1825\tLoss: 0.6019\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0649\tTop_Loss: 0.2140\tBottom_Loss: 0.1244\tLoss: 0.4033\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0626\tTop_Loss: 0.1469\tBottom_Loss: 0.1247\tLoss: 0.3342\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1191\tTop_Loss: 0.1340\tBottom_Loss: 0.2462\tLoss: 0.4993\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0836\tTop_Loss: 0.2297\tBottom_Loss: 0.1641\tLoss: 0.4774\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0348\tTop_Loss: 0.1847\tBottom_Loss: 0.0742\tLoss: 0.2937\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0686\tTop_Loss: 0.1923\tBottom_Loss: 0.0890\tLoss: 0.3499\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0899\tTop_Loss: 0.1674\tBottom_Loss: 0.2149\tLoss: 0.4722\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0287\tTop_Loss: 0.1199\tBottom_Loss: 0.0714\tLoss: 0.2200\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0859\tTop_Loss: 0.2032\tBottom_Loss: 0.2601\tLoss: 0.5492\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0458\tTop_Loss: 0.1204\tBottom_Loss: 0.0880\tLoss: 0.2543\t\n",
      "Subject: 035, n=08 | test_f1: 0.25641 |best_f1: 0.46667\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.938\tLabel_Loss: 0.0868\tTop_Loss: 0.1839\tBottom_Loss: 0.1012\tLoss: 0.3720\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0701\tTop_Loss: 0.1120\tBottom_Loss: 0.2208\tLoss: 0.4028\t\n",
      "Subject: 035, n=08 | test_f1: 0.25641 |best_f1: 0.46667\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1060\tTop_Loss: 0.1481\tBottom_Loss: 0.2038\tLoss: 0.4579\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0481\tTop_Loss: 0.1508\tBottom_Loss: 0.1194\tLoss: 0.3183\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1385\tTop_Loss: 0.2416\tBottom_Loss: 0.3313\tLoss: 0.7115\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0610\tTop_Loss: 0.2348\tBottom_Loss: 0.1453\tLoss: 0.4411\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0752\tTop_Loss: 0.1784\tBottom_Loss: 0.1432\tLoss: 0.3968\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0463\tTop_Loss: 0.2735\tBottom_Loss: 0.1200\tLoss: 0.4398\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0381\tTop_Loss: 0.1050\tBottom_Loss: 0.1345\tLoss: 0.2776\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0621\tTop_Loss: 0.1775\tBottom_Loss: 0.0993\tLoss: 0.3388\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0498\tTop_Loss: 0.1628\tBottom_Loss: 0.0699\tLoss: 0.2824\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0507\tTop_Loss: 0.1113\tBottom_Loss: 0.1758\tLoss: 0.3379\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0247\tTop_Loss: 0.1325\tBottom_Loss: 0.0555\tLoss: 0.2127\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0403\tTop_Loss: 0.1145\tBottom_Loss: 0.1097\tLoss: 0.2645\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0359\tTop_Loss: 0.1325\tBottom_Loss: 0.0855\tLoss: 0.2539\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1251\tTop_Loss: 0.1272\tBottom_Loss: 0.1405\tLoss: 0.3928\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0326\tTop_Loss: 0.1301\tBottom_Loss: 0.1101\tLoss: 0.2728\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0464\tTop_Loss: 0.1575\tBottom_Loss: 0.1040\tLoss: 0.3079\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0684\tTop_Loss: 0.2027\tBottom_Loss: 0.0718\tLoss: 0.3430\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0348\tTop_Loss: 0.1318\tBottom_Loss: 0.0563\tLoss: 0.2228\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0895\tTop_Loss: 0.1658\tBottom_Loss: 0.1421\tLoss: 0.3974\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0398\tTop_Loss: 0.1508\tBottom_Loss: 0.1336\tLoss: 0.3242\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0321\tTop_Loss: 0.0730\tBottom_Loss: 0.1028\tLoss: 0.2079\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0324\tTop_Loss: 0.1393\tBottom_Loss: 0.1192\tLoss: 0.2910\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0468\tTop_Loss: 0.0767\tBottom_Loss: 0.1108\tLoss: 0.2342\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0438\tTop_Loss: 0.1619\tBottom_Loss: 0.1141\tLoss: 0.3199\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0243\tTop_Loss: 0.1180\tBottom_Loss: 0.0537\tLoss: 0.1960\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0878\tTop_Loss: 0.3434\tBottom_Loss: 0.1061\tLoss: 0.5373\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0458\tTop_Loss: 0.1056\tBottom_Loss: 0.1293\tLoss: 0.2807\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0523\tTop_Loss: 0.1791\tBottom_Loss: 0.0953\tLoss: 0.3267\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0433\tTop_Loss: 0.1399\tBottom_Loss: 0.0778\tLoss: 0.2610\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0954\tTop_Loss: 0.2845\tBottom_Loss: 0.1110\tLoss: 0.4909\t\n",
      "Subject: 035, n=08 | test_f1: 0.25641 |best_f1: 0.46667\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1040\tTop_Loss: 0.1656\tBottom_Loss: 0.2156\tLoss: 0.4852\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[71][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1162\tTop_Loss: 0.2337\tBottom_Loss: 0.0701\tLoss: 0.4201\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0302\tTop_Loss: 0.1422\tBottom_Loss: 0.0892\tLoss: 0.2616\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0331\tTop_Loss: 0.0928\tBottom_Loss: 0.0694\tLoss: 0.1953\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0330\tTop_Loss: 0.0545\tBottom_Loss: 0.0698\tLoss: 0.1573\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0234\tTop_Loss: 0.0767\tBottom_Loss: 0.0658\tLoss: 0.1658\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0324\tTop_Loss: 0.0485\tBottom_Loss: 0.1840\tLoss: 0.2649\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0362\tTop_Loss: 0.0875\tBottom_Loss: 0.0900\tLoss: 0.2138\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0126\tTop_Loss: 0.0513\tBottom_Loss: 0.0323\tLoss: 0.0962\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0303\tTop_Loss: 0.0512\tBottom_Loss: 0.1020\tLoss: 0.1834\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0234\tTop_Loss: 0.0379\tBottom_Loss: 0.0874\tLoss: 0.1487\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0125\tTop_Loss: 0.0577\tBottom_Loss: 0.0344\tLoss: 0.1047\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0474\tTop_Loss: 0.1822\tBottom_Loss: 0.1040\tLoss: 0.3337\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0124\tTop_Loss: 0.0689\tBottom_Loss: 0.0346\tLoss: 0.1160\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0457\tTop_Loss: 0.0888\tBottom_Loss: 0.0928\tLoss: 0.2273\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0084\tTop_Loss: 0.0397\tBottom_Loss: 0.0261\tLoss: 0.0742\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0188\tTop_Loss: 0.0540\tBottom_Loss: 0.0479\tLoss: 0.1207\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0114\tTop_Loss: 0.0462\tBottom_Loss: 0.0342\tLoss: 0.0919\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0239\tTop_Loss: 0.0451\tBottom_Loss: 0.1052\tLoss: 0.1742\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0164\tTop_Loss: 0.0543\tBottom_Loss: 0.0447\tLoss: 0.1154\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0568\tTop_Loss: 0.2170\tBottom_Loss: 0.0888\tLoss: 0.3627\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0267\tTop_Loss: 0.0380\tBottom_Loss: 0.0432\tLoss: 0.1078\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0271\tTop_Loss: 0.1025\tBottom_Loss: 0.0341\tLoss: 0.1637\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0468\tTop_Loss: 0.0453\tBottom_Loss: 0.0707\tLoss: 0.1628\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0132\tTop_Loss: 0.0349\tBottom_Loss: 0.0495\tLoss: 0.0975\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0129\tTop_Loss: 0.0567\tBottom_Loss: 0.0460\tLoss: 0.1156\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0181\tTop_Loss: 0.0662\tBottom_Loss: 0.0332\tLoss: 0.1175\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0157\tTop_Loss: 0.0420\tBottom_Loss: 0.0391\tLoss: 0.0968\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0099\tTop_Loss: 0.0661\tBottom_Loss: 0.0327\tLoss: 0.1086\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0836\tTop_Loss: 0.1697\tBottom_Loss: 0.0608\tLoss: 0.3142\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0137\tTop_Loss: 0.0466\tBottom_Loss: 0.0361\tLoss: 0.0964\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0844\tTop_Loss: 0.1685\tBottom_Loss: 0.1512\tLoss: 0.4041\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0238\tTop_Loss: 0.1289\tBottom_Loss: 0.0458\tLoss: 0.1985\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0079\tTop_Loss: 0.0552\tBottom_Loss: 0.0372\tLoss: 0.1004\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0151\tTop_Loss: 0.0895\tBottom_Loss: 0.0261\tLoss: 0.1307\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0182\tTop_Loss: 0.0605\tBottom_Loss: 0.0271\tLoss: 0.1058\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0091\tTop_Loss: 0.0954\tBottom_Loss: 0.0283\tLoss: 0.1328\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0073\tTop_Loss: 0.0441\tBottom_Loss: 0.0283\tLoss: 0.0797\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0428\tTop_Loss: 0.0982\tBottom_Loss: 0.0604\tLoss: 0.2015\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0172\tTop_Loss: 0.0474\tBottom_Loss: 0.0266\tLoss: 0.0911\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0061\tTop_Loss: 0.0597\tBottom_Loss: 0.0202\tLoss: 0.0861\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0095\tTop_Loss: 0.0250\tBottom_Loss: 0.0310\tLoss: 0.0655\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0153\tTop_Loss: 0.0740\tBottom_Loss: 0.0528\tLoss: 0.1420\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0673\tTop_Loss: 0.0653\tBottom_Loss: 0.0341\tLoss: 0.1666\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0761\tTop_Loss: 0.0541\tBottom_Loss: 0.0525\tLoss: 0.1828\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0261\tTop_Loss: 0.1055\tBottom_Loss: 0.0248\tLoss: 0.1564\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0142\tTop_Loss: 0.0606\tBottom_Loss: 0.0205\tLoss: 0.0952\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0153\tTop_Loss: 0.0845\tBottom_Loss: 0.0234\tLoss: 0.1233\t\n",
      "Subject: 035, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0051\tTop_Loss: 0.0191\tBottom_Loss: 0.0267\tLoss: 0.0509\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0100\tTop_Loss: 0.0416\tBottom_Loss: 0.0194\tLoss: 0.0711\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0309\tTop_Loss: 0.1060\tBottom_Loss: 0.0488\tLoss: 0.1857\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0221\tTop_Loss: 0.0640\tBottom_Loss: 0.0184\tLoss: 0.1046\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0138\tTop_Loss: 0.0215\tBottom_Loss: 0.1136\tLoss: 0.1490\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0078\tTop_Loss: 0.0349\tBottom_Loss: 0.0231\tLoss: 0.0658\t\n",
      "Subject: 035, n=08 | test_f1: 0.25641 |best_f1: 0.46667\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0080\tTop_Loss: 0.0097\tBottom_Loss: 0.0137\tLoss: 0.0314\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0053\tTop_Loss: 0.0273\tBottom_Loss: 0.0209\tLoss: 0.0535\t\n",
      "Subject: 035, n=08 | test_f1: 0.25641 |best_f1: 0.46667\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0544\tTop_Loss: 0.0628\tBottom_Loss: 0.1091\tLoss: 0.2263\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0064\tTop_Loss: 0.0307\tBottom_Loss: 0.0182\tLoss: 0.0553\t\n",
      "Subject: 035, n=08 | test_f1: 0.28571 |best_f1: 0.46667\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.375\tLabel_Loss: 1.3222\tTop_Loss: 1.3732\tBottom_Loss: 1.2078\tLoss: 3.9031\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.562\tLabel_Loss: 1.0863\tTop_Loss: 0.9152\tBottom_Loss: 1.0269\tLoss: 3.0284\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.531\tLabel_Loss: 1.0564\tTop_Loss: 0.8960\tBottom_Loss: 1.0896\tLoss: 3.0420\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.469\tLabel_Loss: 0.9702\tTop_Loss: 1.0970\tBottom_Loss: 0.9259\tLoss: 2.9930\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.469\tLabel_Loss: 0.9914\tTop_Loss: 0.9880\tBottom_Loss: 1.0781\tLoss: 3.0575\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.688\tLabel_Loss: 0.9498\tTop_Loss: 0.9428\tBottom_Loss: 1.0400\tLoss: 2.9325\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.531\tLabel_Loss: 0.8338\tTop_Loss: 0.7005\tBottom_Loss: 0.9852\tLoss: 2.5194\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.562\tLabel_Loss: 0.7533\tTop_Loss: 0.8355\tBottom_Loss: 0.7345\tLoss: 2.3233\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.438\tLabel_Loss: 0.9529\tTop_Loss: 1.0460\tBottom_Loss: 0.9037\tLoss: 2.9026\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.562\tLabel_Loss: 0.9522\tTop_Loss: 1.0483\tBottom_Loss: 1.0625\tLoss: 3.0630\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.406\tLabel_Loss: 1.1428\tTop_Loss: 1.2225\tBottom_Loss: 1.0065\tLoss: 3.3718\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7681\tTop_Loss: 0.8390\tBottom_Loss: 1.0066\tLoss: 2.6138\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7890\tTop_Loss: 0.7782\tBottom_Loss: 0.9358\tLoss: 2.5030\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.719\tLabel_Loss: 0.7583\tTop_Loss: 0.8342\tBottom_Loss: 0.9000\tLoss: 2.4925\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.594\tLabel_Loss: 0.7519\tTop_Loss: 0.7832\tBottom_Loss: 0.7941\tLoss: 2.3292\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6698\tTop_Loss: 0.8107\tBottom_Loss: 0.8333\tLoss: 2.3138\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8464\tTop_Loss: 0.9221\tBottom_Loss: 0.9745\tLoss: 2.7430\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5797\tTop_Loss: 0.7646\tBottom_Loss: 0.6676\tLoss: 2.0119\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7708\tTop_Loss: 0.7717\tBottom_Loss: 1.0232\tLoss: 2.5657\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6535\tTop_Loss: 0.8082\tBottom_Loss: 0.7417\tLoss: 2.2033\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.438\tLabel_Loss: 1.1242\tTop_Loss: 1.2348\tBottom_Loss: 1.0535\tLoss: 3.4126\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.594\tLabel_Loss: 0.7850\tTop_Loss: 0.9180\tBottom_Loss: 0.9234\tLoss: 2.6264\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.594\tLabel_Loss: 0.7770\tTop_Loss: 0.8774\tBottom_Loss: 0.9082\tLoss: 2.5625\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8497\tTop_Loss: 0.9854\tBottom_Loss: 0.9641\tLoss: 2.7993\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.688\tLabel_Loss: 0.8278\tTop_Loss: 0.8801\tBottom_Loss: 0.7941\tLoss: 2.5021\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6215\tTop_Loss: 0.7205\tBottom_Loss: 0.7327\tLoss: 2.0746\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6212\tTop_Loss: 0.8172\tBottom_Loss: 0.7155\tLoss: 2.1539\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5488\tTop_Loss: 0.6363\tBottom_Loss: 0.7060\tLoss: 1.8911\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6764\tTop_Loss: 0.8037\tBottom_Loss: 0.8186\tLoss: 2.2987\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5177\tTop_Loss: 0.5889\tBottom_Loss: 0.7144\tLoss: 1.8211\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5951\tTop_Loss: 0.7042\tBottom_Loss: 0.6196\tLoss: 1.9189\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4185\tTop_Loss: 0.6849\tBottom_Loss: 0.6215\tLoss: 1.7248\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6275\tTop_Loss: 0.7109\tBottom_Loss: 0.6553\tLoss: 1.9937\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6305\tTop_Loss: 0.7835\tBottom_Loss: 0.8067\tLoss: 2.2207\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5399\tTop_Loss: 0.7056\tBottom_Loss: 0.6167\tLoss: 1.8622\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6489\tTop_Loss: 0.7677\tBottom_Loss: 0.6519\tLoss: 2.0685\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6048\tTop_Loss: 0.7397\tBottom_Loss: 0.6978\tLoss: 2.0423\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5736\tTop_Loss: 0.7448\tBottom_Loss: 0.8551\tLoss: 2.1735\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4090\tTop_Loss: 0.4187\tBottom_Loss: 0.7406\tLoss: 1.5683\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.906\tLabel_Loss: 0.5690\tTop_Loss: 0.6015\tBottom_Loss: 0.5695\tLoss: 1.7400\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3683\tTop_Loss: 0.5739\tBottom_Loss: 0.3928\tLoss: 1.3349\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7290\tTop_Loss: 0.6896\tBottom_Loss: 0.8106\tLoss: 2.2292\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4532\tTop_Loss: 0.6349\tBottom_Loss: 0.5732\tLoss: 1.6613\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.750\tLabel_Loss: 0.4868\tTop_Loss: 0.5155\tBottom_Loss: 0.7574\tLoss: 1.7598\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.656\tLabel_Loss: 0.6827\tTop_Loss: 0.6639\tBottom_Loss: 0.6521\tLoss: 1.9987\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5204\tTop_Loss: 0.5787\tBottom_Loss: 0.6352\tLoss: 1.7344\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4393\tTop_Loss: 0.4350\tBottom_Loss: 0.5602\tLoss: 1.4345\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.719\tLabel_Loss: 0.5681\tTop_Loss: 0.6174\tBottom_Loss: 0.7618\tLoss: 1.9473\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3600\tTop_Loss: 0.5688\tBottom_Loss: 0.3116\tLoss: 1.2404\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2694\tTop_Loss: 0.4525\tBottom_Loss: 0.3988\tLoss: 1.1208\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3939\tTop_Loss: 0.5381\tBottom_Loss: 0.6091\tLoss: 1.5412\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3689\tTop_Loss: 0.6059\tBottom_Loss: 0.5433\tLoss: 1.5182\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4897\tTop_Loss: 0.5870\tBottom_Loss: 0.5197\tLoss: 1.5963\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2368\tTop_Loss: 0.3933\tBottom_Loss: 0.4122\tLoss: 1.0423\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3453\tTop_Loss: 0.5247\tBottom_Loss: 0.4579\tLoss: 1.3279\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4363\tTop_Loss: 0.3730\tBottom_Loss: 0.5860\tLoss: 1.3953\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3568\tTop_Loss: 0.5400\tBottom_Loss: 0.3806\tLoss: 1.2774\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3179\tTop_Loss: 0.5658\tBottom_Loss: 0.4491\tLoss: 1.3328\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1625\tTop_Loss: 0.2548\tBottom_Loss: 0.3161\tLoss: 0.7334\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4731\tTop_Loss: 0.5970\tBottom_Loss: 0.4683\tLoss: 1.5384\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2869\tTop_Loss: 0.5257\tBottom_Loss: 0.4207\tLoss: 1.2334\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1956\tTop_Loss: 0.4515\tBottom_Loss: 0.3126\tLoss: 0.9596\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.938\tLabel_Loss: 0.3138\tTop_Loss: 0.4023\tBottom_Loss: 0.3841\tLoss: 1.1003\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2138\tTop_Loss: 0.3383\tBottom_Loss: 0.3382\tLoss: 0.8903\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2141\tTop_Loss: 0.3733\tBottom_Loss: 0.3577\tLoss: 0.9451\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2684\tTop_Loss: 0.4757\tBottom_Loss: 0.3264\tLoss: 1.0706\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2124\tTop_Loss: 0.3624\tBottom_Loss: 0.3867\tLoss: 0.9616\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2415\tTop_Loss: 0.4067\tBottom_Loss: 0.4253\tLoss: 1.0735\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2305\tTop_Loss: 0.5416\tBottom_Loss: 0.2885\tLoss: 1.0606\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3840\tTop_Loss: 0.3936\tBottom_Loss: 0.5460\tLoss: 1.3236\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1335\tTop_Loss: 0.3187\tBottom_Loss: 0.2744\tLoss: 0.7266\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2347\tTop_Loss: 0.4805\tBottom_Loss: 0.3111\tLoss: 1.0264\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4090\tTop_Loss: 0.5399\tBottom_Loss: 0.3307\tLoss: 1.2795\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3424\tTop_Loss: 0.4170\tBottom_Loss: 0.3207\tLoss: 1.0801\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1170\tTop_Loss: 0.2585\tBottom_Loss: 0.2938\tLoss: 0.6693\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2782\tTop_Loss: 0.4348\tBottom_Loss: 0.3057\tLoss: 1.0188\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4028\tTop_Loss: 0.4888\tBottom_Loss: 0.3774\tLoss: 1.2690\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0915\tTop_Loss: 0.2325\tBottom_Loss: 0.2257\tLoss: 0.5497\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.844\tLabel_Loss: 0.2531\tTop_Loss: 0.3814\tBottom_Loss: 0.3941\tLoss: 1.0287\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1950\tTop_Loss: 0.3111\tBottom_Loss: 0.2583\tLoss: 0.7644\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1455\tTop_Loss: 0.2877\tBottom_Loss: 0.2553\tLoss: 0.6886\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1817\tTop_Loss: 0.2653\tBottom_Loss: 0.3086\tLoss: 0.7556\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1346\tTop_Loss: 0.2462\tBottom_Loss: 0.2383\tLoss: 0.6192\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1507\tTop_Loss: 0.3519\tBottom_Loss: 0.3315\tLoss: 0.8341\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2337\tTop_Loss: 0.3903\tBottom_Loss: 0.2677\tLoss: 0.8916\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1186\tTop_Loss: 0.3152\tBottom_Loss: 0.2303\tLoss: 0.6641\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1080\tTop_Loss: 0.3625\tBottom_Loss: 0.2063\tLoss: 0.6768\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2243\tTop_Loss: 0.3010\tBottom_Loss: 0.4637\tLoss: 0.9890\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2303\tTop_Loss: 0.3122\tBottom_Loss: 0.3787\tLoss: 0.9212\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1571\tTop_Loss: 0.2131\tBottom_Loss: 0.3105\tLoss: 0.6807\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3387\tTop_Loss: 0.3604\tBottom_Loss: 0.5350\tLoss: 1.2341\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3121\tTop_Loss: 0.5117\tBottom_Loss: 0.3873\tLoss: 1.2111\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1433\tTop_Loss: 0.2254\tBottom_Loss: 0.2469\tLoss: 0.6157\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1154\tTop_Loss: 0.2569\tBottom_Loss: 0.1874\tLoss: 0.5597\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0815\tTop_Loss: 0.2088\tBottom_Loss: 0.2663\tLoss: 0.5566\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0956\tTop_Loss: 0.2160\tBottom_Loss: 0.2359\tLoss: 0.5475\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1525\tTop_Loss: 0.4200\tBottom_Loss: 0.2450\tLoss: 0.8175\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0924\tTop_Loss: 0.2104\tBottom_Loss: 0.1679\tLoss: 0.4708\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1336\tTop_Loss: 0.2060\tBottom_Loss: 0.2615\tLoss: 0.6011\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0795\tTop_Loss: 0.2290\tBottom_Loss: 0.1805\tLoss: 0.4890\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0666\tTop_Loss: 0.1573\tBottom_Loss: 0.1430\tLoss: 0.3669\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1101\tTop_Loss: 0.2867\tBottom_Loss: 0.2175\tLoss: 0.6143\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1370\tTop_Loss: 0.2891\tBottom_Loss: 0.2701\tLoss: 0.6963\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0478\tTop_Loss: 0.2284\tBottom_Loss: 0.0577\tLoss: 0.3339\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0774\tTop_Loss: 0.1448\tBottom_Loss: 0.1054\tLoss: 0.3276\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1859\tTop_Loss: 0.1754\tBottom_Loss: 0.2466\tLoss: 0.6079\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0990\tTop_Loss: 0.2439\tBottom_Loss: 0.2851\tLoss: 0.6280\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1133\tTop_Loss: 0.2379\tBottom_Loss: 0.1713\tLoss: 0.5226\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0628\tTop_Loss: 0.1684\tBottom_Loss: 0.1182\tLoss: 0.3493\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0985\tTop_Loss: 0.2460\tBottom_Loss: 0.1459\tLoss: 0.4904\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0875\tTop_Loss: 0.2044\tBottom_Loss: 0.2618\tLoss: 0.5537\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0399\tTop_Loss: 0.1451\tBottom_Loss: 0.1153\tLoss: 0.3003\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1144\tTop_Loss: 0.1644\tBottom_Loss: 0.1431\tLoss: 0.4220\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0453\tTop_Loss: 0.1692\tBottom_Loss: 0.1493\tLoss: 0.3637\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2008\tTop_Loss: 0.3215\tBottom_Loss: 0.2421\tLoss: 0.7644\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0757\tTop_Loss: 0.2093\tBottom_Loss: 0.0989\tLoss: 0.3840\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0615\tTop_Loss: 0.2153\tBottom_Loss: 0.1421\tLoss: 0.4189\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0431\tTop_Loss: 0.0874\tBottom_Loss: 0.2461\tLoss: 0.3765\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0712\tTop_Loss: 0.1599\tBottom_Loss: 0.1425\tLoss: 0.3736\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 0.938\tLabel_Loss: 0.0911\tTop_Loss: 0.1853\tBottom_Loss: 0.2001\tLoss: 0.4766\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0710\tTop_Loss: 0.1755\tBottom_Loss: 0.1334\tLoss: 0.3799\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0438\tTop_Loss: 0.1564\tBottom_Loss: 0.1096\tLoss: 0.3098\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0636\tTop_Loss: 0.1788\tBottom_Loss: 0.1823\tLoss: 0.4248\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0635\tTop_Loss: 0.1588\tBottom_Loss: 0.1234\tLoss: 0.3457\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0761\tTop_Loss: 0.2486\tBottom_Loss: 0.1194\tLoss: 0.4442\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1854\tTop_Loss: 0.2599\tBottom_Loss: 0.2419\tLoss: 0.6871\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0529\tTop_Loss: 0.1594\tBottom_Loss: 0.1123\tLoss: 0.3246\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0737\tTop_Loss: 0.1532\tBottom_Loss: 0.1290\tLoss: 0.3559\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0371\tTop_Loss: 0.1290\tBottom_Loss: 0.0634\tLoss: 0.2294\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0323\tTop_Loss: 0.1162\tBottom_Loss: 0.1073\tLoss: 0.2557\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1070\tTop_Loss: 0.2099\tBottom_Loss: 0.1451\tLoss: 0.4619\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0906\tTop_Loss: 0.2462\tBottom_Loss: 0.1436\tLoss: 0.4804\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0443\tTop_Loss: 0.1654\tBottom_Loss: 0.0805\tLoss: 0.2902\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0262\tTop_Loss: 0.0848\tBottom_Loss: 0.0731\tLoss: 0.1841\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0339\tTop_Loss: 0.0984\tBottom_Loss: 0.0859\tLoss: 0.2182\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0773\tTop_Loss: 0.2005\tBottom_Loss: 0.0974\tLoss: 0.3752\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0297\tTop_Loss: 0.1096\tBottom_Loss: 0.0766\tLoss: 0.2159\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1466\tTop_Loss: 0.1615\tBottom_Loss: 0.1968\tLoss: 0.5048\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0503\tTop_Loss: 0.1044\tBottom_Loss: 0.1448\tLoss: 0.2995\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0218\tTop_Loss: 0.1136\tBottom_Loss: 0.0755\tLoss: 0.2109\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0171\tTop_Loss: 0.1092\tBottom_Loss: 0.0515\tLoss: 0.1778\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0265\tTop_Loss: 0.1008\tBottom_Loss: 0.0576\tLoss: 0.1848\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0509\tTop_Loss: 0.1395\tBottom_Loss: 0.0648\tLoss: 0.2552\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0127\tTop_Loss: 0.0503\tBottom_Loss: 0.0299\tLoss: 0.0928\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0723\tTop_Loss: 0.1919\tBottom_Loss: 0.1193\tLoss: 0.3834\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0171\tTop_Loss: 0.0668\tBottom_Loss: 0.0516\tLoss: 0.1355\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0265\tTop_Loss: 0.0778\tBottom_Loss: 0.0779\tLoss: 0.1822\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0431\tTop_Loss: 0.1511\tBottom_Loss: 0.1335\tLoss: 0.3277\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0557\tTop_Loss: 0.2141\tBottom_Loss: 0.0737\tLoss: 0.3435\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0134\tTop_Loss: 0.0717\tBottom_Loss: 0.0484\tLoss: 0.1335\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0442\tTop_Loss: 0.0904\tBottom_Loss: 0.1075\tLoss: 0.2420\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0669\tTop_Loss: 0.1773\tBottom_Loss: 0.1717\tLoss: 0.4159\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0228\tTop_Loss: 0.1006\tBottom_Loss: 0.0550\tLoss: 0.1785\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0117\tTop_Loss: 0.0676\tBottom_Loss: 0.0291\tLoss: 0.1084\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0094\tTop_Loss: 0.0498\tBottom_Loss: 0.0418\tLoss: 0.1010\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0105\tTop_Loss: 0.0417\tBottom_Loss: 0.0505\tLoss: 0.1026\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0365\tTop_Loss: 0.1034\tBottom_Loss: 0.0900\tLoss: 0.2299\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0445\tTop_Loss: 0.1209\tBottom_Loss: 0.0506\tLoss: 0.2160\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0075\tTop_Loss: 0.0827\tBottom_Loss: 0.0204\tLoss: 0.1106\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0075\tTop_Loss: 0.0532\tBottom_Loss: 0.0295\tLoss: 0.0901\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0164\tTop_Loss: 0.0686\tBottom_Loss: 0.0551\tLoss: 0.1401\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0943\tTop_Loss: 0.1637\tBottom_Loss: 0.1079\tLoss: 0.3659\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0138\tTop_Loss: 0.0379\tBottom_Loss: 0.0649\tLoss: 0.1167\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0176\tTop_Loss: 0.0581\tBottom_Loss: 0.0610\tLoss: 0.1368\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0108\tTop_Loss: 0.0456\tBottom_Loss: 0.0472\tLoss: 0.1035\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0269\tTop_Loss: 0.0890\tBottom_Loss: 0.0602\tLoss: 0.1762\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0214\tTop_Loss: 0.0790\tBottom_Loss: 0.0391\tLoss: 0.1395\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0671\tTop_Loss: 0.1268\tBottom_Loss: 0.1170\tLoss: 0.3109\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0283\tTop_Loss: 0.0477\tBottom_Loss: 0.1039\tLoss: 0.1799\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0354\tTop_Loss: 0.0777\tBottom_Loss: 0.0498\tLoss: 0.1630\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0053\tTop_Loss: 0.0385\tBottom_Loss: 0.0226\tLoss: 0.0664\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0134\tTop_Loss: 0.0457\tBottom_Loss: 0.0503\tLoss: 0.1094\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0157\tTop_Loss: 0.0330\tBottom_Loss: 0.0916\tLoss: 0.1403\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0584\tTop_Loss: 0.1026\tBottom_Loss: 0.0579\tLoss: 0.2190\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1841\tTop_Loss: 0.1191\tBottom_Loss: 0.2087\tLoss: 0.5120\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0084\tTop_Loss: 0.0274\tBottom_Loss: 0.0327\tLoss: 0.0685\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0553\tTop_Loss: 0.1563\tBottom_Loss: 0.0701\tLoss: 0.2817\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0183\tTop_Loss: 0.0373\tBottom_Loss: 0.0690\tLoss: 0.1246\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0333\tTop_Loss: 0.1332\tBottom_Loss: 0.0517\tLoss: 0.2181\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0073\tTop_Loss: 0.0385\tBottom_Loss: 0.0210\tLoss: 0.0668\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0461\tTop_Loss: 0.1112\tBottom_Loss: 0.0614\tLoss: 0.2187\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0247\tTop_Loss: 0.0638\tBottom_Loss: 0.0575\tLoss: 0.1460\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0272\tTop_Loss: 0.0636\tBottom_Loss: 0.0826\tLoss: 0.1734\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 0.938\tLabel_Loss: 0.0939\tTop_Loss: 0.2250\tBottom_Loss: 0.0731\tLoss: 0.3920\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0054\tTop_Loss: 0.0585\tBottom_Loss: 0.0171\tLoss: 0.0809\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0165\tTop_Loss: 0.0375\tBottom_Loss: 0.0488\tLoss: 0.1028\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0598\tTop_Loss: 0.0873\tBottom_Loss: 0.1149\tLoss: 0.2620\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0057\tTop_Loss: 0.0527\tBottom_Loss: 0.0591\tLoss: 0.1175\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0035\tTop_Loss: 0.0290\tBottom_Loss: 0.0129\tLoss: 0.0454\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0093\tTop_Loss: 0.0373\tBottom_Loss: 0.0152\tLoss: 0.0617\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0055\tTop_Loss: 0.0258\tBottom_Loss: 0.0200\tLoss: 0.0513\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0139\tTop_Loss: 0.0486\tBottom_Loss: 0.0520\tLoss: 0.1144\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0095\tTop_Loss: 0.0294\tBottom_Loss: 0.0240\tLoss: 0.0628\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0099\tTop_Loss: 0.0565\tBottom_Loss: 0.0195\tLoss: 0.0858\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0062\tTop_Loss: 0.0280\tBottom_Loss: 0.0245\tLoss: 0.0587\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0432\tTop_Loss: 0.1108\tBottom_Loss: 0.0618\tLoss: 0.2158\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0062\tTop_Loss: 0.0239\tBottom_Loss: 0.0261\tLoss: 0.0561\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0110\tTop_Loss: 0.0253\tBottom_Loss: 0.0727\tLoss: 0.1090\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0084\tTop_Loss: 0.0421\tBottom_Loss: 0.0530\tLoss: 0.1034\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0071\tTop_Loss: 0.0145\tBottom_Loss: 0.0370\tLoss: 0.0586\t\n",
      "Subject: 036, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.375\tLabel_Loss: 1.4049\tTop_Loss: 1.9438\tBottom_Loss: 2.2002\tLoss: 5.5489\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.625\tLabel_Loss: 0.9397\tTop_Loss: 1.0699\tBottom_Loss: 0.9084\tLoss: 2.9180\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.500\tLabel_Loss: 0.9599\tTop_Loss: 1.1358\tBottom_Loss: 0.9525\tLoss: 3.0482\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.719\tLabel_Loss: 0.9116\tTop_Loss: 1.1530\tBottom_Loss: 1.0763\tLoss: 3.1409\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.438\tLabel_Loss: 1.0502\tTop_Loss: 1.1029\tBottom_Loss: 1.0282\tLoss: 3.1813\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.719\tLabel_Loss: 0.7851\tTop_Loss: 0.7999\tBottom_Loss: 0.8627\tLoss: 2.4477\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7653\tTop_Loss: 0.8065\tBottom_Loss: 0.8155\tLoss: 2.3873\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.656\tLabel_Loss: 0.8172\tTop_Loss: 0.8446\tBottom_Loss: 0.9185\tLoss: 2.5804\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.500\tLabel_Loss: 0.9749\tTop_Loss: 0.8095\tBottom_Loss: 1.0859\tLoss: 2.8702\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.594\tLabel_Loss: 0.7166\tTop_Loss: 0.7583\tBottom_Loss: 0.9610\tLoss: 2.4359\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.594\tLabel_Loss: 1.0953\tTop_Loss: 0.9637\tBottom_Loss: 0.9607\tLoss: 3.0197\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.562\tLabel_Loss: 0.9198\tTop_Loss: 0.8618\tBottom_Loss: 0.8349\tLoss: 2.6165\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8364\tTop_Loss: 0.8140\tBottom_Loss: 0.7164\tLoss: 2.3669\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.594\tLabel_Loss: 0.9585\tTop_Loss: 0.8835\tBottom_Loss: 0.9863\tLoss: 2.8283\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.656\tLabel_Loss: 0.6777\tTop_Loss: 0.6705\tBottom_Loss: 0.9287\tLoss: 2.2769\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.781\tLabel_Loss: 0.6180\tTop_Loss: 0.7914\tBottom_Loss: 0.6169\tLoss: 2.0263\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8676\tTop_Loss: 0.8196\tBottom_Loss: 1.0042\tLoss: 2.6914\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7461\tTop_Loss: 0.9426\tBottom_Loss: 0.7428\tLoss: 2.4315\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7310\tTop_Loss: 0.6771\tBottom_Loss: 0.8152\tLoss: 2.2233\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5593\tTop_Loss: 0.6301\tBottom_Loss: 0.8287\tLoss: 2.0181\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4939\tTop_Loss: 0.5360\tBottom_Loss: 0.6388\tLoss: 1.6687\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8946\tTop_Loss: 0.7285\tBottom_Loss: 0.8966\tLoss: 2.5197\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.594\tLabel_Loss: 0.6745\tTop_Loss: 0.8040\tBottom_Loss: 0.9303\tLoss: 2.4088\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.688\tLabel_Loss: 0.8704\tTop_Loss: 0.9092\tBottom_Loss: 0.8351\tLoss: 2.6148\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.656\tLabel_Loss: 0.6621\tTop_Loss: 0.7984\tBottom_Loss: 0.7690\tLoss: 2.2295\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7093\tTop_Loss: 0.8246\tBottom_Loss: 0.8048\tLoss: 2.3387\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.625\tLabel_Loss: 0.6378\tTop_Loss: 0.5362\tBottom_Loss: 0.6098\tLoss: 1.7838\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6013\tTop_Loss: 0.7535\tBottom_Loss: 0.6856\tLoss: 2.0404\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6200\tTop_Loss: 0.6483\tBottom_Loss: 0.6021\tLoss: 1.8705\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5653\tTop_Loss: 0.6054\tBottom_Loss: 0.8089\tLoss: 1.9796\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5492\tTop_Loss: 0.7119\tBottom_Loss: 0.6275\tLoss: 1.8885\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5740\tTop_Loss: 0.6056\tBottom_Loss: 0.9143\tLoss: 2.0939\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5699\tTop_Loss: 0.7466\tBottom_Loss: 0.4821\tLoss: 1.7986\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6254\tTop_Loss: 0.6973\tBottom_Loss: 0.7782\tLoss: 2.1010\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5849\tTop_Loss: 0.6332\tBottom_Loss: 0.7147\tLoss: 1.9328\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.562\tLabel_Loss: 0.8827\tTop_Loss: 1.0493\tBottom_Loss: 0.8442\tLoss: 2.7762\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5542\tTop_Loss: 0.5258\tBottom_Loss: 0.7392\tLoss: 1.8191\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6179\tTop_Loss: 0.6597\tBottom_Loss: 0.6739\tLoss: 1.9515\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5581\tTop_Loss: 0.6107\tBottom_Loss: 0.7200\tLoss: 1.8888\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.719\tLabel_Loss: 0.5461\tTop_Loss: 0.7333\tBottom_Loss: 0.6295\tLoss: 1.9088\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5934\tTop_Loss: 0.5458\tBottom_Loss: 0.7734\tLoss: 1.9125\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4700\tTop_Loss: 0.6165\tBottom_Loss: 0.5911\tLoss: 1.6775\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4884\tTop_Loss: 0.6064\tBottom_Loss: 0.6027\tLoss: 1.6975\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3280\tTop_Loss: 0.6303\tBottom_Loss: 0.4749\tLoss: 1.4332\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4318\tTop_Loss: 0.5989\tBottom_Loss: 0.7080\tLoss: 1.7388\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4332\tTop_Loss: 0.6219\tBottom_Loss: 0.5437\tLoss: 1.5988\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3913\tTop_Loss: 0.7127\tBottom_Loss: 0.4807\tLoss: 1.5847\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.875\tLabel_Loss: 0.5349\tTop_Loss: 0.6563\tBottom_Loss: 0.6028\tLoss: 1.7941\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4499\tTop_Loss: 0.7076\tBottom_Loss: 0.6205\tLoss: 1.7780\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4995\tTop_Loss: 0.5513\tBottom_Loss: 0.7256\tLoss: 1.7764\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2293\tTop_Loss: 0.4244\tBottom_Loss: 0.3770\tLoss: 1.0308\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4541\tTop_Loss: 0.5001\tBottom_Loss: 0.4413\tLoss: 1.3955\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.938\tLabel_Loss: 0.3210\tTop_Loss: 0.4650\tBottom_Loss: 0.5034\tLoss: 1.2894\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5639\tTop_Loss: 0.5898\tBottom_Loss: 0.5120\tLoss: 1.6657\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4663\tTop_Loss: 0.4706\tBottom_Loss: 0.4833\tLoss: 1.4202\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3362\tTop_Loss: 0.5162\tBottom_Loss: 0.3909\tLoss: 1.2433\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4592\tTop_Loss: 0.5244\tBottom_Loss: 0.6102\tLoss: 1.5938\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3525\tTop_Loss: 0.3502\tBottom_Loss: 0.6056\tLoss: 1.3083\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.781\tLabel_Loss: 0.3884\tTop_Loss: 0.5162\tBottom_Loss: 0.4653\tLoss: 1.3698\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2465\tTop_Loss: 0.3922\tBottom_Loss: 0.4881\tLoss: 1.1269\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3557\tTop_Loss: 0.5665\tBottom_Loss: 0.2975\tLoss: 1.2197\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5100\tTop_Loss: 0.5536\tBottom_Loss: 0.5008\tLoss: 1.5644\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3242\tTop_Loss: 0.4847\tBottom_Loss: 0.5754\tLoss: 1.3843\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3187\tTop_Loss: 0.3582\tBottom_Loss: 0.4773\tLoss: 1.1542\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3019\tTop_Loss: 0.4357\tBottom_Loss: 0.5501\tLoss: 1.2878\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3965\tTop_Loss: 0.5643\tBottom_Loss: 0.3679\tLoss: 1.3287\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4079\tTop_Loss: 0.5405\tBottom_Loss: 0.4817\tLoss: 1.4301\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4447\tTop_Loss: 0.4397\tBottom_Loss: 0.5502\tLoss: 1.4346\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1793\tTop_Loss: 0.2506\tBottom_Loss: 0.4516\tLoss: 0.8815\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4003\tTop_Loss: 0.4273\tBottom_Loss: 0.3878\tLoss: 1.2155\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1735\tTop_Loss: 0.2782\tBottom_Loss: 0.3556\tLoss: 0.8073\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.750\tLabel_Loss: 0.4460\tTop_Loss: 0.4785\tBottom_Loss: 0.4117\tLoss: 1.3363\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2959\tTop_Loss: 0.2156\tBottom_Loss: 0.5424\tLoss: 1.0539\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2866\tTop_Loss: 0.4886\tBottom_Loss: 0.4672\tLoss: 1.2424\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2954\tTop_Loss: 0.4190\tBottom_Loss: 0.4215\tLoss: 1.1358\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2063\tTop_Loss: 0.3801\tBottom_Loss: 0.3293\tLoss: 0.9158\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2749\tTop_Loss: 0.2911\tBottom_Loss: 0.3571\tLoss: 0.9231\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1643\tTop_Loss: 0.2828\tBottom_Loss: 0.2417\tLoss: 0.6888\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2520\tTop_Loss: 0.4332\tBottom_Loss: 0.3044\tLoss: 0.9896\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2800\tTop_Loss: 0.4054\tBottom_Loss: 0.3889\tLoss: 1.0743\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1603\tTop_Loss: 0.2508\tBottom_Loss: 0.3270\tLoss: 0.7380\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1691\tTop_Loss: 0.2155\tBottom_Loss: 0.2600\tLoss: 0.6446\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1729\tTop_Loss: 0.3115\tBottom_Loss: 0.3658\tLoss: 0.8502\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1939\tTop_Loss: 0.2941\tBottom_Loss: 0.4157\tLoss: 0.9037\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1199\tTop_Loss: 0.2694\tBottom_Loss: 0.2328\tLoss: 0.6221\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2065\tTop_Loss: 0.2830\tBottom_Loss: 0.3074\tLoss: 0.7969\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1916\tTop_Loss: 0.2574\tBottom_Loss: 0.2540\tLoss: 0.7030\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2339\tTop_Loss: 0.3488\tBottom_Loss: 0.2459\tLoss: 0.8286\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1183\tTop_Loss: 0.3062\tBottom_Loss: 0.2289\tLoss: 0.6534\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2688\tTop_Loss: 0.3493\tBottom_Loss: 0.2841\tLoss: 0.9022\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1417\tTop_Loss: 0.3159\tBottom_Loss: 0.2086\tLoss: 0.6662\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1826\tTop_Loss: 0.2891\tBottom_Loss: 0.2872\tLoss: 0.7589\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1445\tTop_Loss: 0.2965\tBottom_Loss: 0.1434\tLoss: 0.5845\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2171\tTop_Loss: 0.4070\tBottom_Loss: 0.3410\tLoss: 0.9651\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1673\tTop_Loss: 0.2262\tBottom_Loss: 0.2930\tLoss: 0.6865\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1139\tTop_Loss: 0.2824\tBottom_Loss: 0.1653\tLoss: 0.5616\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1817\tTop_Loss: 0.1986\tBottom_Loss: 0.2566\tLoss: 0.6368\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1259\tTop_Loss: 0.1782\tBottom_Loss: 0.1789\tLoss: 0.4830\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1874\tTop_Loss: 0.2822\tBottom_Loss: 0.2930\tLoss: 0.7626\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0918\tTop_Loss: 0.2519\tBottom_Loss: 0.1695\tLoss: 0.5133\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0975\tTop_Loss: 0.2518\tBottom_Loss: 0.1685\tLoss: 0.5178\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0684\tTop_Loss: 0.0878\tBottom_Loss: 0.2074\tLoss: 0.3636\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1929\tTop_Loss: 0.4145\tBottom_Loss: 0.2661\tLoss: 0.8735\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0533\tTop_Loss: 0.2043\tBottom_Loss: 0.2000\tLoss: 0.4576\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2752\tTop_Loss: 0.4050\tBottom_Loss: 0.3024\tLoss: 0.9826\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2002\tTop_Loss: 0.2921\tBottom_Loss: 0.3137\tLoss: 0.8059\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1042\tTop_Loss: 0.2523\tBottom_Loss: 0.1797\tLoss: 0.5362\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1421\tTop_Loss: 0.2157\tBottom_Loss: 0.2196\tLoss: 0.5775\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2035\tTop_Loss: 0.2484\tBottom_Loss: 0.2496\tLoss: 0.7014\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1031\tTop_Loss: 0.2338\tBottom_Loss: 0.1863\tLoss: 0.5232\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0839\tTop_Loss: 0.1645\tBottom_Loss: 0.2318\tLoss: 0.4802\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1385\tTop_Loss: 0.1891\tBottom_Loss: 0.3079\tLoss: 0.6356\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1684\tTop_Loss: 0.2896\tBottom_Loss: 0.2037\tLoss: 0.6617\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0464\tTop_Loss: 0.0870\tBottom_Loss: 0.1502\tLoss: 0.2835\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 0.875\tLabel_Loss: 0.1811\tTop_Loss: 0.3591\tBottom_Loss: 0.2983\tLoss: 0.8384\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0688\tTop_Loss: 0.1584\tBottom_Loss: 0.1304\tLoss: 0.3577\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0609\tTop_Loss: 0.1209\tBottom_Loss: 0.1171\tLoss: 0.2989\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[58][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1513\tTop_Loss: 0.1804\tBottom_Loss: 0.2101\tLoss: 0.5418\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1529\tTop_Loss: 0.2042\tBottom_Loss: 0.1838\tLoss: 0.5409\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0573\tTop_Loss: 0.1422\tBottom_Loss: 0.0854\tLoss: 0.2850\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0867\tTop_Loss: 0.1744\tBottom_Loss: 0.1808\tLoss: 0.4418\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0384\tTop_Loss: 0.0882\tBottom_Loss: 0.1373\tLoss: 0.2639\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0805\tTop_Loss: 0.1313\tBottom_Loss: 0.1492\tLoss: 0.3610\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0914\tTop_Loss: 0.1261\tBottom_Loss: 0.1218\tLoss: 0.3393\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0512\tTop_Loss: 0.1119\tBottom_Loss: 0.1134\tLoss: 0.2766\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0463\tTop_Loss: 0.1405\tBottom_Loss: 0.0968\tLoss: 0.2836\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1301\tTop_Loss: 0.1538\tBottom_Loss: 0.2480\tLoss: 0.5319\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1279\tTop_Loss: 0.1930\tBottom_Loss: 0.1933\tLoss: 0.5142\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0287\tTop_Loss: 0.1186\tBottom_Loss: 0.0525\tLoss: 0.1997\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0806\tTop_Loss: 0.1312\tBottom_Loss: 0.2124\tLoss: 0.4243\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0399\tTop_Loss: 0.1062\tBottom_Loss: 0.1455\tLoss: 0.2915\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1257\tTop_Loss: 0.1733\tBottom_Loss: 0.0836\tLoss: 0.3826\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0849\tTop_Loss: 0.1190\tBottom_Loss: 0.0822\tLoss: 0.2861\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0406\tTop_Loss: 0.1333\tBottom_Loss: 0.0811\tLoss: 0.2550\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0602\tTop_Loss: 0.0913\tBottom_Loss: 0.1963\tLoss: 0.3479\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0345\tTop_Loss: 0.0762\tBottom_Loss: 0.0973\tLoss: 0.2081\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0294\tTop_Loss: 0.0760\tBottom_Loss: 0.0518\tLoss: 0.1571\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0488\tTop_Loss: 0.1210\tBottom_Loss: 0.0890\tLoss: 0.2589\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1147\tTop_Loss: 0.1494\tBottom_Loss: 0.3039\tLoss: 0.5680\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0278\tTop_Loss: 0.0538\tBottom_Loss: 0.0555\tLoss: 0.1371\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0918\tTop_Loss: 0.2088\tBottom_Loss: 0.1988\tLoss: 0.4994\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0197\tTop_Loss: 0.1328\tBottom_Loss: 0.0508\tLoss: 0.2033\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0653\tTop_Loss: 0.1639\tBottom_Loss: 0.0904\tLoss: 0.3195\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0277\tTop_Loss: 0.1084\tBottom_Loss: 0.0701\tLoss: 0.2062\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0432\tTop_Loss: 0.0880\tBottom_Loss: 0.0992\tLoss: 0.2303\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0899\tTop_Loss: 0.2541\tBottom_Loss: 0.0892\tLoss: 0.4332\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0568\tTop_Loss: 0.0828\tBottom_Loss: 0.1657\tLoss: 0.3053\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0255\tTop_Loss: 0.1073\tBottom_Loss: 0.0408\tLoss: 0.1737\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0267\tTop_Loss: 0.0876\tBottom_Loss: 0.0811\tLoss: 0.1954\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0604\tTop_Loss: 0.1229\tBottom_Loss: 0.0748\tLoss: 0.2580\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0210\tTop_Loss: 0.0671\tBottom_Loss: 0.0624\tLoss: 0.1505\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0197\tTop_Loss: 0.0640\tBottom_Loss: 0.0614\tLoss: 0.1452\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0211\tTop_Loss: 0.0598\tBottom_Loss: 0.1290\tLoss: 0.2099\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0200\tTop_Loss: 0.0565\tBottom_Loss: 0.0740\tLoss: 0.1505\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0503\tTop_Loss: 0.1102\tBottom_Loss: 0.1033\tLoss: 0.2639\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0648\tTop_Loss: 0.1640\tBottom_Loss: 0.0977\tLoss: 0.3265\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0304\tTop_Loss: 0.0681\tBottom_Loss: 0.1278\tLoss: 0.2262\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0322\tTop_Loss: 0.0720\tBottom_Loss: 0.0513\tLoss: 0.1554\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1157\tTop_Loss: 0.1221\tBottom_Loss: 0.1058\tLoss: 0.3436\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0203\tTop_Loss: 0.0319\tBottom_Loss: 0.0785\tLoss: 0.1307\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0540\tTop_Loss: 0.1160\tBottom_Loss: 0.1255\tLoss: 0.2954\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0242\tTop_Loss: 0.0849\tBottom_Loss: 0.0945\tLoss: 0.2036\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0231\tTop_Loss: 0.0377\tBottom_Loss: 0.1012\tLoss: 0.1621\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0371\tTop_Loss: 0.0613\tBottom_Loss: 0.1064\tLoss: 0.2048\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0335\tTop_Loss: 0.0763\tBottom_Loss: 0.0608\tLoss: 0.1707\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0325\tTop_Loss: 0.0649\tBottom_Loss: 0.0445\tLoss: 0.1419\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0219\tTop_Loss: 0.0497\tBottom_Loss: 0.0376\tLoss: 0.1092\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0237\tTop_Loss: 0.0711\tBottom_Loss: 0.0595\tLoss: 0.1543\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0278\tTop_Loss: 0.0379\tBottom_Loss: 0.0940\tLoss: 0.1597\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0837\tTop_Loss: 0.0958\tBottom_Loss: 0.0759\tLoss: 0.2553\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0155\tTop_Loss: 0.0547\tBottom_Loss: 0.0304\tLoss: 0.1007\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0278\tTop_Loss: 0.1182\tBottom_Loss: 0.0825\tLoss: 0.2285\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0167\tTop_Loss: 0.0502\tBottom_Loss: 0.0782\tLoss: 0.1451\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0166\tTop_Loss: 0.1013\tBottom_Loss: 0.0353\tLoss: 0.1532\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0141\tTop_Loss: 0.0319\tBottom_Loss: 0.0468\tLoss: 0.0927\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0371\tTop_Loss: 0.1641\tBottom_Loss: 0.0769\tLoss: 0.2782\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0166\tTop_Loss: 0.0258\tBottom_Loss: 0.0744\tLoss: 0.1168\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0099\tTop_Loss: 0.0498\tBottom_Loss: 0.0457\tLoss: 0.1054\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0134\tTop_Loss: 0.0393\tBottom_Loss: 0.0356\tLoss: 0.0884\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0181\tTop_Loss: 0.0593\tBottom_Loss: 0.0418\tLoss: 0.1192\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0193\tTop_Loss: 0.0887\tBottom_Loss: 0.0315\tLoss: 0.1395\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0093\tTop_Loss: 0.0282\tBottom_Loss: 0.0237\tLoss: 0.0612\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0193\tTop_Loss: 0.0334\tBottom_Loss: 0.1035\tLoss: 0.1563\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0183\tTop_Loss: 0.0294\tBottom_Loss: 0.0586\tLoss: 0.1064\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0290\tTop_Loss: 0.0355\tBottom_Loss: 0.0388\tLoss: 0.1033\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0118\tTop_Loss: 0.0399\tBottom_Loss: 0.0264\tLoss: 0.0781\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0651\tTop_Loss: 0.1215\tBottom_Loss: 0.0642\tLoss: 0.2508\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0126\tTop_Loss: 0.0389\tBottom_Loss: 0.0519\tLoss: 0.1034\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0447\tTop_Loss: 0.1016\tBottom_Loss: 0.0551\tLoss: 0.2014\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0076\tTop_Loss: 0.0484\tBottom_Loss: 0.0296\tLoss: 0.0856\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0282\tTop_Loss: 0.0328\tBottom_Loss: 0.0929\tLoss: 0.1539\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0274\tTop_Loss: 0.0802\tBottom_Loss: 0.0668\tLoss: 0.1744\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0387\tTop_Loss: 0.1148\tBottom_Loss: 0.0565\tLoss: 0.2100\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0075\tTop_Loss: 0.0215\tBottom_Loss: 0.0233\tLoss: 0.0523\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0145\tTop_Loss: 0.0367\tBottom_Loss: 0.0238\tLoss: 0.0751\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0133\tTop_Loss: 0.0223\tBottom_Loss: 0.0501\tLoss: 0.0857\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0104\tTop_Loss: 0.0357\tBottom_Loss: 0.0276\tLoss: 0.0737\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0061\tTop_Loss: 0.0176\tBottom_Loss: 0.0159\tLoss: 0.0396\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0110\tTop_Loss: 0.0454\tBottom_Loss: 0.0173\tLoss: 0.0737\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0127\tTop_Loss: 0.0235\tBottom_Loss: 0.0574\tLoss: 0.0936\t\n",
      "Subject: 037, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.312\tLabel_Loss: 1.3891\tTop_Loss: 1.0144\tBottom_Loss: 1.2746\tLoss: 3.6781\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.188\tLabel_Loss: 1.2661\tTop_Loss: 1.1135\tBottom_Loss: 1.2824\tLoss: 3.6620\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.562\tLabel_Loss: 1.1300\tTop_Loss: 1.1045\tBottom_Loss: 1.0037\tLoss: 3.2382\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8742\tTop_Loss: 1.1380\tBottom_Loss: 1.0410\tLoss: 3.0532\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.500\tLabel_Loss: 0.9703\tTop_Loss: 0.9753\tBottom_Loss: 0.9896\tLoss: 2.9352\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7995\tTop_Loss: 0.8692\tBottom_Loss: 0.8155\tLoss: 2.4842\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.500\tLabel_Loss: 0.8355\tTop_Loss: 0.9818\tBottom_Loss: 0.9810\tLoss: 2.7983\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.438\tLabel_Loss: 1.0831\tTop_Loss: 1.0985\tBottom_Loss: 1.1805\tLoss: 3.3621\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7859\tTop_Loss: 0.7921\tBottom_Loss: 0.7084\tLoss: 2.2864\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.500\tLabel_Loss: 1.0896\tTop_Loss: 1.2039\tBottom_Loss: 1.1188\tLoss: 3.4123\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.469\tLabel_Loss: 0.8942\tTop_Loss: 1.0962\tBottom_Loss: 0.9846\tLoss: 2.9749\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.562\tLabel_Loss: 0.9689\tTop_Loss: 1.0071\tBottom_Loss: 1.0091\tLoss: 2.9851\t\n",
      "Subject: 04, n=02 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.531\tLabel_Loss: 0.8425\tTop_Loss: 0.9451\tBottom_Loss: 1.1452\tLoss: 2.9329\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.594\tLabel_Loss: 0.7915\tTop_Loss: 0.8571\tBottom_Loss: 0.9156\tLoss: 2.5643\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.469\tLabel_Loss: 0.9760\tTop_Loss: 0.7490\tBottom_Loss: 0.9051\tLoss: 2.6301\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7792\tTop_Loss: 0.8498\tBottom_Loss: 0.7118\tLoss: 2.3407\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7017\tTop_Loss: 0.8579\tBottom_Loss: 0.6928\tLoss: 2.2523\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8183\tTop_Loss: 0.9301\tBottom_Loss: 0.9255\tLoss: 2.6739\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.531\tLabel_Loss: 0.9775\tTop_Loss: 1.1039\tBottom_Loss: 0.9577\tLoss: 3.0391\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6952\tTop_Loss: 0.7468\tBottom_Loss: 0.7173\tLoss: 2.1593\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.531\tLabel_Loss: 0.9880\tTop_Loss: 1.0183\tBottom_Loss: 0.9654\tLoss: 2.9718\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8690\tTop_Loss: 1.0609\tBottom_Loss: 0.7749\tLoss: 2.7048\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7551\tTop_Loss: 0.7473\tBottom_Loss: 0.9632\tLoss: 2.4656\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8087\tTop_Loss: 0.8508\tBottom_Loss: 0.9184\tLoss: 2.5779\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6515\tTop_Loss: 0.6701\tBottom_Loss: 0.8219\tLoss: 2.1435\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6018\tTop_Loss: 0.8261\tBottom_Loss: 0.6852\tLoss: 2.1131\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.781\tLabel_Loss: 0.6247\tTop_Loss: 0.7677\tBottom_Loss: 0.8571\tLoss: 2.2495\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6196\tTop_Loss: 0.7388\tBottom_Loss: 0.8006\tLoss: 2.1590\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8696\tTop_Loss: 0.7543\tBottom_Loss: 0.9574\tLoss: 2.5813\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6154\tTop_Loss: 0.8398\tBottom_Loss: 0.6868\tLoss: 2.1421\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5911\tTop_Loss: 0.6503\tBottom_Loss: 0.8997\tLoss: 2.1411\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6928\tTop_Loss: 0.7632\tBottom_Loss: 0.7866\tLoss: 2.2427\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4439\tTop_Loss: 0.5240\tBottom_Loss: 0.4838\tLoss: 1.4516\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.594\tLabel_Loss: 0.6981\tTop_Loss: 0.8428\tBottom_Loss: 0.6235\tLoss: 2.1644\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4173\tTop_Loss: 0.6776\tBottom_Loss: 0.5013\tLoss: 1.5962\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4156\tTop_Loss: 0.5663\tBottom_Loss: 0.3990\tLoss: 1.3810\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5677\tTop_Loss: 0.5486\tBottom_Loss: 0.7065\tLoss: 1.8228\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5452\tTop_Loss: 0.7400\tBottom_Loss: 0.5511\tLoss: 1.8363\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4504\tTop_Loss: 0.6335\tBottom_Loss: 0.6865\tLoss: 1.7704\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4442\tTop_Loss: 0.5955\tBottom_Loss: 0.6239\tLoss: 1.6636\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4798\tTop_Loss: 0.7571\tBottom_Loss: 0.6002\tLoss: 1.8372\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5076\tTop_Loss: 0.6380\tBottom_Loss: 0.5468\tLoss: 1.6924\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5860\tTop_Loss: 0.6250\tBottom_Loss: 0.5993\tLoss: 1.8103\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2558\tTop_Loss: 0.3927\tBottom_Loss: 0.3886\tLoss: 1.0371\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4924\tTop_Loss: 0.6558\tBottom_Loss: 0.5824\tLoss: 1.7307\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3907\tTop_Loss: 0.6542\tBottom_Loss: 0.4251\tLoss: 1.4700\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4249\tTop_Loss: 0.7145\tBottom_Loss: 0.5078\tLoss: 1.6471\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4717\tTop_Loss: 0.6387\tBottom_Loss: 0.5615\tLoss: 1.6719\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5277\tTop_Loss: 0.4176\tBottom_Loss: 0.7111\tLoss: 1.6563\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3145\tTop_Loss: 0.6650\tBottom_Loss: 0.4226\tLoss: 1.4021\t\n",
      "Subject: 04, n=02 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3238\tTop_Loss: 0.5925\tBottom_Loss: 0.4190\tLoss: 1.3353\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4290\tTop_Loss: 0.5605\tBottom_Loss: 0.4585\tLoss: 1.4480\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3862\tTop_Loss: 0.5205\tBottom_Loss: 0.4761\tLoss: 1.3828\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4267\tTop_Loss: 0.5701\tBottom_Loss: 0.6069\tLoss: 1.6037\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3668\tTop_Loss: 0.4630\tBottom_Loss: 0.4173\tLoss: 1.2470\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3468\tTop_Loss: 0.5192\tBottom_Loss: 0.5410\tLoss: 1.4069\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4720\tTop_Loss: 0.6918\tBottom_Loss: 0.4560\tLoss: 1.6198\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2350\tTop_Loss: 0.4138\tBottom_Loss: 0.3602\tLoss: 1.0089\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.938\tLabel_Loss: 0.3237\tTop_Loss: 0.5943\tBottom_Loss: 0.4214\tLoss: 1.3395\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4164\tTop_Loss: 0.6521\tBottom_Loss: 0.5041\tLoss: 1.5727\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.844\tLabel_Loss: 0.2985\tTop_Loss: 0.4198\tBottom_Loss: 0.4763\tLoss: 1.1946\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3328\tTop_Loss: 0.5197\tBottom_Loss: 0.4692\tLoss: 1.3217\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3798\tTop_Loss: 0.6308\tBottom_Loss: 0.5383\tLoss: 1.5489\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3762\tTop_Loss: 0.4674\tBottom_Loss: 0.5247\tLoss: 1.3683\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2377\tTop_Loss: 0.3533\tBottom_Loss: 0.4034\tLoss: 0.9944\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.938\tLabel_Loss: 0.3278\tTop_Loss: 0.5274\tBottom_Loss: 0.3497\tLoss: 1.2049\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2834\tTop_Loss: 0.4877\tBottom_Loss: 0.3597\tLoss: 1.1309\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2963\tTop_Loss: 0.4021\tBottom_Loss: 0.3416\tLoss: 1.0400\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2169\tTop_Loss: 0.4130\tBottom_Loss: 0.3179\tLoss: 0.9478\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2018\tTop_Loss: 0.3236\tBottom_Loss: 0.3358\tLoss: 0.8612\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1808\tTop_Loss: 0.3255\tBottom_Loss: 0.2329\tLoss: 0.7392\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2194\tTop_Loss: 0.5549\tBottom_Loss: 0.1813\tLoss: 0.9556\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2993\tTop_Loss: 0.5301\tBottom_Loss: 0.3665\tLoss: 1.1960\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.812\tLabel_Loss: 0.2504\tTop_Loss: 0.4077\tBottom_Loss: 0.2843\tLoss: 0.9424\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1836\tTop_Loss: 0.3643\tBottom_Loss: 0.2690\tLoss: 0.8169\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1851\tTop_Loss: 0.2686\tBottom_Loss: 0.3670\tLoss: 0.8208\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1953\tTop_Loss: 0.5339\tBottom_Loss: 0.2147\tLoss: 0.9439\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2929\tTop_Loss: 0.4339\tBottom_Loss: 0.3907\tLoss: 1.1176\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2129\tTop_Loss: 0.3905\tBottom_Loss: 0.2834\tLoss: 0.8868\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1862\tTop_Loss: 0.3116\tBottom_Loss: 0.1980\tLoss: 0.6958\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2305\tTop_Loss: 0.3852\tBottom_Loss: 0.2652\tLoss: 0.8810\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3618\tTop_Loss: 0.4855\tBottom_Loss: 0.3497\tLoss: 1.1969\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1823\tTop_Loss: 0.3833\tBottom_Loss: 0.2556\tLoss: 0.8211\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1763\tTop_Loss: 0.2595\tBottom_Loss: 0.1536\tLoss: 0.5893\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1891\tTop_Loss: 0.3603\tBottom_Loss: 0.3624\tLoss: 0.9118\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1935\tTop_Loss: 0.4099\tBottom_Loss: 0.1897\tLoss: 0.7930\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1706\tTop_Loss: 0.4519\tBottom_Loss: 0.1649\tLoss: 0.7874\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2144\tTop_Loss: 0.3582\tBottom_Loss: 0.3699\tLoss: 0.9425\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2570\tTop_Loss: 0.3738\tBottom_Loss: 0.2383\tLoss: 0.8691\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1205\tTop_Loss: 0.1972\tBottom_Loss: 0.1841\tLoss: 0.5018\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2086\tTop_Loss: 0.4190\tBottom_Loss: 0.2445\tLoss: 0.8722\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1248\tTop_Loss: 0.2670\tBottom_Loss: 0.1582\tLoss: 0.5501\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2128\tTop_Loss: 0.2943\tBottom_Loss: 0.2376\tLoss: 0.7447\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1391\tTop_Loss: 0.3418\tBottom_Loss: 0.2757\tLoss: 0.7566\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0504\tTop_Loss: 0.2059\tBottom_Loss: 0.0773\tLoss: 0.3336\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2294\tTop_Loss: 0.3042\tBottom_Loss: 0.1860\tLoss: 0.7196\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2064\tTop_Loss: 0.4229\tBottom_Loss: 0.3341\tLoss: 0.9633\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0896\tTop_Loss: 0.1754\tBottom_Loss: 0.1970\tLoss: 0.4620\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1215\tTop_Loss: 0.2803\tBottom_Loss: 0.1954\tLoss: 0.5972\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1589\tTop_Loss: 0.2296\tBottom_Loss: 0.2323\tLoss: 0.6208\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0869\tTop_Loss: 0.2897\tBottom_Loss: 0.0993\tLoss: 0.4759\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1162\tTop_Loss: 0.2404\tBottom_Loss: 0.2176\tLoss: 0.5743\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0784\tTop_Loss: 0.2399\tBottom_Loss: 0.0900\tLoss: 0.4083\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1386\tTop_Loss: 0.3268\tBottom_Loss: 0.1980\tLoss: 0.6633\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1285\tTop_Loss: 0.2507\tBottom_Loss: 0.2541\tLoss: 0.6333\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0985\tTop_Loss: 0.2942\tBottom_Loss: 0.1427\tLoss: 0.5354\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1009\tTop_Loss: 0.1840\tBottom_Loss: 0.2172\tLoss: 0.5020\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1131\tTop_Loss: 0.2825\tBottom_Loss: 0.1655\tLoss: 0.5612\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1675\tTop_Loss: 0.2275\tBottom_Loss: 0.3862\tLoss: 0.7813\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0992\tTop_Loss: 0.1963\tBottom_Loss: 0.1401\tLoss: 0.4356\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0527\tTop_Loss: 0.2481\tBottom_Loss: 0.1464\tLoss: 0.4471\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0632\tTop_Loss: 0.1129\tBottom_Loss: 0.1266\tLoss: 0.3027\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1106\tTop_Loss: 0.1523\tBottom_Loss: 0.2192\tLoss: 0.4821\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1519\tTop_Loss: 0.2375\tBottom_Loss: 0.1915\tLoss: 0.5809\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0825\tTop_Loss: 0.1970\tBottom_Loss: 0.1951\tLoss: 0.4746\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1451\tTop_Loss: 0.2904\tBottom_Loss: 0.2245\tLoss: 0.6600\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0853\tTop_Loss: 0.2630\tBottom_Loss: 0.2131\tLoss: 0.5615\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1144\tTop_Loss: 0.1690\tBottom_Loss: 0.1019\tLoss: 0.3853\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0724\tTop_Loss: 0.2296\tBottom_Loss: 0.1463\tLoss: 0.4483\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0873\tTop_Loss: 0.1923\tBottom_Loss: 0.1306\tLoss: 0.4102\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0469\tTop_Loss: 0.1509\tBottom_Loss: 0.0871\tLoss: 0.2849\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0973\tTop_Loss: 0.2069\tBottom_Loss: 0.1626\tLoss: 0.4668\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1601\tTop_Loss: 0.2095\tBottom_Loss: 0.2140\tLoss: 0.5836\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0996\tTop_Loss: 0.2094\tBottom_Loss: 0.2063\tLoss: 0.5153\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0532\tTop_Loss: 0.1416\tBottom_Loss: 0.1371\tLoss: 0.3320\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0422\tTop_Loss: 0.1766\tBottom_Loss: 0.0606\tLoss: 0.2794\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0580\tTop_Loss: 0.1202\tBottom_Loss: 0.0867\tLoss: 0.2649\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0978\tTop_Loss: 0.2184\tBottom_Loss: 0.1997\tLoss: 0.5159\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0462\tTop_Loss: 0.2466\tBottom_Loss: 0.0483\tLoss: 0.3411\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1100\tTop_Loss: 0.1121\tBottom_Loss: 0.1155\tLoss: 0.3377\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0701\tTop_Loss: 0.1441\tBottom_Loss: 0.1412\tLoss: 0.3554\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0645\tTop_Loss: 0.2017\tBottom_Loss: 0.1301\tLoss: 0.3964\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0595\tTop_Loss: 0.1472\tBottom_Loss: 0.0959\tLoss: 0.3025\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0376\tTop_Loss: 0.1339\tBottom_Loss: 0.0357\tLoss: 0.2072\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0573\tTop_Loss: 0.1405\tBottom_Loss: 0.0920\tLoss: 0.2897\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0660\tTop_Loss: 0.1564\tBottom_Loss: 0.1227\tLoss: 0.3452\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0688\tTop_Loss: 0.1788\tBottom_Loss: 0.0989\tLoss: 0.3464\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0463\tTop_Loss: 0.0926\tBottom_Loss: 0.0621\tLoss: 0.2010\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0249\tTop_Loss: 0.0953\tBottom_Loss: 0.0583\tLoss: 0.1784\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0695\tTop_Loss: 0.1658\tBottom_Loss: 0.0785\tLoss: 0.3137\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0254\tTop_Loss: 0.0815\tBottom_Loss: 0.0228\tLoss: 0.1296\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0225\tTop_Loss: 0.0741\tBottom_Loss: 0.0473\tLoss: 0.1439\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0481\tTop_Loss: 0.1389\tBottom_Loss: 0.1185\tLoss: 0.3055\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0325\tTop_Loss: 0.1357\tBottom_Loss: 0.0535\tLoss: 0.2217\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0490\tTop_Loss: 0.1826\tBottom_Loss: 0.0700\tLoss: 0.3015\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0185\tTop_Loss: 0.0585\tBottom_Loss: 0.0505\tLoss: 0.1275\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1250\tTop_Loss: 0.2451\tBottom_Loss: 0.1039\tLoss: 0.4739\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0702\tTop_Loss: 0.1395\tBottom_Loss: 0.1335\tLoss: 0.3432\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0400\tTop_Loss: 0.1578\tBottom_Loss: 0.0829\tLoss: 0.2807\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0193\tTop_Loss: 0.0897\tBottom_Loss: 0.0423\tLoss: 0.1512\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0286\tTop_Loss: 0.1331\tBottom_Loss: 0.0346\tLoss: 0.1963\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0610\tTop_Loss: 0.1203\tBottom_Loss: 0.0892\tLoss: 0.2705\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0226\tTop_Loss: 0.1182\tBottom_Loss: 0.0357\tLoss: 0.1765\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0318\tTop_Loss: 0.1407\tBottom_Loss: 0.0551\tLoss: 0.2276\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1121\tTop_Loss: 0.1753\tBottom_Loss: 0.1724\tLoss: 0.4598\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0269\tTop_Loss: 0.1175\tBottom_Loss: 0.0551\tLoss: 0.1995\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0299\tTop_Loss: 0.0954\tBottom_Loss: 0.0672\tLoss: 0.1925\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0328\tTop_Loss: 0.0762\tBottom_Loss: 0.0865\tLoss: 0.1956\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0199\tTop_Loss: 0.0741\tBottom_Loss: 0.0656\tLoss: 0.1596\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0857\tTop_Loss: 0.0879\tBottom_Loss: 0.1188\tLoss: 0.2924\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0163\tTop_Loss: 0.0736\tBottom_Loss: 0.0214\tLoss: 0.1113\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0443\tTop_Loss: 0.1099\tBottom_Loss: 0.0503\tLoss: 0.2045\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0111\tTop_Loss: 0.0680\tBottom_Loss: 0.0355\tLoss: 0.1146\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0929\tTop_Loss: 0.1399\tBottom_Loss: 0.0708\tLoss: 0.3036\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0274\tTop_Loss: 0.0535\tBottom_Loss: 0.0514\tLoss: 0.1322\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0438\tTop_Loss: 0.0630\tBottom_Loss: 0.0844\tLoss: 0.1912\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0130\tTop_Loss: 0.0737\tBottom_Loss: 0.0364\tLoss: 0.1231\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0115\tTop_Loss: 0.0423\tBottom_Loss: 0.0215\tLoss: 0.0753\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0286\tTop_Loss: 0.0842\tBottom_Loss: 0.0617\tLoss: 0.1745\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0374\tTop_Loss: 0.0912\tBottom_Loss: 0.0581\tLoss: 0.1867\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0301\tTop_Loss: 0.1077\tBottom_Loss: 0.0352\tLoss: 0.1731\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0652\tTop_Loss: 0.0742\tBottom_Loss: 0.0953\tLoss: 0.2347\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0305\tTop_Loss: 0.0614\tBottom_Loss: 0.0977\tLoss: 0.1896\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0405\tTop_Loss: 0.0612\tBottom_Loss: 0.0525\tLoss: 0.1542\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0257\tTop_Loss: 0.0445\tBottom_Loss: 0.0446\tLoss: 0.1149\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0753\tTop_Loss: 0.0908\tBottom_Loss: 0.0610\tLoss: 0.2272\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0260\tTop_Loss: 0.0752\tBottom_Loss: 0.0387\tLoss: 0.1398\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0490\tTop_Loss: 0.0545\tBottom_Loss: 0.0755\tLoss: 0.1790\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0642\tTop_Loss: 0.0931\tBottom_Loss: 0.0701\tLoss: 0.2275\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0138\tTop_Loss: 0.0490\tBottom_Loss: 0.0183\tLoss: 0.0811\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0202\tTop_Loss: 0.0807\tBottom_Loss: 0.0440\tLoss: 0.1449\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0166\tTop_Loss: 0.0999\tBottom_Loss: 0.0198\tLoss: 0.1363\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0136\tTop_Loss: 0.0485\tBottom_Loss: 0.0246\tLoss: 0.0867\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0307\tTop_Loss: 0.0437\tBottom_Loss: 0.0818\tLoss: 0.1562\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0371\tTop_Loss: 0.0506\tBottom_Loss: 0.1480\tLoss: 0.2357\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0086\tTop_Loss: 0.0556\tBottom_Loss: 0.0319\tLoss: 0.0962\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0185\tTop_Loss: 0.0568\tBottom_Loss: 0.0496\tLoss: 0.1250\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0111\tTop_Loss: 0.0591\tBottom_Loss: 0.0153\tLoss: 0.0854\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0199\tTop_Loss: 0.0714\tBottom_Loss: 0.0266\tLoss: 0.1180\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0194\tTop_Loss: 0.0650\tBottom_Loss: 0.0146\tLoss: 0.0990\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0198\tTop_Loss: 0.0635\tBottom_Loss: 0.0350\tLoss: 0.1183\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0134\tTop_Loss: 0.0330\tBottom_Loss: 0.0307\tLoss: 0.0770\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0282\tTop_Loss: 0.0919\tBottom_Loss: 0.0720\tLoss: 0.1921\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0175\tTop_Loss: 0.0243\tBottom_Loss: 0.0581\tLoss: 0.0999\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0349\tTop_Loss: 0.1019\tBottom_Loss: 0.0682\tLoss: 0.2049\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0102\tTop_Loss: 0.0292\tBottom_Loss: 0.0078\tLoss: 0.0472\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0119\tTop_Loss: 0.0662\tBottom_Loss: 0.0131\tLoss: 0.0912\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0101\tTop_Loss: 0.0447\tBottom_Loss: 0.0167\tLoss: 0.0715\t\n",
      "Subject: 04, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0129\tTop_Loss: 0.0424\tBottom_Loss: 0.0337\tLoss: 0.0890\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0100\tTop_Loss: 0.0369\tBottom_Loss: 0.0158\tLoss: 0.0626\t\n",
      "Subject: 04, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.469\tLabel_Loss: 1.2390\tTop_Loss: 1.2005\tBottom_Loss: 1.5918\tLoss: 4.0313\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.656\tLabel_Loss: 1.0450\tTop_Loss: 1.1085\tBottom_Loss: 1.2261\tLoss: 3.3797\t\n",
      "Subject: 05, n=06 | test_f1: 0.44444 |best_f1: 0.44444\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.625\tLabel_Loss: 1.0184\tTop_Loss: 1.0291\tBottom_Loss: 1.0664\tLoss: 3.1139\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.500\tLabel_Loss: 0.8918\tTop_Loss: 0.9465\tBottom_Loss: 0.9249\tLoss: 2.7632\t\n",
      "Subject: 05, n=06 | test_f1: 0.6 |best_f1: 0.6\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.281\tLabel_Loss: 1.3032\tTop_Loss: 1.2658\tBottom_Loss: 1.1436\tLoss: 3.7126\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.625\tLabel_Loss: 0.9898\tTop_Loss: 0.9457\tBottom_Loss: 0.8523\tLoss: 2.7878\t\n",
      "Subject: 05, n=06 | test_f1: 0.095238 |best_f1: 0.6\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.500\tLabel_Loss: 0.8870\tTop_Loss: 0.9702\tBottom_Loss: 0.8529\tLoss: 2.7101\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.562\tLabel_Loss: 0.9673\tTop_Loss: 0.9963\tBottom_Loss: 0.9721\tLoss: 2.9358\t\n",
      "Subject: 05, n=06 | test_f1: 0.44444 |best_f1: 0.6\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.469\tLabel_Loss: 1.0238\tTop_Loss: 0.9536\tBottom_Loss: 0.9152\tLoss: 2.8926\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7559\tTop_Loss: 0.8091\tBottom_Loss: 1.0743\tLoss: 2.6393\t\n",
      "Subject: 05, n=06 | test_f1: 0.095238 |best_f1: 0.6\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.688\tLabel_Loss: 0.8186\tTop_Loss: 1.0228\tBottom_Loss: 0.9516\tLoss: 2.7930\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.500\tLabel_Loss: 0.9872\tTop_Loss: 1.0107\tBottom_Loss: 0.8883\tLoss: 2.8862\t\n",
      "Subject: 05, n=06 | test_f1: 0.095238 |best_f1: 0.6\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.625\tLabel_Loss: 0.9307\tTop_Loss: 0.7604\tBottom_Loss: 0.9480\tLoss: 2.6391\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.562\tLabel_Loss: 1.0121\tTop_Loss: 0.9890\tBottom_Loss: 1.0441\tLoss: 3.0452\t\n",
      "Subject: 05, n=06 | test_f1: 0.095238 |best_f1: 0.6\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7744\tTop_Loss: 0.7899\tBottom_Loss: 0.8398\tLoss: 2.4041\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.594\tLabel_Loss: 0.7800\tTop_Loss: 0.7347\tBottom_Loss: 0.7657\tLoss: 2.2804\t\n",
      "Subject: 05, n=06 | test_f1: 0.095238 |best_f1: 0.6\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.594\tLabel_Loss: 0.7883\tTop_Loss: 0.7666\tBottom_Loss: 0.7858\tLoss: 2.3407\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.594\tLabel_Loss: 0.7950\tTop_Loss: 0.8763\tBottom_Loss: 0.8577\tLoss: 2.5290\t\n",
      "Subject: 05, n=06 | test_f1: 0.0 |best_f1: 0.6\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.719\tLabel_Loss: 0.7293\tTop_Loss: 0.7737\tBottom_Loss: 0.6592\tLoss: 2.1622\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.719\tLabel_Loss: 0.7825\tTop_Loss: 0.9577\tBottom_Loss: 0.8456\tLoss: 2.5859\t\n",
      "Subject: 05, n=06 | test_f1: 0.0 |best_f1: 0.6\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.562\tLabel_Loss: 0.7721\tTop_Loss: 0.9569\tBottom_Loss: 0.9859\tLoss: 2.7149\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.750\tLabel_Loss: 0.7623\tTop_Loss: 0.7236\tBottom_Loss: 0.8298\tLoss: 2.3156\t\n",
      "Subject: 05, n=06 | test_f1: 0.44444 |best_f1: 0.6\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.594\tLabel_Loss: 0.7578\tTop_Loss: 0.7898\tBottom_Loss: 0.8539\tLoss: 2.4015\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.531\tLabel_Loss: 1.0589\tTop_Loss: 1.1825\tBottom_Loss: 1.1534\tLoss: 3.3948\t\n",
      "Subject: 05, n=06 | test_f1: 0.13333 |best_f1: 0.6\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.844\tLabel_Loss: 0.5068\tTop_Loss: 0.6028\tBottom_Loss: 0.6853\tLoss: 1.7949\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8079\tTop_Loss: 0.9790\tBottom_Loss: 0.8349\tLoss: 2.6217\t\n",
      "Subject: 05, n=06 | test_f1: 0.13333 |best_f1: 0.6\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7128\tTop_Loss: 0.8881\tBottom_Loss: 0.7922\tLoss: 2.3930\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.719\tLabel_Loss: 0.7466\tTop_Loss: 0.7462\tBottom_Loss: 0.8491\tLoss: 2.3419\t\n",
      "Subject: 05, n=06 | test_f1: 0.095238 |best_f1: 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.719\tLabel_Loss: 0.7685\tTop_Loss: 0.7371\tBottom_Loss: 0.8541\tLoss: 2.3598\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5848\tTop_Loss: 0.7913\tBottom_Loss: 0.7294\tLoss: 2.1056\t\n",
      "Subject: 05, n=06 | test_f1: 0.095238 |best_f1: 0.6\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6353\tTop_Loss: 0.8134\tBottom_Loss: 0.6886\tLoss: 2.1373\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4876\tTop_Loss: 0.6083\tBottom_Loss: 0.6172\tLoss: 1.7131\t\n",
      "Subject: 05, n=06 | test_f1: 0.095238 |best_f1: 0.6\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4289\tTop_Loss: 0.4766\tBottom_Loss: 0.5124\tLoss: 1.4179\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7139\tTop_Loss: 0.6129\tBottom_Loss: 0.7031\tLoss: 2.0299\t\n",
      "Subject: 05, n=06 | test_f1: 0.0 |best_f1: 0.6\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4119\tTop_Loss: 0.6919\tBottom_Loss: 0.4761\tLoss: 1.5799\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6751\tTop_Loss: 0.7023\tBottom_Loss: 0.6184\tLoss: 1.9958\t\n",
      "Subject: 05, n=06 | test_f1: 0.24444 |best_f1: 0.6\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4897\tTop_Loss: 0.5024\tBottom_Loss: 0.6716\tLoss: 1.6637\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4029\tTop_Loss: 0.5064\tBottom_Loss: 0.6865\tLoss: 1.5958\t\n",
      "Subject: 05, n=06 | test_f1: 0.095238 |best_f1: 0.6\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4718\tTop_Loss: 0.7352\tBottom_Loss: 0.6765\tLoss: 1.8835\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5211\tTop_Loss: 0.6743\tBottom_Loss: 0.5535\tLoss: 1.7489\t\n",
      "Subject: 05, n=06 | test_f1: 0.095238 |best_f1: 0.6\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4913\tTop_Loss: 0.7449\tBottom_Loss: 0.5454\tLoss: 1.7815\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.688\tLabel_Loss: 0.5289\tTop_Loss: 0.6353\tBottom_Loss: 0.8151\tLoss: 1.9793\t\n",
      "Subject: 05, n=06 | test_f1: 0.13333 |best_f1: 0.6\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4168\tTop_Loss: 0.6243\tBottom_Loss: 0.4407\tLoss: 1.4818\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3179\tTop_Loss: 0.4086\tBottom_Loss: 0.6117\tLoss: 1.3383\t\n",
      "Subject: 05, n=06 | test_f1: 0.095238 |best_f1: 0.6\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4644\tTop_Loss: 0.6840\tBottom_Loss: 0.4601\tLoss: 1.6084\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3001\tTop_Loss: 0.5334\tBottom_Loss: 0.4019\tLoss: 1.2354\t\n",
      "Subject: 05, n=06 | test_f1: 0.24444 |best_f1: 0.6\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.844\tLabel_Loss: 0.5395\tTop_Loss: 0.6644\tBottom_Loss: 0.6952\tLoss: 1.8991\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3384\tTop_Loss: 0.5223\tBottom_Loss: 0.3567\tLoss: 1.2174\t\n",
      "Subject: 05, n=06 | test_f1: 0.0 |best_f1: 0.6\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.688\tLabel_Loss: 0.5385\tTop_Loss: 0.5933\tBottom_Loss: 0.5280\tLoss: 1.6598\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3466\tTop_Loss: 0.4912\tBottom_Loss: 0.4316\tLoss: 1.2694\t\n",
      "Subject: 05, n=06 | test_f1: 0.0 |best_f1: 0.6\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3299\tTop_Loss: 0.4440\tBottom_Loss: 0.4154\tLoss: 1.1893\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.906\tLabel_Loss: 0.4581\tTop_Loss: 0.5867\tBottom_Loss: 0.4445\tLoss: 1.4893\t\n",
      "Subject: 05, n=06 | test_f1: 0.24444 |best_f1: 0.6\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.844\tLabel_Loss: 0.5619\tTop_Loss: 0.6985\tBottom_Loss: 0.6838\tLoss: 1.9442\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3440\tTop_Loss: 0.7593\tBottom_Loss: 0.3486\tLoss: 1.4519\t\n",
      "Subject: 05, n=06 | test_f1: 0.095238 |best_f1: 0.6\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.719\tLabel_Loss: 0.4935\tTop_Loss: 0.8621\tBottom_Loss: 0.4477\tLoss: 1.8033\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.844\tLabel_Loss: 0.6383\tTop_Loss: 0.6978\tBottom_Loss: 0.5805\tLoss: 1.9166\t\n",
      "Subject: 05, n=06 | test_f1: 0.24444 |best_f1: 0.6\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.844\tLabel_Loss: 0.2929\tTop_Loss: 0.4216\tBottom_Loss: 0.4204\tLoss: 1.1348\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3208\tTop_Loss: 0.4122\tBottom_Loss: 0.4468\tLoss: 1.1798\t\n",
      "Subject: 05, n=06 | test_f1: 0.095238 |best_f1: 0.6\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3107\tTop_Loss: 0.6349\tBottom_Loss: 0.4910\tLoss: 1.4366\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3341\tTop_Loss: 0.4802\tBottom_Loss: 0.5851\tLoss: 1.3994\t\n",
      "Subject: 05, n=06 | test_f1: 0.24444 |best_f1: 0.6\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3642\tTop_Loss: 0.5194\tBottom_Loss: 0.5363\tLoss: 1.4199\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1681\tTop_Loss: 0.3487\tBottom_Loss: 0.3530\tLoss: 0.8698\t\n",
      "Subject: 05, n=06 | test_f1: 0.0 |best_f1: 0.6\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2537\tTop_Loss: 0.4624\tBottom_Loss: 0.2907\tLoss: 1.0068\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3203\tTop_Loss: 0.4728\tBottom_Loss: 0.3242\tLoss: 1.1172\t\n",
      "Subject: 05, n=06 | test_f1: 0.095238 |best_f1: 0.6\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.844\tLabel_Loss: 0.2935\tTop_Loss: 0.5491\tBottom_Loss: 0.3576\tLoss: 1.2002\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2524\tTop_Loss: 0.4279\tBottom_Loss: 0.3091\tLoss: 0.9894\t\n",
      "Subject: 05, n=06 | test_f1: 0.11111 |best_f1: 0.6\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2250\tTop_Loss: 0.3783\tBottom_Loss: 0.3799\tLoss: 0.9832\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2335\tTop_Loss: 0.4213\tBottom_Loss: 0.3206\tLoss: 0.9754\t\n",
      "Subject: 05, n=06 | test_f1: 0.095238 |best_f1: 0.6\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.906\tLabel_Loss: 0.4510\tTop_Loss: 0.6245\tBottom_Loss: 0.5208\tLoss: 1.5963\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.938\tLabel_Loss: 0.3529\tTop_Loss: 0.5776\tBottom_Loss: 0.4122\tLoss: 1.3428\t\n",
      "Subject: 05, n=06 | test_f1: 0.24444 |best_f1: 0.6\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2243\tTop_Loss: 0.3712\tBottom_Loss: 0.3140\tLoss: 0.9096\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1212\tTop_Loss: 0.2912\tBottom_Loss: 0.2205\tLoss: 0.6329\t\n",
      "Subject: 05, n=06 | test_f1: 0.095238 |best_f1: 0.6\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2280\tTop_Loss: 0.4694\tBottom_Loss: 0.3205\tLoss: 1.0178\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1852\tTop_Loss: 0.2132\tBottom_Loss: 0.4459\tLoss: 0.8443\t\n",
      "Subject: 05, n=06 | test_f1: 0.095238 |best_f1: 0.6\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2332\tTop_Loss: 0.4911\tBottom_Loss: 0.3571\tLoss: 1.0814\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3063\tTop_Loss: 0.4433\tBottom_Loss: 0.5046\tLoss: 1.2543\t\n",
      "Subject: 05, n=06 | test_f1: 0.11111 |best_f1: 0.6\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2191\tTop_Loss: 0.4123\tBottom_Loss: 0.3168\tLoss: 0.9482\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2484\tTop_Loss: 0.3474\tBottom_Loss: 0.3576\tLoss: 0.9535\t\n",
      "Subject: 05, n=06 | test_f1: 0.24444 |best_f1: 0.6\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1044\tTop_Loss: 0.3217\tBottom_Loss: 0.2141\tLoss: 0.6401\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1260\tTop_Loss: 0.2722\tBottom_Loss: 0.3588\tLoss: 0.7571\t\n",
      "Subject: 05, n=06 | test_f1: 0.095238 |best_f1: 0.6\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2262\tTop_Loss: 0.2913\tBottom_Loss: 0.2934\tLoss: 0.8109\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1387\tTop_Loss: 0.2864\tBottom_Loss: 0.2310\tLoss: 0.6560\t\n",
      "Subject: 05, n=06 | test_f1: 0.095238 |best_f1: 0.6\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1265\tTop_Loss: 0.3606\tBottom_Loss: 0.2483\tLoss: 0.7354\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2525\tTop_Loss: 0.3675\tBottom_Loss: 0.4424\tLoss: 1.0625\t\n",
      "Subject: 05, n=06 | test_f1: 0.0 |best_f1: 0.6\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1716\tTop_Loss: 0.3528\tBottom_Loss: 0.1996\tLoss: 0.7240\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1909\tTop_Loss: 0.3269\tBottom_Loss: 0.2009\tLoss: 0.7188\t\n",
      "Subject: 05, n=06 | test_f1: 0.24444 |best_f1: 0.6\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0900\tTop_Loss: 0.2667\tBottom_Loss: 0.1286\tLoss: 0.4853\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2577\tTop_Loss: 0.5006\tBottom_Loss: 0.3540\tLoss: 1.1123\t\n",
      "Subject: 05, n=06 | test_f1: 0.0 |best_f1: 0.6\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1838\tTop_Loss: 0.2395\tBottom_Loss: 0.3541\tLoss: 0.7775\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1579\tTop_Loss: 0.4082\tBottom_Loss: 0.2516\tLoss: 0.8177\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 05, n=06 | test_f1: 0.13333 |best_f1: 0.6\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1376\tTop_Loss: 0.4194\tBottom_Loss: 0.1816\tLoss: 0.7386\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0962\tTop_Loss: 0.3132\tBottom_Loss: 0.1920\tLoss: 0.6014\t\n",
      "Subject: 05, n=06 | test_f1: 0.13333 |best_f1: 0.6\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0860\tTop_Loss: 0.3041\tBottom_Loss: 0.2268\tLoss: 0.6169\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0497\tTop_Loss: 0.1494\tBottom_Loss: 0.1627\tLoss: 0.3618\t\n",
      "Subject: 05, n=06 | test_f1: 0.24444 |best_f1: 0.6\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1508\tTop_Loss: 0.2762\tBottom_Loss: 0.3547\tLoss: 0.7818\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2460\tTop_Loss: 0.5363\tBottom_Loss: 0.3211\tLoss: 1.1033\t\n",
      "Subject: 05, n=06 | test_f1: 0.11111 |best_f1: 0.6\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1813\tTop_Loss: 0.3001\tBottom_Loss: 0.3579\tLoss: 0.8393\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0696\tTop_Loss: 0.2201\tBottom_Loss: 0.2836\tLoss: 0.5733\t\n",
      "Subject: 05, n=06 | test_f1: 0.24444 |best_f1: 0.6\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.844\tLabel_Loss: 0.2621\tTop_Loss: 0.5222\tBottom_Loss: 0.2931\tLoss: 1.0775\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1611\tTop_Loss: 0.2718\tBottom_Loss: 0.2081\tLoss: 0.6411\t\n",
      "Subject: 05, n=06 | test_f1: 0.11111 |best_f1: 0.6\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0811\tTop_Loss: 0.2779\tBottom_Loss: 0.1314\tLoss: 0.4904\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0588\tTop_Loss: 0.1657\tBottom_Loss: 0.1796\tLoss: 0.4042\t\n",
      "Subject: 05, n=06 | test_f1: 0.0 |best_f1: 0.6\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1813\tTop_Loss: 0.2813\tBottom_Loss: 0.3059\tLoss: 0.7686\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1396\tTop_Loss: 0.3059\tBottom_Loss: 0.1802\tLoss: 0.6258\t\n",
      "Subject: 05, n=06 | test_f1: 0.095238 |best_f1: 0.6\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0621\tTop_Loss: 0.1936\tBottom_Loss: 0.1372\tLoss: 0.3929\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1867\tTop_Loss: 0.3491\tBottom_Loss: 0.2858\tLoss: 0.8216\t\n",
      "Subject: 05, n=06 | test_f1: 0.24444 |best_f1: 0.6\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1214\tTop_Loss: 0.2416\tBottom_Loss: 0.1643\tLoss: 0.5273\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0905\tTop_Loss: 0.2175\tBottom_Loss: 0.1424\tLoss: 0.4504\t\n",
      "Subject: 05, n=06 | test_f1: 0.24444 |best_f1: 0.6\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1244\tTop_Loss: 0.2789\tBottom_Loss: 0.1510\tLoss: 0.5543\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2518\tTop_Loss: 0.4944\tBottom_Loss: 0.3003\tLoss: 1.0464\t\n",
      "Subject: 05, n=06 | test_f1: 0.24444 |best_f1: 0.6\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2146\tTop_Loss: 0.3933\tBottom_Loss: 0.2001\tLoss: 0.8081\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0718\tTop_Loss: 0.1982\tBottom_Loss: 0.1837\tLoss: 0.4536\t\n",
      "Subject: 05, n=06 | test_f1: 0.24444 |best_f1: 0.6\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0834\tTop_Loss: 0.1939\tBottom_Loss: 0.1096\tLoss: 0.3869\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1100\tTop_Loss: 0.2242\tBottom_Loss: 0.2117\tLoss: 0.5460\t\n",
      "Subject: 05, n=06 | test_f1: 0.24444 |best_f1: 0.6\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0469\tTop_Loss: 0.1890\tBottom_Loss: 0.0962\tLoss: 0.3321\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0629\tTop_Loss: 0.2440\tBottom_Loss: 0.1359\tLoss: 0.4428\t\n",
      "Subject: 05, n=06 | test_f1: 0.095238 |best_f1: 0.6\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0283\tTop_Loss: 0.1474\tBottom_Loss: 0.0526\tLoss: 0.2283\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0649\tTop_Loss: 0.2298\tBottom_Loss: 0.1411\tLoss: 0.4358\t\n",
      "Subject: 05, n=06 | test_f1: 0.24444 |best_f1: 0.6\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0506\tTop_Loss: 0.2375\tBottom_Loss: 0.0746\tLoss: 0.3627\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0471\tTop_Loss: 0.2338\tBottom_Loss: 0.1045\tLoss: 0.3854\t\n",
      "Subject: 05, n=06 | test_f1: 0.24444 |best_f1: 0.6\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0282\tTop_Loss: 0.2008\tBottom_Loss: 0.0716\tLoss: 0.3007\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0256\tTop_Loss: 0.1415\tBottom_Loss: 0.1223\tLoss: 0.2894\t\n",
      "Subject: 05, n=06 | test_f1: 0.24444 |best_f1: 0.6\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0379\tTop_Loss: 0.1409\tBottom_Loss: 0.1054\tLoss: 0.2842\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0940\tTop_Loss: 0.1935\tBottom_Loss: 0.1796\tLoss: 0.4671\t\n",
      "Subject: 05, n=06 | test_f1: 0.13333 |best_f1: 0.6\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1382\tTop_Loss: 0.2417\tBottom_Loss: 0.1623\tLoss: 0.5422\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0474\tTop_Loss: 0.2054\tBottom_Loss: 0.1155\tLoss: 0.3683\t\n",
      "Subject: 05, n=06 | test_f1: 0.26667 |best_f1: 0.6\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1516\tTop_Loss: 0.2326\tBottom_Loss: 0.2178\tLoss: 0.6020\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0417\tTop_Loss: 0.1387\tBottom_Loss: 0.1748\tLoss: 0.3553\t\n",
      "Subject: 05, n=06 | test_f1: 0.095238 |best_f1: 0.6\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0234\tTop_Loss: 0.0991\tBottom_Loss: 0.0723\tLoss: 0.1949\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0807\tTop_Loss: 0.1742\tBottom_Loss: 0.1504\tLoss: 0.4053\t\n",
      "Subject: 05, n=06 | test_f1: 0.24444 |best_f1: 0.6\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1368\tTop_Loss: 0.1312\tBottom_Loss: 0.1427\tLoss: 0.4107\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1059\tTop_Loss: 0.1713\tBottom_Loss: 0.2422\tLoss: 0.5194\t\n",
      "Subject: 05, n=06 | test_f1: 0.24444 |best_f1: 0.6\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0474\tTop_Loss: 0.3087\tBottom_Loss: 0.0450\tLoss: 0.4011\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0264\tTop_Loss: 0.1063\tBottom_Loss: 0.0859\tLoss: 0.2187\t\n",
      "Subject: 05, n=06 | test_f1: 0.24444 |best_f1: 0.6\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1068\tTop_Loss: 0.1422\tBottom_Loss: 0.1280\tLoss: 0.3771\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0524\tTop_Loss: 0.3484\tBottom_Loss: 0.0848\tLoss: 0.4856\t\n",
      "Subject: 05, n=06 | test_f1: 0.26667 |best_f1: 0.6\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0996\tTop_Loss: 0.1844\tBottom_Loss: 0.1660\tLoss: 0.4501\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0784\tTop_Loss: 0.1695\tBottom_Loss: 0.0962\tLoss: 0.3440\t\n",
      "Subject: 05, n=06 | test_f1: 0.11111 |best_f1: 0.6\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0288\tTop_Loss: 0.1040\tBottom_Loss: 0.0488\tLoss: 0.1816\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0579\tTop_Loss: 0.1052\tBottom_Loss: 0.1413\tLoss: 0.3044\t\n",
      "Subject: 05, n=06 | test_f1: 0.35556 |best_f1: 0.6\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0706\tTop_Loss: 0.0922\tBottom_Loss: 0.1754\tLoss: 0.3382\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0246\tTop_Loss: 0.1250\tBottom_Loss: 0.0651\tLoss: 0.2148\t\n",
      "Subject: 05, n=06 | test_f1: 0.095238 |best_f1: 0.6\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0895\tTop_Loss: 0.1113\tBottom_Loss: 0.1234\tLoss: 0.3241\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0432\tTop_Loss: 0.1640\tBottom_Loss: 0.0869\tLoss: 0.2940\t\n",
      "Subject: 05, n=06 | test_f1: 0.24444 |best_f1: 0.6\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0395\tTop_Loss: 0.1440\tBottom_Loss: 0.0933\tLoss: 0.2768\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0179\tTop_Loss: 0.0809\tBottom_Loss: 0.0383\tLoss: 0.1372\t\n",
      "Subject: 05, n=06 | test_f1: 0.24444 |best_f1: 0.6\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0188\tTop_Loss: 0.0695\tBottom_Loss: 0.0323\tLoss: 0.1205\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0478\tTop_Loss: 0.1648\tBottom_Loss: 0.1425\tLoss: 0.3552\t\n",
      "Subject: 05, n=06 | test_f1: 0.095238 |best_f1: 0.6\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0428\tTop_Loss: 0.1199\tBottom_Loss: 0.0768\tLoss: 0.2395\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0222\tTop_Loss: 0.1009\tBottom_Loss: 0.1187\tLoss: 0.2418\t\n",
      "Subject: 05, n=06 | test_f1: 0.24444 |best_f1: 0.6\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0358\tTop_Loss: 0.0535\tBottom_Loss: 0.0897\tLoss: 0.1790\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0738\tTop_Loss: 0.1457\tBottom_Loss: 0.1925\tLoss: 0.4121\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 05, n=06 | test_f1: 0.24444 |best_f1: 0.6\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0719\tTop_Loss: 0.0808\tBottom_Loss: 0.2002\tLoss: 0.3529\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0572\tTop_Loss: 0.1633\tBottom_Loss: 0.1258\tLoss: 0.3463\t\n",
      "Subject: 05, n=06 | test_f1: 0.095238 |best_f1: 0.6\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0268\tTop_Loss: 0.1070\tBottom_Loss: 0.0508\tLoss: 0.1846\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0194\tTop_Loss: 0.0698\tBottom_Loss: 0.1069\tLoss: 0.1961\t\n",
      "Subject: 05, n=06 | test_f1: 0.24444 |best_f1: 0.6\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0174\tTop_Loss: 0.0660\tBottom_Loss: 0.0522\tLoss: 0.1356\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0694\tTop_Loss: 0.1586\tBottom_Loss: 0.0919\tLoss: 0.3200\t\n",
      "Subject: 05, n=06 | test_f1: 0.26667 |best_f1: 0.6\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0097\tTop_Loss: 0.0545\tBottom_Loss: 0.0323\tLoss: 0.0964\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0127\tTop_Loss: 0.0459\tBottom_Loss: 0.0765\tLoss: 0.1351\t\n",
      "Subject: 05, n=06 | test_f1: 0.11111 |best_f1: 0.6\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0180\tTop_Loss: 0.0422\tBottom_Loss: 0.0707\tLoss: 0.1309\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0168\tTop_Loss: 0.1961\tBottom_Loss: 0.0416\tLoss: 0.2544\t\n",
      "Subject: 05, n=06 | test_f1: 0.24444 |best_f1: 0.6\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0346\tTop_Loss: 0.1124\tBottom_Loss: 0.0734\tLoss: 0.2204\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0580\tTop_Loss: 0.1687\tBottom_Loss: 0.0761\tLoss: 0.3028\t\n",
      "Subject: 05, n=06 | test_f1: 0.26667 |best_f1: 0.6\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0171\tTop_Loss: 0.0766\tBottom_Loss: 0.0470\tLoss: 0.1407\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0107\tTop_Loss: 0.0679\tBottom_Loss: 0.0503\tLoss: 0.1288\t\n",
      "Subject: 05, n=06 | test_f1: 0.24444 |best_f1: 0.6\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0213\tTop_Loss: 0.0727\tBottom_Loss: 0.0438\tLoss: 0.1378\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0110\tTop_Loss: 0.0555\tBottom_Loss: 0.0292\tLoss: 0.0957\t\n",
      "Subject: 05, n=06 | test_f1: 0.24444 |best_f1: 0.6\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0085\tTop_Loss: 0.0197\tBottom_Loss: 0.0246\tLoss: 0.0527\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0353\tTop_Loss: 0.0873\tBottom_Loss: 0.0451\tLoss: 0.1677\t\n",
      "Subject: 05, n=06 | test_f1: 0.22222 |best_f1: 0.6\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0767\tTop_Loss: 0.1581\tBottom_Loss: 0.1349\tLoss: 0.3696\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0084\tTop_Loss: 0.0908\tBottom_Loss: 0.0501\tLoss: 0.1493\t\n",
      "Subject: 05, n=06 | test_f1: 0.24444 |best_f1: 0.6\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0771\tTop_Loss: 0.1373\tBottom_Loss: 0.0537\tLoss: 0.2681\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0064\tTop_Loss: 0.0472\tBottom_Loss: 0.0236\tLoss: 0.0771\t\n",
      "Subject: 05, n=06 | test_f1: 0.35556 |best_f1: 0.6\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0213\tTop_Loss: 0.0395\tBottom_Loss: 0.0770\tLoss: 0.1378\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0119\tTop_Loss: 0.1000\tBottom_Loss: 0.0241\tLoss: 0.1359\t\n",
      "Subject: 05, n=06 | test_f1: 0.24444 |best_f1: 0.6\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0053\tTop_Loss: 0.0265\tBottom_Loss: 0.0254\tLoss: 0.0572\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0060\tTop_Loss: 0.0313\tBottom_Loss: 0.0196\tLoss: 0.0570\t\n",
      "Subject: 05, n=06 | test_f1: 0.24444 |best_f1: 0.6\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0043\tTop_Loss: 0.0315\tBottom_Loss: 0.0293\tLoss: 0.0652\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0162\tTop_Loss: 0.0776\tBottom_Loss: 0.0269\tLoss: 0.1207\t\n",
      "Subject: 05, n=06 | test_f1: 0.095238 |best_f1: 0.6\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0122\tTop_Loss: 0.0616\tBottom_Loss: 0.0312\tLoss: 0.1050\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0251\tTop_Loss: 0.0587\tBottom_Loss: 0.0602\tLoss: 0.1440\t\n",
      "Subject: 05, n=06 | test_f1: 0.095238 |best_f1: 0.6\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0100\tTop_Loss: 0.0539\tBottom_Loss: 0.0352\tLoss: 0.0991\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0412\tTop_Loss: 0.0385\tBottom_Loss: 0.1416\tLoss: 0.2213\t\n",
      "Subject: 05, n=06 | test_f1: 0.24444 |best_f1: 0.6\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0622\tTop_Loss: 0.1001\tBottom_Loss: 0.1850\tLoss: 0.3473\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0089\tTop_Loss: 0.0353\tBottom_Loss: 0.0388\tLoss: 0.0830\t\n",
      "Subject: 05, n=06 | test_f1: 0.095238 |best_f1: 0.6\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0346\tTop_Loss: 0.0576\tBottom_Loss: 0.0795\tLoss: 0.1717\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0095\tTop_Loss: 0.0354\tBottom_Loss: 0.0205\tLoss: 0.0654\t\n",
      "Subject: 05, n=06 | test_f1: 0.72222 |best_f1: 0.72222\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0064\tTop_Loss: 0.0275\tBottom_Loss: 0.0348\tLoss: 0.0687\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0039\tTop_Loss: 0.0225\tBottom_Loss: 0.0209\tLoss: 0.0473\t\n",
      "Subject: 05, n=06 | test_f1: 0.26667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0130\tTop_Loss: 0.0807\tBottom_Loss: 0.0218\tLoss: 0.1154\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0074\tTop_Loss: 0.0492\tBottom_Loss: 0.0270\tLoss: 0.0836\t\n",
      "Subject: 05, n=06 | test_f1: 0.35556 |best_f1: 0.72222\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0142\tTop_Loss: 0.0720\tBottom_Loss: 0.0193\tLoss: 0.1054\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0130\tTop_Loss: 0.0316\tBottom_Loss: 0.0649\tLoss: 0.1094\t\n",
      "Subject: 05, n=06 | test_f1: 0.24444 |best_f1: 0.72222\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0074\tTop_Loss: 0.0219\tBottom_Loss: 0.0119\tLoss: 0.0413\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0072\tTop_Loss: 0.0370\tBottom_Loss: 0.0355\tLoss: 0.0797\t\n",
      "Subject: 05, n=06 | test_f1: 0.24444 |best_f1: 0.72222\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0047\tTop_Loss: 0.0272\tBottom_Loss: 0.0144\tLoss: 0.0463\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0047\tTop_Loss: 0.0483\tBottom_Loss: 0.0172\tLoss: 0.0703\t\n",
      "Subject: 05, n=06 | test_f1: 0.26667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0132\tTop_Loss: 0.0379\tBottom_Loss: 0.0176\tLoss: 0.0687\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0071\tTop_Loss: 0.0466\tBottom_Loss: 0.0167\tLoss: 0.0703\t\n",
      "Subject: 05, n=06 | test_f1: 0.24444 |best_f1: 0.72222\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.219\tLabel_Loss: 1.6709\tTop_Loss: 1.2010\tBottom_Loss: 1.6113\tLoss: 4.4832\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.531\tLabel_Loss: 1.1141\tTop_Loss: 1.1073\tBottom_Loss: 1.3383\tLoss: 3.5597\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 0.22222\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.594\tLabel_Loss: 0.9902\tTop_Loss: 1.0998\tBottom_Loss: 1.1138\tLoss: 3.2039\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.531\tLabel_Loss: 1.0809\tTop_Loss: 1.0139\tBottom_Loss: 1.3956\tLoss: 3.4905\t\n",
      "Subject: 06, n=04 | test_f1: 0.13333 |best_f1: 0.22222\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.562\tLabel_Loss: 1.0814\tTop_Loss: 1.1136\tBottom_Loss: 1.0527\tLoss: 3.2477\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7518\tTop_Loss: 0.9308\tBottom_Loss: 0.9270\tLoss: 2.6097\t\n",
      "Subject: 06, n=04 | test_f1: 0.5 |best_f1: 0.5\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.375\tLabel_Loss: 1.1162\tTop_Loss: 1.0469\tBottom_Loss: 1.1685\tLoss: 3.3317\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6905\tTop_Loss: 0.8780\tBottom_Loss: 0.8449\tLoss: 2.4134\t\n",
      "Subject: 06, n=04 | test_f1: 0.44444 |best_f1: 0.5\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7584\tTop_Loss: 0.9390\tBottom_Loss: 0.8488\tLoss: 2.5463\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.688\tLabel_Loss: 0.8075\tTop_Loss: 0.9683\tBottom_Loss: 0.8454\tLoss: 2.6212\t\n",
      "Subject: 06, n=04 | test_f1: 0.16667 |best_f1: 0.5\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8139\tTop_Loss: 0.8185\tBottom_Loss: 0.8706\tLoss: 2.5029\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.531\tLabel_Loss: 0.9472\tTop_Loss: 0.9681\tBottom_Loss: 0.8117\tLoss: 2.7270\t\n",
      "Subject: 06, n=04 | test_f1: 0.6 |best_f1: 0.6\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8775\tTop_Loss: 0.7689\tBottom_Loss: 0.8582\tLoss: 2.5046\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.688\tLabel_Loss: 0.9187\tTop_Loss: 1.0138\tBottom_Loss: 0.7854\tLoss: 2.7179\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 06, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.719\tLabel_Loss: 0.7582\tTop_Loss: 0.8056\tBottom_Loss: 0.7358\tLoss: 2.2996\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.656\tLabel_Loss: 0.8940\tTop_Loss: 0.9775\tBottom_Loss: 0.8123\tLoss: 2.6839\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.531\tLabel_Loss: 0.8532\tTop_Loss: 0.9144\tBottom_Loss: 0.6654\tLoss: 2.4330\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.531\tLabel_Loss: 0.8543\tTop_Loss: 0.8812\tBottom_Loss: 0.8302\tLoss: 2.5657\t\n",
      "Subject: 06, n=04 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.656\tLabel_Loss: 0.6626\tTop_Loss: 0.8599\tBottom_Loss: 0.7410\tLoss: 2.2635\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6859\tTop_Loss: 0.8069\tBottom_Loss: 0.7282\tLoss: 2.2210\t\n",
      "Subject: 06, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.625\tLabel_Loss: 0.6634\tTop_Loss: 0.7139\tBottom_Loss: 0.7890\tLoss: 2.1663\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6287\tTop_Loss: 0.8009\tBottom_Loss: 0.8240\tLoss: 2.2537\t\n",
      "Subject: 06, n=04 | test_f1: 0.5 |best_f1: 1.0\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6605\tTop_Loss: 0.9290\tBottom_Loss: 0.7286\tLoss: 2.3181\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.625\tLabel_Loss: 0.6987\tTop_Loss: 0.7860\tBottom_Loss: 0.7687\tLoss: 2.2534\t\n",
      "Subject: 06, n=04 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6614\tTop_Loss: 0.7158\tBottom_Loss: 0.8494\tLoss: 2.2265\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6198\tTop_Loss: 0.7289\tBottom_Loss: 0.6846\tLoss: 2.0333\t\n",
      "Subject: 06, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3383\tTop_Loss: 0.5005\tBottom_Loss: 0.5175\tLoss: 1.3563\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5006\tTop_Loss: 0.5934\tBottom_Loss: 0.5709\tLoss: 1.6648\t\n",
      "Subject: 06, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4804\tTop_Loss: 0.6098\tBottom_Loss: 0.7201\tLoss: 1.8103\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4689\tTop_Loss: 0.6101\tBottom_Loss: 0.5332\tLoss: 1.6121\t\n",
      "Subject: 06, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3634\tTop_Loss: 0.6286\tBottom_Loss: 0.5464\tLoss: 1.5384\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7040\tTop_Loss: 0.6446\tBottom_Loss: 0.8982\tLoss: 2.2468\t\n",
      "Subject: 06, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4973\tTop_Loss: 0.6482\tBottom_Loss: 0.6159\tLoss: 1.7614\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.875\tLabel_Loss: 0.5403\tTop_Loss: 0.7345\tBottom_Loss: 0.6928\tLoss: 1.9676\t\n",
      "Subject: 06, n=04 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4158\tTop_Loss: 0.4642\tBottom_Loss: 0.6273\tLoss: 1.5073\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.906\tLabel_Loss: 0.4008\tTop_Loss: 0.5484\tBottom_Loss: 0.5996\tLoss: 1.5487\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6062\tTop_Loss: 0.6047\tBottom_Loss: 0.6157\tLoss: 1.8266\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4528\tTop_Loss: 0.6528\tBottom_Loss: 0.5698\tLoss: 1.6754\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2969\tTop_Loss: 0.4779\tBottom_Loss: 0.3610\tLoss: 1.1358\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.938\tLabel_Loss: 0.3572\tTop_Loss: 0.5707\tBottom_Loss: 0.4799\tLoss: 1.4078\t\n",
      "Subject: 06, n=04 | test_f1: 0.38889 |best_f1: 1.0\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4959\tTop_Loss: 0.7569\tBottom_Loss: 0.5524\tLoss: 1.8052\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4699\tTop_Loss: 0.8116\tBottom_Loss: 0.5591\tLoss: 1.8407\t\n",
      "Subject: 06, n=04 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.906\tLabel_Loss: 0.4132\tTop_Loss: 0.5816\tBottom_Loss: 0.5934\tLoss: 1.5883\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.750\tLabel_Loss: 0.4845\tTop_Loss: 0.7227\tBottom_Loss: 0.6362\tLoss: 1.8434\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3336\tTop_Loss: 0.4490\tBottom_Loss: 0.5903\tLoss: 1.3729\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5514\tTop_Loss: 0.8188\tBottom_Loss: 0.5749\tLoss: 1.9450\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6080\tTop_Loss: 0.6858\tBottom_Loss: 0.7339\tLoss: 2.0276\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3588\tTop_Loss: 0.6523\tBottom_Loss: 0.4396\tLoss: 1.4507\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5060\tTop_Loss: 0.8437\tBottom_Loss: 0.5917\tLoss: 1.9414\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2703\tTop_Loss: 0.4724\tBottom_Loss: 0.4515\tLoss: 1.1942\t\n",
      "Subject: 06, n=04 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4638\tTop_Loss: 0.5939\tBottom_Loss: 0.4780\tLoss: 1.5356\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2706\tTop_Loss: 0.3919\tBottom_Loss: 0.4132\tLoss: 1.0757\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2923\tTop_Loss: 0.5015\tBottom_Loss: 0.3242\tLoss: 1.1180\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3148\tTop_Loss: 0.3813\tBottom_Loss: 0.4266\tLoss: 1.1227\t\n",
      "Subject: 06, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4370\tTop_Loss: 0.7508\tBottom_Loss: 0.7353\tLoss: 1.9231\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2053\tTop_Loss: 0.5480\tBottom_Loss: 0.3430\tLoss: 1.0963\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.938\tLabel_Loss: 0.3007\tTop_Loss: 0.5100\tBottom_Loss: 0.5053\tLoss: 1.3160\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3503\tTop_Loss: 0.5082\tBottom_Loss: 0.4822\tLoss: 1.3406\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3198\tTop_Loss: 0.5634\tBottom_Loss: 0.4424\tLoss: 1.3256\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3004\tTop_Loss: 0.4839\tBottom_Loss: 0.4225\tLoss: 1.2068\t\n",
      "Subject: 06, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4034\tTop_Loss: 0.7237\tBottom_Loss: 0.4366\tLoss: 1.5637\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1892\tTop_Loss: 0.4035\tBottom_Loss: 0.3575\tLoss: 0.9503\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1741\tTop_Loss: 0.4451\tBottom_Loss: 0.3102\tLoss: 0.9294\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4189\tTop_Loss: 0.5108\tBottom_Loss: 0.4716\tLoss: 1.4013\t\n",
      "Subject: 06, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3159\tTop_Loss: 0.7697\tBottom_Loss: 0.4483\tLoss: 1.5339\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3062\tTop_Loss: 0.5529\tBottom_Loss: 0.3964\tLoss: 1.2555\t\n",
      "Subject: 06, n=04 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2266\tTop_Loss: 0.4380\tBottom_Loss: 0.3063\tLoss: 0.9709\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3440\tTop_Loss: 0.5174\tBottom_Loss: 0.4590\tLoss: 1.3204\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1445\tTop_Loss: 0.3995\tBottom_Loss: 0.2775\tLoss: 0.8215\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4000\tTop_Loss: 0.5263\tBottom_Loss: 0.4673\tLoss: 1.3935\t\n",
      "Subject: 06, n=04 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3826\tTop_Loss: 0.6010\tBottom_Loss: 0.4723\tLoss: 1.4559\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1342\tTop_Loss: 0.2804\tBottom_Loss: 0.2141\tLoss: 0.6287\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2521\tTop_Loss: 0.3977\tBottom_Loss: 0.3206\tLoss: 0.9703\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1853\tTop_Loss: 0.4894\tBottom_Loss: 0.2794\tLoss: 0.9542\t\n",
      "Subject: 06, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2790\tTop_Loss: 0.4505\tBottom_Loss: 0.4821\tLoss: 1.2116\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1138\tTop_Loss: 0.3272\tBottom_Loss: 0.2377\tLoss: 0.6787\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1474\tTop_Loss: 0.3602\tBottom_Loss: 0.1598\tLoss: 0.6674\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1563\tTop_Loss: 0.3101\tBottom_Loss: 0.3286\tLoss: 0.7950\t\n",
      "Subject: 06, n=04 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2544\tTop_Loss: 0.5173\tBottom_Loss: 0.3327\tLoss: 1.1043\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1874\tTop_Loss: 0.3746\tBottom_Loss: 0.2258\tLoss: 0.7877\t\n",
      "Subject: 06, n=04 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1366\tTop_Loss: 0.3038\tBottom_Loss: 0.2840\tLoss: 0.7244\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1072\tTop_Loss: 0.3714\tBottom_Loss: 0.3166\tLoss: 0.7952\t\n",
      "Subject: 06, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1114\tTop_Loss: 0.2760\tBottom_Loss: 0.2628\tLoss: 0.6501\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3200\tTop_Loss: 0.4839\tBottom_Loss: 0.3059\tLoss: 1.1098\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2166\tTop_Loss: 0.4214\tBottom_Loss: 0.2341\tLoss: 0.8721\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2751\tTop_Loss: 0.3554\tBottom_Loss: 0.4425\tLoss: 1.0730\t\n",
      "Subject: 06, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.938\tLabel_Loss: 0.3034\tTop_Loss: 0.5566\tBottom_Loss: 0.3397\tLoss: 1.1997\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2043\tTop_Loss: 0.3254\tBottom_Loss: 0.2967\tLoss: 0.8264\t\n",
      "Subject: 06, n=04 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2143\tTop_Loss: 0.4176\tBottom_Loss: 0.3169\tLoss: 0.9489\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1117\tTop_Loss: 0.2288\tBottom_Loss: 0.1233\tLoss: 0.4638\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0621\tTop_Loss: 0.2312\tBottom_Loss: 0.1109\tLoss: 0.4041\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2389\tTop_Loss: 0.4059\tBottom_Loss: 0.2457\tLoss: 0.8905\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1415\tTop_Loss: 0.2913\tBottom_Loss: 0.3150\tLoss: 0.7477\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0698\tTop_Loss: 0.2410\tBottom_Loss: 0.1536\tLoss: 0.4643\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0555\tTop_Loss: 0.2728\tBottom_Loss: 0.1487\tLoss: 0.4770\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1975\tTop_Loss: 0.3391\tBottom_Loss: 0.2750\tLoss: 0.8116\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0520\tTop_Loss: 0.2245\tBottom_Loss: 0.1035\tLoss: 0.3800\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1834\tTop_Loss: 0.2913\tBottom_Loss: 0.2859\tLoss: 0.7606\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0753\tTop_Loss: 0.2444\tBottom_Loss: 0.1917\tLoss: 0.5114\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0708\tTop_Loss: 0.2065\tBottom_Loss: 0.1372\tLoss: 0.4146\t\n",
      "Subject: 06, n=04 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0786\tTop_Loss: 0.2332\tBottom_Loss: 0.1293\tLoss: 0.4411\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1084\tTop_Loss: 0.2683\tBottom_Loss: 0.1503\tLoss: 0.5270\t\n",
      "Subject: 06, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0580\tTop_Loss: 0.2781\tBottom_Loss: 0.1393\tLoss: 0.4754\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0739\tTop_Loss: 0.2055\tBottom_Loss: 0.1659\tLoss: 0.4452\t\n",
      "Subject: 06, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.875\tLabel_Loss: 0.1944\tTop_Loss: 0.3838\tBottom_Loss: 0.2091\tLoss: 0.7874\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2776\tTop_Loss: 0.3151\tBottom_Loss: 0.3813\tLoss: 0.9741\t\n",
      "Subject: 06, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1187\tTop_Loss: 0.2405\tBottom_Loss: 0.1736\tLoss: 0.5328\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1509\tTop_Loss: 0.3779\tBottom_Loss: 0.1482\tLoss: 0.6770\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1477\tTop_Loss: 0.3120\tBottom_Loss: 0.2039\tLoss: 0.6636\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0397\tTop_Loss: 0.2322\tBottom_Loss: 0.0915\tLoss: 0.3635\t\n",
      "Subject: 06, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1529\tTop_Loss: 0.2461\tBottom_Loss: 0.1672\tLoss: 0.5662\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0682\tTop_Loss: 0.1999\tBottom_Loss: 0.1385\tLoss: 0.4066\t\n",
      "Subject: 06, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0449\tTop_Loss: 0.1612\tBottom_Loss: 0.1214\tLoss: 0.3276\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0471\tTop_Loss: 0.1319\tBottom_Loss: 0.0708\tLoss: 0.2499\t\n",
      "Subject: 06, n=04 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0721\tTop_Loss: 0.1416\tBottom_Loss: 0.0731\tLoss: 0.2868\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0429\tTop_Loss: 0.1294\tBottom_Loss: 0.1553\tLoss: 0.3276\t\n",
      "Subject: 06, n=04 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1010\tTop_Loss: 0.3514\tBottom_Loss: 0.1643\tLoss: 0.6167\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0709\tTop_Loss: 0.2446\tBottom_Loss: 0.1261\tLoss: 0.4416\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0432\tTop_Loss: 0.1910\tBottom_Loss: 0.1816\tLoss: 0.4157\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0477\tTop_Loss: 0.2193\tBottom_Loss: 0.1038\tLoss: 0.3709\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0387\tTop_Loss: 0.1459\tBottom_Loss: 0.1299\tLoss: 0.3145\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0494\tTop_Loss: 0.2279\tBottom_Loss: 0.1193\tLoss: 0.3966\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0413\tTop_Loss: 0.2047\tBottom_Loss: 0.0791\tLoss: 0.3251\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0142\tTop_Loss: 0.1541\tBottom_Loss: 0.0694\tLoss: 0.2378\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0165\tTop_Loss: 0.1556\tBottom_Loss: 0.0571\tLoss: 0.2291\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1250\tTop_Loss: 0.2412\tBottom_Loss: 0.1973\tLoss: 0.5635\t\n",
      "Subject: 06, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0268\tTop_Loss: 0.1177\tBottom_Loss: 0.0846\tLoss: 0.2291\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0184\tTop_Loss: 0.0927\tBottom_Loss: 0.0739\tLoss: 0.1850\t\n",
      "Subject: 06, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0475\tTop_Loss: 0.1768\tBottom_Loss: 0.0908\tLoss: 0.3151\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0258\tTop_Loss: 0.1265\tBottom_Loss: 0.0689\tLoss: 0.2212\t\n",
      "Subject: 06, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0213\tTop_Loss: 0.1266\tBottom_Loss: 0.0466\tLoss: 0.1944\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0352\tTop_Loss: 0.1536\tBottom_Loss: 0.0490\tLoss: 0.2378\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0432\tTop_Loss: 0.2080\tBottom_Loss: 0.1154\tLoss: 0.3665\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0361\tTop_Loss: 0.1665\tBottom_Loss: 0.0918\tLoss: 0.2945\t\n",
      "Subject: 06, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0318\tTop_Loss: 0.1033\tBottom_Loss: 0.0830\tLoss: 0.2181\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0921\tTop_Loss: 0.1796\tBottom_Loss: 0.2377\tLoss: 0.5094\t\n",
      "Subject: 06, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0146\tTop_Loss: 0.1478\tBottom_Loss: 0.0387\tLoss: 0.2011\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0169\tTop_Loss: 0.0807\tBottom_Loss: 0.0413\tLoss: 0.1389\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 06, n=04 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0405\tTop_Loss: 0.1610\tBottom_Loss: 0.0563\tLoss: 0.2577\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1244\tTop_Loss: 0.2017\tBottom_Loss: 0.1790\tLoss: 0.5051\t\n",
      "Subject: 06, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0417\tTop_Loss: 0.1703\tBottom_Loss: 0.0530\tLoss: 0.2651\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0366\tTop_Loss: 0.2219\tBottom_Loss: 0.0500\tLoss: 0.3086\t\n",
      "Subject: 06, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0177\tTop_Loss: 0.1144\tBottom_Loss: 0.0617\tLoss: 0.1939\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0695\tTop_Loss: 0.3217\tBottom_Loss: 0.0465\tLoss: 0.4376\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0559\tTop_Loss: 0.1366\tBottom_Loss: 0.0968\tLoss: 0.2893\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0541\tTop_Loss: 0.1304\tBottom_Loss: 0.1090\tLoss: 0.2935\t\n",
      "Subject: 06, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0136\tTop_Loss: 0.0683\tBottom_Loss: 0.0562\tLoss: 0.1382\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0360\tTop_Loss: 0.1234\tBottom_Loss: 0.0488\tLoss: 0.2081\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0152\tTop_Loss: 0.1055\tBottom_Loss: 0.0462\tLoss: 0.1669\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0689\tTop_Loss: 0.2683\tBottom_Loss: 0.0973\tLoss: 0.4345\t\n",
      "Subject: 06, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0250\tTop_Loss: 0.1493\tBottom_Loss: 0.0417\tLoss: 0.2160\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0288\tTop_Loss: 0.0746\tBottom_Loss: 0.0916\tLoss: 0.1949\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0138\tTop_Loss: 0.0707\tBottom_Loss: 0.0728\tLoss: 0.1573\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0532\tTop_Loss: 0.1648\tBottom_Loss: 0.1053\tLoss: 0.3234\t\n",
      "Subject: 06, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 0.938\tLabel_Loss: 0.0587\tTop_Loss: 0.1297\tBottom_Loss: 0.1461\tLoss: 0.3345\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0679\tTop_Loss: 0.0872\tBottom_Loss: 0.0608\tLoss: 0.2158\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0427\tTop_Loss: 0.1166\tBottom_Loss: 0.0533\tLoss: 0.2126\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0170\tTop_Loss: 0.0783\tBottom_Loss: 0.0647\tLoss: 0.1600\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0056\tTop_Loss: 0.0480\tBottom_Loss: 0.0250\tLoss: 0.0786\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0064\tTop_Loss: 0.0789\tBottom_Loss: 0.0417\tLoss: 0.1270\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0455\tTop_Loss: 0.0298\tBottom_Loss: 0.0604\tLoss: 0.1357\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0221\tTop_Loss: 0.0955\tBottom_Loss: 0.0441\tLoss: 0.1617\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0297\tTop_Loss: 0.0836\tBottom_Loss: 0.0645\tLoss: 0.1779\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0079\tTop_Loss: 0.0437\tBottom_Loss: 0.0259\tLoss: 0.0776\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0132\tTop_Loss: 0.0660\tBottom_Loss: 0.0292\tLoss: 0.1084\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0078\tTop_Loss: 0.0332\tBottom_Loss: 0.0504\tLoss: 0.0913\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0537\tTop_Loss: 0.1061\tBottom_Loss: 0.1411\tLoss: 0.3009\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0145\tTop_Loss: 0.0961\tBottom_Loss: 0.0344\tLoss: 0.1450\t\n",
      "Subject: 06, n=04 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0200\tTop_Loss: 0.0824\tBottom_Loss: 0.0383\tLoss: 0.1408\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0327\tTop_Loss: 0.1317\tBottom_Loss: 0.0467\tLoss: 0.2111\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0150\tTop_Loss: 0.0362\tBottom_Loss: 0.0401\tLoss: 0.0913\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0149\tTop_Loss: 0.0557\tBottom_Loss: 0.0255\tLoss: 0.0962\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0493\tTop_Loss: 0.1372\tBottom_Loss: 0.0499\tLoss: 0.2364\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0455\tTop_Loss: 0.0655\tBottom_Loss: 0.0546\tLoss: 0.1656\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0224\tTop_Loss: 0.0674\tBottom_Loss: 0.0862\tLoss: 0.1759\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0344\tTop_Loss: 0.0609\tBottom_Loss: 0.1420\tLoss: 0.2372\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0309\tTop_Loss: 0.0986\tBottom_Loss: 0.0784\tLoss: 0.2079\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0138\tTop_Loss: 0.0732\tBottom_Loss: 0.0207\tLoss: 0.1077\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1316\tTop_Loss: 0.3304\tBottom_Loss: 0.2505\tLoss: 0.7124\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1281\tTop_Loss: 0.0628\tBottom_Loss: 0.1560\tLoss: 0.3470\t\n",
      "Subject: 06, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0069\tTop_Loss: 0.0592\tBottom_Loss: 0.0380\tLoss: 0.1040\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0098\tTop_Loss: 0.0504\tBottom_Loss: 0.0345\tLoss: 0.0947\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0141\tTop_Loss: 0.0541\tBottom_Loss: 0.0514\tLoss: 0.1196\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0156\tTop_Loss: 0.1305\tBottom_Loss: 0.0305\tLoss: 0.1766\t\n",
      "Subject: 06, n=04 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0074\tTop_Loss: 0.0537\tBottom_Loss: 0.0331\tLoss: 0.0942\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0069\tTop_Loss: 0.0286\tBottom_Loss: 0.0286\tLoss: 0.0641\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0044\tTop_Loss: 0.0186\tBottom_Loss: 0.0215\tLoss: 0.0445\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0069\tTop_Loss: 0.0953\tBottom_Loss: 0.0153\tLoss: 0.1175\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0419\tTop_Loss: 0.1247\tBottom_Loss: 0.0622\tLoss: 0.2288\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0039\tTop_Loss: 0.0142\tBottom_Loss: 0.0083\tLoss: 0.0264\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0033\tTop_Loss: 0.0200\tBottom_Loss: 0.0109\tLoss: 0.0342\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0070\tTop_Loss: 0.0485\tBottom_Loss: 0.0329\tLoss: 0.0883\t\n",
      "Subject: 06, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0111\tTop_Loss: 0.0370\tBottom_Loss: 0.0307\tLoss: 0.0789\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0076\tTop_Loss: 0.0441\tBottom_Loss: 0.0339\tLoss: 0.0856\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0085\tTop_Loss: 0.0531\tBottom_Loss: 0.0196\tLoss: 0.0813\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0105\tTop_Loss: 0.0377\tBottom_Loss: 0.0348\tLoss: 0.0830\t\n",
      "Subject: 06, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0245\tTop_Loss: 0.0315\tBottom_Loss: 0.0675\tLoss: 0.1236\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0078\tTop_Loss: 0.0222\tBottom_Loss: 0.0363\tLoss: 0.0663\t\n",
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0180\tTop_Loss: 0.1147\tBottom_Loss: 0.0340\tLoss: 0.1667\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0089\tTop_Loss: 0.0288\tBottom_Loss: 0.0170\tLoss: 0.0548\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 06, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.375\tLabel_Loss: 1.2635\tTop_Loss: 1.0237\tBottom_Loss: 1.9123\tLoss: 4.1995\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.375\tLabel_Loss: 1.3351\tTop_Loss: 1.1414\tBottom_Loss: 1.3996\tLoss: 3.8761\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 0.44444\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.469\tLabel_Loss: 1.0262\tTop_Loss: 1.1724\tBottom_Loss: 1.3803\tLoss: 3.5789\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.562\tLabel_Loss: 0.9852\tTop_Loss: 0.9948\tBottom_Loss: 1.0417\tLoss: 3.0217\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.438\tLabel_Loss: 1.0225\tTop_Loss: 0.9624\tBottom_Loss: 1.1397\tLoss: 3.1246\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.656\tLabel_Loss: 0.9293\tTop_Loss: 0.7891\tBottom_Loss: 0.9451\tLoss: 2.6635\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.500\tLabel_Loss: 1.1576\tTop_Loss: 0.9678\tBottom_Loss: 0.9390\tLoss: 3.0644\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.500\tLabel_Loss: 0.9836\tTop_Loss: 0.8933\tBottom_Loss: 1.0053\tLoss: 2.8823\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.375\tLabel_Loss: 1.2789\tTop_Loss: 1.0711\tBottom_Loss: 1.3212\tLoss: 3.6713\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.469\tLabel_Loss: 0.9469\tTop_Loss: 0.8863\tBottom_Loss: 1.1915\tLoss: 3.0247\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.719\tLabel_Loss: 0.7452\tTop_Loss: 0.8348\tBottom_Loss: 0.8163\tLoss: 2.3963\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.594\tLabel_Loss: 0.9375\tTop_Loss: 0.8515\tBottom_Loss: 1.2041\tLoss: 2.9931\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.469\tLabel_Loss: 0.9446\tTop_Loss: 0.7941\tBottom_Loss: 0.9525\tLoss: 2.6913\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7284\tTop_Loss: 0.7393\tBottom_Loss: 0.9426\tLoss: 2.4102\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.562\tLabel_Loss: 0.8390\tTop_Loss: 0.7918\tBottom_Loss: 0.7700\tLoss: 2.4008\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7299\tTop_Loss: 0.6825\tBottom_Loss: 0.8646\tLoss: 2.2770\t\n",
      "Subject: 07, n=05 | test_f1: 0.375 |best_f1: 1.0\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7929\tTop_Loss: 0.7689\tBottom_Loss: 0.8345\tLoss: 2.3963\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.656\tLabel_Loss: 0.8694\tTop_Loss: 0.6879\tBottom_Loss: 0.9537\tLoss: 2.5110\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.500\tLabel_Loss: 0.9796\tTop_Loss: 0.9383\tBottom_Loss: 1.0440\tLoss: 2.9619\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.719\tLabel_Loss: 0.7340\tTop_Loss: 0.8019\tBottom_Loss: 0.7013\tLoss: 2.2372\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8950\tTop_Loss: 0.9815\tBottom_Loss: 0.7808\tLoss: 2.6574\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8554\tTop_Loss: 1.1249\tBottom_Loss: 0.9990\tLoss: 2.9793\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.625\tLabel_Loss: 0.9049\tTop_Loss: 0.8307\tBottom_Loss: 0.7614\tLoss: 2.4971\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7077\tTop_Loss: 0.7358\tBottom_Loss: 0.7132\tLoss: 2.1568\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6276\tTop_Loss: 0.6055\tBottom_Loss: 0.5892\tLoss: 1.8223\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.531\tLabel_Loss: 0.9989\tTop_Loss: 0.7999\tBottom_Loss: 0.9845\tLoss: 2.7833\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6307\tTop_Loss: 0.6559\tBottom_Loss: 0.7329\tLoss: 2.0196\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.594\tLabel_Loss: 0.6829\tTop_Loss: 0.7172\tBottom_Loss: 0.8334\tLoss: 2.2335\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.625\tLabel_Loss: 0.6833\tTop_Loss: 0.7181\tBottom_Loss: 0.7353\tLoss: 2.1368\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.531\tLabel_Loss: 0.7693\tTop_Loss: 0.8003\tBottom_Loss: 0.9255\tLoss: 2.4950\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6799\tTop_Loss: 0.8024\tBottom_Loss: 0.7305\tLoss: 2.2127\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.781\tLabel_Loss: 0.6387\tTop_Loss: 0.8391\tBottom_Loss: 0.6151\tLoss: 2.0929\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6260\tTop_Loss: 0.5637\tBottom_Loss: 0.7504\tLoss: 1.9401\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.531\tLabel_Loss: 0.8491\tTop_Loss: 0.8538\tBottom_Loss: 1.0263\tLoss: 2.7292\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5465\tTop_Loss: 0.5230\tBottom_Loss: 0.7630\tLoss: 1.8325\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.719\tLabel_Loss: 0.7158\tTop_Loss: 0.8604\tBottom_Loss: 0.7720\tLoss: 2.3482\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5611\tTop_Loss: 0.7180\tBottom_Loss: 0.5710\tLoss: 1.8502\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3268\tTop_Loss: 0.3554\tBottom_Loss: 0.4060\tLoss: 1.0883\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5644\tTop_Loss: 0.7255\tBottom_Loss: 0.6351\tLoss: 1.9250\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5490\tTop_Loss: 0.5397\tBottom_Loss: 0.6749\tLoss: 1.7636\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4176\tTop_Loss: 0.5671\tBottom_Loss: 0.6419\tLoss: 1.6265\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6902\tTop_Loss: 0.8994\tBottom_Loss: 0.6147\tLoss: 2.2043\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3270\tTop_Loss: 0.5846\tBottom_Loss: 0.5509\tLoss: 1.4625\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4830\tTop_Loss: 0.6693\tBottom_Loss: 0.3545\tLoss: 1.5068\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4370\tTop_Loss: 0.4561\tBottom_Loss: 0.5520\tLoss: 1.4451\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3600\tTop_Loss: 0.5128\tBottom_Loss: 0.6145\tLoss: 1.4873\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4475\tTop_Loss: 0.5372\tBottom_Loss: 0.7802\tLoss: 1.7649\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.562\tLabel_Loss: 0.6311\tTop_Loss: 0.7126\tBottom_Loss: 0.7352\tLoss: 2.0788\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5727\tTop_Loss: 0.8045\tBottom_Loss: 0.6654\tLoss: 2.0426\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4188\tTop_Loss: 0.4041\tBottom_Loss: 0.4679\tLoss: 1.2909\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3426\tTop_Loss: 0.5055\tBottom_Loss: 0.4690\tLoss: 1.3171\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2919\tTop_Loss: 0.4562\tBottom_Loss: 0.3707\tLoss: 1.1188\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4259\tTop_Loss: 0.4355\tBottom_Loss: 0.5266\tLoss: 1.3880\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4386\tTop_Loss: 0.5059\tBottom_Loss: 0.6277\tLoss: 1.5721\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2629\tTop_Loss: 0.4610\tBottom_Loss: 0.3951\tLoss: 1.1190\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 1.000\tLabel_Loss: 0.2152\tTop_Loss: 0.3386\tBottom_Loss: 0.3593\tLoss: 0.9130\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4972\tTop_Loss: 0.5585\tBottom_Loss: 0.5791\tLoss: 1.6349\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3153\tTop_Loss: 0.6365\tBottom_Loss: 0.4854\tLoss: 1.4372\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2604\tTop_Loss: 0.4475\tBottom_Loss: 0.3497\tLoss: 1.0576\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4571\tTop_Loss: 0.6689\tBottom_Loss: 0.4986\tLoss: 1.6246\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1854\tTop_Loss: 0.3101\tBottom_Loss: 0.3541\tLoss: 0.8497\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3478\tTop_Loss: 0.4787\tBottom_Loss: 0.4130\tLoss: 1.2394\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3026\tTop_Loss: 0.4034\tBottom_Loss: 0.4532\tLoss: 1.1592\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2839\tTop_Loss: 0.5479\tBottom_Loss: 0.3937\tLoss: 1.2255\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.844\tLabel_Loss: 0.2705\tTop_Loss: 0.4187\tBottom_Loss: 0.3412\tLoss: 1.0304\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3064\tTop_Loss: 0.3948\tBottom_Loss: 0.3169\tLoss: 1.0181\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2141\tTop_Loss: 0.3667\tBottom_Loss: 0.4405\tLoss: 1.0213\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3770\tTop_Loss: 0.5399\tBottom_Loss: 0.4507\tLoss: 1.3676\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.938\tLabel_Loss: 0.3354\tTop_Loss: 0.4232\tBottom_Loss: 0.5392\tLoss: 1.2978\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2321\tTop_Loss: 0.3395\tBottom_Loss: 0.3314\tLoss: 0.9030\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2490\tTop_Loss: 0.5005\tBottom_Loss: 0.3835\tLoss: 1.1331\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1918\tTop_Loss: 0.3755\tBottom_Loss: 0.3196\tLoss: 0.8869\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2740\tTop_Loss: 0.3934\tBottom_Loss: 0.4351\tLoss: 1.1025\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3127\tTop_Loss: 0.4723\tBottom_Loss: 0.3960\tLoss: 1.1809\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1993\tTop_Loss: 0.3083\tBottom_Loss: 0.3253\tLoss: 0.8329\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2834\tTop_Loss: 0.4873\tBottom_Loss: 0.3895\tLoss: 1.1601\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2071\tTop_Loss: 0.4482\tBottom_Loss: 0.2846\tLoss: 0.9399\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3496\tTop_Loss: 0.4841\tBottom_Loss: 0.4429\tLoss: 1.2766\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.938\tLabel_Loss: 0.3023\tTop_Loss: 0.3563\tBottom_Loss: 0.3172\tLoss: 0.9758\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2016\tTop_Loss: 0.2364\tBottom_Loss: 0.2910\tLoss: 0.7290\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2039\tTop_Loss: 0.3317\tBottom_Loss: 0.3150\tLoss: 0.8506\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1733\tTop_Loss: 0.2673\tBottom_Loss: 0.2413\tLoss: 0.6818\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1840\tTop_Loss: 0.1705\tBottom_Loss: 0.3123\tLoss: 0.6668\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2674\tTop_Loss: 0.4316\tBottom_Loss: 0.3498\tLoss: 1.0488\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1195\tTop_Loss: 0.1453\tBottom_Loss: 0.2256\tLoss: 0.4904\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.750\tLabel_Loss: 0.3868\tTop_Loss: 0.4172\tBottom_Loss: 0.6197\tLoss: 1.4236\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1610\tTop_Loss: 0.4157\tBottom_Loss: 0.3037\tLoss: 0.8805\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1144\tTop_Loss: 0.3225\tBottom_Loss: 0.2620\tLoss: 0.6990\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1691\tTop_Loss: 0.4148\tBottom_Loss: 0.3658\tLoss: 0.9497\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2149\tTop_Loss: 0.3304\tBottom_Loss: 0.2691\tLoss: 0.8144\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1327\tTop_Loss: 0.1994\tBottom_Loss: 0.3094\tLoss: 0.6414\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1112\tTop_Loss: 0.2305\tBottom_Loss: 0.2520\tLoss: 0.5937\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1512\tTop_Loss: 0.3189\tBottom_Loss: 0.2575\tLoss: 0.7276\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1953\tTop_Loss: 0.3257\tBottom_Loss: 0.2938\tLoss: 0.8147\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1348\tTop_Loss: 0.3941\tBottom_Loss: 0.1833\tLoss: 0.7122\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0840\tTop_Loss: 0.2542\tBottom_Loss: 0.1965\tLoss: 0.5346\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0947\tTop_Loss: 0.2110\tBottom_Loss: 0.1704\tLoss: 0.4761\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1547\tTop_Loss: 0.1623\tBottom_Loss: 0.3304\tLoss: 0.6474\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2341\tTop_Loss: 0.2718\tBottom_Loss: 0.3170\tLoss: 0.8229\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1521\tTop_Loss: 0.5078\tBottom_Loss: 0.1803\tLoss: 0.8403\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1330\tTop_Loss: 0.1621\tBottom_Loss: 0.2756\tLoss: 0.5707\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1535\tTop_Loss: 0.3060\tBottom_Loss: 0.2036\tLoss: 0.6632\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1469\tTop_Loss: 0.2103\tBottom_Loss: 0.1411\tLoss: 0.4983\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1090\tTop_Loss: 0.2300\tBottom_Loss: 0.1905\tLoss: 0.5295\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1221\tTop_Loss: 0.2800\tBottom_Loss: 0.1607\tLoss: 0.5628\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1445\tTop_Loss: 0.2926\tBottom_Loss: 0.1651\tLoss: 0.6022\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1908\tTop_Loss: 0.2288\tBottom_Loss: 0.2656\tLoss: 0.6851\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1213\tTop_Loss: 0.1915\tBottom_Loss: 0.1996\tLoss: 0.5124\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1135\tTop_Loss: 0.1637\tBottom_Loss: 0.1674\tLoss: 0.4445\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0881\tTop_Loss: 0.1692\tBottom_Loss: 0.1023\tLoss: 0.3595\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0951\tTop_Loss: 0.2604\tBottom_Loss: 0.1304\tLoss: 0.4859\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0550\tTop_Loss: 0.1621\tBottom_Loss: 0.1373\tLoss: 0.3544\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0728\tTop_Loss: 0.2200\tBottom_Loss: 0.1779\tLoss: 0.4707\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0881\tTop_Loss: 0.2359\tBottom_Loss: 0.1730\tLoss: 0.4971\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1024\tTop_Loss: 0.1083\tBottom_Loss: 0.3021\tLoss: 0.5127\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0819\tTop_Loss: 0.1440\tBottom_Loss: 0.1485\tLoss: 0.3744\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1000\tTop_Loss: 0.2572\tBottom_Loss: 0.1631\tLoss: 0.5203\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1232\tTop_Loss: 0.2200\tBottom_Loss: 0.2399\tLoss: 0.5831\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1017\tTop_Loss: 0.1946\tBottom_Loss: 0.1291\tLoss: 0.4255\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0526\tTop_Loss: 0.2053\tBottom_Loss: 0.1106\tLoss: 0.3685\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0903\tTop_Loss: 0.1761\tBottom_Loss: 0.1839\tLoss: 0.4503\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1080\tTop_Loss: 0.1992\tBottom_Loss: 0.2241\tLoss: 0.5313\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1478\tTop_Loss: 0.2863\tBottom_Loss: 0.3178\tLoss: 0.7518\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0628\tTop_Loss: 0.1577\tBottom_Loss: 0.1280\tLoss: 0.3484\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[62][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0338\tTop_Loss: 0.1557\tBottom_Loss: 0.0878\tLoss: 0.2774\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0673\tTop_Loss: 0.1342\tBottom_Loss: 0.1305\tLoss: 0.3320\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0589\tTop_Loss: 0.2558\tBottom_Loss: 0.0766\tLoss: 0.3912\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0767\tTop_Loss: 0.2171\tBottom_Loss: 0.1551\tLoss: 0.4489\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0983\tTop_Loss: 0.2501\tBottom_Loss: 0.2352\tLoss: 0.5836\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0507\tTop_Loss: 0.1688\tBottom_Loss: 0.1058\tLoss: 0.3253\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0851\tTop_Loss: 0.1881\tBottom_Loss: 0.1481\tLoss: 0.4213\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0445\tTop_Loss: 0.1737\tBottom_Loss: 0.0707\tLoss: 0.2890\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0457\tTop_Loss: 0.1723\tBottom_Loss: 0.0957\tLoss: 0.3137\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0775\tTop_Loss: 0.2058\tBottom_Loss: 0.1189\tLoss: 0.4022\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0433\tTop_Loss: 0.1105\tBottom_Loss: 0.1305\tLoss: 0.2843\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0770\tTop_Loss: 0.1462\tBottom_Loss: 0.1770\tLoss: 0.4002\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0354\tTop_Loss: 0.1188\tBottom_Loss: 0.0646\tLoss: 0.2187\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0362\tTop_Loss: 0.1492\tBottom_Loss: 0.0950\tLoss: 0.2803\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0829\tTop_Loss: 0.3021\tBottom_Loss: 0.0977\tLoss: 0.4827\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0375\tTop_Loss: 0.0737\tBottom_Loss: 0.1109\tLoss: 0.2221\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1688\tTop_Loss: 0.2178\tBottom_Loss: 0.2829\tLoss: 0.6695\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0584\tTop_Loss: 0.0749\tBottom_Loss: 0.1224\tLoss: 0.2557\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0900\tTop_Loss: 0.2363\tBottom_Loss: 0.1477\tLoss: 0.4739\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0219\tTop_Loss: 0.1088\tBottom_Loss: 0.0637\tLoss: 0.1944\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0861\tTop_Loss: 0.1617\tBottom_Loss: 0.0787\tLoss: 0.3264\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0975\tTop_Loss: 0.2504\tBottom_Loss: 0.0710\tLoss: 0.4190\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0169\tTop_Loss: 0.0976\tBottom_Loss: 0.0537\tLoss: 0.1681\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0564\tTop_Loss: 0.0601\tBottom_Loss: 0.1105\tLoss: 0.2270\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0151\tTop_Loss: 0.0648\tBottom_Loss: 0.0539\tLoss: 0.1338\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0561\tTop_Loss: 0.0800\tBottom_Loss: 0.0904\tLoss: 0.2265\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0188\tTop_Loss: 0.0925\tBottom_Loss: 0.0605\tLoss: 0.1718\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0606\tTop_Loss: 0.1322\tBottom_Loss: 0.1153\tLoss: 0.3081\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0473\tTop_Loss: 0.1289\tBottom_Loss: 0.1274\tLoss: 0.3036\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0328\tTop_Loss: 0.1222\tBottom_Loss: 0.0736\tLoss: 0.2287\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0374\tTop_Loss: 0.0509\tBottom_Loss: 0.1454\tLoss: 0.2338\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0321\tTop_Loss: 0.0902\tBottom_Loss: 0.0884\tLoss: 0.2107\t\n",
      "Subject: 07, n=05 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0207\tTop_Loss: 0.0554\tBottom_Loss: 0.1109\tLoss: 0.1869\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0260\tTop_Loss: 0.0887\tBottom_Loss: 0.0883\tLoss: 0.2030\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0336\tTop_Loss: 0.1136\tBottom_Loss: 0.0590\tLoss: 0.2062\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0283\tTop_Loss: 0.0993\tBottom_Loss: 0.0520\tLoss: 0.1796\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0639\tTop_Loss: 0.1174\tBottom_Loss: 0.0986\tLoss: 0.2799\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0196\tTop_Loss: 0.0971\tBottom_Loss: 0.0472\tLoss: 0.1639\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0291\tTop_Loss: 0.0627\tBottom_Loss: 0.0611\tLoss: 0.1529\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0293\tTop_Loss: 0.1274\tBottom_Loss: 0.0725\tLoss: 0.2292\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0209\tTop_Loss: 0.0880\tBottom_Loss: 0.0639\tLoss: 0.1728\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0717\tTop_Loss: 0.0940\tBottom_Loss: 0.0632\tLoss: 0.2290\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0187\tTop_Loss: 0.0401\tBottom_Loss: 0.1275\tLoss: 0.1864\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0165\tTop_Loss: 0.1248\tBottom_Loss: 0.0331\tLoss: 0.1744\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0332\tTop_Loss: 0.0771\tBottom_Loss: 0.0768\tLoss: 0.1870\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0221\tTop_Loss: 0.0598\tBottom_Loss: 0.0529\tLoss: 0.1349\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0294\tTop_Loss: 0.1230\tBottom_Loss: 0.0834\tLoss: 0.2358\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0182\tTop_Loss: 0.0689\tBottom_Loss: 0.0376\tLoss: 0.1247\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0214\tTop_Loss: 0.0263\tBottom_Loss: 0.1178\tLoss: 0.1655\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0406\tTop_Loss: 0.0443\tBottom_Loss: 0.1175\tLoss: 0.2024\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0433\tTop_Loss: 0.0662\tBottom_Loss: 0.0825\tLoss: 0.1920\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0094\tTop_Loss: 0.0505\tBottom_Loss: 0.0460\tLoss: 0.1059\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0209\tTop_Loss: 0.0697\tBottom_Loss: 0.0649\tLoss: 0.1554\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0060\tTop_Loss: 0.0303\tBottom_Loss: 0.0179\tLoss: 0.0541\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0704\tTop_Loss: 0.1109\tBottom_Loss: 0.0837\tLoss: 0.2650\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0462\tTop_Loss: 0.0863\tBottom_Loss: 0.0281\tLoss: 0.1606\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0131\tTop_Loss: 0.1054\tBottom_Loss: 0.0388\tLoss: 0.1573\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0368\tTop_Loss: 0.1014\tBottom_Loss: 0.0925\tLoss: 0.2307\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0106\tTop_Loss: 0.0903\tBottom_Loss: 0.0256\tLoss: 0.1265\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0152\tTop_Loss: 0.0590\tBottom_Loss: 0.0323\tLoss: 0.1065\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0244\tTop_Loss: 0.1146\tBottom_Loss: 0.0361\tLoss: 0.1750\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0159\tTop_Loss: 0.0516\tBottom_Loss: 0.0424\tLoss: 0.1098\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0293\tTop_Loss: 0.0647\tBottom_Loss: 0.0468\tLoss: 0.1407\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0112\tTop_Loss: 0.0386\tBottom_Loss: 0.0177\tLoss: 0.0675\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0387\tTop_Loss: 0.0351\tBottom_Loss: 0.1375\tLoss: 0.2114\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0127\tTop_Loss: 0.0867\tBottom_Loss: 0.0145\tLoss: 0.1139\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0115\tTop_Loss: 0.0728\tBottom_Loss: 0.0281\tLoss: 0.1124\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0379\tTop_Loss: 0.0576\tBottom_Loss: 0.0763\tLoss: 0.1717\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0083\tTop_Loss: 0.0335\tBottom_Loss: 0.0256\tLoss: 0.0674\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0203\tTop_Loss: 0.0426\tBottom_Loss: 0.0562\tLoss: 0.1191\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0088\tTop_Loss: 0.0402\tBottom_Loss: 0.0160\tLoss: 0.0650\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0113\tTop_Loss: 0.0291\tBottom_Loss: 0.0288\tLoss: 0.0693\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0140\tTop_Loss: 0.0267\tBottom_Loss: 0.0341\tLoss: 0.0749\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0091\tTop_Loss: 0.0934\tBottom_Loss: 0.0280\tLoss: 0.1304\t\n",
      "Subject: 07, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0189\tTop_Loss: 0.0685\tBottom_Loss: 0.0344\tLoss: 0.1217\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0076\tTop_Loss: 0.0152\tBottom_Loss: 0.0399\tLoss: 0.0627\t\n",
      "Subject: 07, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.094\tLabel_Loss: 1.7264\tTop_Loss: 1.1584\tBottom_Loss: 1.1337\tLoss: 4.0186\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.438\tLabel_Loss: 1.2033\tTop_Loss: 1.2439\tBottom_Loss: 1.1883\tLoss: 3.6355\t\n",
      "Subject: 08, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.625\tLabel_Loss: 1.0365\tTop_Loss: 0.9882\tBottom_Loss: 1.0890\tLoss: 3.1137\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.500\tLabel_Loss: 1.1689\tTop_Loss: 1.0655\tBottom_Loss: 1.1520\tLoss: 3.3864\t\n",
      "Subject: 08, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.500\tLabel_Loss: 1.0278\tTop_Loss: 0.8863\tBottom_Loss: 0.9047\tLoss: 2.8187\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.531\tLabel_Loss: 0.9703\tTop_Loss: 1.0073\tBottom_Loss: 1.0101\tLoss: 2.9877\t\n",
      "Subject: 08, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.531\tLabel_Loss: 0.9175\tTop_Loss: 0.8369\tBottom_Loss: 0.8529\tLoss: 2.6073\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.500\tLabel_Loss: 0.9104\tTop_Loss: 0.8689\tBottom_Loss: 0.9493\tLoss: 2.7286\t\n",
      "Subject: 08, n=01 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.719\tLabel_Loss: 0.8130\tTop_Loss: 0.9333\tBottom_Loss: 1.0347\tLoss: 2.7810\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.531\tLabel_Loss: 0.9773\tTop_Loss: 0.8669\tBottom_Loss: 1.0751\tLoss: 2.9193\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.562\tLabel_Loss: 1.0851\tTop_Loss: 1.1245\tBottom_Loss: 1.0349\tLoss: 3.2444\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8153\tTop_Loss: 0.7735\tBottom_Loss: 0.8203\tLoss: 2.4091\t\n",
      "Subject: 08, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.469\tLabel_Loss: 0.9678\tTop_Loss: 0.8115\tBottom_Loss: 0.9519\tLoss: 2.7312\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5825\tTop_Loss: 0.7984\tBottom_Loss: 0.7658\tLoss: 2.1467\t\n",
      "Subject: 08, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.531\tLabel_Loss: 0.9675\tTop_Loss: 1.2094\tBottom_Loss: 1.2199\tLoss: 3.3969\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7202\tTop_Loss: 1.0161\tBottom_Loss: 0.7795\tLoss: 2.5157\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.656\tLabel_Loss: 0.8348\tTop_Loss: 0.8757\tBottom_Loss: 0.8979\tLoss: 2.6083\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.594\tLabel_Loss: 0.7650\tTop_Loss: 0.7231\tBottom_Loss: 0.8567\tLoss: 2.3448\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.594\tLabel_Loss: 0.7970\tTop_Loss: 0.7821\tBottom_Loss: 0.9812\tLoss: 2.5602\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6756\tTop_Loss: 0.9338\tBottom_Loss: 0.5776\tLoss: 2.1869\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7527\tTop_Loss: 0.9009\tBottom_Loss: 0.8547\tLoss: 2.5083\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7930\tTop_Loss: 0.7724\tBottom_Loss: 1.1495\tLoss: 2.7150\t\n",
      "Subject: 08, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.844\tLabel_Loss: 0.5512\tTop_Loss: 0.7370\tBottom_Loss: 0.6483\tLoss: 1.9366\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6157\tTop_Loss: 0.9238\tBottom_Loss: 0.9472\tLoss: 2.4867\t\n",
      "Subject: 08, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6623\tTop_Loss: 0.7830\tBottom_Loss: 0.7516\tLoss: 2.1969\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7660\tTop_Loss: 0.6984\tBottom_Loss: 0.8613\tLoss: 2.3257\t\n",
      "Subject: 08, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6122\tTop_Loss: 0.6919\tBottom_Loss: 0.7313\tLoss: 2.0354\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5778\tTop_Loss: 0.8059\tBottom_Loss: 0.6233\tLoss: 2.0070\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5421\tTop_Loss: 0.6894\tBottom_Loss: 0.6036\tLoss: 1.8351\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5748\tTop_Loss: 0.7597\tBottom_Loss: 0.6629\tLoss: 1.9974\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5503\tTop_Loss: 0.7268\tBottom_Loss: 0.5568\tLoss: 1.8338\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5828\tTop_Loss: 0.6690\tBottom_Loss: 0.6772\tLoss: 1.9290\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4923\tTop_Loss: 0.6754\tBottom_Loss: 0.5827\tLoss: 1.7504\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4928\tTop_Loss: 0.5103\tBottom_Loss: 0.6221\tLoss: 1.6253\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7900\tTop_Loss: 1.0549\tBottom_Loss: 0.8292\tLoss: 2.6742\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.844\tLabel_Loss: 0.5165\tTop_Loss: 0.6061\tBottom_Loss: 0.5789\tLoss: 1.7015\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5937\tTop_Loss: 0.6375\tBottom_Loss: 0.7528\tLoss: 1.9840\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.688\tLabel_Loss: 0.5887\tTop_Loss: 0.8132\tBottom_Loss: 0.8727\tLoss: 2.2746\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3656\tTop_Loss: 0.4858\tBottom_Loss: 0.5168\tLoss: 1.3682\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.625\tLabel_Loss: 0.6909\tTop_Loss: 0.7223\tBottom_Loss: 0.8331\tLoss: 2.2463\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4793\tTop_Loss: 0.6532\tBottom_Loss: 0.6186\tLoss: 1.7511\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.906\tLabel_Loss: 0.4257\tTop_Loss: 0.4959\tBottom_Loss: 0.7154\tLoss: 1.6370\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5019\tTop_Loss: 0.6903\tBottom_Loss: 0.5536\tLoss: 1.7459\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5947\tTop_Loss: 0.6529\tBottom_Loss: 0.6061\tLoss: 1.8537\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4878\tTop_Loss: 0.5184\tBottom_Loss: 0.7339\tLoss: 1.7401\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.969\tLabel_Loss: 0.3114\tTop_Loss: 0.4049\tBottom_Loss: 0.5151\tLoss: 1.2314\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4516\tTop_Loss: 0.5484\tBottom_Loss: 0.5563\tLoss: 1.5564\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2729\tTop_Loss: 0.4555\tBottom_Loss: 0.4357\tLoss: 1.1642\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.688\tLabel_Loss: 0.5139\tTop_Loss: 0.6233\tBottom_Loss: 0.5806\tLoss: 1.7178\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3268\tTop_Loss: 0.4574\tBottom_Loss: 0.4664\tLoss: 1.2506\t\n",
      "Subject: 08, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2100\tTop_Loss: 0.3360\tBottom_Loss: 0.3627\tLoss: 0.9087\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4415\tTop_Loss: 0.5816\tBottom_Loss: 0.4221\tLoss: 1.4452\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3204\tTop_Loss: 0.5607\tBottom_Loss: 0.4316\tLoss: 1.3126\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5927\tTop_Loss: 0.7045\tBottom_Loss: 0.6490\tLoss: 1.9462\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3316\tTop_Loss: 0.4780\tBottom_Loss: 0.5255\tLoss: 1.3352\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3642\tTop_Loss: 0.4197\tBottom_Loss: 0.4418\tLoss: 1.2257\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2205\tTop_Loss: 0.3479\tBottom_Loss: 0.5086\tLoss: 1.0769\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3543\tTop_Loss: 0.5515\tBottom_Loss: 0.5148\tLoss: 1.4207\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5158\tTop_Loss: 0.7276\tBottom_Loss: 0.6343\tLoss: 1.8778\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.938\tLabel_Loss: 0.3323\tTop_Loss: 0.4242\tBottom_Loss: 0.4729\tLoss: 1.2294\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4157\tTop_Loss: 0.7666\tBottom_Loss: 0.4359\tLoss: 1.6181\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2522\tTop_Loss: 0.4755\tBottom_Loss: 0.4648\tLoss: 1.1926\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2373\tTop_Loss: 0.3781\tBottom_Loss: 0.2917\tLoss: 0.9071\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1912\tTop_Loss: 0.3376\tBottom_Loss: 0.2145\tLoss: 0.7433\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4514\tTop_Loss: 0.5632\tBottom_Loss: 0.5838\tLoss: 1.5983\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2466\tTop_Loss: 0.3104\tBottom_Loss: 0.3401\tLoss: 0.8970\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2543\tTop_Loss: 0.5339\tBottom_Loss: 0.3793\tLoss: 1.1675\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2995\tTop_Loss: 0.4537\tBottom_Loss: 0.2935\tLoss: 1.0467\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1863\tTop_Loss: 0.3123\tBottom_Loss: 0.2209\tLoss: 0.7195\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2707\tTop_Loss: 0.5163\tBottom_Loss: 0.3415\tLoss: 1.1284\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2554\tTop_Loss: 0.4132\tBottom_Loss: 0.3582\tLoss: 1.0268\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1570\tTop_Loss: 0.4165\tBottom_Loss: 0.3124\tLoss: 0.8859\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2084\tTop_Loss: 0.3217\tBottom_Loss: 0.3149\tLoss: 0.8450\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2150\tTop_Loss: 0.4025\tBottom_Loss: 0.3595\tLoss: 0.9770\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1713\tTop_Loss: 0.4235\tBottom_Loss: 0.2763\tLoss: 0.8711\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2005\tTop_Loss: 0.3728\tBottom_Loss: 0.4655\tLoss: 1.0388\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2171\tTop_Loss: 0.4811\tBottom_Loss: 0.2148\tLoss: 0.9130\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2971\tTop_Loss: 0.5023\tBottom_Loss: 0.3121\tLoss: 1.1116\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.812\tLabel_Loss: 0.2984\tTop_Loss: 0.3468\tBottom_Loss: 0.3850\tLoss: 1.0303\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1538\tTop_Loss: 0.3674\tBottom_Loss: 0.2455\tLoss: 0.7667\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1904\tTop_Loss: 0.2884\tBottom_Loss: 0.2591\tLoss: 0.7379\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1648\tTop_Loss: 0.2724\tBottom_Loss: 0.2115\tLoss: 0.6487\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1165\tTop_Loss: 0.2457\tBottom_Loss: 0.2566\tLoss: 0.6189\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2418\tTop_Loss: 0.5271\tBottom_Loss: 0.3410\tLoss: 1.1099\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1288\tTop_Loss: 0.2927\tBottom_Loss: 0.2214\tLoss: 0.6429\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0636\tTop_Loss: 0.2969\tBottom_Loss: 0.1529\tLoss: 0.5134\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2121\tTop_Loss: 0.4720\tBottom_Loss: 0.3872\tLoss: 1.0712\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1673\tTop_Loss: 0.2027\tBottom_Loss: 0.2520\tLoss: 0.6220\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3350\tTop_Loss: 0.4029\tBottom_Loss: 0.4821\tLoss: 1.2201\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2209\tTop_Loss: 0.3965\tBottom_Loss: 0.1981\tLoss: 0.8154\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0855\tTop_Loss: 0.1904\tBottom_Loss: 0.1920\tLoss: 0.4679\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1906\tTop_Loss: 0.2900\tBottom_Loss: 0.2477\tLoss: 0.7283\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1099\tTop_Loss: 0.2967\tBottom_Loss: 0.2276\tLoss: 0.6342\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1135\tTop_Loss: 0.3123\tBottom_Loss: 0.1724\tLoss: 0.5982\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1716\tTop_Loss: 0.3133\tBottom_Loss: 0.2745\tLoss: 0.7593\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2003\tTop_Loss: 0.3552\tBottom_Loss: 0.3024\tLoss: 0.8579\t\n",
      "Subject: 08, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2081\tTop_Loss: 0.3481\tBottom_Loss: 0.1800\tLoss: 0.7362\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1439\tTop_Loss: 0.2711\tBottom_Loss: 0.1946\tLoss: 0.6096\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0959\tTop_Loss: 0.2578\tBottom_Loss: 0.1005\tLoss: 0.4542\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2675\tTop_Loss: 0.3090\tBottom_Loss: 0.2957\tLoss: 0.8722\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1250\tTop_Loss: 0.4129\tBottom_Loss: 0.1341\tLoss: 0.6720\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1954\tTop_Loss: 0.3200\tBottom_Loss: 0.3381\tLoss: 0.8535\t\n",
      "Subject: 08, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.844\tLabel_Loss: 0.2579\tTop_Loss: 0.3137\tBottom_Loss: 0.2992\tLoss: 0.8709\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0940\tTop_Loss: 0.1777\tBottom_Loss: 0.2163\tLoss: 0.4881\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0826\tTop_Loss: 0.2483\tBottom_Loss: 0.1431\tLoss: 0.4740\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1461\tTop_Loss: 0.2092\tBottom_Loss: 0.2004\tLoss: 0.5557\t\n",
      "Subject: 08, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1571\tTop_Loss: 0.4593\tBottom_Loss: 0.1233\tLoss: 0.7397\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0483\tTop_Loss: 0.1476\tBottom_Loss: 0.1152\tLoss: 0.3111\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1583\tTop_Loss: 0.2366\tBottom_Loss: 0.1173\tLoss: 0.5123\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0823\tTop_Loss: 0.1859\tBottom_Loss: 0.1289\tLoss: 0.3971\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0781\tTop_Loss: 0.2024\tBottom_Loss: 0.1803\tLoss: 0.4608\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1492\tTop_Loss: 0.2234\tBottom_Loss: 0.1347\tLoss: 0.5074\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 08, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0716\tTop_Loss: 0.1563\tBottom_Loss: 0.0890\tLoss: 0.3170\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0613\tTop_Loss: 0.2356\tBottom_Loss: 0.0977\tLoss: 0.3947\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0658\tTop_Loss: 0.2515\tBottom_Loss: 0.0714\tLoss: 0.3888\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1023\tTop_Loss: 0.2164\tBottom_Loss: 0.0866\tLoss: 0.4053\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0782\tTop_Loss: 0.2476\tBottom_Loss: 0.1678\tLoss: 0.4936\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 0.938\tLabel_Loss: 0.0907\tTop_Loss: 0.1670\tBottom_Loss: 0.1156\tLoss: 0.3733\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0697\tTop_Loss: 0.2026\tBottom_Loss: 0.0973\tLoss: 0.3696\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1130\tTop_Loss: 0.2736\tBottom_Loss: 0.1517\tLoss: 0.5383\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0746\tTop_Loss: 0.2214\tBottom_Loss: 0.1181\tLoss: 0.4141\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0714\tTop_Loss: 0.1443\tBottom_Loss: 0.0908\tLoss: 0.3066\t\n",
      "Subject: 08, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0790\tTop_Loss: 0.2214\tBottom_Loss: 0.1074\tLoss: 0.4078\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0543\tTop_Loss: 0.1390\tBottom_Loss: 0.1203\tLoss: 0.3136\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1226\tTop_Loss: 0.1963\tBottom_Loss: 0.1883\tLoss: 0.5072\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0872\tTop_Loss: 0.3089\tBottom_Loss: 0.1164\tLoss: 0.5126\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0334\tTop_Loss: 0.1078\tBottom_Loss: 0.0713\tLoss: 0.2125\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0926\tTop_Loss: 0.2045\tBottom_Loss: 0.0766\tLoss: 0.3736\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0388\tTop_Loss: 0.1410\tBottom_Loss: 0.0858\tLoss: 0.2655\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1780\tTop_Loss: 0.2588\tBottom_Loss: 0.2017\tLoss: 0.6384\t\n",
      "Subject: 08, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1109\tTop_Loss: 0.3023\tBottom_Loss: 0.1323\tLoss: 0.5455\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0868\tTop_Loss: 0.2044\tBottom_Loss: 0.1954\tLoss: 0.4865\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0278\tTop_Loss: 0.1607\tBottom_Loss: 0.1205\tLoss: 0.3090\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0785\tTop_Loss: 0.1599\tBottom_Loss: 0.1557\tLoss: 0.3942\t\n",
      "Subject: 08, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1361\tTop_Loss: 0.2022\tBottom_Loss: 0.2353\tLoss: 0.5736\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0340\tTop_Loss: 0.1207\tBottom_Loss: 0.0903\tLoss: 0.2450\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0349\tTop_Loss: 0.1247\tBottom_Loss: 0.0987\tLoss: 0.2583\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0553\tTop_Loss: 0.1972\tBottom_Loss: 0.0955\tLoss: 0.3480\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0465\tTop_Loss: 0.1155\tBottom_Loss: 0.1598\tLoss: 0.3217\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0258\tTop_Loss: 0.1373\tBottom_Loss: 0.0468\tLoss: 0.2099\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0520\tTop_Loss: 0.0916\tBottom_Loss: 0.1001\tLoss: 0.2437\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0349\tTop_Loss: 0.1390\tBottom_Loss: 0.0641\tLoss: 0.2379\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1176\tTop_Loss: 0.1951\tBottom_Loss: 0.1527\tLoss: 0.4654\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0424\tTop_Loss: 0.1106\tBottom_Loss: 0.0974\tLoss: 0.2505\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0321\tTop_Loss: 0.1459\tBottom_Loss: 0.1066\tLoss: 0.2845\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0580\tTop_Loss: 0.1062\tBottom_Loss: 0.0396\tLoss: 0.2038\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0294\tTop_Loss: 0.1036\tBottom_Loss: 0.0636\tLoss: 0.1966\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0434\tTop_Loss: 0.1138\tBottom_Loss: 0.0755\tLoss: 0.2327\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0863\tTop_Loss: 0.1940\tBottom_Loss: 0.0876\tLoss: 0.3680\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0157\tTop_Loss: 0.0520\tBottom_Loss: 0.0533\tLoss: 0.1211\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0173\tTop_Loss: 0.0517\tBottom_Loss: 0.0386\tLoss: 0.1077\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0254\tTop_Loss: 0.1111\tBottom_Loss: 0.0813\tLoss: 0.2178\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0403\tTop_Loss: 0.0599\tBottom_Loss: 0.0858\tLoss: 0.1860\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0204\tTop_Loss: 0.1225\tBottom_Loss: 0.0631\tLoss: 0.2060\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0238\tTop_Loss: 0.0732\tBottom_Loss: 0.0889\tLoss: 0.1859\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1404\tTop_Loss: 0.1849\tBottom_Loss: 0.1824\tLoss: 0.5076\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0415\tTop_Loss: 0.1609\tBottom_Loss: 0.0708\tLoss: 0.2732\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0135\tTop_Loss: 0.0452\tBottom_Loss: 0.0327\tLoss: 0.0914\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0274\tTop_Loss: 0.0920\tBottom_Loss: 0.0899\tLoss: 0.2092\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0079\tTop_Loss: 0.0484\tBottom_Loss: 0.0231\tLoss: 0.0794\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0620\tTop_Loss: 0.1989\tBottom_Loss: 0.0576\tLoss: 0.3185\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0452\tTop_Loss: 0.0451\tBottom_Loss: 0.0689\tLoss: 0.1592\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0456\tTop_Loss: 0.1536\tBottom_Loss: 0.0761\tLoss: 0.2752\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0068\tTop_Loss: 0.0389\tBottom_Loss: 0.0206\tLoss: 0.0663\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0139\tTop_Loss: 0.0490\tBottom_Loss: 0.0268\tLoss: 0.0897\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0246\tTop_Loss: 0.0443\tBottom_Loss: 0.1630\tLoss: 0.2320\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0078\tTop_Loss: 0.0438\tBottom_Loss: 0.0271\tLoss: 0.0787\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0246\tTop_Loss: 0.0439\tBottom_Loss: 0.0488\tLoss: 0.1173\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0371\tTop_Loss: 0.1111\tBottom_Loss: 0.0512\tLoss: 0.1994\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0170\tTop_Loss: 0.0640\tBottom_Loss: 0.0558\tLoss: 0.1368\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0148\tTop_Loss: 0.0785\tBottom_Loss: 0.0185\tLoss: 0.1118\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1203\tTop_Loss: 0.1987\tBottom_Loss: 0.1000\tLoss: 0.4190\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0370\tTop_Loss: 0.1328\tBottom_Loss: 0.0384\tLoss: 0.2081\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0290\tTop_Loss: 0.0825\tBottom_Loss: 0.0297\tLoss: 0.1412\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0239\tTop_Loss: 0.0544\tBottom_Loss: 0.0565\tLoss: 0.1347\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0208\tTop_Loss: 0.0555\tBottom_Loss: 0.0369\tLoss: 0.1132\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0402\tTop_Loss: 0.1154\tBottom_Loss: 0.0594\tLoss: 0.2150\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0088\tTop_Loss: 0.0848\tBottom_Loss: 0.0338\tLoss: 0.1274\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0149\tTop_Loss: 0.0419\tBottom_Loss: 0.0607\tLoss: 0.1175\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0416\tTop_Loss: 0.1587\tBottom_Loss: 0.0291\tLoss: 0.2293\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0082\tTop_Loss: 0.0303\tBottom_Loss: 0.0224\tLoss: 0.0609\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0493\tTop_Loss: 0.0961\tBottom_Loss: 0.1015\tLoss: 0.2469\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0265\tTop_Loss: 0.0731\tBottom_Loss: 0.0261\tLoss: 0.1257\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0118\tTop_Loss: 0.1018\tBottom_Loss: 0.0286\tLoss: 0.1423\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0136\tTop_Loss: 0.0769\tBottom_Loss: 0.0211\tLoss: 0.1116\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0115\tTop_Loss: 0.0351\tBottom_Loss: 0.0466\tLoss: 0.0932\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0083\tTop_Loss: 0.0288\tBottom_Loss: 0.0328\tLoss: 0.0699\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0079\tTop_Loss: 0.0343\tBottom_Loss: 0.0134\tLoss: 0.0555\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0054\tTop_Loss: 0.0357\tBottom_Loss: 0.0295\tLoss: 0.0705\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0055\tTop_Loss: 0.0587\tBottom_Loss: 0.0159\tLoss: 0.0801\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0113\tTop_Loss: 0.0411\tBottom_Loss: 0.0289\tLoss: 0.0813\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0203\tTop_Loss: 0.0830\tBottom_Loss: 0.0362\tLoss: 0.1396\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0029\tTop_Loss: 0.0264\tBottom_Loss: 0.0122\tLoss: 0.0414\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0037\tTop_Loss: 0.0208\tBottom_Loss: 0.0131\tLoss: 0.0376\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0033\tTop_Loss: 0.0306\tBottom_Loss: 0.0074\tLoss: 0.0413\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0103\tTop_Loss: 0.0437\tBottom_Loss: 0.0607\tLoss: 0.1147\t\n",
      "Subject: 08, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0165\tTop_Loss: 0.0483\tBottom_Loss: 0.0559\tLoss: 0.1207\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0119\tTop_Loss: 0.0343\tBottom_Loss: 0.0153\tLoss: 0.0615\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0067\tTop_Loss: 0.0384\tBottom_Loss: 0.0299\tLoss: 0.0749\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0116\tTop_Loss: 0.0190\tBottom_Loss: 0.0352\tLoss: 0.0658\t\n",
      "Subject: 08, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.281\tLabel_Loss: 1.5553\tTop_Loss: 1.4354\tBottom_Loss: 1.2291\tLoss: 4.2197\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.531\tLabel_Loss: 1.0544\tTop_Loss: 1.3443\tBottom_Loss: 0.9530\tLoss: 3.3517\t\n",
      "Subject: 09, n=10 | test_f1: 0.28571 |best_f1: 0.28571\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.594\tLabel_Loss: 1.0553\tTop_Loss: 1.0814\tBottom_Loss: 0.9480\tLoss: 3.0847\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.594\tLabel_Loss: 0.9673\tTop_Loss: 1.0366\tBottom_Loss: 0.9814\tLoss: 2.9852\t\n",
      "Subject: 09, n=10 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.438\tLabel_Loss: 1.1319\tTop_Loss: 1.1498\tBottom_Loss: 1.0199\tLoss: 3.3015\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.500\tLabel_Loss: 0.9064\tTop_Loss: 0.9050\tBottom_Loss: 1.0264\tLoss: 2.8379\t\n",
      "Subject: 09, n=10 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8708\tTop_Loss: 0.8478\tBottom_Loss: 0.8972\tLoss: 2.6159\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.594\tLabel_Loss: 0.9385\tTop_Loss: 0.8707\tBottom_Loss: 0.9727\tLoss: 2.7820\t\n",
      "Subject: 09, n=10 | test_f1: 0.23077 |best_f1: 0.33333\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.406\tLabel_Loss: 1.2856\tTop_Loss: 1.3117\tBottom_Loss: 1.1501\tLoss: 3.7475\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.750\tLabel_Loss: 0.7357\tTop_Loss: 0.8947\tBottom_Loss: 1.0241\tLoss: 2.6545\t\n",
      "Subject: 09, n=10 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.562\tLabel_Loss: 0.8960\tTop_Loss: 0.8776\tBottom_Loss: 1.0096\tLoss: 2.7833\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.688\tLabel_Loss: 0.9117\tTop_Loss: 0.9154\tBottom_Loss: 0.8962\tLoss: 2.7233\t\n",
      "Subject: 09, n=10 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.719\tLabel_Loss: 0.7331\tTop_Loss: 0.9605\tBottom_Loss: 0.6889\tLoss: 2.3824\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.469\tLabel_Loss: 1.1047\tTop_Loss: 1.3122\tBottom_Loss: 1.2506\tLoss: 3.6675\t\n",
      "Subject: 09, n=10 | test_f1: 0.58333 |best_f1: 0.58333\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.812\tLabel_Loss: 0.6315\tTop_Loss: 0.7763\tBottom_Loss: 0.7640\tLoss: 2.1718\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6927\tTop_Loss: 0.8664\tBottom_Loss: 0.8523\tLoss: 2.4114\t\n",
      "Subject: 09, n=10 | test_f1: 0.375 |best_f1: 0.58333\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.594\tLabel_Loss: 0.9187\tTop_Loss: 1.1050\tBottom_Loss: 0.8531\tLoss: 2.8768\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.562\tLabel_Loss: 0.6664\tTop_Loss: 0.7671\tBottom_Loss: 0.6752\tLoss: 2.1088\t\n",
      "Subject: 09, n=10 | test_f1: 0.23077 |best_f1: 0.58333\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.719\tLabel_Loss: 0.7144\tTop_Loss: 0.7850\tBottom_Loss: 0.8764\tLoss: 2.3758\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6879\tTop_Loss: 0.6372\tBottom_Loss: 0.7357\tLoss: 2.0608\t\n",
      "Subject: 09, n=10 | test_f1: 0.23077 |best_f1: 0.58333\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.562\tLabel_Loss: 0.8777\tTop_Loss: 0.7564\tBottom_Loss: 0.8416\tLoss: 2.4757\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6153\tTop_Loss: 0.7690\tBottom_Loss: 0.7727\tLoss: 2.1571\t\n",
      "Subject: 09, n=10 | test_f1: 0.28571 |best_f1: 0.58333\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7364\tTop_Loss: 0.8724\tBottom_Loss: 0.7830\tLoss: 2.3917\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6315\tTop_Loss: 0.6604\tBottom_Loss: 0.7322\tLoss: 2.0242\t\n",
      "Subject: 09, n=10 | test_f1: 0.28571 |best_f1: 0.58333\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6475\tTop_Loss: 0.6847\tBottom_Loss: 0.7579\tLoss: 2.0901\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.594\tLabel_Loss: 0.7781\tTop_Loss: 0.9230\tBottom_Loss: 0.6994\tLoss: 2.4005\t\n",
      "Subject: 09, n=10 | test_f1: 0.52381 |best_f1: 0.58333\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5681\tTop_Loss: 0.6620\tBottom_Loss: 0.8176\tLoss: 2.0477\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6588\tTop_Loss: 0.8694\tBottom_Loss: 0.9028\tLoss: 2.4310\t\n",
      "Subject: 09, n=10 | test_f1: 0.375 |best_f1: 0.58333\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6697\tTop_Loss: 0.8648\tBottom_Loss: 0.7060\tLoss: 2.2404\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6240\tTop_Loss: 0.7423\tBottom_Loss: 0.5930\tLoss: 1.9593\t\n",
      "Subject: 09, n=10 | test_f1: 0.28571 |best_f1: 0.58333\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.656\tLabel_Loss: 0.6618\tTop_Loss: 0.6603\tBottom_Loss: 0.6622\tLoss: 1.9844\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5955\tTop_Loss: 0.7396\tBottom_Loss: 0.6537\tLoss: 1.9888\t\n",
      "Subject: 09, n=10 | test_f1: 0.33333 |best_f1: 0.58333\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6999\tTop_Loss: 0.7393\tBottom_Loss: 0.8963\tLoss: 2.3355\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.594\tLabel_Loss: 0.7392\tTop_Loss: 0.9156\tBottom_Loss: 0.6231\tLoss: 2.2780\t\n",
      "Subject: 09, n=10 | test_f1: 0.28571 |best_f1: 0.58333\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5521\tTop_Loss: 0.7096\tBottom_Loss: 0.7013\tLoss: 1.9631\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4583\tTop_Loss: 0.5025\tBottom_Loss: 0.5625\tLoss: 1.5233\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 09, n=10 | test_f1: 0.52381 |best_f1: 0.58333\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4224\tTop_Loss: 0.5791\tBottom_Loss: 0.6049\tLoss: 1.6064\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7442\tTop_Loss: 0.8361\tBottom_Loss: 0.7725\tLoss: 2.3528\t\n",
      "Subject: 09, n=10 | test_f1: 0.28571 |best_f1: 0.58333\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.844\tLabel_Loss: 0.5414\tTop_Loss: 0.5137\tBottom_Loss: 0.6143\tLoss: 1.6695\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.719\tLabel_Loss: 0.5753\tTop_Loss: 0.4743\tBottom_Loss: 0.8708\tLoss: 1.9204\t\n",
      "Subject: 09, n=10 | test_f1: 0.33333 |best_f1: 0.58333\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5593\tTop_Loss: 0.6154\tBottom_Loss: 0.5172\tLoss: 1.6919\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5702\tTop_Loss: 0.5549\tBottom_Loss: 0.8076\tLoss: 1.9327\t\n",
      "Subject: 09, n=10 | test_f1: 0.28571 |best_f1: 0.58333\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3604\tTop_Loss: 0.4852\tBottom_Loss: 0.5014\tLoss: 1.3470\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2990\tTop_Loss: 0.4878\tBottom_Loss: 0.4703\tLoss: 1.2572\t\n",
      "Subject: 09, n=10 | test_f1: 0.67033 |best_f1: 0.67033\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4454\tTop_Loss: 0.6195\tBottom_Loss: 0.5008\tLoss: 1.5657\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3427\tTop_Loss: 0.4395\tBottom_Loss: 0.5405\tLoss: 1.3227\t\n",
      "Subject: 09, n=10 | test_f1: 0.28571 |best_f1: 0.67033\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5176\tTop_Loss: 0.6834\tBottom_Loss: 0.5550\tLoss: 1.7561\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3349\tTop_Loss: 0.5162\tBottom_Loss: 0.3649\tLoss: 1.2160\t\n",
      "Subject: 09, n=10 | test_f1: 0.45055 |best_f1: 0.67033\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4542\tTop_Loss: 0.5613\tBottom_Loss: 0.5487\tLoss: 1.5642\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4030\tTop_Loss: 0.4269\tBottom_Loss: 0.4333\tLoss: 1.2631\t\n",
      "Subject: 09, n=10 | test_f1: 0.45055 |best_f1: 0.67033\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4776\tTop_Loss: 0.6508\tBottom_Loss: 0.7246\tLoss: 1.8530\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4322\tTop_Loss: 0.5666\tBottom_Loss: 0.6266\tLoss: 1.6255\t\n",
      "Subject: 09, n=10 | test_f1: 0.33333 |best_f1: 0.67033\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3400\tTop_Loss: 0.5846\tBottom_Loss: 0.4677\tLoss: 1.3923\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3886\tTop_Loss: 0.5532\tBottom_Loss: 0.6015\tLoss: 1.5433\t\n",
      "Subject: 09, n=10 | test_f1: 0.28571 |best_f1: 0.67033\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4275\tTop_Loss: 0.5961\tBottom_Loss: 0.5167\tLoss: 1.5404\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4914\tTop_Loss: 0.5154\tBottom_Loss: 0.6344\tLoss: 1.6413\t\n",
      "Subject: 09, n=10 | test_f1: 0.28571 |best_f1: 0.67033\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2103\tTop_Loss: 0.3251\tBottom_Loss: 0.4495\tLoss: 0.9849\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3901\tTop_Loss: 0.6026\tBottom_Loss: 0.6162\tLoss: 1.6089\t\n",
      "Subject: 09, n=10 | test_f1: 0.28571 |best_f1: 0.67033\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3053\tTop_Loss: 0.3540\tBottom_Loss: 0.4236\tLoss: 1.0829\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3059\tTop_Loss: 0.4765\tBottom_Loss: 0.3741\tLoss: 1.1565\t\n",
      "Subject: 09, n=10 | test_f1: 0.45055 |best_f1: 0.67033\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3515\tTop_Loss: 0.5963\tBottom_Loss: 0.4241\tLoss: 1.3719\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4232\tTop_Loss: 0.5801\tBottom_Loss: 0.4358\tLoss: 1.4390\t\n",
      "Subject: 09, n=10 | test_f1: 0.23077 |best_f1: 0.67033\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.938\tLabel_Loss: 0.3715\tTop_Loss: 0.5454\tBottom_Loss: 0.5372\tLoss: 1.4541\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.938\tLabel_Loss: 0.3216\tTop_Loss: 0.3355\tBottom_Loss: 0.4776\tLoss: 1.1347\t\n",
      "Subject: 09, n=10 | test_f1: 0.52381 |best_f1: 0.67033\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1917\tTop_Loss: 0.3380\tBottom_Loss: 0.3691\tLoss: 0.8988\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1899\tTop_Loss: 0.3093\tBottom_Loss: 0.3360\tLoss: 0.8353\t\n",
      "Subject: 09, n=10 | test_f1: 0.28571 |best_f1: 0.67033\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2840\tTop_Loss: 0.3641\tBottom_Loss: 0.4594\tLoss: 1.1075\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3889\tTop_Loss: 0.4937\tBottom_Loss: 0.5375\tLoss: 1.4201\t\n",
      "Subject: 09, n=10 | test_f1: 0.28571 |best_f1: 0.67033\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2776\tTop_Loss: 0.4377\tBottom_Loss: 0.2407\tLoss: 0.9561\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2492\tTop_Loss: 0.4345\tBottom_Loss: 0.2414\tLoss: 0.9251\t\n",
      "Subject: 09, n=10 | test_f1: 0.45055 |best_f1: 0.67033\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4005\tTop_Loss: 0.5549\tBottom_Loss: 0.5755\tLoss: 1.5308\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1977\tTop_Loss: 0.3476\tBottom_Loss: 0.3034\tLoss: 0.8486\t\n",
      "Subject: 09, n=10 | test_f1: 0.16667 |best_f1: 0.67033\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1779\tTop_Loss: 0.3261\tBottom_Loss: 0.3268\tLoss: 0.8308\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2510\tTop_Loss: 0.3428\tBottom_Loss: 0.3302\tLoss: 0.9240\t\n",
      "Subject: 09, n=10 | test_f1: 0.33333 |best_f1: 0.67033\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2336\tTop_Loss: 0.3828\tBottom_Loss: 0.4397\tLoss: 1.0562\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2305\tTop_Loss: 0.3639\tBottom_Loss: 0.3923\tLoss: 0.9867\t\n",
      "Subject: 09, n=10 | test_f1: 0.28571 |best_f1: 0.67033\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2445\tTop_Loss: 0.5560\tBottom_Loss: 0.2713\tLoss: 1.0718\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1394\tTop_Loss: 0.2943\tBottom_Loss: 0.2814\tLoss: 0.7152\t\n",
      "Subject: 09, n=10 | test_f1: 0.33333 |best_f1: 0.67033\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1687\tTop_Loss: 0.2673\tBottom_Loss: 0.2752\tLoss: 0.7112\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1988\tTop_Loss: 0.3838\tBottom_Loss: 0.3765\tLoss: 0.9592\t\n",
      "Subject: 09, n=10 | test_f1: 0.23077 |best_f1: 0.67033\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1295\tTop_Loss: 0.2840\tBottom_Loss: 0.2764\tLoss: 0.6899\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1357\tTop_Loss: 0.3353\tBottom_Loss: 0.1897\tLoss: 0.6608\t\n",
      "Subject: 09, n=10 | test_f1: 0.45055 |best_f1: 0.67033\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1707\tTop_Loss: 0.2996\tBottom_Loss: 0.2817\tLoss: 0.7520\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2680\tTop_Loss: 0.2682\tBottom_Loss: 0.3763\tLoss: 0.9125\t\n",
      "Subject: 09, n=10 | test_f1: 0.52381 |best_f1: 0.67033\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1440\tTop_Loss: 0.3102\tBottom_Loss: 0.2725\tLoss: 0.7268\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2414\tTop_Loss: 0.3527\tBottom_Loss: 0.2678\tLoss: 0.8619\t\n",
      "Subject: 09, n=10 | test_f1: 0.33333 |best_f1: 0.67033\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1631\tTop_Loss: 0.2320\tBottom_Loss: 0.2593\tLoss: 0.6544\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1709\tTop_Loss: 0.3186\tBottom_Loss: 0.1815\tLoss: 0.6711\t\n",
      "Subject: 09, n=10 | test_f1: 0.33333 |best_f1: 0.67033\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1231\tTop_Loss: 0.2159\tBottom_Loss: 0.2386\tLoss: 0.5777\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1234\tTop_Loss: 0.2500\tBottom_Loss: 0.1965\tLoss: 0.5698\t\n",
      "Subject: 09, n=10 | test_f1: 0.45055 |best_f1: 0.67033\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1487\tTop_Loss: 0.1804\tBottom_Loss: 0.4375\tLoss: 0.7666\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1047\tTop_Loss: 0.2747\tBottom_Loss: 0.1608\tLoss: 0.5402\t\n",
      "Subject: 09, n=10 | test_f1: 0.49495 |best_f1: 0.67033\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2924\tTop_Loss: 0.3831\tBottom_Loss: 0.4310\tLoss: 1.1065\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2400\tTop_Loss: 0.2731\tBottom_Loss: 0.2183\tLoss: 0.7314\t\n",
      "Subject: 09, n=10 | test_f1: 0.33333 |best_f1: 0.67033\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1468\tTop_Loss: 0.2145\tBottom_Loss: 0.2447\tLoss: 0.6059\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1680\tTop_Loss: 0.3016\tBottom_Loss: 0.2057\tLoss: 0.6753\t\n",
      "Subject: 09, n=10 | test_f1: 0.16667 |best_f1: 0.67033\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1338\tTop_Loss: 0.2580\tBottom_Loss: 0.3095\tLoss: 0.7013\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1103\tTop_Loss: 0.2296\tBottom_Loss: 0.2204\tLoss: 0.5603\t\n",
      "Subject: 09, n=10 | test_f1: 0.33333 |best_f1: 0.67033\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1218\tTop_Loss: 0.1721\tBottom_Loss: 0.3154\tLoss: 0.6093\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0982\tTop_Loss: 0.2479\tBottom_Loss: 0.2293\tLoss: 0.5754\t\n",
      "Subject: 09, n=10 | test_f1: 0.52381 |best_f1: 0.67033\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0628\tTop_Loss: 0.1631\tBottom_Loss: 0.1754\tLoss: 0.4014\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1443\tTop_Loss: 0.2642\tBottom_Loss: 0.1843\tLoss: 0.5928\t\n",
      "Subject: 09, n=10 | test_f1: 0.45055 |best_f1: 0.67033\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1359\tTop_Loss: 0.2446\tBottom_Loss: 0.2529\tLoss: 0.6335\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1121\tTop_Loss: 0.2722\tBottom_Loss: 0.2120\tLoss: 0.5962\t\n",
      "Subject: 09, n=10 | test_f1: 0.28571 |best_f1: 0.67033\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1609\tTop_Loss: 0.2522\tBottom_Loss: 0.2074\tLoss: 0.6205\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2379\tTop_Loss: 0.3636\tBottom_Loss: 0.2642\tLoss: 0.8657\t\n",
      "Subject: 09, n=10 | test_f1: 0.33333 |best_f1: 0.67033\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1388\tTop_Loss: 0.2825\tBottom_Loss: 0.2257\tLoss: 0.6470\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0532\tTop_Loss: 0.1808\tBottom_Loss: 0.1146\tLoss: 0.3487\t\n",
      "Subject: 09, n=10 | test_f1: 0.52381 |best_f1: 0.67033\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0727\tTop_Loss: 0.1283\tBottom_Loss: 0.0715\tLoss: 0.2725\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1400\tTop_Loss: 0.1878\tBottom_Loss: 0.1799\tLoss: 0.5077\t\n",
      "Subject: 09, n=10 | test_f1: 0.28571 |best_f1: 0.67033\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0786\tTop_Loss: 0.1440\tBottom_Loss: 0.2090\tLoss: 0.4316\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0580\tTop_Loss: 0.1612\tBottom_Loss: 0.1614\tLoss: 0.3807\t\n",
      "Subject: 09, n=10 | test_f1: 0.52381 |best_f1: 0.67033\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0790\tTop_Loss: 0.1796\tBottom_Loss: 0.1308\tLoss: 0.3894\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1119\tTop_Loss: 0.2120\tBottom_Loss: 0.1336\tLoss: 0.4575\t\n",
      "Subject: 09, n=10 | test_f1: 0.52381 |best_f1: 0.67033\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1331\tTop_Loss: 0.2632\tBottom_Loss: 0.1714\tLoss: 0.5677\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0750\tTop_Loss: 0.1914\tBottom_Loss: 0.1995\tLoss: 0.4658\t\n",
      "Subject: 09, n=10 | test_f1: 0.28571 |best_f1: 0.67033\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1462\tTop_Loss: 0.2325\tBottom_Loss: 0.2164\tLoss: 0.5950\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1777\tTop_Loss: 0.3535\tBottom_Loss: 0.1028\tLoss: 0.6340\t\n",
      "Subject: 09, n=10 | test_f1: 0.45055 |best_f1: 0.67033\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0846\tTop_Loss: 0.2168\tBottom_Loss: 0.1899\tLoss: 0.4913\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0920\tTop_Loss: 0.1722\tBottom_Loss: 0.1739\tLoss: 0.4382\t\n",
      "Subject: 09, n=10 | test_f1: 0.33333 |best_f1: 0.67033\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0915\tTop_Loss: 0.1352\tBottom_Loss: 0.1268\tLoss: 0.3536\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0328\tTop_Loss: 0.0876\tBottom_Loss: 0.1279\tLoss: 0.2483\t\n",
      "Subject: 09, n=10 | test_f1: 0.33333 |best_f1: 0.67033\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0702\tTop_Loss: 0.1775\tBottom_Loss: 0.1285\tLoss: 0.3762\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0864\tTop_Loss: 0.2049\tBottom_Loss: 0.1717\tLoss: 0.4630\t\n",
      "Subject: 09, n=10 | test_f1: 0.28571 |best_f1: 0.67033\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0921\tTop_Loss: 0.1941\tBottom_Loss: 0.1461\tLoss: 0.4322\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0424\tTop_Loss: 0.1698\tBottom_Loss: 0.0750\tLoss: 0.2872\t\n",
      "Subject: 09, n=10 | test_f1: 0.45055 |best_f1: 0.67033\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0407\tTop_Loss: 0.0625\tBottom_Loss: 0.0890\tLoss: 0.1922\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1567\tTop_Loss: 0.2262\tBottom_Loss: 0.1912\tLoss: 0.5741\t\n",
      "Subject: 09, n=10 | test_f1: 0.33333 |best_f1: 0.67033\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0584\tTop_Loss: 0.1338\tBottom_Loss: 0.1913\tLoss: 0.3835\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1058\tTop_Loss: 0.1524\tBottom_Loss: 0.1466\tLoss: 0.4048\t\n",
      "Subject: 09, n=10 | test_f1: 0.67033 |best_f1: 0.67033\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1876\tTop_Loss: 0.4160\tBottom_Loss: 0.1980\tLoss: 0.8015\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0567\tTop_Loss: 0.1430\tBottom_Loss: 0.1706\tLoss: 0.3704\t\n",
      "Subject: 09, n=10 | test_f1: 0.45055 |best_f1: 0.67033\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0633\tTop_Loss: 0.1439\tBottom_Loss: 0.1031\tLoss: 0.3103\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2076\tTop_Loss: 0.2328\tBottom_Loss: 0.1754\tLoss: 0.6158\t\n",
      "Subject: 09, n=10 | test_f1: 0.28571 |best_f1: 0.67033\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0842\tTop_Loss: 0.1556\tBottom_Loss: 0.1562\tLoss: 0.3960\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0466\tTop_Loss: 0.1545\tBottom_Loss: 0.0869\tLoss: 0.2880\t\n",
      "Subject: 09, n=10 | test_f1: 0.28571 |best_f1: 0.67033\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0361\tTop_Loss: 0.1640\tBottom_Loss: 0.1131\tLoss: 0.3131\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0335\tTop_Loss: 0.1948\tBottom_Loss: 0.0544\tLoss: 0.2827\t\n",
      "Subject: 09, n=10 | test_f1: 0.33333 |best_f1: 0.67033\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0636\tTop_Loss: 0.1668\tBottom_Loss: 0.0564\tLoss: 0.2867\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1025\tTop_Loss: 0.2502\tBottom_Loss: 0.1803\tLoss: 0.5330\t\n",
      "Subject: 09, n=10 | test_f1: 0.28571 |best_f1: 0.67033\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0477\tTop_Loss: 0.1243\tBottom_Loss: 0.1146\tLoss: 0.2866\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0228\tTop_Loss: 0.1012\tBottom_Loss: 0.0592\tLoss: 0.1833\t\n",
      "Subject: 09, n=10 | test_f1: 0.33333 |best_f1: 0.67033\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0245\tTop_Loss: 0.0736\tBottom_Loss: 0.0965\tLoss: 0.1947\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0520\tTop_Loss: 0.0977\tBottom_Loss: 0.0841\tLoss: 0.2338\t\n",
      "Subject: 09, n=10 | test_f1: 0.28571 |best_f1: 0.67033\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0455\tTop_Loss: 0.0936\tBottom_Loss: 0.1231\tLoss: 0.2622\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0510\tTop_Loss: 0.1284\tBottom_Loss: 0.1318\tLoss: 0.3112\t\n",
      "Subject: 09, n=10 | test_f1: 0.45055 |best_f1: 0.67033\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0387\tTop_Loss: 0.0524\tBottom_Loss: 0.1110\tLoss: 0.2021\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0396\tTop_Loss: 0.0779\tBottom_Loss: 0.0602\tLoss: 0.1777\t\n",
      "Subject: 09, n=10 | test_f1: 0.45055 |best_f1: 0.67033\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0423\tTop_Loss: 0.0745\tBottom_Loss: 0.1304\tLoss: 0.2472\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0254\tTop_Loss: 0.0663\tBottom_Loss: 0.0392\tLoss: 0.1308\t\n",
      "Subject: 09, n=10 | test_f1: 0.28571 |best_f1: 0.67033\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0273\tTop_Loss: 0.1163\tBottom_Loss: 0.0320\tLoss: 0.1756\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0206\tTop_Loss: 0.1067\tBottom_Loss: 0.0555\tLoss: 0.1828\t\n",
      "Subject: 09, n=10 | test_f1: 0.33333 |best_f1: 0.67033\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0512\tTop_Loss: 0.1323\tBottom_Loss: 0.0829\tLoss: 0.2663\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0501\tTop_Loss: 0.1802\tBottom_Loss: 0.0947\tLoss: 0.3250\t\n",
      "Subject: 09, n=10 | test_f1: 0.28571 |best_f1: 0.67033\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0398\tTop_Loss: 0.0685\tBottom_Loss: 0.0573\tLoss: 0.1656\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0265\tTop_Loss: 0.0874\tBottom_Loss: 0.0485\tLoss: 0.1624\t\n",
      "Subject: 09, n=10 | test_f1: 0.28571 |best_f1: 0.67033\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0364\tTop_Loss: 0.0834\tBottom_Loss: 0.1118\tLoss: 0.2316\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0120\tTop_Loss: 0.0245\tBottom_Loss: 0.0270\tLoss: 0.0635\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 09, n=10 | test_f1: 0.45055 |best_f1: 0.67033\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0401\tTop_Loss: 0.1818\tBottom_Loss: 0.0993\tLoss: 0.3211\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0253\tTop_Loss: 0.0658\tBottom_Loss: 0.0933\tLoss: 0.1844\t\n",
      "Subject: 09, n=10 | test_f1: 0.28571 |best_f1: 0.67033\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0298\tTop_Loss: 0.0521\tBottom_Loss: 0.0578\tLoss: 0.1397\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0363\tTop_Loss: 0.0439\tBottom_Loss: 0.0605\tLoss: 0.1407\t\n",
      "Subject: 09, n=10 | test_f1: 0.52381 |best_f1: 0.67033\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0474\tTop_Loss: 0.0366\tBottom_Loss: 0.0840\tLoss: 0.1680\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0314\tTop_Loss: 0.0647\tBottom_Loss: 0.0960\tLoss: 0.1921\t\n",
      "Subject: 09, n=10 | test_f1: 0.33333 |best_f1: 0.67033\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1031\tTop_Loss: 0.1208\tBottom_Loss: 0.1131\tLoss: 0.3369\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0295\tTop_Loss: 0.0873\tBottom_Loss: 0.0592\tLoss: 0.1760\t\n",
      "Subject: 09, n=10 | test_f1: 0.45055 |best_f1: 0.67033\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0221\tTop_Loss: 0.0672\tBottom_Loss: 0.0318\tLoss: 0.1211\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0167\tTop_Loss: 0.0448\tBottom_Loss: 0.0488\tLoss: 0.1103\t\n",
      "Subject: 09, n=10 | test_f1: 0.33333 |best_f1: 0.67033\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0252\tTop_Loss: 0.0316\tBottom_Loss: 0.0691\tLoss: 0.1259\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0322\tTop_Loss: 0.1011\tBottom_Loss: 0.0329\tLoss: 0.1662\t\n",
      "Subject: 09, n=10 | test_f1: 0.375 |best_f1: 0.67033\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0140\tTop_Loss: 0.0503\tBottom_Loss: 0.0550\tLoss: 0.1193\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0181\tTop_Loss: 0.1012\tBottom_Loss: 0.0549\tLoss: 0.1742\t\n",
      "Subject: 09, n=10 | test_f1: 0.28571 |best_f1: 0.67033\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0361\tTop_Loss: 0.1328\tBottom_Loss: 0.0844\tLoss: 0.2532\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0515\tTop_Loss: 0.0392\tBottom_Loss: 0.0977\tLoss: 0.1884\t\n",
      "Subject: 09, n=10 | test_f1: 0.33333 |best_f1: 0.67033\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0456\tTop_Loss: 0.1110\tBottom_Loss: 0.0369\tLoss: 0.1936\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0136\tTop_Loss: 0.0612\tBottom_Loss: 0.0240\tLoss: 0.0988\t\n",
      "Subject: 09, n=10 | test_f1: 0.28571 |best_f1: 0.67033\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0224\tTop_Loss: 0.0543\tBottom_Loss: 0.0575\tLoss: 0.1342\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0188\tTop_Loss: 0.1148\tBottom_Loss: 0.0440\tLoss: 0.1776\t\n",
      "Subject: 09, n=10 | test_f1: 0.28571 |best_f1: 0.67033\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0167\tTop_Loss: 0.0563\tBottom_Loss: 0.0530\tLoss: 0.1260\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0224\tTop_Loss: 0.0544\tBottom_Loss: 0.0946\tLoss: 0.1714\t\n",
      "Subject: 09, n=10 | test_f1: 0.33333 |best_f1: 0.67033\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0064\tTop_Loss: 0.0404\tBottom_Loss: 0.0121\tLoss: 0.0588\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0304\tTop_Loss: 0.0599\tBottom_Loss: 0.0430\tLoss: 0.1333\t\n",
      "Subject: 09, n=10 | test_f1: 0.33333 |best_f1: 0.67033\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0158\tTop_Loss: 0.0805\tBottom_Loss: 0.0184\tLoss: 0.1147\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0491\tTop_Loss: 0.0420\tBottom_Loss: 0.0263\tLoss: 0.1175\t\n",
      "Subject: 09, n=10 | test_f1: 0.28571 |best_f1: 0.67033\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0057\tTop_Loss: 0.0509\tBottom_Loss: 0.0142\tLoss: 0.0708\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0074\tTop_Loss: 0.0328\tBottom_Loss: 0.0252\tLoss: 0.0654\t\n",
      "Subject: 09, n=10 | test_f1: 0.33333 |best_f1: 0.67033\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0147\tTop_Loss: 0.0531\tBottom_Loss: 0.0449\tLoss: 0.1128\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0109\tTop_Loss: 0.0233\tBottom_Loss: 0.0285\tLoss: 0.0628\t\n",
      "Subject: 09, n=10 | test_f1: 0.45055 |best_f1: 0.67033\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0181\tTop_Loss: 0.0296\tBottom_Loss: 0.0310\tLoss: 0.0787\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0384\tTop_Loss: 0.0949\tBottom_Loss: 0.0471\tLoss: 0.1804\t\n",
      "Subject: 09, n=10 | test_f1: 0.45055 |best_f1: 0.67033\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0151\tTop_Loss: 0.0287\tBottom_Loss: 0.1091\tLoss: 0.1530\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0160\tTop_Loss: 0.0285\tBottom_Loss: 0.0392\tLoss: 0.0838\t\n",
      "Subject: 09, n=10 | test_f1: 0.52381 |best_f1: 0.67033\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0356\tTop_Loss: 0.0403\tBottom_Loss: 0.0563\tLoss: 0.1322\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0047\tTop_Loss: 0.0123\tBottom_Loss: 0.0121\tLoss: 0.0292\t\n",
      "Subject: 09, n=10 | test_f1: 0.28571 |best_f1: 0.67033\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0054\tTop_Loss: 0.0128\tBottom_Loss: 0.0333\tLoss: 0.0514\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0205\tTop_Loss: 0.0678\tBottom_Loss: 0.0557\tLoss: 0.1440\t\n",
      "Subject: 09, n=10 | test_f1: 0.45055 |best_f1: 0.67033\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0054\tTop_Loss: 0.0189\tBottom_Loss: 0.0148\tLoss: 0.0391\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0130\tTop_Loss: 0.0664\tBottom_Loss: 0.0369\tLoss: 0.1163\t\n",
      "Subject: 09, n=10 | test_f1: 0.45055 |best_f1: 0.67033\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0092\tTop_Loss: 0.0632\tBottom_Loss: 0.0309\tLoss: 0.1033\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0098\tTop_Loss: 0.0472\tBottom_Loss: 0.0155\tLoss: 0.0725\t\n",
      "Subject: 09, n=10 | test_f1: 0.33333 |best_f1: 0.67033\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.281\tLabel_Loss: 1.3909\tTop_Loss: 1.0172\tBottom_Loss: 1.7407\tLoss: 4.1488\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.406\tLabel_Loss: 1.1673\tTop_Loss: 1.0547\tBottom_Loss: 0.8885\tLoss: 3.1105\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.625\tLabel_Loss: 0.9610\tTop_Loss: 0.9958\tBottom_Loss: 1.1251\tLoss: 3.0820\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.500\tLabel_Loss: 0.9484\tTop_Loss: 0.8955\tBottom_Loss: 1.0787\tLoss: 2.9227\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.562\tLabel_Loss: 0.8781\tTop_Loss: 0.8105\tBottom_Loss: 1.0806\tLoss: 2.7692\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.688\tLabel_Loss: 0.8793\tTop_Loss: 0.7693\tBottom_Loss: 0.8817\tLoss: 2.5303\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.594\tLabel_Loss: 0.9713\tTop_Loss: 1.0734\tBottom_Loss: 0.7755\tLoss: 2.8202\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.781\tLabel_Loss: 0.6476\tTop_Loss: 0.7352\tBottom_Loss: 0.7528\tLoss: 2.1356\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.719\tLabel_Loss: 0.8050\tTop_Loss: 0.9611\tBottom_Loss: 0.9771\tLoss: 2.7433\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.531\tLabel_Loss: 0.9706\tTop_Loss: 1.0577\tBottom_Loss: 0.8573\tLoss: 2.8856\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.469\tLabel_Loss: 0.9631\tTop_Loss: 1.0157\tBottom_Loss: 1.0326\tLoss: 3.0114\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.594\tLabel_Loss: 0.9058\tTop_Loss: 0.8132\tBottom_Loss: 0.7835\tLoss: 2.5026\t\n",
      "Subject: 11, n=04 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8096\tTop_Loss: 1.0043\tBottom_Loss: 0.8230\tLoss: 2.6369\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.562\tLabel_Loss: 0.9244\tTop_Loss: 0.9887\tBottom_Loss: 0.9418\tLoss: 2.8549\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.438\tLabel_Loss: 1.1488\tTop_Loss: 1.0303\tBottom_Loss: 1.0511\tLoss: 3.2302\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.562\tLabel_Loss: 0.9478\tTop_Loss: 0.8892\tBottom_Loss: 0.7357\tLoss: 2.5726\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7628\tTop_Loss: 1.0455\tBottom_Loss: 0.8206\tLoss: 2.6288\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6885\tTop_Loss: 0.8880\tBottom_Loss: 0.7481\tLoss: 2.3247\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7747\tTop_Loss: 1.0051\tBottom_Loss: 0.8702\tLoss: 2.6500\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6153\tTop_Loss: 0.6392\tBottom_Loss: 0.7152\tLoss: 1.9696\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7400\tTop_Loss: 0.8360\tBottom_Loss: 0.9745\tLoss: 2.5505\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.562\tLabel_Loss: 0.8044\tTop_Loss: 0.9749\tBottom_Loss: 0.9192\tLoss: 2.6985\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.656\tLabel_Loss: 0.8133\tTop_Loss: 1.0495\tBottom_Loss: 0.7637\tLoss: 2.6265\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.719\tLabel_Loss: 0.7120\tTop_Loss: 0.7744\tBottom_Loss: 0.5928\tLoss: 2.0792\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.656\tLabel_Loss: 0.5746\tTop_Loss: 0.7521\tBottom_Loss: 0.7295\tLoss: 2.0562\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8307\tTop_Loss: 1.0284\tBottom_Loss: 0.7728\tLoss: 2.6319\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7520\tTop_Loss: 0.7670\tBottom_Loss: 0.8607\tLoss: 2.3797\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.688\tLabel_Loss: 0.5825\tTop_Loss: 0.7857\tBottom_Loss: 0.5591\tLoss: 1.9274\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.844\tLabel_Loss: 0.5778\tTop_Loss: 0.9002\tBottom_Loss: 0.6495\tLoss: 2.1275\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5102\tTop_Loss: 0.6030\tBottom_Loss: 0.6358\tLoss: 1.7491\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7953\tTop_Loss: 0.7331\tBottom_Loss: 0.8500\tLoss: 2.3784\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6290\tTop_Loss: 0.7432\tBottom_Loss: 0.7923\tLoss: 2.1646\t\n",
      "Subject: 11, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5549\tTop_Loss: 0.7130\tBottom_Loss: 0.6154\tLoss: 1.8833\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.531\tLabel_Loss: 0.8417\tTop_Loss: 0.8798\tBottom_Loss: 0.7878\tLoss: 2.5092\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7662\tTop_Loss: 0.9555\tBottom_Loss: 0.7575\tLoss: 2.4791\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4034\tTop_Loss: 0.7130\tBottom_Loss: 0.4112\tLoss: 1.5276\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4241\tTop_Loss: 0.5773\tBottom_Loss: 0.6534\tLoss: 1.6548\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.656\tLabel_Loss: 0.6785\tTop_Loss: 0.6988\tBottom_Loss: 0.6332\tLoss: 2.0106\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5533\tTop_Loss: 0.7732\tBottom_Loss: 0.6547\tLoss: 1.9811\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3904\tTop_Loss: 0.4834\tBottom_Loss: 0.5966\tLoss: 1.4704\t\n",
      "Subject: 11, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5672\tTop_Loss: 0.8194\tBottom_Loss: 0.6037\tLoss: 1.9902\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3625\tTop_Loss: 0.4634\tBottom_Loss: 0.5245\tLoss: 1.3503\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4231\tTop_Loss: 0.6185\tBottom_Loss: 0.7475\tLoss: 1.7891\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4827\tTop_Loss: 0.6724\tBottom_Loss: 0.6954\tLoss: 1.8505\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.844\tLabel_Loss: 0.5282\tTop_Loss: 0.5920\tBottom_Loss: 0.6772\tLoss: 1.7974\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3410\tTop_Loss: 0.4521\tBottom_Loss: 0.4409\tLoss: 1.2340\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4327\tTop_Loss: 0.6151\tBottom_Loss: 0.5535\tLoss: 1.6013\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3227\tTop_Loss: 0.5467\tBottom_Loss: 0.6269\tLoss: 1.4963\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3315\tTop_Loss: 0.5195\tBottom_Loss: 0.5465\tLoss: 1.3975\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.906\tLabel_Loss: 0.4069\tTop_Loss: 0.6431\tBottom_Loss: 0.3332\tLoss: 1.3832\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.938\tLabel_Loss: 0.3846\tTop_Loss: 0.7636\tBottom_Loss: 0.4109\tLoss: 1.5591\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4365\tTop_Loss: 0.3901\tBottom_Loss: 0.7341\tLoss: 1.5607\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5055\tTop_Loss: 0.5851\tBottom_Loss: 0.7201\tLoss: 1.8107\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2687\tTop_Loss: 0.3600\tBottom_Loss: 0.4532\tLoss: 1.0818\t\n",
      "Subject: 11, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4797\tTop_Loss: 0.6475\tBottom_Loss: 0.6547\tLoss: 1.7819\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3470\tTop_Loss: 0.5611\tBottom_Loss: 0.5033\tLoss: 1.4113\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.719\tLabel_Loss: 0.7183\tTop_Loss: 0.6698\tBottom_Loss: 0.8006\tLoss: 2.1888\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2995\tTop_Loss: 0.6314\tBottom_Loss: 0.2793\tLoss: 1.2102\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4585\tTop_Loss: 0.7597\tBottom_Loss: 0.5848\tLoss: 1.8030\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2684\tTop_Loss: 0.4419\tBottom_Loss: 0.6076\tLoss: 1.3179\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5957\tTop_Loss: 0.7698\tBottom_Loss: 0.4615\tLoss: 1.8270\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1987\tTop_Loss: 0.3527\tBottom_Loss: 0.2932\tLoss: 0.8445\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3608\tTop_Loss: 0.5699\tBottom_Loss: 0.4192\tLoss: 1.3499\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2347\tTop_Loss: 0.6588\tBottom_Loss: 0.3594\tLoss: 1.2529\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3423\tTop_Loss: 0.6085\tBottom_Loss: 0.5089\tLoss: 1.4597\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3459\tTop_Loss: 0.4711\tBottom_Loss: 0.3871\tLoss: 1.2042\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3971\tTop_Loss: 0.4936\tBottom_Loss: 0.5056\tLoss: 1.3962\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2775\tTop_Loss: 0.4928\tBottom_Loss: 0.3155\tLoss: 1.0858\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1909\tTop_Loss: 0.3178\tBottom_Loss: 0.2817\tLoss: 0.7904\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2907\tTop_Loss: 0.4503\tBottom_Loss: 0.3574\tLoss: 1.0983\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1945\tTop_Loss: 0.4723\tBottom_Loss: 0.3117\tLoss: 0.9785\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2235\tTop_Loss: 0.3355\tBottom_Loss: 0.4109\tLoss: 0.9699\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2284\tTop_Loss: 0.2555\tBottom_Loss: 0.4052\tLoss: 0.8892\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2409\tTop_Loss: 0.4155\tBottom_Loss: 0.4086\tLoss: 1.0651\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2747\tTop_Loss: 0.5347\tBottom_Loss: 0.3850\tLoss: 1.1944\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3764\tTop_Loss: 0.5195\tBottom_Loss: 0.4571\tLoss: 1.3531\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2276\tTop_Loss: 0.5355\tBottom_Loss: 0.2860\tLoss: 1.0491\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1455\tTop_Loss: 0.3118\tBottom_Loss: 0.2351\tLoss: 0.6923\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2181\tTop_Loss: 0.5577\tBottom_Loss: 0.3262\tLoss: 1.1020\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2320\tTop_Loss: 0.3603\tBottom_Loss: 0.2997\tLoss: 0.8919\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2075\tTop_Loss: 0.3336\tBottom_Loss: 0.2506\tLoss: 0.7917\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1499\tTop_Loss: 0.3868\tBottom_Loss: 0.3493\tLoss: 0.8860\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1516\tTop_Loss: 0.3049\tBottom_Loss: 0.3245\tLoss: 0.7810\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2171\tTop_Loss: 0.3544\tBottom_Loss: 0.3732\tLoss: 0.9447\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1100\tTop_Loss: 0.2339\tBottom_Loss: 0.1699\tLoss: 0.5139\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1201\tTop_Loss: 0.2545\tBottom_Loss: 0.2726\tLoss: 0.6471\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0752\tTop_Loss: 0.2168\tBottom_Loss: 0.1940\tLoss: 0.4859\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1571\tTop_Loss: 0.3042\tBottom_Loss: 0.2778\tLoss: 0.7392\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1336\tTop_Loss: 0.2838\tBottom_Loss: 0.2414\tLoss: 0.6589\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1036\tTop_Loss: 0.3309\tBottom_Loss: 0.2835\tLoss: 0.7179\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0949\tTop_Loss: 0.3055\tBottom_Loss: 0.2336\tLoss: 0.6340\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0977\tTop_Loss: 0.3541\tBottom_Loss: 0.2081\tLoss: 0.6599\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0890\tTop_Loss: 0.2371\tBottom_Loss: 0.2079\tLoss: 0.5340\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1245\tTop_Loss: 0.2422\tBottom_Loss: 0.1842\tLoss: 0.5508\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1283\tTop_Loss: 0.2591\tBottom_Loss: 0.2298\tLoss: 0.6173\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1063\tTop_Loss: 0.2084\tBottom_Loss: 0.2333\tLoss: 0.5480\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1185\tTop_Loss: 0.2003\tBottom_Loss: 0.2519\tLoss: 0.5707\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1141\tTop_Loss: 0.1918\tBottom_Loss: 0.2532\tLoss: 0.5590\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0868\tTop_Loss: 0.1709\tBottom_Loss: 0.3557\tLoss: 0.6135\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1753\tTop_Loss: 0.4875\tBottom_Loss: 0.2585\tLoss: 0.9213\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0569\tTop_Loss: 0.1779\tBottom_Loss: 0.1336\tLoss: 0.3684\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2720\tTop_Loss: 0.3667\tBottom_Loss: 0.3581\tLoss: 0.9969\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0809\tTop_Loss: 0.2112\tBottom_Loss: 0.1626\tLoss: 0.4547\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1015\tTop_Loss: 0.2006\tBottom_Loss: 0.2004\tLoss: 0.5026\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1015\tTop_Loss: 0.2248\tBottom_Loss: 0.1898\tLoss: 0.5161\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0562\tTop_Loss: 0.1767\tBottom_Loss: 0.1232\tLoss: 0.3560\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1830\tTop_Loss: 0.3023\tBottom_Loss: 0.2625\tLoss: 0.7479\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0650\tTop_Loss: 0.1688\tBottom_Loss: 0.0932\tLoss: 0.3270\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1058\tTop_Loss: 0.2797\tBottom_Loss: 0.1727\tLoss: 0.5582\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0526\tTop_Loss: 0.0925\tBottom_Loss: 0.1175\tLoss: 0.2627\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1026\tTop_Loss: 0.2422\tBottom_Loss: 0.1787\tLoss: 0.5235\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0797\tTop_Loss: 0.2020\tBottom_Loss: 0.1708\tLoss: 0.4525\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1352\tTop_Loss: 0.2777\tBottom_Loss: 0.2579\tLoss: 0.6709\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0622\tTop_Loss: 0.1480\tBottom_Loss: 0.1741\tLoss: 0.3842\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0388\tTop_Loss: 0.1369\tBottom_Loss: 0.0793\tLoss: 0.2550\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0861\tTop_Loss: 0.2152\tBottom_Loss: 0.2087\tLoss: 0.5100\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0724\tTop_Loss: 0.2011\tBottom_Loss: 0.1275\tLoss: 0.4011\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0719\tTop_Loss: 0.2216\tBottom_Loss: 0.1183\tLoss: 0.4118\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0923\tTop_Loss: 0.3024\tBottom_Loss: 0.2150\tLoss: 0.6097\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 0.875\tLabel_Loss: 0.1547\tTop_Loss: 0.1809\tBottom_Loss: 0.2241\tLoss: 0.5597\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0735\tTop_Loss: 0.2220\tBottom_Loss: 0.1121\tLoss: 0.4076\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0556\tTop_Loss: 0.1278\tBottom_Loss: 0.1460\tLoss: 0.3294\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0937\tTop_Loss: 0.1877\tBottom_Loss: 0.1093\tLoss: 0.3907\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0842\tTop_Loss: 0.1270\tBottom_Loss: 0.1999\tLoss: 0.4110\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0759\tTop_Loss: 0.1426\tBottom_Loss: 0.1873\tLoss: 0.4058\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0632\tTop_Loss: 0.2268\tBottom_Loss: 0.1479\tLoss: 0.4379\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0692\tTop_Loss: 0.1023\tBottom_Loss: 0.2115\tLoss: 0.3831\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0847\tTop_Loss: 0.2269\tBottom_Loss: 0.1210\tLoss: 0.4326\t\n",
      "Subject: 11, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0555\tTop_Loss: 0.2648\tBottom_Loss: 0.1666\tLoss: 0.4869\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0511\tTop_Loss: 0.1206\tBottom_Loss: 0.0821\tLoss: 0.2537\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0404\tTop_Loss: 0.0893\tBottom_Loss: 0.1075\tLoss: 0.2372\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0435\tTop_Loss: 0.1381\tBottom_Loss: 0.0677\tLoss: 0.2493\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0382\tTop_Loss: 0.1092\tBottom_Loss: 0.0927\tLoss: 0.2401\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0252\tTop_Loss: 0.0688\tBottom_Loss: 0.0598\tLoss: 0.1538\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0451\tTop_Loss: 0.1356\tBottom_Loss: 0.0846\tLoss: 0.2653\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0695\tTop_Loss: 0.1953\tBottom_Loss: 0.0989\tLoss: 0.3636\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0236\tTop_Loss: 0.0716\tBottom_Loss: 0.0830\tLoss: 0.1782\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1640\tTop_Loss: 0.1452\tBottom_Loss: 0.2611\tLoss: 0.5703\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0826\tTop_Loss: 0.2970\tBottom_Loss: 0.0841\tLoss: 0.4637\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0513\tTop_Loss: 0.1667\tBottom_Loss: 0.1697\tLoss: 0.3877\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0213\tTop_Loss: 0.0634\tBottom_Loss: 0.0662\tLoss: 0.1508\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0416\tTop_Loss: 0.0924\tBottom_Loss: 0.1284\tLoss: 0.2623\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0968\tTop_Loss: 0.1370\tBottom_Loss: 0.1633\tLoss: 0.3971\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[71][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1122\tTop_Loss: 0.0965\tBottom_Loss: 0.1385\tLoss: 0.3472\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0207\tTop_Loss: 0.0818\tBottom_Loss: 0.0411\tLoss: 0.1436\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0538\tTop_Loss: 0.1482\tBottom_Loss: 0.0774\tLoss: 0.2794\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0393\tTop_Loss: 0.1092\tBottom_Loss: 0.1185\tLoss: 0.2669\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0295\tTop_Loss: 0.0962\tBottom_Loss: 0.0768\tLoss: 0.2026\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0394\tTop_Loss: 0.1269\tBottom_Loss: 0.1090\tLoss: 0.2753\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0801\tTop_Loss: 0.1486\tBottom_Loss: 0.2071\tLoss: 0.4358\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1293\tTop_Loss: 0.2740\tBottom_Loss: 0.2397\tLoss: 0.6430\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0585\tTop_Loss: 0.1126\tBottom_Loss: 0.0592\tLoss: 0.2303\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0275\tTop_Loss: 0.0657\tBottom_Loss: 0.0715\tLoss: 0.1647\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0225\tTop_Loss: 0.0975\tBottom_Loss: 0.0707\tLoss: 0.1907\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0161\tTop_Loss: 0.0623\tBottom_Loss: 0.0458\tLoss: 0.1242\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0192\tTop_Loss: 0.0472\tBottom_Loss: 0.0266\tLoss: 0.0930\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0161\tTop_Loss: 0.0748\tBottom_Loss: 0.0655\tLoss: 0.1565\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0340\tTop_Loss: 0.1327\tBottom_Loss: 0.0424\tLoss: 0.2090\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0502\tTop_Loss: 0.0820\tBottom_Loss: 0.0799\tLoss: 0.2121\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0414\tTop_Loss: 0.1137\tBottom_Loss: 0.0667\tLoss: 0.2219\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0475\tTop_Loss: 0.1124\tBottom_Loss: 0.1057\tLoss: 0.2656\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0197\tTop_Loss: 0.0804\tBottom_Loss: 0.0798\tLoss: 0.1799\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0366\tTop_Loss: 0.1240\tBottom_Loss: 0.0492\tLoss: 0.2098\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0379\tTop_Loss: 0.1225\tBottom_Loss: 0.0603\tLoss: 0.2207\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0192\tTop_Loss: 0.0651\tBottom_Loss: 0.0719\tLoss: 0.1562\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0249\tTop_Loss: 0.0706\tBottom_Loss: 0.0814\tLoss: 0.1768\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0145\tTop_Loss: 0.0643\tBottom_Loss: 0.0461\tLoss: 0.1249\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0241\tTop_Loss: 0.0709\tBottom_Loss: 0.0665\tLoss: 0.1615\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0228\tTop_Loss: 0.0550\tBottom_Loss: 0.0652\tLoss: 0.1430\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0305\tTop_Loss: 0.0689\tBottom_Loss: 0.0472\tLoss: 0.1466\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0204\tTop_Loss: 0.0504\tBottom_Loss: 0.0389\tLoss: 0.1097\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0080\tTop_Loss: 0.0706\tBottom_Loss: 0.0277\tLoss: 0.1063\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0133\tTop_Loss: 0.0386\tBottom_Loss: 0.0340\tLoss: 0.0859\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0216\tTop_Loss: 0.0689\tBottom_Loss: 0.0847\tLoss: 0.1752\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0232\tTop_Loss: 0.0380\tBottom_Loss: 0.0458\tLoss: 0.1070\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0618\tTop_Loss: 0.0763\tBottom_Loss: 0.2092\tLoss: 0.3473\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0429\tTop_Loss: 0.0719\tBottom_Loss: 0.0883\tLoss: 0.2030\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0049\tTop_Loss: 0.0200\tBottom_Loss: 0.0178\tLoss: 0.0428\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0105\tTop_Loss: 0.0340\tBottom_Loss: 0.1104\tLoss: 0.1549\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0132\tTop_Loss: 0.0590\tBottom_Loss: 0.0338\tLoss: 0.1061\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0100\tTop_Loss: 0.0300\tBottom_Loss: 0.0514\tLoss: 0.0913\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0134\tTop_Loss: 0.0297\tBottom_Loss: 0.0249\tLoss: 0.0680\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0218\tTop_Loss: 0.0986\tBottom_Loss: 0.0237\tLoss: 0.1441\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0622\tTop_Loss: 0.1095\tBottom_Loss: 0.1159\tLoss: 0.2877\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0100\tTop_Loss: 0.0539\tBottom_Loss: 0.0499\tLoss: 0.1138\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0101\tTop_Loss: 0.0677\tBottom_Loss: 0.0271\tLoss: 0.1049\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0673\tTop_Loss: 0.0632\tBottom_Loss: 0.1197\tLoss: 0.2502\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0033\tTop_Loss: 0.0204\tBottom_Loss: 0.0159\tLoss: 0.0396\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0155\tTop_Loss: 0.0486\tBottom_Loss: 0.0560\tLoss: 0.1201\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0070\tTop_Loss: 0.0285\tBottom_Loss: 0.0208\tLoss: 0.0563\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0298\tTop_Loss: 0.1170\tBottom_Loss: 0.0630\tLoss: 0.2098\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0457\tTop_Loss: 0.0722\tBottom_Loss: 0.0796\tLoss: 0.1975\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0074\tTop_Loss: 0.0194\tBottom_Loss: 0.0166\tLoss: 0.0434\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0110\tTop_Loss: 0.0405\tBottom_Loss: 0.0733\tLoss: 0.1247\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0320\tTop_Loss: 0.0486\tBottom_Loss: 0.0823\tLoss: 0.1629\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0095\tTop_Loss: 0.0240\tBottom_Loss: 0.0341\tLoss: 0.0676\t\n",
      "Subject: 11, n=04 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0089\tTop_Loss: 0.0440\tBottom_Loss: 0.0217\tLoss: 0.0746\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0132\tTop_Loss: 0.0343\tBottom_Loss: 0.0644\tLoss: 0.1119\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0095\tTop_Loss: 0.0447\tBottom_Loss: 0.0201\tLoss: 0.0743\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0060\tTop_Loss: 0.0257\tBottom_Loss: 0.0193\tLoss: 0.0510\t\n",
      "Subject: 11, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.219\tLabel_Loss: 1.8497\tTop_Loss: 1.3223\tBottom_Loss: 1.3571\tLoss: 4.5290\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.312\tLabel_Loss: 1.1658\tTop_Loss: 1.4081\tBottom_Loss: 1.1604\tLoss: 3.7343\t\n",
      "Subject: 12, n=11 | test_f1: 0.20833 |best_f1: 0.20833\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.625\tLabel_Loss: 1.1043\tTop_Loss: 1.1372\tBottom_Loss: 1.1457\tLoss: 3.3872\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.625\tLabel_Loss: 0.9065\tTop_Loss: 0.8845\tBottom_Loss: 0.9695\tLoss: 2.7605\t\n",
      "Subject: 12, n=11 | test_f1: 0.30159 |best_f1: 0.30159\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.531\tLabel_Loss: 1.0350\tTop_Loss: 0.9825\tBottom_Loss: 0.9275\tLoss: 2.9450\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8770\tTop_Loss: 0.7559\tBottom_Loss: 0.7982\tLoss: 2.4311\t\n",
      "Subject: 12, n=11 | test_f1: 0.24908 |best_f1: 0.30159\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7666\tTop_Loss: 0.8324\tBottom_Loss: 0.8808\tLoss: 2.4798\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.406\tLabel_Loss: 1.1198\tTop_Loss: 0.9898\tBottom_Loss: 1.1948\tLoss: 3.3044\t\n",
      "Subject: 12, n=11 | test_f1: 0.20833 |best_f1: 0.30159\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8257\tTop_Loss: 0.7031\tBottom_Loss: 0.8784\tLoss: 2.4072\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.719\tLabel_Loss: 0.9254\tTop_Loss: 0.7912\tBottom_Loss: 1.0050\tLoss: 2.7216\t\n",
      "Subject: 12, n=11 | test_f1: 0.22222 |best_f1: 0.30159\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.531\tLabel_Loss: 0.9558\tTop_Loss: 0.8946\tBottom_Loss: 0.8836\tLoss: 2.7341\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8274\tTop_Loss: 0.7789\tBottom_Loss: 0.8587\tLoss: 2.4650\t\n",
      "Subject: 12, n=11 | test_f1: 0.43182 |best_f1: 0.43182\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.594\tLabel_Loss: 0.9455\tTop_Loss: 1.0073\tBottom_Loss: 1.1154\tLoss: 3.0681\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7741\tTop_Loss: 0.8564\tBottom_Loss: 0.7456\tLoss: 2.3762\t\n",
      "Subject: 12, n=11 | test_f1: 0.20833 |best_f1: 0.43182\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.781\tLabel_Loss: 0.6442\tTop_Loss: 0.6457\tBottom_Loss: 0.6172\tLoss: 1.9071\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.438\tLabel_Loss: 1.0549\tTop_Loss: 0.9946\tBottom_Loss: 1.0196\tLoss: 3.0691\t\n",
      "Subject: 12, n=11 | test_f1: 0.37566 |best_f1: 0.43182\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7517\tTop_Loss: 0.7731\tBottom_Loss: 0.8762\tLoss: 2.4010\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.500\tLabel_Loss: 0.9653\tTop_Loss: 0.9777\tBottom_Loss: 0.9027\tLoss: 2.8458\t\n",
      "Subject: 12, n=11 | test_f1: 0.33333 |best_f1: 0.43182\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.781\tLabel_Loss: 0.6193\tTop_Loss: 0.6901\tBottom_Loss: 0.7333\tLoss: 2.0427\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.562\tLabel_Loss: 0.7869\tTop_Loss: 0.9174\tBottom_Loss: 0.9659\tLoss: 2.6702\t\n",
      "Subject: 12, n=11 | test_f1: 0.40404 |best_f1: 0.43182\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7943\tTop_Loss: 0.9032\tBottom_Loss: 0.8644\tLoss: 2.5619\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.781\tLabel_Loss: 0.6291\tTop_Loss: 0.7977\tBottom_Loss: 0.6382\tLoss: 2.0650\t\n",
      "Subject: 12, n=11 | test_f1: 0.47222 |best_f1: 0.47222\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8100\tTop_Loss: 0.8978\tBottom_Loss: 0.8811\tLoss: 2.5889\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.531\tLabel_Loss: 0.8378\tTop_Loss: 0.9087\tBottom_Loss: 0.7779\tLoss: 2.5244\t\n",
      "Subject: 12, n=11 | test_f1: 0.64444 |best_f1: 0.64444\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.688\tLabel_Loss: 0.8335\tTop_Loss: 0.8057\tBottom_Loss: 1.0430\tLoss: 2.6822\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.594\tLabel_Loss: 0.9708\tTop_Loss: 1.1131\tBottom_Loss: 0.9279\tLoss: 3.0118\t\n",
      "Subject: 12, n=11 | test_f1: 0.53872 |best_f1: 0.64444\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5662\tTop_Loss: 0.8044\tBottom_Loss: 0.6695\tLoss: 2.0401\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4676\tTop_Loss: 0.5399\tBottom_Loss: 0.5997\tLoss: 1.6072\t\n",
      "Subject: 12, n=11 | test_f1: 0.39057 |best_f1: 0.64444\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5389\tTop_Loss: 0.6193\tBottom_Loss: 0.6271\tLoss: 1.7853\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6505\tTop_Loss: 0.7482\tBottom_Loss: 0.7331\tLoss: 2.1318\t\n",
      "Subject: 12, n=11 | test_f1: 0.64444 |best_f1: 0.64444\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4671\tTop_Loss: 0.6505\tBottom_Loss: 0.7425\tLoss: 1.8601\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5058\tTop_Loss: 0.6294\tBottom_Loss: 0.6514\tLoss: 1.7866\t\n",
      "Subject: 12, n=11 | test_f1: 0.26496 |best_f1: 0.64444\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.688\tLabel_Loss: 0.5999\tTop_Loss: 0.8587\tBottom_Loss: 0.7638\tLoss: 2.2224\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.656\tLabel_Loss: 0.6484\tTop_Loss: 0.6950\tBottom_Loss: 0.7356\tLoss: 2.0790\t\n",
      "Subject: 12, n=11 | test_f1: 0.53872 |best_f1: 0.64444\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6613\tTop_Loss: 0.7445\tBottom_Loss: 0.7773\tLoss: 2.1831\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5686\tTop_Loss: 0.7048\tBottom_Loss: 0.7009\tLoss: 1.9743\t\n",
      "Subject: 12, n=11 | test_f1: 0.47222 |best_f1: 0.64444\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.719\tLabel_Loss: 0.4995\tTop_Loss: 0.6949\tBottom_Loss: 0.6395\tLoss: 1.8339\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5700\tTop_Loss: 0.4930\tBottom_Loss: 0.7563\tLoss: 1.8194\t\n",
      "Subject: 12, n=11 | test_f1: 0.71111 |best_f1: 0.71111\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5699\tTop_Loss: 0.8094\tBottom_Loss: 0.5082\tLoss: 1.8875\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.750\tLabel_Loss: 0.4940\tTop_Loss: 0.5553\tBottom_Loss: 0.6311\tLoss: 1.6804\t\n",
      "Subject: 12, n=11 | test_f1: 0.46667 |best_f1: 0.71111\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4179\tTop_Loss: 0.5994\tBottom_Loss: 0.6386\tLoss: 1.6560\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4389\tTop_Loss: 0.5358\tBottom_Loss: 0.5971\tLoss: 1.5718\t\n",
      "Subject: 12, n=11 | test_f1: 0.71465 |best_f1: 0.71465\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5599\tTop_Loss: 0.5487\tBottom_Loss: 0.7231\tLoss: 1.8317\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4311\tTop_Loss: 0.3849\tBottom_Loss: 0.6159\tLoss: 1.4319\t\n",
      "Subject: 12, n=11 | test_f1: 0.46667 |best_f1: 0.71465\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3732\tTop_Loss: 0.4738\tBottom_Loss: 0.5443\tLoss: 1.3912\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.719\tLabel_Loss: 0.4680\tTop_Loss: 0.5593\tBottom_Loss: 0.5181\tLoss: 1.5455\t\n",
      "Subject: 12, n=11 | test_f1: 0.38889 |best_f1: 0.71465\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4959\tTop_Loss: 0.7915\tBottom_Loss: 0.7088\tLoss: 1.9962\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3861\tTop_Loss: 0.3488\tBottom_Loss: 0.6019\tLoss: 1.3368\t\n",
      "Subject: 12, n=11 | test_f1: 0.71465 |best_f1: 0.71465\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5566\tTop_Loss: 0.7275\tBottom_Loss: 0.5779\tLoss: 1.8620\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.750\tLabel_Loss: 0.4449\tTop_Loss: 0.5080\tBottom_Loss: 0.6024\tLoss: 1.5553\t\n",
      "Subject: 12, n=11 | test_f1: 0.71465 |best_f1: 0.71465\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2147\tTop_Loss: 0.5155\tBottom_Loss: 0.4255\tLoss: 1.1557\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5463\tTop_Loss: 0.6733\tBottom_Loss: 0.6341\tLoss: 1.8537\t\n",
      "Subject: 12, n=11 | test_f1: 0.57071 |best_f1: 0.71465\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4568\tTop_Loss: 0.5207\tBottom_Loss: 0.7095\tLoss: 1.6870\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2676\tTop_Loss: 0.6313\tBottom_Loss: 0.3853\tLoss: 1.2842\t\n",
      "Subject: 12, n=11 | test_f1: 0.78519 |best_f1: 0.78519\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4135\tTop_Loss: 0.5885\tBottom_Loss: 0.6124\tLoss: 1.6144\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3069\tTop_Loss: 0.4972\tBottom_Loss: 0.3671\tLoss: 1.1712\t\n",
      "Subject: 12, n=11 | test_f1: 0.63131 |best_f1: 0.78519\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2716\tTop_Loss: 0.3658\tBottom_Loss: 0.4493\tLoss: 1.0867\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3461\tTop_Loss: 0.3622\tBottom_Loss: 0.4803\tLoss: 1.1886\t\n",
      "Subject: 12, n=11 | test_f1: 0.39057 |best_f1: 0.78519\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4352\tTop_Loss: 0.6109\tBottom_Loss: 0.4366\tLoss: 1.4828\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3863\tTop_Loss: 0.5826\tBottom_Loss: 0.3997\tLoss: 1.3685\t\n",
      "Subject: 12, n=11 | test_f1: 0.47222 |best_f1: 0.78519\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3192\tTop_Loss: 0.4114\tBottom_Loss: 0.4508\tLoss: 1.1814\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.844\tLabel_Loss: 0.2914\tTop_Loss: 0.4843\tBottom_Loss: 0.3620\tLoss: 1.1378\t\n",
      "Subject: 12, n=11 | test_f1: 0.53846 |best_f1: 0.78519\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3965\tTop_Loss: 0.4778\tBottom_Loss: 0.4435\tLoss: 1.3178\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2667\tTop_Loss: 0.4718\tBottom_Loss: 0.4321\tLoss: 1.1706\t\n",
      "Subject: 12, n=11 | test_f1: 0.4 |best_f1: 0.78519\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2200\tTop_Loss: 0.4894\tBottom_Loss: 0.3690\tLoss: 1.0783\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2736\tTop_Loss: 0.5664\tBottom_Loss: 0.3446\tLoss: 1.1845\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 12, n=11 | test_f1: 0.53896 |best_f1: 0.78519\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1810\tTop_Loss: 0.5671\tBottom_Loss: 0.2796\tLoss: 1.0277\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2810\tTop_Loss: 0.3360\tBottom_Loss: 0.4371\tLoss: 1.0542\t\n",
      "Subject: 12, n=11 | test_f1: 0.52778 |best_f1: 0.78519\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2371\tTop_Loss: 0.2961\tBottom_Loss: 0.5185\tLoss: 1.0518\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2603\tTop_Loss: 0.4307\tBottom_Loss: 0.3710\tLoss: 1.0621\t\n",
      "Subject: 12, n=11 | test_f1: 0.33333 |best_f1: 0.78519\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2433\tTop_Loss: 0.4357\tBottom_Loss: 0.3783\tLoss: 1.0573\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1703\tTop_Loss: 0.3424\tBottom_Loss: 0.2772\tLoss: 0.7899\t\n",
      "Subject: 12, n=11 | test_f1: 0.78519 |best_f1: 0.78519\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3008\tTop_Loss: 0.4325\tBottom_Loss: 0.4187\tLoss: 1.1520\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1237\tTop_Loss: 0.3047\tBottom_Loss: 0.2479\tLoss: 0.6763\t\n",
      "Subject: 12, n=11 | test_f1: 0.71465 |best_f1: 0.78519\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2629\tTop_Loss: 0.5124\tBottom_Loss: 0.4159\tLoss: 1.1912\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1762\tTop_Loss: 0.3760\tBottom_Loss: 0.3792\tLoss: 0.9315\t\n",
      "Subject: 12, n=11 | test_f1: 0.71465 |best_f1: 0.78519\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2268\tTop_Loss: 0.3926\tBottom_Loss: 0.3336\tLoss: 0.9530\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5236\tTop_Loss: 0.5988\tBottom_Loss: 0.6143\tLoss: 1.7367\t\n",
      "Subject: 12, n=11 | test_f1: 0.53333 |best_f1: 0.78519\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2320\tTop_Loss: 0.3048\tBottom_Loss: 0.3738\tLoss: 0.9106\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3532\tTop_Loss: 0.3515\tBottom_Loss: 0.3203\tLoss: 1.0250\t\n",
      "Subject: 12, n=11 | test_f1: 0.64444 |best_f1: 0.78519\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2187\tTop_Loss: 0.3560\tBottom_Loss: 0.3412\tLoss: 0.9159\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1321\tTop_Loss: 0.2799\tBottom_Loss: 0.2876\tLoss: 0.6996\t\n",
      "Subject: 12, n=11 | test_f1: 0.38889 |best_f1: 0.78519\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3470\tTop_Loss: 0.3094\tBottom_Loss: 0.4506\tLoss: 1.1070\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2356\tTop_Loss: 0.3590\tBottom_Loss: 0.2625\tLoss: 0.8571\t\n",
      "Subject: 12, n=11 | test_f1: 0.53872 |best_f1: 0.78519\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1247\tTop_Loss: 0.2320\tBottom_Loss: 0.2187\tLoss: 0.5754\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0931\tTop_Loss: 0.2266\tBottom_Loss: 0.1574\tLoss: 0.4771\t\n",
      "Subject: 12, n=11 | test_f1: 0.4 |best_f1: 0.78519\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1332\tTop_Loss: 0.3368\tBottom_Loss: 0.1920\tLoss: 0.6620\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0823\tTop_Loss: 0.1299\tBottom_Loss: 0.1775\tLoss: 0.3897\t\n",
      "Subject: 12, n=11 | test_f1: 0.57037 |best_f1: 0.78519\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1799\tTop_Loss: 0.3936\tBottom_Loss: 0.2745\tLoss: 0.8480\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0718\tTop_Loss: 0.2201\tBottom_Loss: 0.1642\tLoss: 0.4561\t\n",
      "Subject: 12, n=11 | test_f1: 0.56296 |best_f1: 0.78519\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1150\tTop_Loss: 0.2322\tBottom_Loss: 0.1623\tLoss: 0.5095\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1570\tTop_Loss: 0.2876\tBottom_Loss: 0.2235\tLoss: 0.6681\t\n",
      "Subject: 12, n=11 | test_f1: 0.48889 |best_f1: 0.78519\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0848\tTop_Loss: 0.3057\tBottom_Loss: 0.2481\tLoss: 0.6386\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0763\tTop_Loss: 0.2194\tBottom_Loss: 0.2390\tLoss: 0.5347\t\n",
      "Subject: 12, n=11 | test_f1: 0.4 |best_f1: 0.78519\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1847\tTop_Loss: 0.4563\tBottom_Loss: 0.1909\tLoss: 0.8318\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1115\tTop_Loss: 0.3319\tBottom_Loss: 0.1956\tLoss: 0.6390\t\n",
      "Subject: 12, n=11 | test_f1: 0.30037 |best_f1: 0.78519\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1378\tTop_Loss: 0.3630\tBottom_Loss: 0.2390\tLoss: 0.7398\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1224\tTop_Loss: 0.3288\tBottom_Loss: 0.1295\tLoss: 0.5807\t\n",
      "Subject: 12, n=11 | test_f1: 0.53333 |best_f1: 0.78519\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0821\tTop_Loss: 0.2686\tBottom_Loss: 0.1569\tLoss: 0.5075\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1267\tTop_Loss: 0.2289\tBottom_Loss: 0.2293\tLoss: 0.5848\t\n",
      "Subject: 12, n=11 | test_f1: 0.30556 |best_f1: 0.78519\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2069\tTop_Loss: 0.3638\tBottom_Loss: 0.2860\tLoss: 0.8567\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0826\tTop_Loss: 0.2538\tBottom_Loss: 0.1201\tLoss: 0.4565\t\n",
      "Subject: 12, n=11 | test_f1: 0.46465 |best_f1: 0.78519\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1859\tTop_Loss: 0.2945\tBottom_Loss: 0.2056\tLoss: 0.6861\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0899\tTop_Loss: 0.2337\tBottom_Loss: 0.1459\tLoss: 0.4695\t\n",
      "Subject: 12, n=11 | test_f1: 0.46667 |best_f1: 0.78519\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0732\tTop_Loss: 0.2347\tBottom_Loss: 0.1103\tLoss: 0.4183\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1097\tTop_Loss: 0.2859\tBottom_Loss: 0.2368\tLoss: 0.6325\t\n",
      "Subject: 12, n=11 | test_f1: 0.46667 |best_f1: 0.78519\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1368\tTop_Loss: 0.1571\tBottom_Loss: 0.2167\tLoss: 0.5106\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0849\tTop_Loss: 0.1429\tBottom_Loss: 0.2351\tLoss: 0.4629\t\n",
      "Subject: 12, n=11 | test_f1: 0.31746 |best_f1: 0.78519\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0533\tTop_Loss: 0.2205\tBottom_Loss: 0.1172\tLoss: 0.3909\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0585\tTop_Loss: 0.1681\tBottom_Loss: 0.1021\tLoss: 0.3287\t\n",
      "Subject: 12, n=11 | test_f1: 0.53872 |best_f1: 0.78519\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.938\tLabel_Loss: 0.0869\tTop_Loss: 0.1631\tBottom_Loss: 0.1418\tLoss: 0.3918\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0913\tTop_Loss: 0.2237\tBottom_Loss: 0.1932\tLoss: 0.5082\t\n",
      "Subject: 12, n=11 | test_f1: 0.48889 |best_f1: 0.78519\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1156\tTop_Loss: 0.1418\tBottom_Loss: 0.2123\tLoss: 0.4697\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0488\tTop_Loss: 0.1871\tBottom_Loss: 0.0794\tLoss: 0.3153\t\n",
      "Subject: 12, n=11 | test_f1: 0.42222 |best_f1: 0.78519\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0396\tTop_Loss: 0.1174\tBottom_Loss: 0.1318\tLoss: 0.2888\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0613\tTop_Loss: 0.1525\tBottom_Loss: 0.1160\tLoss: 0.3298\t\n",
      "Subject: 12, n=11 | test_f1: 0.64444 |best_f1: 0.78519\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0210\tTop_Loss: 0.1286\tBottom_Loss: 0.0542\tLoss: 0.2039\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0513\tTop_Loss: 0.1324\tBottom_Loss: 0.1256\tLoss: 0.3093\t\n",
      "Subject: 12, n=11 | test_f1: 0.46667 |best_f1: 0.78519\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0496\tTop_Loss: 0.1731\tBottom_Loss: 0.0730\tLoss: 0.2958\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0882\tTop_Loss: 0.1390\tBottom_Loss: 0.1828\tLoss: 0.4100\t\n",
      "Subject: 12, n=11 | test_f1: 0.30159 |best_f1: 0.78519\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0487\tTop_Loss: 0.1128\tBottom_Loss: 0.1223\tLoss: 0.2838\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0722\tTop_Loss: 0.2660\tBottom_Loss: 0.1208\tLoss: 0.4590\t\n",
      "Subject: 12, n=11 | test_f1: 0.57037 |best_f1: 0.78519\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0387\tTop_Loss: 0.1271\tBottom_Loss: 0.0703\tLoss: 0.2362\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0948\tTop_Loss: 0.1569\tBottom_Loss: 0.1963\tLoss: 0.4480\t\n",
      "Subject: 12, n=11 | test_f1: 0.78519 |best_f1: 0.78519\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1181\tTop_Loss: 0.2515\tBottom_Loss: 0.1096\tLoss: 0.4792\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0496\tTop_Loss: 0.1052\tBottom_Loss: 0.0874\tLoss: 0.2422\t\n",
      "Subject: 12, n=11 | test_f1: 0.56296 |best_f1: 0.78519\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0576\tTop_Loss: 0.1609\tBottom_Loss: 0.1261\tLoss: 0.3446\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[63][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0391\tTop_Loss: 0.0851\tBottom_Loss: 0.0665\tLoss: 0.1906\t\n",
      "Subject: 12, n=11 | test_f1: 0.76667 |best_f1: 0.78519\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0748\tTop_Loss: 0.1615\tBottom_Loss: 0.0866\tLoss: 0.3230\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1123\tTop_Loss: 0.1380\tBottom_Loss: 0.2179\tLoss: 0.4681\t\n",
      "Subject: 12, n=11 | test_f1: 0.46465 |best_f1: 0.78519\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1052\tTop_Loss: 0.1366\tBottom_Loss: 0.1560\tLoss: 0.3978\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0453\tTop_Loss: 0.1548\tBottom_Loss: 0.0948\tLoss: 0.2949\t\n",
      "Subject: 12, n=11 | test_f1: 0.4 |best_f1: 0.78519\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0650\tTop_Loss: 0.1985\tBottom_Loss: 0.0897\tLoss: 0.3532\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0334\tTop_Loss: 0.0945\tBottom_Loss: 0.0921\tLoss: 0.2200\t\n",
      "Subject: 12, n=11 | test_f1: 0.64444 |best_f1: 0.78519\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0379\tTop_Loss: 0.0870\tBottom_Loss: 0.1199\tLoss: 0.2449\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0115\tTop_Loss: 0.1080\tBottom_Loss: 0.0425\tLoss: 0.1619\t\n",
      "Subject: 12, n=11 | test_f1: 0.38889 |best_f1: 0.78519\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0302\tTop_Loss: 0.0787\tBottom_Loss: 0.0527\tLoss: 0.1617\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0379\tTop_Loss: 0.0788\tBottom_Loss: 0.0993\tLoss: 0.2160\t\n",
      "Subject: 12, n=11 | test_f1: 0.52778 |best_f1: 0.78519\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0574\tTop_Loss: 0.1697\tBottom_Loss: 0.1053\tLoss: 0.3324\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0699\tTop_Loss: 0.1387\tBottom_Loss: 0.0739\tLoss: 0.2826\t\n",
      "Subject: 12, n=11 | test_f1: 0.4127 |best_f1: 0.78519\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0610\tTop_Loss: 0.1290\tBottom_Loss: 0.1415\tLoss: 0.3315\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 0.938\tLabel_Loss: 0.0977\tTop_Loss: 0.2099\tBottom_Loss: 0.1898\tLoss: 0.4975\t\n",
      "Subject: 12, n=11 | test_f1: 0.53704 |best_f1: 0.78519\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0349\tTop_Loss: 0.0888\tBottom_Loss: 0.0749\tLoss: 0.1985\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0120\tTop_Loss: 0.0681\tBottom_Loss: 0.0258\tLoss: 0.1058\t\n",
      "Subject: 12, n=11 | test_f1: 0.78519 |best_f1: 0.78519\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0151\tTop_Loss: 0.0631\tBottom_Loss: 0.0399\tLoss: 0.1181\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0486\tTop_Loss: 0.0699\tBottom_Loss: 0.0574\tLoss: 0.1758\t\n",
      "Subject: 12, n=11 | test_f1: 0.63131 |best_f1: 0.78519\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0476\tTop_Loss: 0.0914\tBottom_Loss: 0.1395\tLoss: 0.2785\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0218\tTop_Loss: 0.1136\tBottom_Loss: 0.0599\tLoss: 0.1953\t\n",
      "Subject: 12, n=11 | test_f1: 0.32997 |best_f1: 0.78519\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0126\tTop_Loss: 0.0415\tBottom_Loss: 0.0419\tLoss: 0.0959\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0296\tTop_Loss: 0.0960\tBottom_Loss: 0.1173\tLoss: 0.2428\t\n",
      "Subject: 12, n=11 | test_f1: 0.57071 |best_f1: 0.78519\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0402\tTop_Loss: 0.1106\tBottom_Loss: 0.0797\tLoss: 0.2306\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1244\tTop_Loss: 0.2449\tBottom_Loss: 0.1320\tLoss: 0.5012\t\n",
      "Subject: 12, n=11 | test_f1: 0.53896 |best_f1: 0.78519\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1350\tTop_Loss: 0.1460\tBottom_Loss: 0.1120\tLoss: 0.3930\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0290\tTop_Loss: 0.1253\tBottom_Loss: 0.0498\tLoss: 0.2041\t\n",
      "Subject: 12, n=11 | test_f1: 0.57071 |best_f1: 0.78519\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0269\tTop_Loss: 0.0915\tBottom_Loss: 0.0561\tLoss: 0.1745\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1184\tTop_Loss: 0.0861\tBottom_Loss: 0.2165\tLoss: 0.4210\t\n",
      "Subject: 12, n=11 | test_f1: 0.41481 |best_f1: 0.78519\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0155\tTop_Loss: 0.0575\tBottom_Loss: 0.0759\tLoss: 0.1488\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0234\tTop_Loss: 0.0976\tBottom_Loss: 0.0345\tLoss: 0.1555\t\n",
      "Subject: 12, n=11 | test_f1: 0.48889 |best_f1: 0.78519\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0210\tTop_Loss: 0.0568\tBottom_Loss: 0.0527\tLoss: 0.1305\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0147\tTop_Loss: 0.0590\tBottom_Loss: 0.0503\tLoss: 0.1241\t\n",
      "Subject: 12, n=11 | test_f1: 0.46667 |best_f1: 0.78519\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0093\tTop_Loss: 0.0674\tBottom_Loss: 0.0305\tLoss: 0.1072\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0316\tTop_Loss: 0.0466\tBottom_Loss: 0.0452\tLoss: 0.1233\t\n",
      "Subject: 12, n=11 | test_f1: 0.4 |best_f1: 0.78519\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0272\tTop_Loss: 0.1102\tBottom_Loss: 0.0879\tLoss: 0.2253\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0117\tTop_Loss: 0.0453\tBottom_Loss: 0.0652\tLoss: 0.1222\t\n",
      "Subject: 12, n=11 | test_f1: 0.34815 |best_f1: 0.78519\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0117\tTop_Loss: 0.0414\tBottom_Loss: 0.0288\tLoss: 0.0819\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0091\tTop_Loss: 0.0329\tBottom_Loss: 0.0441\tLoss: 0.0862\t\n",
      "Subject: 12, n=11 | test_f1: 0.38889 |best_f1: 0.78519\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1918\tTop_Loss: 0.1577\tBottom_Loss: 0.1652\tLoss: 0.5147\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0264\tTop_Loss: 0.0511\tBottom_Loss: 0.0857\tLoss: 0.1633\t\n",
      "Subject: 12, n=11 | test_f1: 0.46465 |best_f1: 0.78519\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0161\tTop_Loss: 0.0744\tBottom_Loss: 0.0254\tLoss: 0.1159\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0061\tTop_Loss: 0.0240\tBottom_Loss: 0.0208\tLoss: 0.0509\t\n",
      "Subject: 12, n=11 | test_f1: 0.38889 |best_f1: 0.78519\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0087\tTop_Loss: 0.0618\tBottom_Loss: 0.0306\tLoss: 0.1012\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0249\tTop_Loss: 0.0705\tBottom_Loss: 0.0822\tLoss: 0.1776\t\n",
      "Subject: 12, n=11 | test_f1: 0.46465 |best_f1: 0.78519\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0923\tTop_Loss: 0.0691\tBottom_Loss: 0.0960\tLoss: 0.2574\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0105\tTop_Loss: 0.0785\tBottom_Loss: 0.0167\tLoss: 0.1057\t\n",
      "Subject: 12, n=11 | test_f1: 0.68519 |best_f1: 0.78519\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0182\tTop_Loss: 0.0498\tBottom_Loss: 0.0495\tLoss: 0.1175\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0207\tTop_Loss: 0.0602\tBottom_Loss: 0.0397\tLoss: 0.1206\t\n",
      "Subject: 12, n=11 | test_f1: 0.69481 |best_f1: 0.78519\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0254\tTop_Loss: 0.1307\tBottom_Loss: 0.0817\tLoss: 0.2378\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0102\tTop_Loss: 0.0260\tBottom_Loss: 0.0186\tLoss: 0.0548\t\n",
      "Subject: 12, n=11 | test_f1: 0.53872 |best_f1: 0.78519\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0034\tTop_Loss: 0.0182\tBottom_Loss: 0.0153\tLoss: 0.0369\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0101\tTop_Loss: 0.0423\tBottom_Loss: 0.0244\tLoss: 0.0769\t\n",
      "Subject: 12, n=11 | test_f1: 0.68519 |best_f1: 0.78519\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0239\tTop_Loss: 0.0514\tBottom_Loss: 0.0891\tLoss: 0.1644\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0216\tTop_Loss: 0.0586\tBottom_Loss: 0.0480\tLoss: 0.1283\t\n",
      "Subject: 12, n=11 | test_f1: 0.71465 |best_f1: 0.78519\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0521\tTop_Loss: 0.1194\tBottom_Loss: 0.1393\tLoss: 0.3107\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0323\tTop_Loss: 0.0913\tBottom_Loss: 0.0926\tLoss: 0.2163\t\n",
      "Subject: 12, n=11 | test_f1: 0.46465 |best_f1: 0.78519\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0071\tTop_Loss: 0.0236\tBottom_Loss: 0.0238\tLoss: 0.0545\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0396\tTop_Loss: 0.0570\tBottom_Loss: 0.0642\tLoss: 0.1608\t\n",
      "Subject: 12, n=11 | test_f1: 0.46465 |best_f1: 0.78519\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0186\tTop_Loss: 0.0868\tBottom_Loss: 0.0235\tLoss: 0.1289\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0102\tTop_Loss: 0.0594\tBottom_Loss: 0.0177\tLoss: 0.0872\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 12, n=11 | test_f1: 0.4 |best_f1: 0.78519\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0115\tTop_Loss: 0.0449\tBottom_Loss: 0.0393\tLoss: 0.0957\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0156\tTop_Loss: 0.0422\tBottom_Loss: 0.0305\tLoss: 0.0883\t\n",
      "Subject: 12, n=11 | test_f1: 0.53896 |best_f1: 0.78519\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0096\tTop_Loss: 0.0212\tBottom_Loss: 0.0164\tLoss: 0.0473\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0193\tTop_Loss: 0.0388\tBottom_Loss: 0.0619\tLoss: 0.1200\t\n",
      "Subject: 12, n=11 | test_f1: 0.45714 |best_f1: 0.78519\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0261\tTop_Loss: 0.0291\tBottom_Loss: 0.0297\tLoss: 0.0849\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0087\tTop_Loss: 0.0633\tBottom_Loss: 0.0341\tLoss: 0.1061\t\n",
      "Subject: 12, n=11 | test_f1: 0.61667 |best_f1: 0.78519\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0117\tTop_Loss: 0.0171\tBottom_Loss: 0.0515\tLoss: 0.0803\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0061\tTop_Loss: 0.0291\tBottom_Loss: 0.0245\tLoss: 0.0597\t\n",
      "Subject: 12, n=11 | test_f1: 0.78519 |best_f1: 0.78519\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0181\tTop_Loss: 0.0436\tBottom_Loss: 0.0506\tLoss: 0.1123\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0031\tTop_Loss: 0.0107\tBottom_Loss: 0.0132\tLoss: 0.0270\t\n",
      "Subject: 12, n=11 | test_f1: 0.85859 |best_f1: 0.85859\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0032\tTop_Loss: 0.0172\tBottom_Loss: 0.0113\tLoss: 0.0316\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0132\tTop_Loss: 0.0314\tBottom_Loss: 0.0176\tLoss: 0.0622\t\n",
      "Subject: 12, n=11 | test_f1: 0.46465 |best_f1: 0.85859\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.375\tLabel_Loss: 1.3313\tTop_Loss: 1.1204\tBottom_Loss: 1.0343\tLoss: 3.4860\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.625\tLabel_Loss: 0.9576\tTop_Loss: 0.9494\tBottom_Loss: 1.2025\tLoss: 3.1094\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8960\tTop_Loss: 0.7483\tBottom_Loss: 0.9398\tLoss: 2.5840\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.438\tLabel_Loss: 1.1245\tTop_Loss: 1.3561\tBottom_Loss: 1.4001\tLoss: 3.8807\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.562\tLabel_Loss: 0.9405\tTop_Loss: 0.8172\tBottom_Loss: 0.9805\tLoss: 2.7382\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7784\tTop_Loss: 0.9407\tBottom_Loss: 0.8963\tLoss: 2.6153\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.750\tLabel_Loss: 0.7393\tTop_Loss: 0.7858\tBottom_Loss: 0.8073\tLoss: 2.3323\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.719\tLabel_Loss: 0.7174\tTop_Loss: 0.9015\tBottom_Loss: 0.7427\tLoss: 2.3616\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8550\tTop_Loss: 0.9959\tBottom_Loss: 0.9635\tLoss: 2.8144\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7882\tTop_Loss: 0.7626\tBottom_Loss: 0.8148\tLoss: 2.3657\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.719\tLabel_Loss: 0.7408\tTop_Loss: 0.7575\tBottom_Loss: 0.8191\tLoss: 2.3174\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.531\tLabel_Loss: 1.0406\tTop_Loss: 1.2207\tBottom_Loss: 1.1154\tLoss: 3.3767\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6647\tTop_Loss: 0.6702\tBottom_Loss: 0.5580\tLoss: 1.8930\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8519\tTop_Loss: 0.9289\tBottom_Loss: 0.6951\tLoss: 2.4759\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8896\tTop_Loss: 0.9307\tBottom_Loss: 1.0540\tLoss: 2.8742\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7409\tTop_Loss: 0.7649\tBottom_Loss: 1.1485\tLoss: 2.6543\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7981\tTop_Loss: 0.8829\tBottom_Loss: 0.8832\tLoss: 2.5642\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7380\tTop_Loss: 0.8490\tBottom_Loss: 0.8360\tLoss: 2.4229\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.719\tLabel_Loss: 0.7139\tTop_Loss: 0.7071\tBottom_Loss: 0.6509\tLoss: 2.0719\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6086\tTop_Loss: 0.6046\tBottom_Loss: 0.5313\tLoss: 1.7446\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.562\tLabel_Loss: 0.8681\tTop_Loss: 0.9490\tBottom_Loss: 0.9374\tLoss: 2.7545\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.844\tLabel_Loss: 0.5652\tTop_Loss: 0.5145\tBottom_Loss: 0.6985\tLoss: 1.7782\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7740\tTop_Loss: 0.7522\tBottom_Loss: 0.8163\tLoss: 2.3424\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.625\tLabel_Loss: 0.9696\tTop_Loss: 0.9076\tBottom_Loss: 1.0289\tLoss: 2.9060\t\n",
      "Subject: 13, n=02 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.562\tLabel_Loss: 0.8138\tTop_Loss: 0.9282\tBottom_Loss: 0.8004\tLoss: 2.5424\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5008\tTop_Loss: 0.8259\tBottom_Loss: 0.7884\tLoss: 2.1151\t\n",
      "Subject: 13, n=02 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6181\tTop_Loss: 0.7039\tBottom_Loss: 0.7490\tLoss: 2.0711\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3483\tTop_Loss: 0.6491\tBottom_Loss: 0.4075\tLoss: 1.4048\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6619\tTop_Loss: 0.7587\tBottom_Loss: 0.6523\tLoss: 2.0728\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.969\tLabel_Loss: 0.3054\tTop_Loss: 0.5844\tBottom_Loss: 0.4465\tLoss: 1.3363\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3908\tTop_Loss: 0.4926\tBottom_Loss: 0.4326\tLoss: 1.3161\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4616\tTop_Loss: 0.6539\tBottom_Loss: 0.5422\tLoss: 1.6577\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5446\tTop_Loss: 0.6173\tBottom_Loss: 0.6511\tLoss: 1.8130\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7495\tTop_Loss: 0.9843\tBottom_Loss: 0.7868\tLoss: 2.5205\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4604\tTop_Loss: 0.6078\tBottom_Loss: 0.4311\tLoss: 1.4993\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6657\tTop_Loss: 0.9759\tBottom_Loss: 0.8510\tLoss: 2.4926\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5909\tTop_Loss: 0.8086\tBottom_Loss: 0.7747\tLoss: 2.1742\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4783\tTop_Loss: 0.6163\tBottom_Loss: 0.5721\tLoss: 1.6667\t\n",
      "Subject: 13, n=02 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6915\tTop_Loss: 0.8650\tBottom_Loss: 0.7632\tLoss: 2.3197\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3804\tTop_Loss: 0.4751\tBottom_Loss: 0.6286\tLoss: 1.4841\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4415\tTop_Loss: 0.6566\tBottom_Loss: 0.4940\tLoss: 1.5922\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4703\tTop_Loss: 0.5940\tBottom_Loss: 0.6152\tLoss: 1.6795\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5159\tTop_Loss: 0.7405\tBottom_Loss: 0.5181\tLoss: 1.7745\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7718\tTop_Loss: 0.6915\tBottom_Loss: 0.8975\tLoss: 2.3608\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3659\tTop_Loss: 0.5628\tBottom_Loss: 0.3829\tLoss: 1.3116\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3594\tTop_Loss: 0.4530\tBottom_Loss: 0.4925\tLoss: 1.3048\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4768\tTop_Loss: 0.6231\tBottom_Loss: 0.4999\tLoss: 1.5998\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4555\tTop_Loss: 0.5157\tBottom_Loss: 0.6836\tLoss: 1.6548\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4213\tTop_Loss: 0.8353\tBottom_Loss: 0.4449\tLoss: 1.7014\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2612\tTop_Loss: 0.3755\tBottom_Loss: 0.5039\tLoss: 1.1406\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3492\tTop_Loss: 0.5738\tBottom_Loss: 0.4587\tLoss: 1.3817\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5371\tTop_Loss: 0.7178\tBottom_Loss: 0.5946\tLoss: 1.8495\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3750\tTop_Loss: 0.3943\tBottom_Loss: 0.5668\tLoss: 1.3361\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3514\tTop_Loss: 0.4492\tBottom_Loss: 0.4735\tLoss: 1.2741\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5757\tTop_Loss: 0.8435\tBottom_Loss: 0.7941\tLoss: 2.2133\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3733\tTop_Loss: 0.4490\tBottom_Loss: 0.3625\tLoss: 1.1848\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4285\tTop_Loss: 0.7015\tBottom_Loss: 0.3980\tLoss: 1.5279\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2488\tTop_Loss: 0.4393\tBottom_Loss: 0.2134\tLoss: 0.9014\t\n",
      "Subject: 13, n=02 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2756\tTop_Loss: 0.5579\tBottom_Loss: 0.2954\tLoss: 1.1288\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2928\tTop_Loss: 0.4149\tBottom_Loss: 0.5006\tLoss: 1.2083\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3909\tTop_Loss: 0.5314\tBottom_Loss: 0.4405\tLoss: 1.3628\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2226\tTop_Loss: 0.3243\tBottom_Loss: 0.3425\tLoss: 0.8894\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5781\tTop_Loss: 0.6919\tBottom_Loss: 0.7724\tLoss: 2.0424\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2804\tTop_Loss: 0.4395\tBottom_Loss: 0.4230\tLoss: 1.1429\t\n",
      "Subject: 13, n=02 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3482\tTop_Loss: 0.5721\tBottom_Loss: 0.4638\tLoss: 1.3841\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2773\tTop_Loss: 0.4206\tBottom_Loss: 0.4724\tLoss: 1.1703\t\n",
      "Subject: 13, n=02 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2846\tTop_Loss: 0.4357\tBottom_Loss: 0.5351\tLoss: 1.2554\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2730\tTop_Loss: 0.5969\tBottom_Loss: 0.3281\tLoss: 1.1980\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2693\tTop_Loss: 0.5391\tBottom_Loss: 0.4521\tLoss: 1.2605\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1625\tTop_Loss: 0.1858\tBottom_Loss: 0.3062\tLoss: 0.6545\t\n",
      "Subject: 13, n=02 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1806\tTop_Loss: 0.2966\tBottom_Loss: 0.2378\tLoss: 0.7150\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1712\tTop_Loss: 0.3650\tBottom_Loss: 0.2419\tLoss: 0.7781\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2045\tTop_Loss: 0.3623\tBottom_Loss: 0.2856\tLoss: 0.8524\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1735\tTop_Loss: 0.2737\tBottom_Loss: 0.2037\tLoss: 0.6508\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2601\tTop_Loss: 0.4547\tBottom_Loss: 0.2973\tLoss: 1.0122\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1604\tTop_Loss: 0.2972\tBottom_Loss: 0.3152\tLoss: 0.7728\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1644\tTop_Loss: 0.2936\tBottom_Loss: 0.2839\tLoss: 0.7419\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1330\tTop_Loss: 0.2775\tBottom_Loss: 0.2587\tLoss: 0.6692\t\n",
      "Subject: 13, n=02 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3128\tTop_Loss: 0.5640\tBottom_Loss: 0.2647\tLoss: 1.1415\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1836\tTop_Loss: 0.2320\tBottom_Loss: 0.3165\tLoss: 0.7321\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1625\tTop_Loss: 0.3540\tBottom_Loss: 0.3187\tLoss: 0.8352\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0904\tTop_Loss: 0.1549\tBottom_Loss: 0.2370\tLoss: 0.4822\t\n",
      "Subject: 13, n=02 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1927\tTop_Loss: 0.3561\tBottom_Loss: 0.3389\tLoss: 0.8877\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3160\tTop_Loss: 0.4921\tBottom_Loss: 0.2948\tLoss: 1.1029\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1760\tTop_Loss: 0.3792\tBottom_Loss: 0.3049\tLoss: 0.8601\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1192\tTop_Loss: 0.2993\tBottom_Loss: 0.1338\tLoss: 0.5522\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2212\tTop_Loss: 0.3481\tBottom_Loss: 0.1694\tLoss: 0.7386\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1500\tTop_Loss: 0.3223\tBottom_Loss: 0.1751\tLoss: 0.6473\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1359\tTop_Loss: 0.2377\tBottom_Loss: 0.2253\tLoss: 0.5989\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1990\tTop_Loss: 0.4193\tBottom_Loss: 0.3037\tLoss: 0.9220\t\n",
      "Subject: 13, n=02 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1657\tTop_Loss: 0.3110\tBottom_Loss: 0.2208\tLoss: 0.6975\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1295\tTop_Loss: 0.3245\tBottom_Loss: 0.1607\tLoss: 0.6147\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1107\tTop_Loss: 0.2935\tBottom_Loss: 0.2285\tLoss: 0.6328\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1255\tTop_Loss: 0.3758\tBottom_Loss: 0.1281\tLoss: 0.6294\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2112\tTop_Loss: 0.3784\tBottom_Loss: 0.2872\tLoss: 0.8769\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2043\tTop_Loss: 0.4553\tBottom_Loss: 0.2785\tLoss: 0.9381\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0507\tTop_Loss: 0.1843\tBottom_Loss: 0.1256\tLoss: 0.3606\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0919\tTop_Loss: 0.1423\tBottom_Loss: 0.2608\tLoss: 0.4949\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0857\tTop_Loss: 0.1922\tBottom_Loss: 0.1414\tLoss: 0.4193\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1058\tTop_Loss: 0.1712\tBottom_Loss: 0.2934\tLoss: 0.5704\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0818\tTop_Loss: 0.1832\tBottom_Loss: 0.1767\tLoss: 0.4416\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1332\tTop_Loss: 0.2309\tBottom_Loss: 0.2758\tLoss: 0.6399\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1069\tTop_Loss: 0.1717\tBottom_Loss: 0.1532\tLoss: 0.4318\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0883\tTop_Loss: 0.2402\tBottom_Loss: 0.0976\tLoss: 0.4261\t\n",
      "Subject: 13, n=02 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.844\tLabel_Loss: 0.2006\tTop_Loss: 0.3004\tBottom_Loss: 0.1508\tLoss: 0.6518\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0752\tTop_Loss: 0.2904\tBottom_Loss: 0.1104\tLoss: 0.4759\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0924\tTop_Loss: 0.2203\tBottom_Loss: 0.1724\tLoss: 0.4851\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0500\tTop_Loss: 0.1764\tBottom_Loss: 0.0827\tLoss: 0.3091\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1361\tTop_Loss: 0.2600\tBottom_Loss: 0.2325\tLoss: 0.6285\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0778\tTop_Loss: 0.2002\tBottom_Loss: 0.1486\tLoss: 0.4266\t\n",
      "Subject: 13, n=02 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1400\tTop_Loss: 0.2571\tBottom_Loss: 0.2594\tLoss: 0.6564\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[55][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0820\tTop_Loss: 0.2027\tBottom_Loss: 0.1415\tLoss: 0.4262\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1041\tTop_Loss: 0.2536\tBottom_Loss: 0.1452\tLoss: 0.5029\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0503\tTop_Loss: 0.1468\tBottom_Loss: 0.0904\tLoss: 0.2874\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0651\tTop_Loss: 0.1954\tBottom_Loss: 0.1599\tLoss: 0.4204\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0724\tTop_Loss: 0.1844\tBottom_Loss: 0.1707\tLoss: 0.4276\t\n",
      "Subject: 13, n=02 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0886\tTop_Loss: 0.2116\tBottom_Loss: 0.1100\tLoss: 0.4102\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0648\tTop_Loss: 0.1501\tBottom_Loss: 0.1190\tLoss: 0.3339\t\n",
      "Subject: 13, n=02 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0668\tTop_Loss: 0.1333\tBottom_Loss: 0.1225\tLoss: 0.3225\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0971\tTop_Loss: 0.2063\tBottom_Loss: 0.2433\tLoss: 0.5467\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1429\tTop_Loss: 0.2464\tBottom_Loss: 0.2282\tLoss: 0.6175\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2019\tTop_Loss: 0.2801\tBottom_Loss: 0.2223\tLoss: 0.7042\t\n",
      "Subject: 13, n=02 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0903\tTop_Loss: 0.1519\tBottom_Loss: 0.1307\tLoss: 0.3729\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0802\tTop_Loss: 0.1586\tBottom_Loss: 0.1152\tLoss: 0.3539\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0513\tTop_Loss: 0.1090\tBottom_Loss: 0.1268\tLoss: 0.2871\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0455\tTop_Loss: 0.1149\tBottom_Loss: 0.1112\tLoss: 0.2716\t\n",
      "Subject: 13, n=02 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0645\tTop_Loss: 0.1223\tBottom_Loss: 0.1240\tLoss: 0.3107\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0375\tTop_Loss: 0.1301\tBottom_Loss: 0.1035\tLoss: 0.2711\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0205\tTop_Loss: 0.1203\tBottom_Loss: 0.0208\tLoss: 0.1616\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0292\tTop_Loss: 0.0952\tBottom_Loss: 0.0976\tLoss: 0.2220\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0432\tTop_Loss: 0.1072\tBottom_Loss: 0.0737\tLoss: 0.2241\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0802\tTop_Loss: 0.1718\tBottom_Loss: 0.1651\tLoss: 0.4171\t\n",
      "Subject: 13, n=02 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1184\tTop_Loss: 0.1483\tBottom_Loss: 0.1704\tLoss: 0.4372\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1929\tTop_Loss: 0.3291\tBottom_Loss: 0.1405\tLoss: 0.6625\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0480\tTop_Loss: 0.1246\tBottom_Loss: 0.1231\tLoss: 0.2957\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0244\tTop_Loss: 0.0607\tBottom_Loss: 0.0753\tLoss: 0.1604\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0217\tTop_Loss: 0.0986\tBottom_Loss: 0.0669\tLoss: 0.1872\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0356\tTop_Loss: 0.1659\tBottom_Loss: 0.0493\tLoss: 0.2508\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0715\tTop_Loss: 0.1649\tBottom_Loss: 0.1456\tLoss: 0.3820\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0411\tTop_Loss: 0.1272\tBottom_Loss: 0.0924\tLoss: 0.2607\t\n",
      "Subject: 13, n=02 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0518\tTop_Loss: 0.1952\tBottom_Loss: 0.0837\tLoss: 0.3306\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0204\tTop_Loss: 0.0455\tBottom_Loss: 0.0863\tLoss: 0.1523\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0477\tTop_Loss: 0.1187\tBottom_Loss: 0.0415\tLoss: 0.2079\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0265\tTop_Loss: 0.1155\tBottom_Loss: 0.0511\tLoss: 0.1930\t\n",
      "Subject: 13, n=02 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 0.938\tLabel_Loss: 0.0982\tTop_Loss: 0.2293\tBottom_Loss: 0.1677\tLoss: 0.4953\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0688\tTop_Loss: 0.0657\tBottom_Loss: 0.0554\tLoss: 0.1899\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 0.938\tLabel_Loss: 0.0915\tTop_Loss: 0.3158\tBottom_Loss: 0.1002\tLoss: 0.5075\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0686\tTop_Loss: 0.0425\tBottom_Loss: 0.0758\tLoss: 0.1870\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0281\tTop_Loss: 0.1165\tBottom_Loss: 0.0489\tLoss: 0.1935\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0189\tTop_Loss: 0.0786\tBottom_Loss: 0.0413\tLoss: 0.1388\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0538\tTop_Loss: 0.1797\tBottom_Loss: 0.1057\tLoss: 0.3393\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0156\tTop_Loss: 0.0653\tBottom_Loss: 0.0549\tLoss: 0.1358\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0144\tTop_Loss: 0.0406\tBottom_Loss: 0.0303\tLoss: 0.0852\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0744\tTop_Loss: 0.1472\tBottom_Loss: 0.0649\tLoss: 0.2865\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0203\tTop_Loss: 0.0615\tBottom_Loss: 0.0989\tLoss: 0.1807\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0154\tTop_Loss: 0.0683\tBottom_Loss: 0.0280\tLoss: 0.1117\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0197\tTop_Loss: 0.0593\tBottom_Loss: 0.0250\tLoss: 0.1040\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0303\tTop_Loss: 0.1042\tBottom_Loss: 0.0798\tLoss: 0.2143\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0248\tTop_Loss: 0.0698\tBottom_Loss: 0.0623\tLoss: 0.1569\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0257\tTop_Loss: 0.1158\tBottom_Loss: 0.0496\tLoss: 0.1910\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0235\tTop_Loss: 0.1156\tBottom_Loss: 0.0798\tLoss: 0.2189\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0657\tTop_Loss: 0.1529\tBottom_Loss: 0.1298\tLoss: 0.3484\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0171\tTop_Loss: 0.1042\tBottom_Loss: 0.0165\tLoss: 0.1377\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0172\tTop_Loss: 0.0749\tBottom_Loss: 0.0306\tLoss: 0.1228\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0203\tTop_Loss: 0.0821\tBottom_Loss: 0.0216\tLoss: 0.1240\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0576\tTop_Loss: 0.1160\tBottom_Loss: 0.0917\tLoss: 0.2653\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0318\tTop_Loss: 0.0865\tBottom_Loss: 0.0667\tLoss: 0.1850\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0380\tTop_Loss: 0.0813\tBottom_Loss: 0.0428\tLoss: 0.1621\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0172\tTop_Loss: 0.0330\tBottom_Loss: 0.0370\tLoss: 0.0872\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0111\tTop_Loss: 0.0471\tBottom_Loss: 0.0153\tLoss: 0.0735\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0600\tTop_Loss: 0.0999\tBottom_Loss: 0.0663\tLoss: 0.2261\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0097\tTop_Loss: 0.0352\tBottom_Loss: 0.0396\tLoss: 0.0846\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[86][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0839\tTop_Loss: 0.0826\tBottom_Loss: 0.1098\tLoss: 0.2763\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0086\tTop_Loss: 0.0339\tBottom_Loss: 0.0137\tLoss: 0.0562\t\n",
      "Subject: 13, n=02 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0217\tTop_Loss: 0.0589\tBottom_Loss: 0.0212\tLoss: 0.1019\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0114\tTop_Loss: 0.0486\tBottom_Loss: 0.0311\tLoss: 0.0910\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0359\tTop_Loss: 0.0680\tBottom_Loss: 0.0559\tLoss: 0.1598\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0243\tTop_Loss: 0.0543\tBottom_Loss: 0.0527\tLoss: 0.1313\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0770\tTop_Loss: 0.1057\tBottom_Loss: 0.0834\tLoss: 0.2661\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0161\tTop_Loss: 0.0786\tBottom_Loss: 0.0211\tLoss: 0.1158\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0248\tTop_Loss: 0.0512\tBottom_Loss: 0.0608\tLoss: 0.1368\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0289\tTop_Loss: 0.1033\tBottom_Loss: 0.0208\tLoss: 0.1530\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0072\tTop_Loss: 0.0284\tBottom_Loss: 0.0156\tLoss: 0.0512\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0230\tTop_Loss: 0.0559\tBottom_Loss: 0.0567\tLoss: 0.1357\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0377\tTop_Loss: 0.1748\tBottom_Loss: 0.0483\tLoss: 0.2608\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0166\tTop_Loss: 0.0378\tBottom_Loss: 0.0256\tLoss: 0.0800\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0133\tTop_Loss: 0.0427\tBottom_Loss: 0.0175\tLoss: 0.0735\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0461\tTop_Loss: 0.1012\tBottom_Loss: 0.0641\tLoss: 0.2114\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0132\tTop_Loss: 0.0194\tBottom_Loss: 0.0321\tLoss: 0.0647\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 0.938\tLabel_Loss: 0.0857\tTop_Loss: 0.0941\tBottom_Loss: 0.1364\tLoss: 0.3162\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0507\tTop_Loss: 0.0541\tBottom_Loss: 0.0677\tLoss: 0.1724\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0124\tTop_Loss: 0.0274\tBottom_Loss: 0.0113\tLoss: 0.0512\t\n",
      "Subject: 13, n=02 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0062\tTop_Loss: 0.0187\tBottom_Loss: 0.0249\tLoss: 0.0499\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0113\tTop_Loss: 0.0462\tBottom_Loss: 0.0199\tLoss: 0.0773\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0058\tTop_Loss: 0.0304\tBottom_Loss: 0.0130\tLoss: 0.0491\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0253\tTop_Loss: 0.0493\tBottom_Loss: 0.0438\tLoss: 0.1184\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0092\tTop_Loss: 0.0251\tBottom_Loss: 0.0203\tLoss: 0.0546\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0027\tTop_Loss: 0.0143\tBottom_Loss: 0.0066\tLoss: 0.0236\t\n",
      "Subject: 13, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0107\tTop_Loss: 0.0375\tBottom_Loss: 0.0320\tLoss: 0.0803\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0073\tTop_Loss: 0.0317\tBottom_Loss: 0.0265\tLoss: 0.0655\t\n",
      "Subject: 13, n=02 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.438\tLabel_Loss: 1.2597\tTop_Loss: 1.3583\tBottom_Loss: 2.0832\tLoss: 4.7012\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.500\tLabel_Loss: 1.1681\tTop_Loss: 1.2196\tBottom_Loss: 1.1239\tLoss: 3.5116\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.531\tLabel_Loss: 1.1045\tTop_Loss: 0.9043\tBottom_Loss: 1.0480\tLoss: 3.0568\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.531\tLabel_Loss: 1.1523\tTop_Loss: 1.3145\tBottom_Loss: 1.2071\tLoss: 3.6739\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.500\tLabel_Loss: 1.0124\tTop_Loss: 0.9092\tBottom_Loss: 0.7567\tLoss: 2.6783\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.406\tLabel_Loss: 1.1231\tTop_Loss: 0.9995\tBottom_Loss: 1.0977\tLoss: 3.2203\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.719\tLabel_Loss: 0.7371\tTop_Loss: 0.7648\tBottom_Loss: 0.8558\tLoss: 2.3577\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.469\tLabel_Loss: 1.0009\tTop_Loss: 0.9860\tBottom_Loss: 1.2215\tLoss: 3.2085\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.688\tLabel_Loss: 0.8252\tTop_Loss: 0.7762\tBottom_Loss: 0.8817\tLoss: 2.4831\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.406\tLabel_Loss: 1.0181\tTop_Loss: 1.1764\tBottom_Loss: 1.2624\tLoss: 3.4569\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.562\tLabel_Loss: 0.9274\tTop_Loss: 1.0651\tBottom_Loss: 0.9042\tLoss: 2.8967\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.531\tLabel_Loss: 0.9394\tTop_Loss: 1.0505\tBottom_Loss: 1.0534\tLoss: 3.0434\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6661\tTop_Loss: 0.6719\tBottom_Loss: 0.7300\tLoss: 2.0681\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.562\tLabel_Loss: 0.8835\tTop_Loss: 0.9246\tBottom_Loss: 0.8797\tLoss: 2.6878\t\n",
      "Subject: 14, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8802\tTop_Loss: 1.0615\tBottom_Loss: 1.0326\tLoss: 2.9743\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.531\tLabel_Loss: 0.9382\tTop_Loss: 0.9963\tBottom_Loss: 0.9462\tLoss: 2.8806\t\n",
      "Subject: 14, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7208\tTop_Loss: 0.8130\tBottom_Loss: 0.8345\tLoss: 2.3683\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6087\tTop_Loss: 0.5512\tBottom_Loss: 0.6511\tLoss: 1.8110\t\n",
      "Subject: 14, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6289\tTop_Loss: 0.7106\tBottom_Loss: 0.7971\tLoss: 2.1365\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8339\tTop_Loss: 0.8055\tBottom_Loss: 0.9048\tLoss: 2.5441\t\n",
      "Subject: 14, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.656\tLabel_Loss: 0.8941\tTop_Loss: 0.9720\tBottom_Loss: 1.0795\tLoss: 2.9456\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.844\tLabel_Loss: 0.6146\tTop_Loss: 0.6280\tBottom_Loss: 0.8784\tLoss: 2.1210\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7644\tTop_Loss: 0.8855\tBottom_Loss: 0.6982\tLoss: 2.3481\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5017\tTop_Loss: 0.6334\tBottom_Loss: 0.5184\tLoss: 1.6534\t\n",
      "Subject: 14, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7839\tTop_Loss: 0.8025\tBottom_Loss: 0.5909\tLoss: 2.1773\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6310\tTop_Loss: 0.7881\tBottom_Loss: 0.7138\tLoss: 2.1329\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7449\tTop_Loss: 0.8130\tBottom_Loss: 0.7958\tLoss: 2.3537\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4427\tTop_Loss: 0.6328\tBottom_Loss: 0.6716\tLoss: 1.7472\t\n",
      "Subject: 14, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6445\tTop_Loss: 0.7104\tBottom_Loss: 0.7050\tLoss: 2.0599\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4315\tTop_Loss: 0.6528\tBottom_Loss: 0.6094\tLoss: 1.6937\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.500\tLabel_Loss: 0.7443\tTop_Loss: 0.6914\tBottom_Loss: 0.7695\tLoss: 2.2052\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.844\tLabel_Loss: 0.5908\tTop_Loss: 0.6512\tBottom_Loss: 0.5932\tLoss: 1.8352\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.688\tLabel_Loss: 0.4856\tTop_Loss: 0.6918\tBottom_Loss: 0.5465\tLoss: 1.7240\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.656\tLabel_Loss: 0.6864\tTop_Loss: 0.6018\tBottom_Loss: 0.7733\tLoss: 2.0616\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4486\tTop_Loss: 0.6579\tBottom_Loss: 0.5303\tLoss: 1.6368\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6478\tTop_Loss: 0.5999\tBottom_Loss: 0.8674\tLoss: 2.1151\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5758\tTop_Loss: 0.6204\tBottom_Loss: 0.6155\tLoss: 1.8116\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4292\tTop_Loss: 0.6378\tBottom_Loss: 0.5470\tLoss: 1.6140\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3872\tTop_Loss: 0.5841\tBottom_Loss: 0.5217\tLoss: 1.4930\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3579\tTop_Loss: 0.4721\tBottom_Loss: 0.4983\tLoss: 1.3283\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.781\tLabel_Loss: 0.3978\tTop_Loss: 0.6009\tBottom_Loss: 0.6679\tLoss: 1.6666\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3902\tTop_Loss: 0.5486\tBottom_Loss: 0.5251\tLoss: 1.4639\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3204\tTop_Loss: 0.3494\tBottom_Loss: 0.5489\tLoss: 1.2187\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4557\tTop_Loss: 0.5528\tBottom_Loss: 0.4788\tLoss: 1.4872\t\n",
      "Subject: 14, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4158\tTop_Loss: 0.6739\tBottom_Loss: 0.4881\tLoss: 1.5778\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3048\tTop_Loss: 0.4985\tBottom_Loss: 0.4406\tLoss: 1.2439\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2891\tTop_Loss: 0.5049\tBottom_Loss: 0.4325\tLoss: 1.2265\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4254\tTop_Loss: 0.4541\tBottom_Loss: 0.4240\tLoss: 1.3035\t\n",
      "Subject: 14, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3408\tTop_Loss: 0.6058\tBottom_Loss: 0.4821\tLoss: 1.4286\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3587\tTop_Loss: 0.5984\tBottom_Loss: 0.4818\tLoss: 1.4389\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4044\tTop_Loss: 0.6038\tBottom_Loss: 0.5802\tLoss: 1.5884\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6142\tTop_Loss: 0.7152\tBottom_Loss: 0.8154\tLoss: 2.1447\t\n",
      "Subject: 14, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3736\tTop_Loss: 0.4914\tBottom_Loss: 0.6337\tLoss: 1.4987\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.719\tLabel_Loss: 0.4386\tTop_Loss: 0.4791\tBottom_Loss: 0.5202\tLoss: 1.4379\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2636\tTop_Loss: 0.2772\tBottom_Loss: 0.5959\tLoss: 1.1367\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2812\tTop_Loss: 0.5369\tBottom_Loss: 0.3044\tLoss: 1.1225\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3157\tTop_Loss: 0.4533\tBottom_Loss: 0.3564\tLoss: 1.1254\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3414\tTop_Loss: 0.4344\tBottom_Loss: 0.6322\tLoss: 1.4080\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3151\tTop_Loss: 0.5812\tBottom_Loss: 0.4701\tLoss: 1.3664\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.938\tLabel_Loss: 0.3020\tTop_Loss: 0.3212\tBottom_Loss: 0.4750\tLoss: 1.0982\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2307\tTop_Loss: 0.4604\tBottom_Loss: 0.2874\tLoss: 0.9785\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5725\tTop_Loss: 0.4663\tBottom_Loss: 0.6470\tLoss: 1.6859\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2162\tTop_Loss: 0.4412\tBottom_Loss: 0.3423\tLoss: 0.9996\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2264\tTop_Loss: 0.4410\tBottom_Loss: 0.3646\tLoss: 1.0320\t\n",
      "Subject: 14, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2232\tTop_Loss: 0.3907\tBottom_Loss: 0.3494\tLoss: 0.9634\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3616\tTop_Loss: 0.6710\tBottom_Loss: 0.3794\tLoss: 1.4120\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2701\tTop_Loss: 0.3054\tBottom_Loss: 0.3853\tLoss: 0.9608\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.844\tLabel_Loss: 0.2493\tTop_Loss: 0.3582\tBottom_Loss: 0.3591\tLoss: 0.9666\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2298\tTop_Loss: 0.4396\tBottom_Loss: 0.2831\tLoss: 0.9525\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2042\tTop_Loss: 0.3781\tBottom_Loss: 0.3288\tLoss: 0.9111\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1270\tTop_Loss: 0.2680\tBottom_Loss: 0.4198\tLoss: 0.8148\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1609\tTop_Loss: 0.3473\tBottom_Loss: 0.3649\tLoss: 0.8731\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2397\tTop_Loss: 0.3755\tBottom_Loss: 0.3573\tLoss: 0.9725\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1492\tTop_Loss: 0.3873\tBottom_Loss: 0.2910\tLoss: 0.8275\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.812\tLabel_Loss: 0.2574\tTop_Loss: 0.3345\tBottom_Loss: 0.4114\tLoss: 1.0033\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2514\tTop_Loss: 0.3873\tBottom_Loss: 0.3836\tLoss: 1.0223\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1544\tTop_Loss: 0.2886\tBottom_Loss: 0.3831\tLoss: 0.8261\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1293\tTop_Loss: 0.2270\tBottom_Loss: 0.3277\tLoss: 0.6840\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0987\tTop_Loss: 0.3079\tBottom_Loss: 0.1970\tLoss: 0.6036\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1937\tTop_Loss: 0.2954\tBottom_Loss: 0.3575\tLoss: 0.8466\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1113\tTop_Loss: 0.3143\tBottom_Loss: 0.2497\tLoss: 0.6753\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1632\tTop_Loss: 0.3430\tBottom_Loss: 0.2363\tLoss: 0.7425\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2043\tTop_Loss: 0.2810\tBottom_Loss: 0.2943\tLoss: 0.7797\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2695\tTop_Loss: 0.4213\tBottom_Loss: 0.4905\tLoss: 1.1813\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1056\tTop_Loss: 0.2697\tBottom_Loss: 0.1912\tLoss: 0.5665\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1683\tTop_Loss: 0.3251\tBottom_Loss: 0.1482\tLoss: 0.6416\t\n",
      "Subject: 14, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1463\tTop_Loss: 0.4298\tBottom_Loss: 0.2933\tLoss: 0.8694\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2319\tTop_Loss: 0.3640\tBottom_Loss: 0.2905\tLoss: 0.8864\t\n",
      "Subject: 14, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1337\tTop_Loss: 0.2452\tBottom_Loss: 0.1331\tLoss: 0.5120\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1024\tTop_Loss: 0.1960\tBottom_Loss: 0.2886\tLoss: 0.5871\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2081\tTop_Loss: 0.4480\tBottom_Loss: 0.1831\tLoss: 0.8391\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2062\tTop_Loss: 0.3757\tBottom_Loss: 0.2324\tLoss: 0.8143\t\n",
      "Subject: 14, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0930\tTop_Loss: 0.2037\tBottom_Loss: 0.1472\tLoss: 0.4439\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1482\tTop_Loss: 0.2630\tBottom_Loss: 0.2177\tLoss: 0.6289\t\n",
      "Subject: 14, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2634\tTop_Loss: 0.3821\tBottom_Loss: 0.3510\tLoss: 0.9965\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1264\tTop_Loss: 0.1954\tBottom_Loss: 0.2025\tLoss: 0.5243\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1896\tTop_Loss: 0.2998\tBottom_Loss: 0.2562\tLoss: 0.7456\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[48][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0830\tTop_Loss: 0.1901\tBottom_Loss: 0.1649\tLoss: 0.4380\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2035\tTop_Loss: 0.3694\tBottom_Loss: 0.3726\tLoss: 0.9454\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0728\tTop_Loss: 0.2829\tBottom_Loss: 0.2629\tLoss: 0.6186\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1582\tTop_Loss: 0.2538\tBottom_Loss: 0.2398\tLoss: 0.6517\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0828\tTop_Loss: 0.1783\tBottom_Loss: 0.2927\tLoss: 0.5539\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1041\tTop_Loss: 0.1931\tBottom_Loss: 0.3036\tLoss: 0.6008\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0520\tTop_Loss: 0.2208\tBottom_Loss: 0.1074\tLoss: 0.3801\t\n",
      "Subject: 14, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0723\tTop_Loss: 0.1334\tBottom_Loss: 0.2235\tLoss: 0.4292\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2082\tTop_Loss: 0.3059\tBottom_Loss: 0.2766\tLoss: 0.7907\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0582\tTop_Loss: 0.2408\tBottom_Loss: 0.0930\tLoss: 0.3920\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3406\tTop_Loss: 0.3013\tBottom_Loss: 0.4741\tLoss: 1.1160\t\n",
      "Subject: 14, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0531\tTop_Loss: 0.1205\tBottom_Loss: 0.1169\tLoss: 0.2905\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0501\tTop_Loss: 0.1619\tBottom_Loss: 0.1487\tLoss: 0.3606\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1478\tTop_Loss: 0.1556\tBottom_Loss: 0.2346\tLoss: 0.5381\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0447\tTop_Loss: 0.1441\tBottom_Loss: 0.0827\tLoss: 0.2716\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0557\tTop_Loss: 0.1743\tBottom_Loss: 0.1150\tLoss: 0.3450\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0842\tTop_Loss: 0.2054\tBottom_Loss: 0.1762\tLoss: 0.4659\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0509\tTop_Loss: 0.1573\tBottom_Loss: 0.0555\tLoss: 0.2637\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0851\tTop_Loss: 0.1626\tBottom_Loss: 0.1615\tLoss: 0.4093\t\n",
      "Subject: 14, n=03 | test_f1: 0.16667 |best_f1: 0.25\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0750\tTop_Loss: 0.1343\tBottom_Loss: 0.1818\tLoss: 0.3911\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0618\tTop_Loss: 0.1540\tBottom_Loss: 0.1649\tLoss: 0.3807\t\n",
      "Subject: 14, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1154\tTop_Loss: 0.1109\tBottom_Loss: 0.1710\tLoss: 0.3973\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0975\tTop_Loss: 0.1068\tBottom_Loss: 0.1367\tLoss: 0.3410\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0350\tTop_Loss: 0.1205\tBottom_Loss: 0.0929\tLoss: 0.2483\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0504\tTop_Loss: 0.1767\tBottom_Loss: 0.1072\tLoss: 0.3343\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1272\tTop_Loss: 0.2314\tBottom_Loss: 0.1607\tLoss: 0.5193\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0324\tTop_Loss: 0.1355\tBottom_Loss: 0.1065\tLoss: 0.2743\t\n",
      "Subject: 14, n=03 | test_f1: 0.16667 |best_f1: 0.25\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0310\tTop_Loss: 0.1057\tBottom_Loss: 0.1224\tLoss: 0.2591\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0710\tTop_Loss: 0.1677\tBottom_Loss: 0.0983\tLoss: 0.3370\t\n",
      "Subject: 14, n=03 | test_f1: 0.16667 |best_f1: 0.25\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0333\tTop_Loss: 0.1086\tBottom_Loss: 0.0686\tLoss: 0.2104\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0776\tTop_Loss: 0.2329\tBottom_Loss: 0.1286\tLoss: 0.4391\t\n",
      "Subject: 14, n=03 | test_f1: 0.16667 |best_f1: 0.25\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0535\tTop_Loss: 0.0956\tBottom_Loss: 0.1223\tLoss: 0.2714\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0375\tTop_Loss: 0.1527\tBottom_Loss: 0.0795\tLoss: 0.2698\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0162\tTop_Loss: 0.0620\tBottom_Loss: 0.0996\tLoss: 0.1779\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0732\tTop_Loss: 0.1004\tBottom_Loss: 0.1367\tLoss: 0.3103\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0457\tTop_Loss: 0.1748\tBottom_Loss: 0.1254\tLoss: 0.3459\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0819\tTop_Loss: 0.1420\tBottom_Loss: 0.1144\tLoss: 0.3384\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0491\tTop_Loss: 0.1564\tBottom_Loss: 0.0645\tLoss: 0.2700\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0555\tTop_Loss: 0.1081\tBottom_Loss: 0.1186\tLoss: 0.2822\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0311\tTop_Loss: 0.1078\tBottom_Loss: 0.0574\tLoss: 0.1963\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0198\tTop_Loss: 0.0812\tBottom_Loss: 0.1365\tLoss: 0.2376\t\n",
      "Subject: 14, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1536\tTop_Loss: 0.1895\tBottom_Loss: 0.3667\tLoss: 0.7098\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1004\tTop_Loss: 0.1432\tBottom_Loss: 0.1361\tLoss: 0.3796\t\n",
      "Subject: 14, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0203\tTop_Loss: 0.0969\tBottom_Loss: 0.0319\tLoss: 0.1490\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0716\tTop_Loss: 0.1295\tBottom_Loss: 0.1068\tLoss: 0.3078\t\n",
      "Subject: 14, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0374\tTop_Loss: 0.0916\tBottom_Loss: 0.1455\tLoss: 0.2745\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0204\tTop_Loss: 0.0620\tBottom_Loss: 0.0628\tLoss: 0.1452\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0459\tTop_Loss: 0.1059\tBottom_Loss: 0.2123\tLoss: 0.3641\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0224\tTop_Loss: 0.0805\tBottom_Loss: 0.0305\tLoss: 0.1333\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0226\tTop_Loss: 0.1068\tBottom_Loss: 0.0532\tLoss: 0.1826\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0113\tTop_Loss: 0.1323\tBottom_Loss: 0.0340\tLoss: 0.1777\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0707\tTop_Loss: 0.1040\tBottom_Loss: 0.1776\tLoss: 0.3524\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0160\tTop_Loss: 0.0635\tBottom_Loss: 0.0604\tLoss: 0.1400\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1042\tTop_Loss: 0.2039\tBottom_Loss: 0.0850\tLoss: 0.3930\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0316\tTop_Loss: 0.1249\tBottom_Loss: 0.1089\tLoss: 0.2654\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0596\tTop_Loss: 0.0695\tBottom_Loss: 0.0499\tLoss: 0.1790\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0171\tTop_Loss: 0.0675\tBottom_Loss: 0.0872\tLoss: 0.1718\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0311\tTop_Loss: 0.1080\tBottom_Loss: 0.0793\tLoss: 0.2184\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0154\tTop_Loss: 0.0420\tBottom_Loss: 0.0264\tLoss: 0.0839\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0414\tTop_Loss: 0.0948\tBottom_Loss: 0.0791\tLoss: 0.2154\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0229\tTop_Loss: 0.1338\tBottom_Loss: 0.0360\tLoss: 0.1926\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0060\tTop_Loss: 0.0413\tBottom_Loss: 0.0219\tLoss: 0.0692\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0107\tTop_Loss: 0.1041\tBottom_Loss: 0.0264\tLoss: 0.1413\t\n",
      "Subject: 14, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0154\tTop_Loss: 0.0665\tBottom_Loss: 0.0346\tLoss: 0.1165\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0187\tTop_Loss: 0.0591\tBottom_Loss: 0.0430\tLoss: 0.1208\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0308\tTop_Loss: 0.0919\tBottom_Loss: 0.1023\tLoss: 0.2250\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0483\tTop_Loss: 0.0576\tBottom_Loss: 0.0715\tLoss: 0.1775\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0116\tTop_Loss: 0.0514\tBottom_Loss: 0.0487\tLoss: 0.1117\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0205\tTop_Loss: 0.0836\tBottom_Loss: 0.0515\tLoss: 0.1556\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0254\tTop_Loss: 0.1272\tBottom_Loss: 0.0337\tLoss: 0.1862\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0094\tTop_Loss: 0.0693\tBottom_Loss: 0.0212\tLoss: 0.0999\t\n",
      "Subject: 14, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0097\tTop_Loss: 0.0446\tBottom_Loss: 0.0467\tLoss: 0.1010\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0123\tTop_Loss: 0.0834\tBottom_Loss: 0.0148\tLoss: 0.1104\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0310\tTop_Loss: 0.0801\tBottom_Loss: 0.0579\tLoss: 0.1690\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0528\tTop_Loss: 0.0807\tBottom_Loss: 0.0886\tLoss: 0.2221\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0558\tTop_Loss: 0.0524\tBottom_Loss: 0.1006\tLoss: 0.2088\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0065\tTop_Loss: 0.0405\tBottom_Loss: 0.0265\tLoss: 0.0735\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0073\tTop_Loss: 0.0274\tBottom_Loss: 0.0285\tLoss: 0.0633\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0058\tTop_Loss: 0.0306\tBottom_Loss: 0.0197\tLoss: 0.0562\t\n",
      "Subject: 14, n=03 | test_f1: 0.16667 |best_f1: 0.25\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0781\tTop_Loss: 0.0998\tBottom_Loss: 0.0442\tLoss: 0.2221\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0799\tTop_Loss: 0.0831\tBottom_Loss: 0.1271\tLoss: 0.2900\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0777\tTop_Loss: 0.1855\tBottom_Loss: 0.1753\tLoss: 0.4385\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0111\tTop_Loss: 0.0405\tBottom_Loss: 0.0284\tLoss: 0.0799\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0135\tTop_Loss: 0.0498\tBottom_Loss: 0.0987\tLoss: 0.1620\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0055\tTop_Loss: 0.0368\tBottom_Loss: 0.0331\tLoss: 0.0753\t\n",
      "Subject: 14, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0092\tTop_Loss: 0.0391\tBottom_Loss: 0.0356\tLoss: 0.0839\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0094\tTop_Loss: 0.0553\tBottom_Loss: 0.0216\tLoss: 0.0863\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0046\tTop_Loss: 0.0384\tBottom_Loss: 0.0145\tLoss: 0.0575\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0081\tTop_Loss: 0.0857\tBottom_Loss: 0.0229\tLoss: 0.1167\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0056\tTop_Loss: 0.0312\tBottom_Loss: 0.0231\tLoss: 0.0598\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0138\tTop_Loss: 0.0269\tBottom_Loss: 0.0347\tLoss: 0.0754\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0277\tTop_Loss: 0.0364\tBottom_Loss: 0.0428\tLoss: 0.1069\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0063\tTop_Loss: 0.0436\tBottom_Loss: 0.0734\tLoss: 0.1233\t\n",
      "Subject: 14, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0081\tTop_Loss: 0.0277\tBottom_Loss: 0.0325\tLoss: 0.0683\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0067\tTop_Loss: 0.0198\tBottom_Loss: 0.0121\tLoss: 0.0387\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0107\tTop_Loss: 0.0279\tBottom_Loss: 0.0521\tLoss: 0.0908\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0448\tTop_Loss: 0.1267\tBottom_Loss: 0.0731\tLoss: 0.2446\t\n",
      "Subject: 14, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0039\tTop_Loss: 0.0268\tBottom_Loss: 0.0099\tLoss: 0.0405\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0174\tTop_Loss: 0.1070\tBottom_Loss: 0.0721\tLoss: 0.1965\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0143\tTop_Loss: 0.0478\tBottom_Loss: 0.0098\tLoss: 0.0719\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0287\tTop_Loss: 0.0557\tBottom_Loss: 0.0319\tLoss: 0.1163\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0121\tTop_Loss: 0.0219\tBottom_Loss: 0.0069\tLoss: 0.0409\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0057\tTop_Loss: 0.0360\tBottom_Loss: 0.0223\tLoss: 0.0639\t\n",
      "Subject: 14, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.281\tLabel_Loss: 1.3468\tTop_Loss: 1.7583\tBottom_Loss: 1.1147\tLoss: 4.2197\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.406\tLabel_Loss: 1.4376\tTop_Loss: 1.3526\tBottom_Loss: 1.1125\tLoss: 3.9027\t\n",
      "Subject: 15, n=03 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.438\tLabel_Loss: 1.1013\tTop_Loss: 0.9557\tBottom_Loss: 1.0467\tLoss: 3.1038\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.531\tLabel_Loss: 0.9386\tTop_Loss: 0.9443\tBottom_Loss: 0.9768\tLoss: 2.8597\t\n",
      "Subject: 15, n=03 | test_f1: 0.16667 |best_f1: 0.16667\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.469\tLabel_Loss: 1.1525\tTop_Loss: 1.1052\tBottom_Loss: 1.0771\tLoss: 3.3348\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.406\tLabel_Loss: 1.0723\tTop_Loss: 0.9772\tBottom_Loss: 0.9787\tLoss: 3.0282\t\n",
      "Subject: 15, n=03 | test_f1: 0.22222 |best_f1: 0.22222\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.562\tLabel_Loss: 1.0398\tTop_Loss: 1.1079\tBottom_Loss: 1.0587\tLoss: 3.2064\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.625\tLabel_Loss: 0.9486\tTop_Loss: 0.9686\tBottom_Loss: 0.9274\tLoss: 2.8445\t\n",
      "Subject: 15, n=03 | test_f1: 0.22222 |best_f1: 0.22222\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.562\tLabel_Loss: 0.8788\tTop_Loss: 0.8411\tBottom_Loss: 0.7447\tLoss: 2.4646\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.656\tLabel_Loss: 0.8699\tTop_Loss: 0.9343\tBottom_Loss: 0.9240\tLoss: 2.7282\t\n",
      "Subject: 15, n=03 | test_f1: 0.16667 |best_f1: 0.22222\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.594\tLabel_Loss: 0.7472\tTop_Loss: 0.8854\tBottom_Loss: 0.8295\tLoss: 2.4622\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.469\tLabel_Loss: 0.9712\tTop_Loss: 0.9860\tBottom_Loss: 1.0482\tLoss: 3.0054\t\n",
      "Subject: 15, n=03 | test_f1: 0.16667 |best_f1: 0.22222\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.594\tLabel_Loss: 0.7953\tTop_Loss: 0.7977\tBottom_Loss: 0.8672\tLoss: 2.4603\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.500\tLabel_Loss: 1.0668\tTop_Loss: 0.8384\tBottom_Loss: 1.1314\tLoss: 3.0366\t\n",
      "Subject: 15, n=03 | test_f1: 0.16667 |best_f1: 0.22222\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.469\tLabel_Loss: 1.0701\tTop_Loss: 0.9065\tBottom_Loss: 0.8838\tLoss: 2.8604\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7199\tTop_Loss: 0.8873\tBottom_Loss: 0.8822\tLoss: 2.4894\t\n",
      "Subject: 15, n=03 | test_f1: 0.16667 |best_f1: 0.22222\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7571\tTop_Loss: 1.0039\tBottom_Loss: 0.7805\tLoss: 2.5414\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.656\tLabel_Loss: 0.8067\tTop_Loss: 0.8242\tBottom_Loss: 0.8307\tLoss: 2.4617\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 0.55556\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7319\tTop_Loss: 0.7659\tBottom_Loss: 0.8656\tLoss: 2.3634\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8301\tTop_Loss: 0.8301\tBottom_Loss: 0.8273\tLoss: 2.4875\t\n",
      "Subject: 15, n=03 | test_f1: 0.16667 |best_f1: 0.55556\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.688\tLabel_Loss: 0.8510\tTop_Loss: 0.8923\tBottom_Loss: 0.8950\tLoss: 2.6383\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6554\tTop_Loss: 0.7057\tBottom_Loss: 0.8599\tLoss: 2.2210\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 0.55556\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7433\tTop_Loss: 0.9402\tBottom_Loss: 0.7902\tLoss: 2.4737\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.562\tLabel_Loss: 0.8369\tTop_Loss: 0.7729\tBottom_Loss: 0.7695\tLoss: 2.3793\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 0.55556\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6669\tTop_Loss: 0.6865\tBottom_Loss: 0.6114\tLoss: 1.9648\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7586\tTop_Loss: 0.8015\tBottom_Loss: 0.8844\tLoss: 2.4445\t\n",
      "Subject: 15, n=03 | test_f1: 0.22222 |best_f1: 0.55556\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.719\tLabel_Loss: 0.8048\tTop_Loss: 0.9237\tBottom_Loss: 0.6783\tLoss: 2.4068\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.812\tLabel_Loss: 0.6152\tTop_Loss: 0.7318\tBottom_Loss: 0.7643\tLoss: 2.1114\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 0.55556\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5789\tTop_Loss: 0.6668\tBottom_Loss: 0.4861\tLoss: 1.7319\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6331\tTop_Loss: 0.5567\tBottom_Loss: 0.7140\tLoss: 1.9038\t\n",
      "Subject: 15, n=03 | test_f1: 0.16667 |best_f1: 0.55556\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6147\tTop_Loss: 0.5530\tBottom_Loss: 0.5308\tLoss: 1.6985\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4171\tTop_Loss: 0.5974\tBottom_Loss: 0.4459\tLoss: 1.4603\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 0.55556\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4894\tTop_Loss: 0.6864\tBottom_Loss: 0.5833\tLoss: 1.7590\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.844\tLabel_Loss: 0.5614\tTop_Loss: 0.7160\tBottom_Loss: 0.7845\tLoss: 2.0619\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 0.55556\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4349\tTop_Loss: 0.6974\tBottom_Loss: 0.4127\tLoss: 1.5450\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8195\tTop_Loss: 0.7975\tBottom_Loss: 0.7514\tLoss: 2.3684\t\n",
      "Subject: 15, n=03 | test_f1: 0.22222 |best_f1: 0.55556\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3368\tTop_Loss: 0.3918\tBottom_Loss: 0.4403\tLoss: 1.1690\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7035\tTop_Loss: 0.8177\tBottom_Loss: 0.7241\tLoss: 2.2453\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 0.55556\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4597\tTop_Loss: 0.6533\tBottom_Loss: 0.5162\tLoss: 1.6292\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4524\tTop_Loss: 0.7357\tBottom_Loss: 0.5928\tLoss: 1.7809\t\n",
      "Subject: 15, n=03 | test_f1: 0.16667 |best_f1: 0.55556\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.688\tLabel_Loss: 0.5121\tTop_Loss: 0.5704\tBottom_Loss: 0.7467\tLoss: 1.8292\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4983\tTop_Loss: 0.7281\tBottom_Loss: 0.6111\tLoss: 1.8375\t\n",
      "Subject: 15, n=03 | test_f1: 0.0 |best_f1: 0.55556\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3546\tTop_Loss: 0.4102\tBottom_Loss: 0.4809\tLoss: 1.2458\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4575\tTop_Loss: 0.5093\tBottom_Loss: 0.5323\tLoss: 1.4991\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 0.55556\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4952\tTop_Loss: 0.6966\tBottom_Loss: 0.5171\tLoss: 1.7089\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.812\tLabel_Loss: 0.6561\tTop_Loss: 0.9189\tBottom_Loss: 0.6156\tLoss: 2.1907\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 0.55556\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4758\tTop_Loss: 0.5384\tBottom_Loss: 0.4867\tLoss: 1.5008\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3086\tTop_Loss: 0.4279\tBottom_Loss: 0.3965\tLoss: 1.1329\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 0.55556\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3672\tTop_Loss: 0.5291\tBottom_Loss: 0.5000\tLoss: 1.3963\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2195\tTop_Loss: 0.2756\tBottom_Loss: 0.4095\tLoss: 0.9046\t\n",
      "Subject: 15, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4357\tTop_Loss: 0.6540\tBottom_Loss: 0.4559\tLoss: 1.5456\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2939\tTop_Loss: 0.4763\tBottom_Loss: 0.3119\tLoss: 1.0821\t\n",
      "Subject: 15, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3774\tTop_Loss: 0.6563\tBottom_Loss: 0.3661\tLoss: 1.3998\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4345\tTop_Loss: 0.6714\tBottom_Loss: 0.6828\tLoss: 1.7887\t\n",
      "Subject: 15, n=03 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.719\tLabel_Loss: 0.4894\tTop_Loss: 0.5239\tBottom_Loss: 0.6086\tLoss: 1.6219\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3725\tTop_Loss: 0.6590\tBottom_Loss: 0.4185\tLoss: 1.4500\t\n",
      "Subject: 15, n=03 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4915\tTop_Loss: 0.5624\tBottom_Loss: 0.6415\tLoss: 1.6954\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.781\tLabel_Loss: 0.3915\tTop_Loss: 0.5348\tBottom_Loss: 0.4613\tLoss: 1.3876\t\n",
      "Subject: 15, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3135\tTop_Loss: 0.3894\tBottom_Loss: 0.3950\tLoss: 1.0979\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3099\tTop_Loss: 0.5900\tBottom_Loss: 0.3596\tLoss: 1.2595\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5216\tTop_Loss: 0.6849\tBottom_Loss: 0.5738\tLoss: 1.7803\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4000\tTop_Loss: 0.5804\tBottom_Loss: 0.4317\tLoss: 1.4121\t\n",
      "Subject: 15, n=03 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3402\tTop_Loss: 0.5604\tBottom_Loss: 0.5416\tLoss: 1.4422\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4679\tTop_Loss: 0.4751\tBottom_Loss: 0.6232\tLoss: 1.5661\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1872\tTop_Loss: 0.2629\tBottom_Loss: 0.3547\tLoss: 0.8047\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2784\tTop_Loss: 0.3335\tBottom_Loss: 0.3956\tLoss: 1.0075\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2900\tTop_Loss: 0.4642\tBottom_Loss: 0.3314\tLoss: 1.0856\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2923\tTop_Loss: 0.4795\tBottom_Loss: 0.4123\tLoss: 1.1841\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1476\tTop_Loss: 0.3852\tBottom_Loss: 0.2742\tLoss: 0.8070\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2524\tTop_Loss: 0.3279\tBottom_Loss: 0.4934\tLoss: 1.0737\t\n",
      "Subject: 15, n=03 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1962\tTop_Loss: 0.3094\tBottom_Loss: 0.4017\tLoss: 0.9073\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3660\tTop_Loss: 0.4579\tBottom_Loss: 0.3248\tLoss: 1.1487\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2103\tTop_Loss: 0.2826\tBottom_Loss: 0.2841\tLoss: 0.7770\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2287\tTop_Loss: 0.2815\tBottom_Loss: 0.3070\tLoss: 0.8172\t\n",
      "Subject: 15, n=03 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2159\tTop_Loss: 0.2622\tBottom_Loss: 0.3771\tLoss: 0.8552\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2352\tTop_Loss: 0.4781\tBottom_Loss: 0.3055\tLoss: 1.0188\t\n",
      "Subject: 15, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2071\tTop_Loss: 0.4298\tBottom_Loss: 0.2889\tLoss: 0.9257\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1618\tTop_Loss: 0.4334\tBottom_Loss: 0.2618\tLoss: 0.8570\t\n",
      "Subject: 15, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1492\tTop_Loss: 0.3204\tBottom_Loss: 0.2162\tLoss: 0.6858\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1808\tTop_Loss: 0.4513\tBottom_Loss: 0.2606\tLoss: 0.8927\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1963\tTop_Loss: 0.3377\tBottom_Loss: 0.2640\tLoss: 0.7980\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2261\tTop_Loss: 0.2817\tBottom_Loss: 0.2850\tLoss: 0.7928\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2099\tTop_Loss: 0.2815\tBottom_Loss: 0.1492\tLoss: 0.6405\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2178\tTop_Loss: 0.3557\tBottom_Loss: 0.2719\tLoss: 0.8454\t\n",
      "Subject: 15, n=03 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2123\tTop_Loss: 0.3387\tBottom_Loss: 0.2902\tLoss: 0.8412\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1028\tTop_Loss: 0.1643\tBottom_Loss: 0.2191\tLoss: 0.4862\t\n",
      "Subject: 15, n=03 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1550\tTop_Loss: 0.2909\tBottom_Loss: 0.3193\tLoss: 0.7653\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1126\tTop_Loss: 0.2947\tBottom_Loss: 0.1269\tLoss: 0.5343\t\n",
      "Subject: 15, n=03 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1226\tTop_Loss: 0.3424\tBottom_Loss: 0.1559\tLoss: 0.6210\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1705\tTop_Loss: 0.4175\tBottom_Loss: 0.2079\tLoss: 0.7958\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1760\tTop_Loss: 0.2179\tBottom_Loss: 0.2322\tLoss: 0.6261\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1292\tTop_Loss: 0.1950\tBottom_Loss: 0.2051\tLoss: 0.5293\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0840\tTop_Loss: 0.2577\tBottom_Loss: 0.1112\tLoss: 0.4530\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0924\tTop_Loss: 0.3454\tBottom_Loss: 0.1540\tLoss: 0.5917\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1140\tTop_Loss: 0.2640\tBottom_Loss: 0.2388\tLoss: 0.6168\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3010\tTop_Loss: 0.4507\tBottom_Loss: 0.2545\tLoss: 1.0061\t\n",
      "Subject: 15, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1477\tTop_Loss: 0.2537\tBottom_Loss: 0.2463\tLoss: 0.6478\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1005\tTop_Loss: 0.1631\tBottom_Loss: 0.2108\tLoss: 0.4743\t\n",
      "Subject: 15, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1485\tTop_Loss: 0.3697\tBottom_Loss: 0.1968\tLoss: 0.7150\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0626\tTop_Loss: 0.2015\tBottom_Loss: 0.1284\tLoss: 0.3925\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0833\tTop_Loss: 0.1459\tBottom_Loss: 0.1642\tLoss: 0.3934\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0870\tTop_Loss: 0.1322\tBottom_Loss: 0.1345\tLoss: 0.3537\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1130\tTop_Loss: 0.2202\tBottom_Loss: 0.1894\tLoss: 0.5226\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1138\tTop_Loss: 0.2603\tBottom_Loss: 0.1807\tLoss: 0.5547\t\n",
      "Subject: 15, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2115\tTop_Loss: 0.2945\tBottom_Loss: 0.2217\tLoss: 0.7277\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0678\tTop_Loss: 0.1602\tBottom_Loss: 0.1704\tLoss: 0.3984\t\n",
      "Subject: 15, n=03 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1213\tTop_Loss: 0.2496\tBottom_Loss: 0.2327\tLoss: 0.6037\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0660\tTop_Loss: 0.1784\tBottom_Loss: 0.1211\tLoss: 0.3655\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1291\tTop_Loss: 0.2335\tBottom_Loss: 0.1974\tLoss: 0.5599\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1793\tTop_Loss: 0.2640\tBottom_Loss: 0.2077\tLoss: 0.6510\t\n",
      "Subject: 15, n=03 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0494\tTop_Loss: 0.1695\tBottom_Loss: 0.1767\tLoss: 0.3956\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1007\tTop_Loss: 0.2520\tBottom_Loss: 0.1706\tLoss: 0.5234\t\n",
      "Subject: 15, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0842\tTop_Loss: 0.1850\tBottom_Loss: 0.1862\tLoss: 0.4554\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1668\tTop_Loss: 0.2509\tBottom_Loss: 0.2552\tLoss: 0.6729\t\n",
      "Subject: 15, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0650\tTop_Loss: 0.1487\tBottom_Loss: 0.1048\tLoss: 0.3185\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0555\tTop_Loss: 0.1037\tBottom_Loss: 0.1053\tLoss: 0.2645\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1339\tTop_Loss: 0.2884\tBottom_Loss: 0.1746\tLoss: 0.5969\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0697\tTop_Loss: 0.2271\tBottom_Loss: 0.1210\tLoss: 0.4178\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1315\tTop_Loss: 0.1941\tBottom_Loss: 0.2655\tLoss: 0.5911\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0878\tTop_Loss: 0.2830\tBottom_Loss: 0.1177\tLoss: 0.4885\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0282\tTop_Loss: 0.1174\tBottom_Loss: 0.1093\tLoss: 0.2548\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0353\tTop_Loss: 0.1405\tBottom_Loss: 0.0497\tLoss: 0.2255\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0598\tTop_Loss: 0.1519\tBottom_Loss: 0.1473\tLoss: 0.3589\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0669\tTop_Loss: 0.2244\tBottom_Loss: 0.1125\tLoss: 0.4038\t\n",
      "Subject: 15, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1148\tTop_Loss: 0.1538\tBottom_Loss: 0.1267\tLoss: 0.3953\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0689\tTop_Loss: 0.1543\tBottom_Loss: 0.1220\tLoss: 0.3452\t\n",
      "Subject: 15, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0390\tTop_Loss: 0.1464\tBottom_Loss: 0.0840\tLoss: 0.2693\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0512\tTop_Loss: 0.1875\tBottom_Loss: 0.0881\tLoss: 0.3268\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0212\tTop_Loss: 0.1369\tBottom_Loss: 0.0834\tLoss: 0.2415\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0289\tTop_Loss: 0.1579\tBottom_Loss: 0.0620\tLoss: 0.2488\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0586\tTop_Loss: 0.1515\tBottom_Loss: 0.0665\tLoss: 0.2766\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0225\tTop_Loss: 0.0490\tBottom_Loss: 0.0724\tLoss: 0.1439\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0262\tTop_Loss: 0.0879\tBottom_Loss: 0.0638\tLoss: 0.1779\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0475\tTop_Loss: 0.1157\tBottom_Loss: 0.1210\tLoss: 0.2842\t\n",
      "Subject: 15, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0679\tTop_Loss: 0.0961\tBottom_Loss: 0.1895\tLoss: 0.3535\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0350\tTop_Loss: 0.0610\tBottom_Loss: 0.1064\tLoss: 0.2023\t\n",
      "Subject: 15, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0474\tTop_Loss: 0.1027\tBottom_Loss: 0.0778\tLoss: 0.2279\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0567\tTop_Loss: 0.1569\tBottom_Loss: 0.0950\tLoss: 0.3085\t\n",
      "Subject: 15, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0327\tTop_Loss: 0.1507\tBottom_Loss: 0.1033\tLoss: 0.2867\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0252\tTop_Loss: 0.1036\tBottom_Loss: 0.0693\tLoss: 0.1982\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0214\tTop_Loss: 0.0618\tBottom_Loss: 0.0419\tLoss: 0.1252\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0480\tTop_Loss: 0.1723\tBottom_Loss: 0.0675\tLoss: 0.2878\t\n",
      "Subject: 15, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0669\tTop_Loss: 0.2112\tBottom_Loss: 0.0774\tLoss: 0.3554\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0309\tTop_Loss: 0.0540\tBottom_Loss: 0.0604\tLoss: 0.1453\t\n",
      "Subject: 15, n=03 | test_f1: 0.16667 |best_f1: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0345\tTop_Loss: 0.0931\tBottom_Loss: 0.0524\tLoss: 0.1800\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0829\tTop_Loss: 0.2567\tBottom_Loss: 0.1031\tLoss: 0.4427\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0298\tTop_Loss: 0.0893\tBottom_Loss: 0.0593\tLoss: 0.1784\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0164\tTop_Loss: 0.1125\tBottom_Loss: 0.0373\tLoss: 0.1662\t\n",
      "Subject: 15, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0849\tTop_Loss: 0.1902\tBottom_Loss: 0.1506\tLoss: 0.4257\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0284\tTop_Loss: 0.0975\tBottom_Loss: 0.0641\tLoss: 0.1900\t\n",
      "Subject: 15, n=03 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0363\tTop_Loss: 0.0658\tBottom_Loss: 0.0839\tLoss: 0.1860\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0168\tTop_Loss: 0.0436\tBottom_Loss: 0.0347\tLoss: 0.0950\t\n",
      "Subject: 15, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0225\tTop_Loss: 0.0583\tBottom_Loss: 0.0447\tLoss: 0.1255\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0226\tTop_Loss: 0.1181\tBottom_Loss: 0.0305\tLoss: 0.1712\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0193\tTop_Loss: 0.0418\tBottom_Loss: 0.0463\tLoss: 0.1073\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0289\tTop_Loss: 0.1030\tBottom_Loss: 0.0687\tLoss: 0.2006\t\n",
      "Subject: 15, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1614\tTop_Loss: 0.1594\tBottom_Loss: 0.1752\tLoss: 0.4960\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0579\tTop_Loss: 0.1232\tBottom_Loss: 0.1357\tLoss: 0.3168\t\n",
      "Subject: 15, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0159\tTop_Loss: 0.0544\tBottom_Loss: 0.0255\tLoss: 0.0957\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0144\tTop_Loss: 0.0525\tBottom_Loss: 0.0244\tLoss: 0.0912\t\n",
      "Subject: 15, n=03 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0339\tTop_Loss: 0.0979\tBottom_Loss: 0.0527\tLoss: 0.1845\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0127\tTop_Loss: 0.0876\tBottom_Loss: 0.0209\tLoss: 0.1213\t\n",
      "Subject: 15, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0660\tTop_Loss: 0.1385\tBottom_Loss: 0.1311\tLoss: 0.3356\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0121\tTop_Loss: 0.0644\tBottom_Loss: 0.0363\tLoss: 0.1127\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0106\tTop_Loss: 0.0393\tBottom_Loss: 0.0163\tLoss: 0.0662\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0174\tTop_Loss: 0.0673\tBottom_Loss: 0.0533\tLoss: 0.1380\t\n",
      "Subject: 15, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0238\tTop_Loss: 0.0526\tBottom_Loss: 0.0469\tLoss: 0.1233\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0512\tTop_Loss: 0.0572\tBottom_Loss: 0.0797\tLoss: 0.1881\t\n",
      "Subject: 15, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0291\tTop_Loss: 0.0642\tBottom_Loss: 0.0779\tLoss: 0.1713\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0423\tTop_Loss: 0.1534\tBottom_Loss: 0.0399\tLoss: 0.2356\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0062\tTop_Loss: 0.0361\tBottom_Loss: 0.0167\tLoss: 0.0590\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1419\tTop_Loss: 0.1993\tBottom_Loss: 0.0628\tLoss: 0.4040\t\n",
      "Subject: 15, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0191\tTop_Loss: 0.0928\tBottom_Loss: 0.0300\tLoss: 0.1419\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0079\tTop_Loss: 0.0493\tBottom_Loss: 0.0217\tLoss: 0.0789\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0096\tTop_Loss: 0.0367\tBottom_Loss: 0.0257\tLoss: 0.0720\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0216\tTop_Loss: 0.1101\tBottom_Loss: 0.0563\tLoss: 0.1879\t\n",
      "Subject: 15, n=03 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0107\tTop_Loss: 0.0400\tBottom_Loss: 0.0317\tLoss: 0.0825\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0635\tTop_Loss: 0.0597\tBottom_Loss: 0.1179\tLoss: 0.2411\t\n",
      "Subject: 15, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0083\tTop_Loss: 0.0227\tBottom_Loss: 0.0345\tLoss: 0.0655\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1091\tTop_Loss: 0.2364\tBottom_Loss: 0.0562\tLoss: 0.4016\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0078\tTop_Loss: 0.0454\tBottom_Loss: 0.0290\tLoss: 0.0821\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0260\tTop_Loss: 0.0997\tBottom_Loss: 0.0333\tLoss: 0.1589\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0857\tTop_Loss: 0.0512\tBottom_Loss: 0.1125\tLoss: 0.2494\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0131\tTop_Loss: 0.0287\tBottom_Loss: 0.0341\tLoss: 0.0759\t\n",
      "Subject: 15, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0097\tTop_Loss: 0.0563\tBottom_Loss: 0.0545\tLoss: 0.1204\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0182\tTop_Loss: 0.0592\tBottom_Loss: 0.0261\tLoss: 0.1034\t\n",
      "Subject: 15, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0163\tTop_Loss: 0.0555\tBottom_Loss: 0.0608\tLoss: 0.1327\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0070\tTop_Loss: 0.0318\tBottom_Loss: 0.0090\tLoss: 0.0478\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0189\tTop_Loss: 0.0355\tBottom_Loss: 0.0381\tLoss: 0.0925\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0075\tTop_Loss: 0.0448\tBottom_Loss: 0.0130\tLoss: 0.0652\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0281\tTop_Loss: 0.0742\tBottom_Loss: 0.0443\tLoss: 0.1465\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0114\tTop_Loss: 0.0323\tBottom_Loss: 0.0438\tLoss: 0.0875\t\n",
      "Subject: 15, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0121\tTop_Loss: 0.0364\tBottom_Loss: 0.0312\tLoss: 0.0798\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0198\tTop_Loss: 0.0737\tBottom_Loss: 0.0460\tLoss: 0.1395\t\n",
      "Subject: 15, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0106\tTop_Loss: 0.0160\tBottom_Loss: 0.0321\tLoss: 0.0587\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0233\tTop_Loss: 0.0219\tBottom_Loss: 0.0616\tLoss: 0.1069\t\n",
      "Subject: 15, n=03 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0058\tTop_Loss: 0.0290\tBottom_Loss: 0.0315\tLoss: 0.0664\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0107\tTop_Loss: 0.0548\tBottom_Loss: 0.0563\tLoss: 0.1219\t\n",
      "Subject: 15, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0047\tTop_Loss: 0.0308\tBottom_Loss: 0.0182\tLoss: 0.0537\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0089\tTop_Loss: 0.0185\tBottom_Loss: 0.0221\tLoss: 0.0495\t\n",
      "Subject: 15, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.312\tLabel_Loss: 1.2778\tTop_Loss: 1.7170\tBottom_Loss: 1.1069\tLoss: 4.1017\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.375\tLabel_Loss: 1.5149\tTop_Loss: 1.8437\tBottom_Loss: 1.1531\tLoss: 4.5118\t\n",
      "Subject: 16, n=03 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7856\tTop_Loss: 1.1239\tBottom_Loss: 0.8665\tLoss: 2.7759\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.469\tLabel_Loss: 1.1927\tTop_Loss: 1.0240\tBottom_Loss: 1.0772\tLoss: 3.2938\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.719\tLabel_Loss: 0.8335\tTop_Loss: 0.7862\tBottom_Loss: 0.7925\tLoss: 2.4122\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8835\tTop_Loss: 0.8773\tBottom_Loss: 0.9077\tLoss: 2.6686\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.531\tLabel_Loss: 0.9141\tTop_Loss: 1.0184\tBottom_Loss: 0.8771\tLoss: 2.8097\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.562\tLabel_Loss: 0.9849\tTop_Loss: 1.0276\tBottom_Loss: 0.8510\tLoss: 2.8635\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.562\tLabel_Loss: 0.8444\tTop_Loss: 0.9521\tBottom_Loss: 0.7665\tLoss: 2.5629\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.562\tLabel_Loss: 0.8699\tTop_Loss: 0.9760\tBottom_Loss: 0.9520\tLoss: 2.7978\t\n",
      "Subject: 16, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.562\tLabel_Loss: 0.8690\tTop_Loss: 0.9186\tBottom_Loss: 0.9597\tLoss: 2.7473\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.469\tLabel_Loss: 0.9707\tTop_Loss: 1.0117\tBottom_Loss: 0.9483\tLoss: 2.9308\t\n",
      "Subject: 16, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.469\tLabel_Loss: 0.9580\tTop_Loss: 0.9761\tBottom_Loss: 0.8097\tLoss: 2.7438\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.688\tLabel_Loss: 0.8380\tTop_Loss: 0.7491\tBottom_Loss: 0.9022\tLoss: 2.4893\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.25\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.531\tLabel_Loss: 0.9393\tTop_Loss: 0.8698\tBottom_Loss: 0.8209\tLoss: 2.6301\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.656\tLabel_Loss: 0.6698\tTop_Loss: 0.6347\tBottom_Loss: 0.7526\tLoss: 2.0570\t\n",
      "Subject: 16, n=03 | test_f1: 0.0 |best_f1: 0.25\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.688\tLabel_Loss: 0.8208\tTop_Loss: 0.8902\tBottom_Loss: 1.0505\tLoss: 2.7615\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7538\tTop_Loss: 0.7367\tBottom_Loss: 0.9877\tLoss: 2.4783\t\n",
      "Subject: 16, n=03 | test_f1: 0.66667 |best_f1: 0.66667\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.781\tLabel_Loss: 0.7287\tTop_Loss: 0.6872\tBottom_Loss: 0.7197\tLoss: 2.1356\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7925\tTop_Loss: 0.6758\tBottom_Loss: 0.7931\tLoss: 2.2614\t\n",
      "Subject: 16, n=03 | test_f1: 0.0 |best_f1: 0.66667\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6745\tTop_Loss: 0.6716\tBottom_Loss: 0.9009\tLoss: 2.2470\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.594\tLabel_Loss: 0.7746\tTop_Loss: 0.8671\tBottom_Loss: 0.8396\tLoss: 2.4813\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6001\tTop_Loss: 0.7694\tBottom_Loss: 0.9351\tLoss: 2.3046\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8394\tTop_Loss: 0.9243\tBottom_Loss: 0.8312\tLoss: 2.5949\t\n",
      "Subject: 16, n=03 | test_f1: 0.0 |best_f1: 0.66667\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6867\tTop_Loss: 0.8385\tBottom_Loss: 0.7964\tLoss: 2.3217\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5288\tTop_Loss: 0.7478\tBottom_Loss: 0.6571\tLoss: 1.9338\t\n",
      "Subject: 16, n=03 | test_f1: 0.22222 |best_f1: 0.66667\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7434\tTop_Loss: 0.7359\tBottom_Loss: 0.8057\tLoss: 2.2850\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5551\tTop_Loss: 0.6950\tBottom_Loss: 0.5892\tLoss: 1.8392\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.844\tLabel_Loss: 0.5532\tTop_Loss: 0.6307\tBottom_Loss: 0.6670\tLoss: 1.8509\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6427\tTop_Loss: 0.7552\tBottom_Loss: 0.6691\tLoss: 2.0670\t\n",
      "Subject: 16, n=03 | test_f1: 0.0 |best_f1: 0.66667\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5706\tTop_Loss: 0.8351\tBottom_Loss: 0.5659\tLoss: 1.9716\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6971\tTop_Loss: 0.5951\tBottom_Loss: 0.8309\tLoss: 2.1232\t\n",
      "Subject: 16, n=03 | test_f1: 0.0 |best_f1: 0.66667\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6189\tTop_Loss: 0.6594\tBottom_Loss: 0.6317\tLoss: 1.9100\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.656\tLabel_Loss: 0.8499\tTop_Loss: 0.8295\tBottom_Loss: 1.1449\tLoss: 2.8243\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5391\tTop_Loss: 0.6141\tBottom_Loss: 0.5073\tLoss: 1.6604\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5365\tTop_Loss: 0.6017\tBottom_Loss: 0.7685\tLoss: 1.9066\t\n",
      "Subject: 16, n=03 | test_f1: 0.0 |best_f1: 0.66667\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.656\tLabel_Loss: 0.6147\tTop_Loss: 0.6623\tBottom_Loss: 0.7110\tLoss: 1.9880\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.625\tLabel_Loss: 1.1419\tTop_Loss: 0.9627\tBottom_Loss: 1.1474\tLoss: 3.2520\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3787\tTop_Loss: 0.4396\tBottom_Loss: 0.5222\tLoss: 1.3405\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5207\tTop_Loss: 0.7046\tBottom_Loss: 0.6260\tLoss: 1.8513\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.844\tLabel_Loss: 0.5423\tTop_Loss: 0.7052\tBottom_Loss: 0.5232\tLoss: 1.7706\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4366\tTop_Loss: 0.5814\tBottom_Loss: 0.4438\tLoss: 1.4617\t\n",
      "Subject: 16, n=03 | test_f1: 0.0 |best_f1: 0.66667\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4759\tTop_Loss: 0.7074\tBottom_Loss: 0.5205\tLoss: 1.7037\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6119\tTop_Loss: 0.5992\tBottom_Loss: 0.4587\tLoss: 1.6698\t\n",
      "Subject: 16, n=03 | test_f1: 0.0 |best_f1: 0.66667\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.875\tLabel_Loss: 0.5252\tTop_Loss: 0.6063\tBottom_Loss: 0.5744\tLoss: 1.7060\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4848\tTop_Loss: 0.6018\tBottom_Loss: 0.4726\tLoss: 1.5591\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3085\tTop_Loss: 0.4979\tBottom_Loss: 0.4408\tLoss: 1.2473\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.750\tLabel_Loss: 0.7620\tTop_Loss: 0.8044\tBottom_Loss: 0.6760\tLoss: 2.2425\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3645\tTop_Loss: 0.5435\tBottom_Loss: 0.4492\tLoss: 1.3572\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.656\tLabel_Loss: 0.6174\tTop_Loss: 0.8462\tBottom_Loss: 0.6713\tLoss: 2.1349\t\n",
      "Subject: 16, n=03 | test_f1: 0.0 |best_f1: 0.66667\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.750\tLabel_Loss: 0.4093\tTop_Loss: 0.4989\tBottom_Loss: 0.4445\tLoss: 1.3527\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2913\tTop_Loss: 0.4654\tBottom_Loss: 0.5115\tLoss: 1.2682\t\n",
      "Subject: 16, n=03 | test_f1: 0.0 |best_f1: 0.66667\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3381\tTop_Loss: 0.5829\tBottom_Loss: 0.4479\tLoss: 1.3689\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4347\tTop_Loss: 0.5670\tBottom_Loss: 0.5451\tLoss: 1.5468\t\n",
      "Subject: 16, n=03 | test_f1: 0.66667 |best_f1: 0.66667\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2983\tTop_Loss: 0.5490\tBottom_Loss: 0.5351\tLoss: 1.3824\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4564\tTop_Loss: 0.4600\tBottom_Loss: 0.4488\tLoss: 1.3651\t\n",
      "Subject: 16, n=03 | test_f1: 0.4 |best_f1: 0.66667\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2772\tTop_Loss: 0.4829\tBottom_Loss: 0.3967\tLoss: 1.1569\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4540\tTop_Loss: 0.7277\tBottom_Loss: 0.5150\tLoss: 1.6967\t\n",
      "Subject: 16, n=03 | test_f1: 0.0 |best_f1: 0.66667\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3201\tTop_Loss: 0.5204\tBottom_Loss: 0.3651\tLoss: 1.2055\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3017\tTop_Loss: 0.5206\tBottom_Loss: 0.4305\tLoss: 1.2528\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3672\tTop_Loss: 0.5587\tBottom_Loss: 0.4617\tLoss: 1.3876\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4800\tTop_Loss: 0.4895\tBottom_Loss: 0.5967\tLoss: 1.5662\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4643\tTop_Loss: 0.6433\tBottom_Loss: 0.4877\tLoss: 1.5953\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 1.000\tLabel_Loss: 0.2317\tTop_Loss: 0.3847\tBottom_Loss: 0.4137\tLoss: 1.0300\t\n",
      "Subject: 16, n=03 | test_f1: 0.0 |best_f1: 0.66667\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2107\tTop_Loss: 0.3812\tBottom_Loss: 0.3430\tLoss: 0.9349\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3810\tTop_Loss: 0.4311\tBottom_Loss: 0.4573\tLoss: 1.2695\t\n",
      "Subject: 16, n=03 | test_f1: 0.0 |best_f1: 0.66667\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1985\tTop_Loss: 0.3043\tBottom_Loss: 0.3011\tLoss: 0.8039\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2805\tTop_Loss: 0.4866\tBottom_Loss: 0.3154\tLoss: 1.0825\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 16, n=03 | test_f1: 0.0 |best_f1: 0.66667\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1655\tTop_Loss: 0.3188\tBottom_Loss: 0.3089\tLoss: 0.7932\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1955\tTop_Loss: 0.2909\tBottom_Loss: 0.2713\tLoss: 0.7577\t\n",
      "Subject: 16, n=03 | test_f1: 0.66667 |best_f1: 0.66667\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2040\tTop_Loss: 0.3377\tBottom_Loss: 0.4620\tLoss: 1.0037\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1329\tTop_Loss: 0.2805\tBottom_Loss: 0.1910\tLoss: 0.6044\t\n",
      "Subject: 16, n=03 | test_f1: 0.0 |best_f1: 0.66667\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2274\tTop_Loss: 0.4637\tBottom_Loss: 0.3299\tLoss: 1.0210\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3165\tTop_Loss: 0.4201\tBottom_Loss: 0.3655\tLoss: 1.1021\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1713\tTop_Loss: 0.3389\tBottom_Loss: 0.2324\tLoss: 0.7426\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0907\tTop_Loss: 0.2031\tBottom_Loss: 0.1661\tLoss: 0.4599\t\n",
      "Subject: 16, n=03 | test_f1: 0.55556 |best_f1: 0.66667\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3561\tTop_Loss: 0.4633\tBottom_Loss: 0.4064\tLoss: 1.2257\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2415\tTop_Loss: 0.3859\tBottom_Loss: 0.3627\tLoss: 0.9901\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1918\tTop_Loss: 0.4989\tBottom_Loss: 0.3207\tLoss: 1.0113\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2501\tTop_Loss: 0.4717\tBottom_Loss: 0.2794\tLoss: 1.0012\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1547\tTop_Loss: 0.2758\tBottom_Loss: 0.3451\tLoss: 0.7755\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1015\tTop_Loss: 0.1757\tBottom_Loss: 0.2265\tLoss: 0.5037\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0981\tTop_Loss: 0.1752\tBottom_Loss: 0.2046\tLoss: 0.4779\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1081\tTop_Loss: 0.2347\tBottom_Loss: 0.2170\tLoss: 0.5598\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1903\tTop_Loss: 0.4137\tBottom_Loss: 0.1499\tLoss: 0.7539\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1424\tTop_Loss: 0.2737\tBottom_Loss: 0.2151\tLoss: 0.6312\t\n",
      "Subject: 16, n=03 | test_f1: 0.0 |best_f1: 0.66667\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1647\tTop_Loss: 0.3642\tBottom_Loss: 0.2053\tLoss: 0.7341\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1597\tTop_Loss: 0.2490\tBottom_Loss: 0.2928\tLoss: 0.7015\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1470\tTop_Loss: 0.2842\tBottom_Loss: 0.3473\tLoss: 0.7785\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1318\tTop_Loss: 0.2793\tBottom_Loss: 0.1970\tLoss: 0.6081\t\n",
      "Subject: 16, n=03 | test_f1: 0.0 |best_f1: 0.66667\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1768\tTop_Loss: 0.3421\tBottom_Loss: 0.2226\tLoss: 0.7415\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0996\tTop_Loss: 0.2507\tBottom_Loss: 0.1757\tLoss: 0.5260\t\n",
      "Subject: 16, n=03 | test_f1: 0.66667 |best_f1: 0.66667\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.938\tLabel_Loss: 0.0965\tTop_Loss: 0.2997\tBottom_Loss: 0.1073\tLoss: 0.5034\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1048\tTop_Loss: 0.2411\tBottom_Loss: 0.2065\tLoss: 0.5524\t\n",
      "Subject: 16, n=03 | test_f1: 0.0 |best_f1: 0.66667\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0772\tTop_Loss: 0.2321\tBottom_Loss: 0.1152\tLoss: 0.4245\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1290\tTop_Loss: 0.2569\tBottom_Loss: 0.2376\tLoss: 0.6235\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2742\tTop_Loss: 0.4319\tBottom_Loss: 0.2276\tLoss: 0.9336\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1158\tTop_Loss: 0.2465\tBottom_Loss: 0.1489\tLoss: 0.5112\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0757\tTop_Loss: 0.2324\tBottom_Loss: 0.1876\tLoss: 0.4957\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1259\tTop_Loss: 0.2801\tBottom_Loss: 0.1816\tLoss: 0.5877\t\n",
      "Subject: 16, n=03 | test_f1: 0.0 |best_f1: 0.66667\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1606\tTop_Loss: 0.3293\tBottom_Loss: 0.2400\tLoss: 0.7299\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1016\tTop_Loss: 0.1898\tBottom_Loss: 0.2425\tLoss: 0.5339\t\n",
      "Subject: 16, n=03 | test_f1: 0.0 |best_f1: 0.66667\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1240\tTop_Loss: 0.2403\tBottom_Loss: 0.2110\tLoss: 0.5754\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0641\tTop_Loss: 0.2548\tBottom_Loss: 0.1117\tLoss: 0.4305\t\n",
      "Subject: 16, n=03 | test_f1: 0.22222 |best_f1: 0.66667\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0831\tTop_Loss: 0.2096\tBottom_Loss: 0.2333\tLoss: 0.5260\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0792\tTop_Loss: 0.2546\tBottom_Loss: 0.1766\tLoss: 0.5104\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0614\tTop_Loss: 0.1892\tBottom_Loss: 0.1342\tLoss: 0.3848\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0503\tTop_Loss: 0.1551\tBottom_Loss: 0.1412\tLoss: 0.3466\t\n",
      "Subject: 16, n=03 | test_f1: 0.66667 |best_f1: 0.66667\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0766\tTop_Loss: 0.1499\tBottom_Loss: 0.1811\tLoss: 0.4076\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1107\tTop_Loss: 0.3103\tBottom_Loss: 0.1291\tLoss: 0.5500\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1396\tTop_Loss: 0.2695\tBottom_Loss: 0.1311\tLoss: 0.5402\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0869\tTop_Loss: 0.1908\tBottom_Loss: 0.2002\tLoss: 0.4779\t\n",
      "Subject: 16, n=03 | test_f1: 0.4 |best_f1: 0.66667\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0627\tTop_Loss: 0.2071\tBottom_Loss: 0.1439\tLoss: 0.4137\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0905\tTop_Loss: 0.1310\tBottom_Loss: 0.1240\tLoss: 0.3454\t\n",
      "Subject: 16, n=03 | test_f1: 0.66667 |best_f1: 0.66667\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1176\tTop_Loss: 0.2685\tBottom_Loss: 0.1025\tLoss: 0.4886\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1360\tTop_Loss: 0.1886\tBottom_Loss: 0.1475\tLoss: 0.4722\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1428\tTop_Loss: 0.2718\tBottom_Loss: 0.1804\tLoss: 0.5951\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1109\tTop_Loss: 0.2006\tBottom_Loss: 0.1564\tLoss: 0.4680\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0625\tTop_Loss: 0.1558\tBottom_Loss: 0.1359\tLoss: 0.3542\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0446\tTop_Loss: 0.1729\tBottom_Loss: 0.1366\tLoss: 0.3542\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0549\tTop_Loss: 0.1551\tBottom_Loss: 0.0983\tLoss: 0.3082\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1330\tTop_Loss: 0.1041\tBottom_Loss: 0.1680\tLoss: 0.4051\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0365\tTop_Loss: 0.1481\tBottom_Loss: 0.1075\tLoss: 0.2921\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0520\tTop_Loss: 0.1807\tBottom_Loss: 0.1170\tLoss: 0.3497\t\n",
      "Subject: 16, n=03 | test_f1: 0.66667 |best_f1: 0.66667\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1192\tTop_Loss: 0.2484\tBottom_Loss: 0.2213\tLoss: 0.5889\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0688\tTop_Loss: 0.2389\tBottom_Loss: 0.1308\tLoss: 0.4385\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0279\tTop_Loss: 0.1510\tBottom_Loss: 0.0449\tLoss: 0.2238\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0667\tTop_Loss: 0.1844\tBottom_Loss: 0.1192\tLoss: 0.3703\t\n",
      "Subject: 16, n=03 | test_f1: 0.66667 |best_f1: 0.66667\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0571\tTop_Loss: 0.1156\tBottom_Loss: 0.1170\tLoss: 0.2897\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0448\tTop_Loss: 0.1988\tBottom_Loss: 0.0747\tLoss: 0.3183\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0249\tTop_Loss: 0.1079\tBottom_Loss: 0.0594\tLoss: 0.1922\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1011\tTop_Loss: 0.2502\tBottom_Loss: 0.1821\tLoss: 0.5334\t\n",
      "Subject: 16, n=03 | test_f1: 0.0 |best_f1: 0.66667\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0230\tTop_Loss: 0.0777\tBottom_Loss: 0.1083\tLoss: 0.2090\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0675\tTop_Loss: 0.1958\tBottom_Loss: 0.1227\tLoss: 0.3859\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0510\tTop_Loss: 0.1888\tBottom_Loss: 0.0646\tLoss: 0.3044\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0405\tTop_Loss: 0.1294\tBottom_Loss: 0.0740\tLoss: 0.2440\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0453\tTop_Loss: 0.1270\tBottom_Loss: 0.0837\tLoss: 0.2560\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0254\tTop_Loss: 0.0964\tBottom_Loss: 0.0899\tLoss: 0.2116\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0135\tTop_Loss: 0.0589\tBottom_Loss: 0.0620\tLoss: 0.1345\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0155\tTop_Loss: 0.1156\tBottom_Loss: 0.0407\tLoss: 0.1718\t\n",
      "Subject: 16, n=03 | test_f1: 0.66667 |best_f1: 0.66667\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1164\tTop_Loss: 0.3806\tBottom_Loss: 0.0995\tLoss: 0.5965\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0781\tTop_Loss: 0.1957\tBottom_Loss: 0.1204\tLoss: 0.3941\t\n",
      "Subject: 16, n=03 | test_f1: 0.0 |best_f1: 0.66667\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0223\tTop_Loss: 0.0805\tBottom_Loss: 0.0457\tLoss: 0.1484\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0426\tTop_Loss: 0.1290\tBottom_Loss: 0.1005\tLoss: 0.2721\t\n",
      "Subject: 16, n=03 | test_f1: 0.0 |best_f1: 0.66667\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0103\tTop_Loss: 0.0574\tBottom_Loss: 0.0243\tLoss: 0.0920\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0470\tTop_Loss: 0.1292\tBottom_Loss: 0.0915\tLoss: 0.2678\t\n",
      "Subject: 16, n=03 | test_f1: 0.66667 |best_f1: 0.66667\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0267\tTop_Loss: 0.0777\tBottom_Loss: 0.0924\tLoss: 0.1967\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0149\tTop_Loss: 0.0744\tBottom_Loss: 0.0359\tLoss: 0.1252\t\n",
      "Subject: 16, n=03 | test_f1: 0.0 |best_f1: 0.66667\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0143\tTop_Loss: 0.0739\tBottom_Loss: 0.0534\tLoss: 0.1416\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0744\tTop_Loss: 0.1453\tBottom_Loss: 0.1311\tLoss: 0.3508\t\n",
      "Subject: 16, n=03 | test_f1: 0.66667 |best_f1: 0.66667\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0231\tTop_Loss: 0.1077\tBottom_Loss: 0.0302\tLoss: 0.1611\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0185\tTop_Loss: 0.1008\tBottom_Loss: 0.0405\tLoss: 0.1598\t\n",
      "Subject: 16, n=03 | test_f1: 0.0 |best_f1: 0.66667\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0192\tTop_Loss: 0.0804\tBottom_Loss: 0.0426\tLoss: 0.1422\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0245\tTop_Loss: 0.0626\tBottom_Loss: 0.0660\tLoss: 0.1531\t\n",
      "Subject: 16, n=03 | test_f1: 0.66667 |best_f1: 0.66667\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0356\tTop_Loss: 0.0638\tBottom_Loss: 0.0856\tLoss: 0.1850\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0221\tTop_Loss: 0.1240\tBottom_Loss: 0.0372\tLoss: 0.1833\t\n",
      "Subject: 16, n=03 | test_f1: 0.0 |best_f1: 0.66667\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0469\tTop_Loss: 0.0910\tBottom_Loss: 0.0964\tLoss: 0.2343\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0275\tTop_Loss: 0.1564\tBottom_Loss: 0.0363\tLoss: 0.2202\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0104\tTop_Loss: 0.0673\tBottom_Loss: 0.0205\tLoss: 0.0982\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0197\tTop_Loss: 0.0622\tBottom_Loss: 0.0465\tLoss: 0.1284\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0202\tTop_Loss: 0.0629\tBottom_Loss: 0.0324\tLoss: 0.1155\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0419\tTop_Loss: 0.0803\tBottom_Loss: 0.0862\tLoss: 0.2085\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0327\tTop_Loss: 0.1581\tBottom_Loss: 0.0688\tLoss: 0.2597\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0224\tTop_Loss: 0.0744\tBottom_Loss: 0.0596\tLoss: 0.1564\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0138\tTop_Loss: 0.0429\tBottom_Loss: 0.0754\tLoss: 0.1320\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0289\tTop_Loss: 0.1256\tBottom_Loss: 0.0382\tLoss: 0.1927\t\n",
      "Subject: 16, n=03 | test_f1: 0.0 |best_f1: 0.66667\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0200\tTop_Loss: 0.0522\tBottom_Loss: 0.0834\tLoss: 0.1556\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0167\tTop_Loss: 0.0543\tBottom_Loss: 0.0741\tLoss: 0.1452\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0175\tTop_Loss: 0.0644\tBottom_Loss: 0.0613\tLoss: 0.1432\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0228\tTop_Loss: 0.0790\tBottom_Loss: 0.0570\tLoss: 0.1587\t\n",
      "Subject: 16, n=03 | test_f1: 0.22222 |best_f1: 0.66667\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0275\tTop_Loss: 0.0451\tBottom_Loss: 0.0559\tLoss: 0.1285\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0153\tTop_Loss: 0.0724\tBottom_Loss: 0.0665\tLoss: 0.1542\t\n",
      "Subject: 16, n=03 | test_f1: 0.0 |best_f1: 0.66667\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0151\tTop_Loss: 0.0523\tBottom_Loss: 0.0507\tLoss: 0.1181\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0090\tTop_Loss: 0.0385\tBottom_Loss: 0.0220\tLoss: 0.0694\t\n",
      "Subject: 16, n=03 | test_f1: 0.22222 |best_f1: 0.66667\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0045\tTop_Loss: 0.0272\tBottom_Loss: 0.0342\tLoss: 0.0659\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0302\tTop_Loss: 0.0970\tBottom_Loss: 0.0524\tLoss: 0.1796\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0662\tTop_Loss: 0.0653\tBottom_Loss: 0.0986\tLoss: 0.2300\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0158\tTop_Loss: 0.0306\tBottom_Loss: 0.0413\tLoss: 0.0877\t\n",
      "Subject: 16, n=03 | test_f1: 0.66667 |best_f1: 0.66667\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0143\tTop_Loss: 0.0383\tBottom_Loss: 0.0322\tLoss: 0.0847\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0154\tTop_Loss: 0.0519\tBottom_Loss: 0.0841\tLoss: 0.1513\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0415\tTop_Loss: 0.1193\tBottom_Loss: 0.0902\tLoss: 0.2509\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0102\tTop_Loss: 0.0592\tBottom_Loss: 0.0206\tLoss: 0.0901\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0132\tTop_Loss: 0.0431\tBottom_Loss: 0.0423\tLoss: 0.0986\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0087\tTop_Loss: 0.0274\tBottom_Loss: 0.0677\tLoss: 0.1038\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0112\tTop_Loss: 0.0275\tBottom_Loss: 0.0293\tLoss: 0.0680\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0079\tTop_Loss: 0.0533\tBottom_Loss: 0.0304\tLoss: 0.0916\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0140\tTop_Loss: 0.0697\tBottom_Loss: 0.0611\tLoss: 0.1448\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0106\tTop_Loss: 0.0781\tBottom_Loss: 0.0174\tLoss: 0.1061\t\n",
      "Subject: 16, n=03 | test_f1: 0.0 |best_f1: 0.66667\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0213\tTop_Loss: 0.0838\tBottom_Loss: 0.0212\tLoss: 0.1262\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0187\tTop_Loss: 0.0449\tBottom_Loss: 0.0487\tLoss: 0.1122\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0063\tTop_Loss: 0.0243\tBottom_Loss: 0.0344\tLoss: 0.0649\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0785\tTop_Loss: 0.0770\tBottom_Loss: 0.1225\tLoss: 0.2780\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0054\tTop_Loss: 0.0233\tBottom_Loss: 0.0176\tLoss: 0.0464\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1174\tTop_Loss: 0.0685\tBottom_Loss: 0.2680\tLoss: 0.4539\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0053\tTop_Loss: 0.0487\tBottom_Loss: 0.0229\tLoss: 0.0769\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0182\tTop_Loss: 0.0456\tBottom_Loss: 0.0710\tLoss: 0.1348\t\n",
      "Subject: 16, n=03 | test_f1: 0.0 |best_f1: 0.66667\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0042\tTop_Loss: 0.0458\tBottom_Loss: 0.0112\tLoss: 0.0612\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0155\tTop_Loss: 0.0623\tBottom_Loss: 0.0590\tLoss: 0.1368\t\n",
      "Subject: 16, n=03 | test_f1: 0.0 |best_f1: 0.66667\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0214\tTop_Loss: 0.0986\tBottom_Loss: 0.0152\tLoss: 0.1353\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0062\tTop_Loss: 0.0193\tBottom_Loss: 0.0217\tLoss: 0.0471\t\n",
      "Subject: 16, n=03 | test_f1: 0.25 |best_f1: 0.66667\n",
      "Train:\tEpoch:[0][1/13]   \tAcc: 0.344\tLabel_Loss: 1.0808\tTop_Loss: 2.1019\tBottom_Loss: 0.9862\tLoss: 4.1689\t\n",
      "Train:\tEpoch:[0][8/13]   \tAcc: 0.531\tLabel_Loss: 1.0206\tTop_Loss: 1.3592\tBottom_Loss: 1.2692\tLoss: 3.6490\t\n",
      "Subject: 17, n=31 | test_f1: 0.61538 |best_f1: 0.61538\n",
      "Train:\tEpoch:[1][1/13]   \tAcc: 0.594\tLabel_Loss: 0.9217\tTop_Loss: 1.0373\tBottom_Loss: 1.0179\tLoss: 2.9769\t\n",
      "Train:\tEpoch:[1][8/13]   \tAcc: 0.656\tLabel_Loss: 0.9759\tTop_Loss: 0.8568\tBottom_Loss: 0.9439\tLoss: 2.7766\t\n",
      "Subject: 17, n=31 | test_f1: 0.26923 |best_f1: 0.61538\n",
      "Train:\tEpoch:[2][1/13]   \tAcc: 0.531\tLabel_Loss: 0.9374\tTop_Loss: 1.2207\tBottom_Loss: 1.1015\tLoss: 3.2596\t\n",
      "Train:\tEpoch:[2][8/13]   \tAcc: 0.531\tLabel_Loss: 1.0933\tTop_Loss: 1.0179\tBottom_Loss: 0.9020\tLoss: 3.0132\t\n",
      "Subject: 17, n=31 | test_f1: 0.28395 |best_f1: 0.61538\n",
      "Train:\tEpoch:[3][1/13]   \tAcc: 0.688\tLabel_Loss: 0.7496\tTop_Loss: 0.6278\tBottom_Loss: 0.6081\tLoss: 1.9855\t\n",
      "Train:\tEpoch:[3][8/13]   \tAcc: 0.562\tLabel_Loss: 0.9739\tTop_Loss: 0.8625\tBottom_Loss: 1.2612\tLoss: 3.0976\t\n",
      "Subject: 17, n=31 | test_f1: 0.25333 |best_f1: 0.61538\n",
      "Train:\tEpoch:[4][1/13]   \tAcc: 0.562\tLabel_Loss: 0.9605\tTop_Loss: 1.0139\tBottom_Loss: 0.8482\tLoss: 2.8226\t\n",
      "Train:\tEpoch:[4][8/13]   \tAcc: 0.688\tLabel_Loss: 0.9706\tTop_Loss: 0.9509\tBottom_Loss: 0.9006\tLoss: 2.8221\t\n",
      "Subject: 17, n=31 | test_f1: 0.3078 |best_f1: 0.61538\n",
      "Train:\tEpoch:[5][1/13]   \tAcc: 0.531\tLabel_Loss: 1.0550\tTop_Loss: 1.1904\tBottom_Loss: 1.0431\tLoss: 3.2886\t\n",
      "Train:\tEpoch:[5][8/13]   \tAcc: 0.812\tLabel_Loss: 0.5956\tTop_Loss: 0.7353\tBottom_Loss: 0.7135\tLoss: 2.0443\t\n",
      "Subject: 17, n=31 | test_f1: 0.36111 |best_f1: 0.61538\n",
      "Train:\tEpoch:[6][1/13]   \tAcc: 0.594\tLabel_Loss: 0.9359\tTop_Loss: 0.8249\tBottom_Loss: 0.7349\tLoss: 2.4957\t\n",
      "Train:\tEpoch:[6][8/13]   \tAcc: 0.531\tLabel_Loss: 1.0064\tTop_Loss: 0.8638\tBottom_Loss: 1.0843\tLoss: 2.9544\t\n",
      "Subject: 17, n=31 | test_f1: 0.23462 |best_f1: 0.61538\n",
      "Train:\tEpoch:[7][1/13]   \tAcc: 0.531\tLabel_Loss: 0.9626\tTop_Loss: 0.8126\tBottom_Loss: 0.8951\tLoss: 2.6703\t\n",
      "Train:\tEpoch:[7][8/13]   \tAcc: 0.625\tLabel_Loss: 0.7420\tTop_Loss: 0.7663\tBottom_Loss: 0.8347\tLoss: 2.3430\t\n",
      "Subject: 17, n=31 | test_f1: 0.26923 |best_f1: 0.61538\n",
      "Train:\tEpoch:[8][1/13]   \tAcc: 0.625\tLabel_Loss: 0.9080\tTop_Loss: 0.8985\tBottom_Loss: 0.7946\tLoss: 2.6010\t\n",
      "Train:\tEpoch:[8][8/13]   \tAcc: 0.500\tLabel_Loss: 0.9359\tTop_Loss: 0.8992\tBottom_Loss: 0.9891\tLoss: 2.8242\t\n",
      "Subject: 17, n=31 | test_f1: 0.37608 |best_f1: 0.61538\n",
      "Train:\tEpoch:[9][1/13]   \tAcc: 0.625\tLabel_Loss: 0.9128\tTop_Loss: 0.9287\tBottom_Loss: 0.9178\tLoss: 2.7593\t\n",
      "Train:\tEpoch:[9][8/13]   \tAcc: 0.656\tLabel_Loss: 0.6725\tTop_Loss: 0.8574\tBottom_Loss: 1.0135\tLoss: 2.5435\t\n",
      "Subject: 17, n=31 | test_f1: 0.39495 |best_f1: 0.61538\n",
      "Train:\tEpoch:[10][1/13]   \tAcc: 0.688\tLabel_Loss: 0.6829\tTop_Loss: 0.7816\tBottom_Loss: 0.6941\tLoss: 2.1586\t\n",
      "Train:\tEpoch:[10][8/13]   \tAcc: 0.594\tLabel_Loss: 0.7794\tTop_Loss: 1.0526\tBottom_Loss: 0.7071\tLoss: 2.5392\t\n",
      "Subject: 17, n=31 | test_f1: 0.40902 |best_f1: 0.61538\n",
      "Train:\tEpoch:[11][1/13]   \tAcc: 0.750\tLabel_Loss: 0.7142\tTop_Loss: 0.8080\tBottom_Loss: 0.7006\tLoss: 2.2229\t\n",
      "Train:\tEpoch:[11][8/13]   \tAcc: 0.688\tLabel_Loss: 0.7344\tTop_Loss: 0.7811\tBottom_Loss: 0.7153\tLoss: 2.2308\t\n",
      "Subject: 17, n=31 | test_f1: 0.4359 |best_f1: 0.61538\n",
      "Train:\tEpoch:[12][1/13]   \tAcc: 0.750\tLabel_Loss: 0.6646\tTop_Loss: 0.6636\tBottom_Loss: 0.8918\tLoss: 2.2200\t\n",
      "Train:\tEpoch:[12][8/13]   \tAcc: 0.688\tLabel_Loss: 0.7406\tTop_Loss: 0.7028\tBottom_Loss: 0.7325\tLoss: 2.1758\t\n",
      "Subject: 17, n=31 | test_f1: 0.50427 |best_f1: 0.61538\n",
      "Train:\tEpoch:[13][1/13]   \tAcc: 0.625\tLabel_Loss: 0.7900\tTop_Loss: 0.8226\tBottom_Loss: 0.7199\tLoss: 2.3326\t\n",
      "Train:\tEpoch:[13][8/13]   \tAcc: 0.719\tLabel_Loss: 0.9133\tTop_Loss: 0.9952\tBottom_Loss: 0.8465\tLoss: 2.7549\t\n",
      "Subject: 17, n=31 | test_f1: 0.35328 |best_f1: 0.61538\n",
      "Train:\tEpoch:[14][1/13]   \tAcc: 0.688\tLabel_Loss: 0.6439\tTop_Loss: 0.6283\tBottom_Loss: 0.7418\tLoss: 2.0140\t\n",
      "Train:\tEpoch:[14][8/13]   \tAcc: 0.656\tLabel_Loss: 0.7182\tTop_Loss: 0.7756\tBottom_Loss: 0.7572\tLoss: 2.2510\t\n",
      "Subject: 17, n=31 | test_f1: 0.40542 |best_f1: 0.61538\n",
      "Train:\tEpoch:[15][1/13]   \tAcc: 0.688\tLabel_Loss: 0.6973\tTop_Loss: 0.7748\tBottom_Loss: 0.7415\tLoss: 2.2135\t\n",
      "Train:\tEpoch:[15][8/13]   \tAcc: 0.781\tLabel_Loss: 0.6068\tTop_Loss: 0.5956\tBottom_Loss: 0.7107\tLoss: 1.9130\t\n",
      "Subject: 17, n=31 | test_f1: 0.35424 |best_f1: 0.61538\n",
      "Train:\tEpoch:[16][1/13]   \tAcc: 0.719\tLabel_Loss: 0.5259\tTop_Loss: 0.5911\tBottom_Loss: 0.7667\tLoss: 1.8837\t\n",
      "Train:\tEpoch:[16][8/13]   \tAcc: 0.875\tLabel_Loss: 0.4633\tTop_Loss: 0.5142\tBottom_Loss: 0.3952\tLoss: 1.3727\t\n",
      "Subject: 17, n=31 | test_f1: 0.50729 |best_f1: 0.61538\n",
      "Train:\tEpoch:[17][1/13]   \tAcc: 0.750\tLabel_Loss: 0.5804\tTop_Loss: 0.7222\tBottom_Loss: 0.6450\tLoss: 1.9476\t\n",
      "Train:\tEpoch:[17][8/13]   \tAcc: 0.594\tLabel_Loss: 0.8311\tTop_Loss: 0.6901\tBottom_Loss: 0.7069\tLoss: 2.2282\t\n",
      "Subject: 17, n=31 | test_f1: 0.61313 |best_f1: 0.61538\n",
      "Train:\tEpoch:[18][1/13]   \tAcc: 0.875\tLabel_Loss: 0.4012\tTop_Loss: 0.3935\tBottom_Loss: 0.4646\tLoss: 1.2593\t\n",
      "Train:\tEpoch:[18][8/13]   \tAcc: 0.719\tLabel_Loss: 0.6721\tTop_Loss: 0.6554\tBottom_Loss: 0.7457\tLoss: 2.0732\t\n",
      "Subject: 17, n=31 | test_f1: 0.48811 |best_f1: 0.61538\n",
      "Train:\tEpoch:[19][1/13]   \tAcc: 0.781\tLabel_Loss: 0.4200\tTop_Loss: 0.4511\tBottom_Loss: 0.5157\tLoss: 1.3868\t\n",
      "Train:\tEpoch:[19][8/13]   \tAcc: 0.781\tLabel_Loss: 0.6338\tTop_Loss: 0.7885\tBottom_Loss: 0.8021\tLoss: 2.2244\t\n",
      "Subject: 17, n=31 | test_f1: 0.3933 |best_f1: 0.61538\n",
      "Train:\tEpoch:[20][1/13]   \tAcc: 0.750\tLabel_Loss: 0.5893\tTop_Loss: 0.5310\tBottom_Loss: 0.7415\tLoss: 1.8618\t\n",
      "Train:\tEpoch:[20][8/13]   \tAcc: 0.844\tLabel_Loss: 0.3833\tTop_Loss: 0.5489\tBottom_Loss: 0.5831\tLoss: 1.5153\t\n",
      "Subject: 17, n=31 | test_f1: 0.32449 |best_f1: 0.61538\n",
      "Train:\tEpoch:[21][1/13]   \tAcc: 0.812\tLabel_Loss: 0.4398\tTop_Loss: 0.6019\tBottom_Loss: 0.5431\tLoss: 1.5848\t\n",
      "Train:\tEpoch:[21][8/13]   \tAcc: 0.906\tLabel_Loss: 0.3886\tTop_Loss: 0.3540\tBottom_Loss: 0.6167\tLoss: 1.3593\t\n",
      "Subject: 17, n=31 | test_f1: 0.37758 |best_f1: 0.61538\n",
      "Train:\tEpoch:[22][1/13]   \tAcc: 0.688\tLabel_Loss: 0.5204\tTop_Loss: 0.6743\tBottom_Loss: 0.5412\tLoss: 1.7359\t\n",
      "Train:\tEpoch:[22][8/13]   \tAcc: 0.688\tLabel_Loss: 0.7190\tTop_Loss: 0.8677\tBottom_Loss: 0.7048\tLoss: 2.2915\t\n",
      "Subject: 17, n=31 | test_f1: 0.38335 |best_f1: 0.61538\n",
      "Train:\tEpoch:[23][1/13]   \tAcc: 0.906\tLabel_Loss: 0.4472\tTop_Loss: 0.4487\tBottom_Loss: 0.5899\tLoss: 1.4858\t\n",
      "Train:\tEpoch:[23][8/13]   \tAcc: 0.812\tLabel_Loss: 0.5186\tTop_Loss: 0.6827\tBottom_Loss: 0.7271\tLoss: 1.9284\t\n",
      "Subject: 17, n=31 | test_f1: 0.23188 |best_f1: 0.61538\n",
      "Train:\tEpoch:[24][1/13]   \tAcc: 0.719\tLabel_Loss: 0.6010\tTop_Loss: 0.6648\tBottom_Loss: 0.4283\tLoss: 1.6942\t\n",
      "Train:\tEpoch:[24][8/13]   \tAcc: 0.844\tLabel_Loss: 0.4030\tTop_Loss: 0.4329\tBottom_Loss: 0.5859\tLoss: 1.4218\t\n",
      "Subject: 17, n=31 | test_f1: 0.51948 |best_f1: 0.61538\n",
      "Train:\tEpoch:[25][1/13]   \tAcc: 0.969\tLabel_Loss: 0.2797\tTop_Loss: 0.5374\tBottom_Loss: 0.3804\tLoss: 1.1974\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[25][8/13]   \tAcc: 0.812\tLabel_Loss: 0.4975\tTop_Loss: 0.4216\tBottom_Loss: 0.5378\tLoss: 1.4570\t\n",
      "Subject: 17, n=31 | test_f1: 0.47619 |best_f1: 0.61538\n",
      "Train:\tEpoch:[26][1/13]   \tAcc: 0.938\tLabel_Loss: 0.2845\tTop_Loss: 0.3144\tBottom_Loss: 0.2998\tLoss: 0.8987\t\n",
      "Train:\tEpoch:[26][8/13]   \tAcc: 0.844\tLabel_Loss: 0.4717\tTop_Loss: 0.6180\tBottom_Loss: 0.4868\tLoss: 1.5765\t\n",
      "Subject: 17, n=31 | test_f1: 0.28317 |best_f1: 0.61538\n",
      "Train:\tEpoch:[27][1/13]   \tAcc: 0.844\tLabel_Loss: 0.4208\tTop_Loss: 0.5093\tBottom_Loss: 0.4481\tLoss: 1.3782\t\n",
      "Train:\tEpoch:[27][8/13]   \tAcc: 0.844\tLabel_Loss: 0.4743\tTop_Loss: 0.4884\tBottom_Loss: 0.6450\tLoss: 1.6077\t\n",
      "Subject: 17, n=31 | test_f1: 0.33878 |best_f1: 0.61538\n",
      "Train:\tEpoch:[28][1/13]   \tAcc: 0.875\tLabel_Loss: 0.3755\tTop_Loss: 0.4730\tBottom_Loss: 0.4485\tLoss: 1.2970\t\n",
      "Train:\tEpoch:[28][8/13]   \tAcc: 0.938\tLabel_Loss: 0.3444\tTop_Loss: 0.4880\tBottom_Loss: 0.3413\tLoss: 1.1737\t\n",
      "Subject: 17, n=31 | test_f1: 0.2735 |best_f1: 0.61538\n",
      "Train:\tEpoch:[29][1/13]   \tAcc: 0.812\tLabel_Loss: 0.3708\tTop_Loss: 0.5038\tBottom_Loss: 0.6092\tLoss: 1.4837\t\n",
      "Train:\tEpoch:[29][8/13]   \tAcc: 0.875\tLabel_Loss: 0.3322\tTop_Loss: 0.4388\tBottom_Loss: 0.3999\tLoss: 1.1710\t\n",
      "Subject: 17, n=31 | test_f1: 0.75376 |best_f1: 0.75376\n",
      "Train:\tEpoch:[30][1/13]   \tAcc: 0.750\tLabel_Loss: 0.4370\tTop_Loss: 0.6137\tBottom_Loss: 0.4362\tLoss: 1.4869\t\n",
      "Train:\tEpoch:[30][8/13]   \tAcc: 1.000\tLabel_Loss: 0.1869\tTop_Loss: 0.4865\tBottom_Loss: 0.2678\tLoss: 0.9412\t\n",
      "Subject: 17, n=31 | test_f1: 0.41473 |best_f1: 0.75376\n",
      "Train:\tEpoch:[31][1/13]   \tAcc: 0.875\tLabel_Loss: 0.2933\tTop_Loss: 0.4144\tBottom_Loss: 0.3626\tLoss: 1.0703\t\n",
      "Train:\tEpoch:[31][8/13]   \tAcc: 0.938\tLabel_Loss: 0.2904\tTop_Loss: 0.3651\tBottom_Loss: 0.4116\tLoss: 1.0671\t\n",
      "Subject: 17, n=31 | test_f1: 0.30741 |best_f1: 0.75376\n",
      "Train:\tEpoch:[32][1/13]   \tAcc: 0.719\tLabel_Loss: 0.4492\tTop_Loss: 0.5222\tBottom_Loss: 0.4283\tLoss: 1.3997\t\n",
      "Train:\tEpoch:[32][8/13]   \tAcc: 0.969\tLabel_Loss: 0.1737\tTop_Loss: 0.3037\tBottom_Loss: 0.3583\tLoss: 0.8356\t\n",
      "Subject: 17, n=31 | test_f1: 0.28401 |best_f1: 0.75376\n",
      "Train:\tEpoch:[33][1/13]   \tAcc: 0.906\tLabel_Loss: 0.2786\tTop_Loss: 0.3203\tBottom_Loss: 0.3031\tLoss: 0.9020\t\n",
      "Train:\tEpoch:[33][8/13]   \tAcc: 0.875\tLabel_Loss: 0.2849\tTop_Loss: 0.4504\tBottom_Loss: 0.3983\tLoss: 1.1335\t\n",
      "Subject: 17, n=31 | test_f1: 0.65143 |best_f1: 0.75376\n",
      "Train:\tEpoch:[34][1/13]   \tAcc: 0.875\tLabel_Loss: 0.3236\tTop_Loss: 0.6223\tBottom_Loss: 0.5406\tLoss: 1.4865\t\n",
      "Train:\tEpoch:[34][8/13]   \tAcc: 1.000\tLabel_Loss: 0.1934\tTop_Loss: 0.2465\tBottom_Loss: 0.3358\tLoss: 0.7757\t\n",
      "Subject: 17, n=31 | test_f1: 0.60284 |best_f1: 0.75376\n",
      "Train:\tEpoch:[35][1/13]   \tAcc: 0.938\tLabel_Loss: 0.2531\tTop_Loss: 0.3708\tBottom_Loss: 0.2578\tLoss: 0.8817\t\n",
      "Train:\tEpoch:[35][8/13]   \tAcc: 0.875\tLabel_Loss: 0.2839\tTop_Loss: 0.4087\tBottom_Loss: 0.3510\tLoss: 1.0436\t\n",
      "Subject: 17, n=31 | test_f1: 0.57778 |best_f1: 0.75376\n",
      "Train:\tEpoch:[36][1/13]   \tAcc: 0.906\tLabel_Loss: 0.3073\tTop_Loss: 0.4374\tBottom_Loss: 0.3908\tLoss: 1.1356\t\n",
      "Train:\tEpoch:[36][8/13]   \tAcc: 0.906\tLabel_Loss: 0.2435\tTop_Loss: 0.3597\tBottom_Loss: 0.3905\tLoss: 0.9938\t\n",
      "Subject: 17, n=31 | test_f1: 0.45714 |best_f1: 0.75376\n",
      "Train:\tEpoch:[37][1/13]   \tAcc: 0.875\tLabel_Loss: 0.3486\tTop_Loss: 0.5539\tBottom_Loss: 0.4502\tLoss: 1.3527\t\n",
      "Train:\tEpoch:[37][8/13]   \tAcc: 0.969\tLabel_Loss: 0.1826\tTop_Loss: 0.2419\tBottom_Loss: 0.3905\tLoss: 0.8149\t\n",
      "Subject: 17, n=31 | test_f1: 0.67273 |best_f1: 0.75376\n",
      "Train:\tEpoch:[38][1/13]   \tAcc: 0.938\tLabel_Loss: 0.2005\tTop_Loss: 0.2514\tBottom_Loss: 0.2571\tLoss: 0.7090\t\n",
      "Train:\tEpoch:[38][8/13]   \tAcc: 0.844\tLabel_Loss: 0.3417\tTop_Loss: 0.4628\tBottom_Loss: 0.4392\tLoss: 1.2437\t\n",
      "Subject: 17, n=31 | test_f1: 0.34709 |best_f1: 0.75376\n",
      "Train:\tEpoch:[39][1/13]   \tAcc: 1.000\tLabel_Loss: 0.1194\tTop_Loss: 0.2767\tBottom_Loss: 0.2039\tLoss: 0.6000\t\n",
      "Train:\tEpoch:[39][8/13]   \tAcc: 0.812\tLabel_Loss: 0.5133\tTop_Loss: 0.6202\tBottom_Loss: 0.6291\tLoss: 1.7626\t\n",
      "Subject: 17, n=31 | test_f1: 0.41354 |best_f1: 0.75376\n",
      "Train:\tEpoch:[40][1/13]   \tAcc: 0.906\tLabel_Loss: 0.2489\tTop_Loss: 0.3239\tBottom_Loss: 0.3501\tLoss: 0.9229\t\n",
      "Train:\tEpoch:[40][8/13]   \tAcc: 0.906\tLabel_Loss: 0.2518\tTop_Loss: 0.3189\tBottom_Loss: 0.4426\tLoss: 1.0133\t\n",
      "Subject: 17, n=31 | test_f1: 0.51542 |best_f1: 0.75376\n",
      "Train:\tEpoch:[41][1/13]   \tAcc: 1.000\tLabel_Loss: 0.1365\tTop_Loss: 0.2592\tBottom_Loss: 0.2375\tLoss: 0.6331\t\n",
      "Train:\tEpoch:[41][8/13]   \tAcc: 0.938\tLabel_Loss: 0.2312\tTop_Loss: 0.3175\tBottom_Loss: 0.3617\tLoss: 0.9104\t\n",
      "Subject: 17, n=31 | test_f1: 0.25397 |best_f1: 0.75376\n",
      "Train:\tEpoch:[42][1/13]   \tAcc: 0.938\tLabel_Loss: 0.1572\tTop_Loss: 0.2629\tBottom_Loss: 0.2426\tLoss: 0.6627\t\n",
      "Train:\tEpoch:[42][8/13]   \tAcc: 0.906\tLabel_Loss: 0.1842\tTop_Loss: 0.4050\tBottom_Loss: 0.2513\tLoss: 0.8405\t\n",
      "Subject: 17, n=31 | test_f1: 0.46174 |best_f1: 0.75376\n",
      "Train:\tEpoch:[43][1/13]   \tAcc: 0.938\tLabel_Loss: 0.1417\tTop_Loss: 0.2675\tBottom_Loss: 0.2694\tLoss: 0.6786\t\n",
      "Train:\tEpoch:[43][8/13]   \tAcc: 0.938\tLabel_Loss: 0.1576\tTop_Loss: 0.2846\tBottom_Loss: 0.2759\tLoss: 0.7181\t\n",
      "Subject: 17, n=31 | test_f1: 0.37207 |best_f1: 0.75376\n",
      "Train:\tEpoch:[44][1/13]   \tAcc: 0.969\tLabel_Loss: 0.1946\tTop_Loss: 0.3396\tBottom_Loss: 0.2088\tLoss: 0.7431\t\n",
      "Train:\tEpoch:[44][8/13]   \tAcc: 0.906\tLabel_Loss: 0.3636\tTop_Loss: 0.4468\tBottom_Loss: 0.3016\tLoss: 1.1121\t\n",
      "Subject: 17, n=31 | test_f1: 0.55991 |best_f1: 0.75376\n",
      "Train:\tEpoch:[45][1/13]   \tAcc: 0.969\tLabel_Loss: 0.1632\tTop_Loss: 0.2971\tBottom_Loss: 0.1284\tLoss: 0.5887\t\n",
      "Train:\tEpoch:[45][8/13]   \tAcc: 0.969\tLabel_Loss: 0.1440\tTop_Loss: 0.2648\tBottom_Loss: 0.2800\tLoss: 0.6887\t\n",
      "Subject: 17, n=31 | test_f1: 0.37198 |best_f1: 0.75376\n",
      "Train:\tEpoch:[46][1/13]   \tAcc: 1.000\tLabel_Loss: 0.1598\tTop_Loss: 0.2794\tBottom_Loss: 0.4118\tLoss: 0.8509\t\n",
      "Train:\tEpoch:[46][8/13]   \tAcc: 0.906\tLabel_Loss: 0.2262\tTop_Loss: 0.3425\tBottom_Loss: 0.4201\tLoss: 0.9887\t\n",
      "Subject: 17, n=31 | test_f1: 0.62828 |best_f1: 0.75376\n",
      "Train:\tEpoch:[47][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0991\tTop_Loss: 0.1863\tBottom_Loss: 0.1881\tLoss: 0.4735\t\n",
      "Train:\tEpoch:[47][8/13]   \tAcc: 0.906\tLabel_Loss: 0.3009\tTop_Loss: 0.3131\tBottom_Loss: 0.4904\tLoss: 1.1044\t\n",
      "Subject: 17, n=31 | test_f1: 0.29669 |best_f1: 0.75376\n",
      "Train:\tEpoch:[48][1/13]   \tAcc: 0.969\tLabel_Loss: 0.1043\tTop_Loss: 0.2464\tBottom_Loss: 0.1629\tLoss: 0.5136\t\n",
      "Train:\tEpoch:[48][8/13]   \tAcc: 0.969\tLabel_Loss: 0.1151\tTop_Loss: 0.2119\tBottom_Loss: 0.1816\tLoss: 0.5085\t\n",
      "Subject: 17, n=31 | test_f1: 0.30193 |best_f1: 0.75376\n",
      "Train:\tEpoch:[49][1/13]   \tAcc: 0.938\tLabel_Loss: 0.1899\tTop_Loss: 0.2191\tBottom_Loss: 0.1902\tLoss: 0.5992\t\n",
      "Train:\tEpoch:[49][8/13]   \tAcc: 1.000\tLabel_Loss: 0.1258\tTop_Loss: 0.3536\tBottom_Loss: 0.2419\tLoss: 0.7214\t\n",
      "Subject: 17, n=31 | test_f1: 0.33333 |best_f1: 0.75376\n",
      "Train:\tEpoch:[50][1/13]   \tAcc: 0.875\tLabel_Loss: 0.1908\tTop_Loss: 0.3851\tBottom_Loss: 0.2609\tLoss: 0.8369\t\n",
      "Train:\tEpoch:[50][8/13]   \tAcc: 0.969\tLabel_Loss: 0.1339\tTop_Loss: 0.1980\tBottom_Loss: 0.1361\tLoss: 0.4680\t\n",
      "Subject: 17, n=31 | test_f1: 0.52425 |best_f1: 0.75376\n",
      "Train:\tEpoch:[51][1/13]   \tAcc: 0.969\tLabel_Loss: 0.1238\tTop_Loss: 0.2071\tBottom_Loss: 0.2127\tLoss: 0.5435\t\n",
      "Train:\tEpoch:[51][8/13]   \tAcc: 0.969\tLabel_Loss: 0.1518\tTop_Loss: 0.2336\tBottom_Loss: 0.2339\tLoss: 0.6193\t\n",
      "Subject: 17, n=31 | test_f1: 0.44167 |best_f1: 0.75376\n",
      "Train:\tEpoch:[52][1/13]   \tAcc: 1.000\tLabel_Loss: 0.1033\tTop_Loss: 0.2040\tBottom_Loss: 0.1562\tLoss: 0.4635\t\n",
      "Train:\tEpoch:[52][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0647\tTop_Loss: 0.1489\tBottom_Loss: 0.1170\tLoss: 0.3305\t\n",
      "Subject: 17, n=31 | test_f1: 0.41812 |best_f1: 0.75376\n",
      "Train:\tEpoch:[53][1/13]   \tAcc: 0.938\tLabel_Loss: 0.1479\tTop_Loss: 0.2417\tBottom_Loss: 0.1932\tLoss: 0.5828\t\n",
      "Train:\tEpoch:[53][8/13]   \tAcc: 0.969\tLabel_Loss: 0.1180\tTop_Loss: 0.2366\tBottom_Loss: 0.2195\tLoss: 0.5742\t\n",
      "Subject: 17, n=31 | test_f1: 0.40544 |best_f1: 0.75376\n",
      "Train:\tEpoch:[54][1/13]   \tAcc: 0.969\tLabel_Loss: 0.1116\tTop_Loss: 0.1724\tBottom_Loss: 0.1584\tLoss: 0.4424\t\n",
      "Train:\tEpoch:[54][8/13]   \tAcc: 0.969\tLabel_Loss: 0.0807\tTop_Loss: 0.2255\tBottom_Loss: 0.1378\tLoss: 0.4440\t\n",
      "Subject: 17, n=31 | test_f1: 0.36667 |best_f1: 0.75376\n",
      "Train:\tEpoch:[55][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0483\tTop_Loss: 0.1234\tBottom_Loss: 0.0868\tLoss: 0.2586\t\n",
      "Train:\tEpoch:[55][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0631\tTop_Loss: 0.1342\tBottom_Loss: 0.1969\tLoss: 0.3941\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 17, n=31 | test_f1: 0.36643 |best_f1: 0.75376\n",
      "Train:\tEpoch:[56][1/13]   \tAcc: 0.969\tLabel_Loss: 0.0828\tTop_Loss: 0.1715\tBottom_Loss: 0.1603\tLoss: 0.4145\t\n",
      "Train:\tEpoch:[56][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0634\tTop_Loss: 0.1220\tBottom_Loss: 0.1286\tLoss: 0.3141\t\n",
      "Subject: 17, n=31 | test_f1: 0.55991 |best_f1: 0.75376\n",
      "Train:\tEpoch:[57][1/13]   \tAcc: 0.969\tLabel_Loss: 0.1169\tTop_Loss: 0.2018\tBottom_Loss: 0.1469\tLoss: 0.4656\t\n",
      "Train:\tEpoch:[57][8/13]   \tAcc: 0.875\tLabel_Loss: 0.2249\tTop_Loss: 0.2029\tBottom_Loss: 0.2462\tLoss: 0.6740\t\n",
      "Subject: 17, n=31 | test_f1: 0.5671 |best_f1: 0.75376\n",
      "Train:\tEpoch:[58][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0511\tTop_Loss: 0.1446\tBottom_Loss: 0.1396\tLoss: 0.3352\t\n",
      "Train:\tEpoch:[58][8/13]   \tAcc: 0.969\tLabel_Loss: 0.1283\tTop_Loss: 0.2505\tBottom_Loss: 0.2063\tLoss: 0.5851\t\n",
      "Subject: 17, n=31 | test_f1: 0.53617 |best_f1: 0.75376\n",
      "Train:\tEpoch:[59][1/13]   \tAcc: 0.938\tLabel_Loss: 0.1394\tTop_Loss: 0.1863\tBottom_Loss: 0.2465\tLoss: 0.5722\t\n",
      "Train:\tEpoch:[59][8/13]   \tAcc: 0.969\tLabel_Loss: 0.1164\tTop_Loss: 0.1818\tBottom_Loss: 0.1353\tLoss: 0.4335\t\n",
      "Subject: 17, n=31 | test_f1: 0.38889 |best_f1: 0.75376\n",
      "Train:\tEpoch:[60][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0808\tTop_Loss: 0.2731\tBottom_Loss: 0.1109\tLoss: 0.4648\t\n",
      "Train:\tEpoch:[60][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0504\tTop_Loss: 0.0847\tBottom_Loss: 0.1023\tLoss: 0.2374\t\n",
      "Subject: 17, n=31 | test_f1: 0.52795 |best_f1: 0.75376\n",
      "Train:\tEpoch:[61][1/13]   \tAcc: 0.969\tLabel_Loss: 0.1210\tTop_Loss: 0.1601\tBottom_Loss: 0.1594\tLoss: 0.4406\t\n",
      "Train:\tEpoch:[61][8/13]   \tAcc: 0.969\tLabel_Loss: 0.1467\tTop_Loss: 0.1701\tBottom_Loss: 0.3378\tLoss: 0.6546\t\n",
      "Subject: 17, n=31 | test_f1: 0.43333 |best_f1: 0.75376\n",
      "Train:\tEpoch:[62][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0207\tTop_Loss: 0.0831\tBottom_Loss: 0.0770\tLoss: 0.1809\t\n",
      "Train:\tEpoch:[62][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0386\tTop_Loss: 0.0907\tBottom_Loss: 0.0967\tLoss: 0.2260\t\n",
      "Subject: 17, n=31 | test_f1: 0.45238 |best_f1: 0.75376\n",
      "Train:\tEpoch:[63][1/13]   \tAcc: 0.969\tLabel_Loss: 0.0730\tTop_Loss: 0.1293\tBottom_Loss: 0.2280\tLoss: 0.4303\t\n",
      "Train:\tEpoch:[63][8/13]   \tAcc: 0.938\tLabel_Loss: 0.1179\tTop_Loss: 0.2249\tBottom_Loss: 0.1423\tLoss: 0.4851\t\n",
      "Subject: 17, n=31 | test_f1: 0.33638 |best_f1: 0.75376\n",
      "Train:\tEpoch:[64][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0320\tTop_Loss: 0.0819\tBottom_Loss: 0.0665\tLoss: 0.1804\t\n",
      "Train:\tEpoch:[64][8/13]   \tAcc: 0.969\tLabel_Loss: 0.0878\tTop_Loss: 0.0737\tBottom_Loss: 0.2021\tLoss: 0.3636\t\n",
      "Subject: 17, n=31 | test_f1: 0.35442 |best_f1: 0.75376\n",
      "Train:\tEpoch:[65][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0496\tTop_Loss: 0.0678\tBottom_Loss: 0.0854\tLoss: 0.2027\t\n",
      "Train:\tEpoch:[65][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0459\tTop_Loss: 0.1057\tBottom_Loss: 0.1094\tLoss: 0.2610\t\n",
      "Subject: 17, n=31 | test_f1: 0.36589 |best_f1: 0.75376\n",
      "Train:\tEpoch:[66][1/13]   \tAcc: 0.969\tLabel_Loss: 0.0971\tTop_Loss: 0.1922\tBottom_Loss: 0.1730\tLoss: 0.4624\t\n",
      "Train:\tEpoch:[66][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0283\tTop_Loss: 0.0780\tBottom_Loss: 0.0471\tLoss: 0.1534\t\n",
      "Subject: 17, n=31 | test_f1: 0.3396 |best_f1: 0.75376\n",
      "Train:\tEpoch:[67][1/13]   \tAcc: 0.969\tLabel_Loss: 0.0958\tTop_Loss: 0.2309\tBottom_Loss: 0.1614\tLoss: 0.4881\t\n",
      "Train:\tEpoch:[67][8/13]   \tAcc: 0.969\tLabel_Loss: 0.0705\tTop_Loss: 0.1210\tBottom_Loss: 0.1959\tLoss: 0.3874\t\n",
      "Subject: 17, n=31 | test_f1: 0.41852 |best_f1: 0.75376\n",
      "Train:\tEpoch:[68][1/13]   \tAcc: 0.969\tLabel_Loss: 0.0524\tTop_Loss: 0.1183\tBottom_Loss: 0.0874\tLoss: 0.2581\t\n",
      "Train:\tEpoch:[68][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0596\tTop_Loss: 0.0704\tBottom_Loss: 0.0699\tLoss: 0.2000\t\n",
      "Subject: 17, n=31 | test_f1: 0.41472 |best_f1: 0.75376\n",
      "Train:\tEpoch:[69][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0406\tTop_Loss: 0.1606\tBottom_Loss: 0.1525\tLoss: 0.3536\t\n",
      "Train:\tEpoch:[69][8/13]   \tAcc: 0.938\tLabel_Loss: 0.1268\tTop_Loss: 0.1460\tBottom_Loss: 0.1515\tLoss: 0.4243\t\n",
      "Subject: 17, n=31 | test_f1: 0.43617 |best_f1: 0.75376\n",
      "Train:\tEpoch:[70][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0421\tTop_Loss: 0.1169\tBottom_Loss: 0.0775\tLoss: 0.2364\t\n",
      "Train:\tEpoch:[70][8/13]   \tAcc: 0.969\tLabel_Loss: 0.0863\tTop_Loss: 0.1998\tBottom_Loss: 0.2407\tLoss: 0.5268\t\n",
      "Subject: 17, n=31 | test_f1: 0.45714 |best_f1: 0.75376\n",
      "Train:\tEpoch:[71][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0446\tTop_Loss: 0.1289\tBottom_Loss: 0.1328\tLoss: 0.3063\t\n",
      "Train:\tEpoch:[71][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0445\tTop_Loss: 0.1438\tBottom_Loss: 0.0917\tLoss: 0.2800\t\n",
      "Subject: 17, n=31 | test_f1: 0.67273 |best_f1: 0.75376\n",
      "Train:\tEpoch:[72][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0275\tTop_Loss: 0.0868\tBottom_Loss: 0.0923\tLoss: 0.2066\t\n",
      "Train:\tEpoch:[72][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0270\tTop_Loss: 0.0946\tBottom_Loss: 0.0855\tLoss: 0.2072\t\n",
      "Subject: 17, n=31 | test_f1: 0.59528 |best_f1: 0.75376\n",
      "Train:\tEpoch:[73][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0434\tTop_Loss: 0.1052\tBottom_Loss: 0.0669\tLoss: 0.2156\t\n",
      "Train:\tEpoch:[73][8/13]   \tAcc: 0.969\tLabel_Loss: 0.0889\tTop_Loss: 0.1241\tBottom_Loss: 0.0803\tLoss: 0.2933\t\n",
      "Subject: 17, n=31 | test_f1: 0.42051 |best_f1: 0.75376\n",
      "Train:\tEpoch:[74][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0198\tTop_Loss: 0.0451\tBottom_Loss: 0.0926\tLoss: 0.1575\t\n",
      "Train:\tEpoch:[74][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0511\tTop_Loss: 0.1146\tBottom_Loss: 0.0618\tLoss: 0.2276\t\n",
      "Subject: 17, n=31 | test_f1: 0.57941 |best_f1: 0.75376\n",
      "Train:\tEpoch:[75][1/13]   \tAcc: 0.969\tLabel_Loss: 0.1076\tTop_Loss: 0.1839\tBottom_Loss: 0.1811\tLoss: 0.4726\t\n",
      "Train:\tEpoch:[75][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0433\tTop_Loss: 0.0756\tBottom_Loss: 0.0674\tLoss: 0.1863\t\n",
      "Subject: 17, n=31 | test_f1: 0.30556 |best_f1: 0.75376\n",
      "Train:\tEpoch:[76][1/13]   \tAcc: 0.969\tLabel_Loss: 0.0449\tTop_Loss: 0.1020\tBottom_Loss: 0.0748\tLoss: 0.2217\t\n",
      "Train:\tEpoch:[76][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0512\tTop_Loss: 0.1250\tBottom_Loss: 0.0776\tLoss: 0.2538\t\n",
      "Subject: 17, n=31 | test_f1: 0.62121 |best_f1: 0.75376\n",
      "Train:\tEpoch:[77][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0273\tTop_Loss: 0.0970\tBottom_Loss: 0.0545\tLoss: 0.1788\t\n",
      "Train:\tEpoch:[77][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0142\tTop_Loss: 0.0278\tBottom_Loss: 0.0296\tLoss: 0.0716\t\n",
      "Subject: 17, n=31 | test_f1: 0.34161 |best_f1: 0.75376\n",
      "Train:\tEpoch:[78][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0661\tTop_Loss: 0.1219\tBottom_Loss: 0.0748\tLoss: 0.2628\t\n",
      "Train:\tEpoch:[78][8/13]   \tAcc: 0.969\tLabel_Loss: 0.0607\tTop_Loss: 0.1464\tBottom_Loss: 0.0894\tLoss: 0.2965\t\n",
      "Subject: 17, n=31 | test_f1: 0.44444 |best_f1: 0.75376\n",
      "Train:\tEpoch:[79][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0238\tTop_Loss: 0.0634\tBottom_Loss: 0.0500\tLoss: 0.1372\t\n",
      "Train:\tEpoch:[79][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0272\tTop_Loss: 0.1534\tBottom_Loss: 0.0842\tLoss: 0.2648\t\n",
      "Subject: 17, n=31 | test_f1: 0.81447 |best_f1: 0.81447\n",
      "Train:\tEpoch:[80][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0440\tTop_Loss: 0.0821\tBottom_Loss: 0.1001\tLoss: 0.2262\t\n",
      "Train:\tEpoch:[80][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0195\tTop_Loss: 0.0444\tBottom_Loss: 0.0304\tLoss: 0.0942\t\n",
      "Subject: 17, n=31 | test_f1: 0.36645 |best_f1: 0.81447\n",
      "Train:\tEpoch:[81][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0361\tTop_Loss: 0.0805\tBottom_Loss: 0.0629\tLoss: 0.1796\t\n",
      "Train:\tEpoch:[81][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0130\tTop_Loss: 0.0648\tBottom_Loss: 0.0539\tLoss: 0.1318\t\n",
      "Subject: 17, n=31 | test_f1: 0.37198 |best_f1: 0.81447\n",
      "Train:\tEpoch:[82][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0275\tTop_Loss: 0.0494\tBottom_Loss: 0.0765\tLoss: 0.1535\t\n",
      "Train:\tEpoch:[82][8/13]   \tAcc: 0.938\tLabel_Loss: 0.0626\tTop_Loss: 0.0671\tBottom_Loss: 0.0859\tLoss: 0.2156\t\n",
      "Subject: 17, n=31 | test_f1: 0.70963 |best_f1: 0.81447\n",
      "Train:\tEpoch:[83][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0103\tTop_Loss: 0.0375\tBottom_Loss: 0.0315\tLoss: 0.0793\t\n",
      "Train:\tEpoch:[83][8/13]   \tAcc: 0.969\tLabel_Loss: 0.0637\tTop_Loss: 0.0633\tBottom_Loss: 0.0963\tLoss: 0.2233\t\n",
      "Subject: 17, n=31 | test_f1: 0.42335 |best_f1: 0.81447\n",
      "Train:\tEpoch:[84][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0187\tTop_Loss: 0.0445\tBottom_Loss: 0.0790\tLoss: 0.1423\t\n",
      "Train:\tEpoch:[84][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0116\tTop_Loss: 0.0408\tBottom_Loss: 0.0244\tLoss: 0.0768\t\n",
      "Subject: 17, n=31 | test_f1: 0.38519 |best_f1: 0.81447\n",
      "Train:\tEpoch:[85][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0196\tTop_Loss: 0.0297\tBottom_Loss: 0.0341\tLoss: 0.0835\t\n",
      "Train:\tEpoch:[85][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0233\tTop_Loss: 0.0655\tBottom_Loss: 0.0728\tLoss: 0.1616\t\n",
      "Subject: 17, n=31 | test_f1: 0.4719 |best_f1: 0.81447\n",
      "Train:\tEpoch:[86][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0278\tTop_Loss: 0.0873\tBottom_Loss: 0.0734\tLoss: 0.1885\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[86][8/13]   \tAcc: 0.969\tLabel_Loss: 0.0845\tTop_Loss: 0.0804\tBottom_Loss: 0.0935\tLoss: 0.2584\t\n",
      "Subject: 17, n=31 | test_f1: 0.50997 |best_f1: 0.81447\n",
      "Train:\tEpoch:[87][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0178\tTop_Loss: 0.0551\tBottom_Loss: 0.0247\tLoss: 0.0977\t\n",
      "Train:\tEpoch:[87][8/13]   \tAcc: 0.969\tLabel_Loss: 0.0419\tTop_Loss: 0.1323\tBottom_Loss: 0.0313\tLoss: 0.2054\t\n",
      "Subject: 17, n=31 | test_f1: 0.43162 |best_f1: 0.81447\n",
      "Train:\tEpoch:[88][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0287\tTop_Loss: 0.0929\tBottom_Loss: 0.0654\tLoss: 0.1870\t\n",
      "Train:\tEpoch:[88][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0459\tTop_Loss: 0.0601\tBottom_Loss: 0.1205\tLoss: 0.2265\t\n",
      "Subject: 17, n=31 | test_f1: 0.39432 |best_f1: 0.81447\n",
      "Train:\tEpoch:[89][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0108\tTop_Loss: 0.0282\tBottom_Loss: 0.0235\tLoss: 0.0625\t\n",
      "Train:\tEpoch:[89][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0315\tTop_Loss: 0.0405\tBottom_Loss: 0.0588\tLoss: 0.1309\t\n",
      "Subject: 17, n=31 | test_f1: 0.45005 |best_f1: 0.81447\n",
      "Train:\tEpoch:[90][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0159\tTop_Loss: 0.0309\tBottom_Loss: 0.0353\tLoss: 0.0821\t\n",
      "Train:\tEpoch:[90][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0252\tTop_Loss: 0.0552\tBottom_Loss: 0.1112\tLoss: 0.1916\t\n",
      "Subject: 17, n=31 | test_f1: 0.42921 |best_f1: 0.81447\n",
      "Train:\tEpoch:[91][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0134\tTop_Loss: 0.0372\tBottom_Loss: 0.0534\tLoss: 0.1039\t\n",
      "Train:\tEpoch:[91][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0259\tTop_Loss: 0.0267\tBottom_Loss: 0.0529\tLoss: 0.1056\t\n",
      "Subject: 17, n=31 | test_f1: 0.43333 |best_f1: 0.81447\n",
      "Train:\tEpoch:[92][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0248\tTop_Loss: 0.0562\tBottom_Loss: 0.0365\tLoss: 0.1175\t\n",
      "Train:\tEpoch:[92][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0071\tTop_Loss: 0.0229\tBottom_Loss: 0.0336\tLoss: 0.0635\t\n",
      "Subject: 17, n=31 | test_f1: 0.42335 |best_f1: 0.81447\n",
      "Train:\tEpoch:[93][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0132\tTop_Loss: 0.0369\tBottom_Loss: 0.0518\tLoss: 0.1019\t\n",
      "Train:\tEpoch:[93][8/13]   \tAcc: 0.969\tLabel_Loss: 0.0422\tTop_Loss: 0.1457\tBottom_Loss: 0.0198\tLoss: 0.2077\t\n",
      "Subject: 17, n=31 | test_f1: 0.45964 |best_f1: 0.81447\n",
      "Train:\tEpoch:[94][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0045\tTop_Loss: 0.0227\tBottom_Loss: 0.0243\tLoss: 0.0515\t\n",
      "Train:\tEpoch:[94][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0062\tTop_Loss: 0.0187\tBottom_Loss: 0.0141\tLoss: 0.0389\t\n",
      "Subject: 17, n=31 | test_f1: 0.45714 |best_f1: 0.81447\n",
      "Train:\tEpoch:[95][1/13]   \tAcc: 0.969\tLabel_Loss: 0.2216\tTop_Loss: 0.1659\tBottom_Loss: 0.2166\tLoss: 0.6041\t\n",
      "Train:\tEpoch:[95][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0184\tTop_Loss: 0.0281\tBottom_Loss: 0.0525\tLoss: 0.0990\t\n",
      "Subject: 17, n=31 | test_f1: 0.5037 |best_f1: 0.81447\n",
      "Train:\tEpoch:[96][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0077\tTop_Loss: 0.0294\tBottom_Loss: 0.0201\tLoss: 0.0572\t\n",
      "Train:\tEpoch:[96][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0229\tTop_Loss: 0.0642\tBottom_Loss: 0.0453\tLoss: 0.1324\t\n",
      "Subject: 17, n=31 | test_f1: 0.6 |best_f1: 0.81447\n",
      "Train:\tEpoch:[97][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0258\tTop_Loss: 0.0404\tBottom_Loss: 0.0441\tLoss: 0.1102\t\n",
      "Train:\tEpoch:[97][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0074\tTop_Loss: 0.0266\tBottom_Loss: 0.0191\tLoss: 0.0531\t\n",
      "Subject: 17, n=31 | test_f1: 0.49679 |best_f1: 0.81447\n",
      "Train:\tEpoch:[98][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0141\tTop_Loss: 0.0211\tBottom_Loss: 0.0257\tLoss: 0.0608\t\n",
      "Train:\tEpoch:[98][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0170\tTop_Loss: 0.0504\tBottom_Loss: 0.0227\tLoss: 0.0901\t\n",
      "Subject: 17, n=31 | test_f1: 0.42921 |best_f1: 0.81447\n",
      "Train:\tEpoch:[99][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0142\tTop_Loss: 0.0214\tBottom_Loss: 0.0217\tLoss: 0.0573\t\n",
      "Train:\tEpoch:[99][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0091\tTop_Loss: 0.0330\tBottom_Loss: 0.0188\tLoss: 0.0608\t\n",
      "Subject: 17, n=31 | test_f1: 0.58225 |best_f1: 0.81447\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.531\tLabel_Loss: 0.9706\tTop_Loss: 1.5149\tBottom_Loss: 1.5469\tLoss: 4.0325\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.594\tLabel_Loss: 1.0824\tTop_Loss: 1.0870\tBottom_Loss: 1.0901\tLoss: 3.2596\t\n",
      "Subject: 19, n=11 | test_f1: 0.2619 |best_f1: 0.2619\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.625\tLabel_Loss: 0.9236\tTop_Loss: 1.1011\tBottom_Loss: 1.0205\tLoss: 3.0452\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.594\tLabel_Loss: 1.0315\tTop_Loss: 0.9076\tBottom_Loss: 1.0096\tLoss: 2.9487\t\n",
      "Subject: 19, n=11 | test_f1: 0.53333 |best_f1: 0.53333\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.531\tLabel_Loss: 1.0412\tTop_Loss: 0.9306\tBottom_Loss: 1.0347\tLoss: 3.0065\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.469\tLabel_Loss: 0.9380\tTop_Loss: 0.9259\tBottom_Loss: 0.7579\tLoss: 2.6218\t\n",
      "Subject: 19, n=11 | test_f1: 0.26496 |best_f1: 0.53333\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.500\tLabel_Loss: 1.0713\tTop_Loss: 1.0263\tBottom_Loss: 1.0484\tLoss: 3.1459\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.406\tLabel_Loss: 1.0765\tTop_Loss: 1.0695\tBottom_Loss: 1.0965\tLoss: 3.2424\t\n",
      "Subject: 19, n=11 | test_f1: 0.14286 |best_f1: 0.53333\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.750\tLabel_Loss: 0.7295\tTop_Loss: 0.9927\tBottom_Loss: 0.9763\tLoss: 2.6985\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.438\tLabel_Loss: 0.8949\tTop_Loss: 0.9039\tBottom_Loss: 0.9809\tLoss: 2.7797\t\n",
      "Subject: 19, n=11 | test_f1: 0.14286 |best_f1: 0.53333\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7555\tTop_Loss: 0.8477\tBottom_Loss: 0.6560\tLoss: 2.2593\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8732\tTop_Loss: 0.8349\tBottom_Loss: 0.9379\tLoss: 2.6459\t\n",
      "Subject: 19, n=11 | test_f1: 0.46667 |best_f1: 0.53333\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.500\tLabel_Loss: 1.0434\tTop_Loss: 1.0250\tBottom_Loss: 1.1803\tLoss: 3.2487\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.719\tLabel_Loss: 0.7134\tTop_Loss: 0.7381\tBottom_Loss: 0.8582\tLoss: 2.3096\t\n",
      "Subject: 19, n=11 | test_f1: 0.14286 |best_f1: 0.53333\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.531\tLabel_Loss: 0.9248\tTop_Loss: 1.0158\tBottom_Loss: 0.8552\tLoss: 2.7958\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7024\tTop_Loss: 0.7868\tBottom_Loss: 0.7016\tLoss: 2.1907\t\n",
      "Subject: 19, n=11 | test_f1: 0.44444 |best_f1: 0.53333\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7318\tTop_Loss: 0.7854\tBottom_Loss: 0.6386\tLoss: 2.1558\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8490\tTop_Loss: 0.7509\tBottom_Loss: 0.7405\tLoss: 2.3404\t\n",
      "Subject: 19, n=11 | test_f1: 0.28788 |best_f1: 0.53333\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.594\tLabel_Loss: 0.7475\tTop_Loss: 0.8221\tBottom_Loss: 0.7130\tLoss: 2.2826\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6774\tTop_Loss: 0.8898\tBottom_Loss: 0.8580\tLoss: 2.4252\t\n",
      "Subject: 19, n=11 | test_f1: 0.14286 |best_f1: 0.53333\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.750\tLabel_Loss: 0.7683\tTop_Loss: 0.8465\tBottom_Loss: 0.8656\tLoss: 2.4804\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.719\tLabel_Loss: 0.7048\tTop_Loss: 0.7312\tBottom_Loss: 0.9336\tLoss: 2.3697\t\n",
      "Subject: 19, n=11 | test_f1: 0.66017 |best_f1: 0.66017\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6924\tTop_Loss: 0.8236\tBottom_Loss: 0.7847\tLoss: 2.3007\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.656\tLabel_Loss: 0.6365\tTop_Loss: 0.6413\tBottom_Loss: 0.6523\tLoss: 1.9302\t\n",
      "Subject: 19, n=11 | test_f1: 0.37229 |best_f1: 0.66017\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7938\tTop_Loss: 0.7282\tBottom_Loss: 0.6628\tLoss: 2.1848\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.656\tLabel_Loss: 0.8010\tTop_Loss: 0.8196\tBottom_Loss: 0.7915\tLoss: 2.4120\t\n",
      "Subject: 19, n=11 | test_f1: 0.43182 |best_f1: 0.66017\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5079\tTop_Loss: 0.6470\tBottom_Loss: 0.6472\tLoss: 1.8022\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.781\tLabel_Loss: 0.7564\tTop_Loss: 0.8934\tBottom_Loss: 0.6810\tLoss: 2.3308\t\n",
      "Subject: 19, n=11 | test_f1: 0.26496 |best_f1: 0.66017\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5606\tTop_Loss: 0.6082\tBottom_Loss: 0.5736\tLoss: 1.7424\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.719\tLabel_Loss: 0.8737\tTop_Loss: 1.1702\tBottom_Loss: 0.8706\tLoss: 2.9144\t\n",
      "Subject: 19, n=11 | test_f1: 0.26496 |best_f1: 0.66017\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7012\tTop_Loss: 0.7581\tBottom_Loss: 0.9883\tLoss: 2.4476\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5075\tTop_Loss: 0.5473\tBottom_Loss: 0.5728\tLoss: 1.6276\t\n",
      "Subject: 19, n=11 | test_f1: 0.53896 |best_f1: 0.66017\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5626\tTop_Loss: 0.5759\tBottom_Loss: 0.6352\tLoss: 1.7737\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.594\tLabel_Loss: 0.9085\tTop_Loss: 0.8743\tBottom_Loss: 0.9639\tLoss: 2.7467\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 19, n=11 | test_f1: 0.27778 |best_f1: 0.66017\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3907\tTop_Loss: 0.5290\tBottom_Loss: 0.5035\tLoss: 1.4232\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5045\tTop_Loss: 0.5797\tBottom_Loss: 0.6257\tLoss: 1.7099\t\n",
      "Subject: 19, n=11 | test_f1: 0.72222 |best_f1: 0.72222\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4059\tTop_Loss: 0.5945\tBottom_Loss: 0.5570\tLoss: 1.5573\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4803\tTop_Loss: 0.6828\tBottom_Loss: 0.4842\tLoss: 1.6473\t\n",
      "Subject: 19, n=11 | test_f1: 0.65714 |best_f1: 0.72222\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3383\tTop_Loss: 0.6255\tBottom_Loss: 0.4495\tLoss: 1.4133\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7932\tTop_Loss: 1.1159\tBottom_Loss: 0.6145\tLoss: 2.5236\t\n",
      "Subject: 19, n=11 | test_f1: 0.27778 |best_f1: 0.72222\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5875\tTop_Loss: 0.6153\tBottom_Loss: 0.8593\tLoss: 2.0622\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4217\tTop_Loss: 0.5272\tBottom_Loss: 0.5282\tLoss: 1.4771\t\n",
      "Subject: 19, n=11 | test_f1: 0.61667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4605\tTop_Loss: 0.4962\tBottom_Loss: 0.5505\tLoss: 1.5072\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4695\tTop_Loss: 0.7037\tBottom_Loss: 0.5631\tLoss: 1.7362\t\n",
      "Subject: 19, n=11 | test_f1: 0.35714 |best_f1: 0.72222\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4557\tTop_Loss: 0.5845\tBottom_Loss: 0.5420\tLoss: 1.5822\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5820\tTop_Loss: 0.8232\tBottom_Loss: 0.6239\tLoss: 2.0292\t\n",
      "Subject: 19, n=11 | test_f1: 0.43182 |best_f1: 0.72222\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.781\tLabel_Loss: 0.3969\tTop_Loss: 0.6626\tBottom_Loss: 0.5442\tLoss: 1.6036\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3389\tTop_Loss: 0.5313\tBottom_Loss: 0.4528\tLoss: 1.3229\t\n",
      "Subject: 19, n=11 | test_f1: 0.35714 |best_f1: 0.72222\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.812\tLabel_Loss: 0.6039\tTop_Loss: 0.6794\tBottom_Loss: 0.7715\tLoss: 2.0548\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.750\tLabel_Loss: 0.4837\tTop_Loss: 0.5664\tBottom_Loss: 0.5884\tLoss: 1.6385\t\n",
      "Subject: 19, n=11 | test_f1: 0.14286 |best_f1: 0.72222\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3441\tTop_Loss: 0.5266\tBottom_Loss: 0.5176\tLoss: 1.3884\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3534\tTop_Loss: 0.4322\tBottom_Loss: 0.4507\tLoss: 1.2363\t\n",
      "Subject: 19, n=11 | test_f1: 0.53704 |best_f1: 0.72222\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.781\tLabel_Loss: 0.6495\tTop_Loss: 0.7489\tBottom_Loss: 0.5689\tLoss: 1.9674\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4104\tTop_Loss: 0.5803\tBottom_Loss: 0.5980\tLoss: 1.5886\t\n",
      "Subject: 19, n=11 | test_f1: 0.61667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4352\tTop_Loss: 0.5159\tBottom_Loss: 0.6404\tLoss: 1.5915\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4230\tTop_Loss: 0.5260\tBottom_Loss: 0.4696\tLoss: 1.4185\t\n",
      "Subject: 19, n=11 | test_f1: 0.26496 |best_f1: 0.72222\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3496\tTop_Loss: 0.4592\tBottom_Loss: 0.4215\tLoss: 1.2304\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4162\tTop_Loss: 0.5202\tBottom_Loss: 0.3627\tLoss: 1.2992\t\n",
      "Subject: 19, n=11 | test_f1: 0.53896 |best_f1: 0.72222\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3538\tTop_Loss: 0.4574\tBottom_Loss: 0.5711\tLoss: 1.3823\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3715\tTop_Loss: 0.4004\tBottom_Loss: 0.5620\tLoss: 1.3339\t\n",
      "Subject: 19, n=11 | test_f1: 0.35714 |best_f1: 0.72222\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2794\tTop_Loss: 0.3298\tBottom_Loss: 0.4486\tLoss: 1.0579\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5894\tTop_Loss: 0.7652\tBottom_Loss: 0.7008\tLoss: 2.0554\t\n",
      "Subject: 19, n=11 | test_f1: 0.35714 |best_f1: 0.72222\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3137\tTop_Loss: 0.4119\tBottom_Loss: 0.4848\tLoss: 1.2104\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3333\tTop_Loss: 0.5707\tBottom_Loss: 0.4230\tLoss: 1.3271\t\n",
      "Subject: 19, n=11 | test_f1: 0.53333 |best_f1: 0.72222\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3806\tTop_Loss: 0.3898\tBottom_Loss: 0.5042\tLoss: 1.2746\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2064\tTop_Loss: 0.4542\tBottom_Loss: 0.3200\tLoss: 0.9806\t\n",
      "Subject: 19, n=11 | test_f1: 0.35714 |best_f1: 0.72222\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2794\tTop_Loss: 0.3808\tBottom_Loss: 0.4333\tLoss: 1.0936\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1623\tTop_Loss: 0.2816\tBottom_Loss: 0.3034\tLoss: 0.7473\t\n",
      "Subject: 19, n=11 | test_f1: 0.4963 |best_f1: 0.72222\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2965\tTop_Loss: 0.5299\tBottom_Loss: 0.2766\tLoss: 1.1029\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3632\tTop_Loss: 0.6001\tBottom_Loss: 0.5714\tLoss: 1.5347\t\n",
      "Subject: 19, n=11 | test_f1: 0.47222 |best_f1: 0.72222\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1946\tTop_Loss: 0.3078\tBottom_Loss: 0.3128\tLoss: 0.8152\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2973\tTop_Loss: 0.4125\tBottom_Loss: 0.4229\tLoss: 1.1327\t\n",
      "Subject: 19, n=11 | test_f1: 0.52222 |best_f1: 0.72222\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1773\tTop_Loss: 0.3012\tBottom_Loss: 0.2000\tLoss: 0.6784\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2814\tTop_Loss: 0.5158\tBottom_Loss: 0.2779\tLoss: 1.0750\t\n",
      "Subject: 19, n=11 | test_f1: 0.53333 |best_f1: 0.72222\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.844\tLabel_Loss: 0.2754\tTop_Loss: 0.4303\tBottom_Loss: 0.2905\tLoss: 0.9962\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2281\tTop_Loss: 0.4161\tBottom_Loss: 0.2663\tLoss: 0.9105\t\n",
      "Subject: 19, n=11 | test_f1: 0.43182 |best_f1: 0.72222\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2884\tTop_Loss: 0.4134\tBottom_Loss: 0.3444\tLoss: 1.0462\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2737\tTop_Loss: 0.4816\tBottom_Loss: 0.4024\tLoss: 1.1577\t\n",
      "Subject: 19, n=11 | test_f1: 0.45 |best_f1: 0.72222\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1843\tTop_Loss: 0.4462\tBottom_Loss: 0.1778\tLoss: 0.8083\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1621\tTop_Loss: 0.3148\tBottom_Loss: 0.3668\tLoss: 0.8436\t\n",
      "Subject: 19, n=11 | test_f1: 0.34815 |best_f1: 0.72222\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1946\tTop_Loss: 0.1992\tBottom_Loss: 0.2061\tLoss: 0.5998\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1908\tTop_Loss: 0.2952\tBottom_Loss: 0.3241\tLoss: 0.8101\t\n",
      "Subject: 19, n=11 | test_f1: 0.61667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2799\tTop_Loss: 0.6797\tBottom_Loss: 0.3419\tLoss: 1.3014\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1597\tTop_Loss: 0.4022\tBottom_Loss: 0.2060\tLoss: 0.7679\t\n",
      "Subject: 19, n=11 | test_f1: 0.14286 |best_f1: 0.72222\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1244\tTop_Loss: 0.2728\tBottom_Loss: 0.2186\tLoss: 0.6157\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2262\tTop_Loss: 0.3077\tBottom_Loss: 0.3808\tLoss: 0.9147\t\n",
      "Subject: 19, n=11 | test_f1: 0.52222 |best_f1: 0.72222\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2658\tTop_Loss: 0.4029\tBottom_Loss: 0.3313\tLoss: 1.0000\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.812\tLabel_Loss: 0.2882\tTop_Loss: 0.3956\tBottom_Loss: 0.2655\tLoss: 0.9494\t\n",
      "Subject: 19, n=11 | test_f1: 0.26496 |best_f1: 0.72222\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0934\tTop_Loss: 0.2239\tBottom_Loss: 0.1794\tLoss: 0.4968\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1318\tTop_Loss: 0.3334\tBottom_Loss: 0.2413\tLoss: 0.7065\t\n",
      "Subject: 19, n=11 | test_f1: 0.35714 |best_f1: 0.72222\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2657\tTop_Loss: 0.3517\tBottom_Loss: 0.3259\tLoss: 0.9433\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3116\tTop_Loss: 0.3598\tBottom_Loss: 0.4625\tLoss: 1.1338\t\n",
      "Subject: 19, n=11 | test_f1: 0.53896 |best_f1: 0.72222\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1498\tTop_Loss: 0.3182\tBottom_Loss: 0.2049\tLoss: 0.6729\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0734\tTop_Loss: 0.2099\tBottom_Loss: 0.2570\tLoss: 0.5402\t\n",
      "Subject: 19, n=11 | test_f1: 0.61667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1387\tTop_Loss: 0.3048\tBottom_Loss: 0.1562\tLoss: 0.5997\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1797\tTop_Loss: 0.3733\tBottom_Loss: 0.1909\tLoss: 0.7439\t\n",
      "Subject: 19, n=11 | test_f1: 0.63095 |best_f1: 0.72222\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1340\tTop_Loss: 0.3156\tBottom_Loss: 0.2417\tLoss: 0.6913\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1146\tTop_Loss: 0.2646\tBottom_Loss: 0.1855\tLoss: 0.5646\t\n",
      "Subject: 19, n=11 | test_f1: 0.52222 |best_f1: 0.72222\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1775\tTop_Loss: 0.3202\tBottom_Loss: 0.2284\tLoss: 0.7261\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1658\tTop_Loss: 0.2355\tBottom_Loss: 0.3540\tLoss: 0.7553\t\n",
      "Subject: 19, n=11 | test_f1: 0.73889 |best_f1: 0.73889\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0866\tTop_Loss: 0.2322\tBottom_Loss: 0.1189\tLoss: 0.4376\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1106\tTop_Loss: 0.2637\tBottom_Loss: 0.1303\tLoss: 0.5046\t\n",
      "Subject: 19, n=11 | test_f1: 0.26496 |best_f1: 0.73889\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0717\tTop_Loss: 0.1445\tBottom_Loss: 0.1545\tLoss: 0.3706\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1497\tTop_Loss: 0.2377\tBottom_Loss: 0.2441\tLoss: 0.6315\t\n",
      "Subject: 19, n=11 | test_f1: 0.43182 |best_f1: 0.73889\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0502\tTop_Loss: 0.1990\tBottom_Loss: 0.2216\tLoss: 0.4708\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0832\tTop_Loss: 0.2591\tBottom_Loss: 0.1757\tLoss: 0.5181\t\n",
      "Subject: 19, n=11 | test_f1: 0.4963 |best_f1: 0.73889\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0519\tTop_Loss: 0.1128\tBottom_Loss: 0.1684\tLoss: 0.3330\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1996\tTop_Loss: 0.4098\tBottom_Loss: 0.2805\tLoss: 0.8899\t\n",
      "Subject: 19, n=11 | test_f1: 0.53896 |best_f1: 0.73889\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1475\tTop_Loss: 0.2726\tBottom_Loss: 0.2087\tLoss: 0.6288\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1016\tTop_Loss: 0.1849\tBottom_Loss: 0.1434\tLoss: 0.4299\t\n",
      "Subject: 19, n=11 | test_f1: 0.61667 |best_f1: 0.73889\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2074\tTop_Loss: 0.4570\tBottom_Loss: 0.1839\tLoss: 0.8483\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0596\tTop_Loss: 0.1441\tBottom_Loss: 0.1604\tLoss: 0.3641\t\n",
      "Subject: 19, n=11 | test_f1: 0.46667 |best_f1: 0.73889\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1013\tTop_Loss: 0.2052\tBottom_Loss: 0.2038\tLoss: 0.5103\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1026\tTop_Loss: 0.1854\tBottom_Loss: 0.1872\tLoss: 0.4752\t\n",
      "Subject: 19, n=11 | test_f1: 0.65714 |best_f1: 0.73889\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0290\tTop_Loss: 0.1216\tBottom_Loss: 0.0663\tLoss: 0.2168\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0521\tTop_Loss: 0.1939\tBottom_Loss: 0.1254\tLoss: 0.3714\t\n",
      "Subject: 19, n=11 | test_f1: 0.44444 |best_f1: 0.73889\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0406\tTop_Loss: 0.2360\tBottom_Loss: 0.0723\tLoss: 0.3490\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1585\tTop_Loss: 0.3453\tBottom_Loss: 0.1467\tLoss: 0.6506\t\n",
      "Subject: 19, n=11 | test_f1: 0.52381 |best_f1: 0.73889\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0709\tTop_Loss: 0.1432\tBottom_Loss: 0.1511\tLoss: 0.3652\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0300\tTop_Loss: 0.1433\tBottom_Loss: 0.0733\tLoss: 0.2467\t\n",
      "Subject: 19, n=11 | test_f1: 0.4963 |best_f1: 0.73889\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0657\tTop_Loss: 0.1554\tBottom_Loss: 0.1016\tLoss: 0.3226\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1928\tTop_Loss: 0.3391\tBottom_Loss: 0.1849\tLoss: 0.7168\t\n",
      "Subject: 19, n=11 | test_f1: 0.53148 |best_f1: 0.73889\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0711\tTop_Loss: 0.1336\tBottom_Loss: 0.1421\tLoss: 0.3467\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0322\tTop_Loss: 0.1571\tBottom_Loss: 0.0619\tLoss: 0.2513\t\n",
      "Subject: 19, n=11 | test_f1: 0.5596 |best_f1: 0.73889\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1541\tTop_Loss: 0.1316\tBottom_Loss: 0.1838\tLoss: 0.4695\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0531\tTop_Loss: 0.1619\tBottom_Loss: 0.0895\tLoss: 0.3045\t\n",
      "Subject: 19, n=11 | test_f1: 0.52381 |best_f1: 0.73889\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0492\tTop_Loss: 0.1484\tBottom_Loss: 0.0646\tLoss: 0.2622\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0556\tTop_Loss: 0.1861\tBottom_Loss: 0.0935\tLoss: 0.3352\t\n",
      "Subject: 19, n=11 | test_f1: 0.61667 |best_f1: 0.73889\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0480\tTop_Loss: 0.1060\tBottom_Loss: 0.0781\tLoss: 0.2320\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0967\tTop_Loss: 0.2387\tBottom_Loss: 0.1449\tLoss: 0.4803\t\n",
      "Subject: 19, n=11 | test_f1: 0.61667 |best_f1: 0.73889\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0446\tTop_Loss: 0.1096\tBottom_Loss: 0.1140\tLoss: 0.2682\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0472\tTop_Loss: 0.2097\tBottom_Loss: 0.0755\tLoss: 0.3323\t\n",
      "Subject: 19, n=11 | test_f1: 0.42222 |best_f1: 0.73889\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0719\tTop_Loss: 0.1608\tBottom_Loss: 0.1505\tLoss: 0.3832\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0313\tTop_Loss: 0.1442\tBottom_Loss: 0.1239\tLoss: 0.2994\t\n",
      "Subject: 19, n=11 | test_f1: 0.26496 |best_f1: 0.73889\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0531\tTop_Loss: 0.1701\tBottom_Loss: 0.0547\tLoss: 0.2780\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0689\tTop_Loss: 0.1733\tBottom_Loss: 0.0882\tLoss: 0.3304\t\n",
      "Subject: 19, n=11 | test_f1: 0.43182 |best_f1: 0.73889\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0273\tTop_Loss: 0.0996\tBottom_Loss: 0.1027\tLoss: 0.2296\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0260\tTop_Loss: 0.0775\tBottom_Loss: 0.0527\tLoss: 0.1562\t\n",
      "Subject: 19, n=11 | test_f1: 0.61667 |best_f1: 0.73889\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1823\tTop_Loss: 0.2679\tBottom_Loss: 0.1809\tLoss: 0.6312\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0298\tTop_Loss: 0.0556\tBottom_Loss: 0.0635\tLoss: 0.1489\t\n",
      "Subject: 19, n=11 | test_f1: 0.35714 |best_f1: 0.73889\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0615\tTop_Loss: 0.2039\tBottom_Loss: 0.1723\tLoss: 0.4377\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0221\tTop_Loss: 0.0828\tBottom_Loss: 0.0662\tLoss: 0.1711\t\n",
      "Subject: 19, n=11 | test_f1: 0.35556 |best_f1: 0.73889\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0396\tTop_Loss: 0.0883\tBottom_Loss: 0.1120\tLoss: 0.2399\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0397\tTop_Loss: 0.0951\tBottom_Loss: 0.0724\tLoss: 0.2072\t\n",
      "Subject: 19, n=11 | test_f1: 0.43182 |best_f1: 0.73889\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0487\tTop_Loss: 0.1071\tBottom_Loss: 0.0608\tLoss: 0.2166\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0292\tTop_Loss: 0.0995\tBottom_Loss: 0.0700\tLoss: 0.1986\t\n",
      "Subject: 19, n=11 | test_f1: 0.52381 |best_f1: 0.73889\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0342\tTop_Loss: 0.0992\tBottom_Loss: 0.0600\tLoss: 0.1933\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0512\tTop_Loss: 0.1218\tBottom_Loss: 0.0801\tLoss: 0.2531\t\n",
      "Subject: 19, n=11 | test_f1: 0.43182 |best_f1: 0.73889\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0876\tTop_Loss: 0.2059\tBottom_Loss: 0.1465\tLoss: 0.4400\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0707\tTop_Loss: 0.1212\tBottom_Loss: 0.0889\tLoss: 0.2808\t\n",
      "Subject: 19, n=11 | test_f1: 0.53148 |best_f1: 0.73889\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0273\tTop_Loss: 0.0886\tBottom_Loss: 0.0603\tLoss: 0.1761\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0785\tTop_Loss: 0.1677\tBottom_Loss: 0.0510\tLoss: 0.2972\t\n",
      "Subject: 19, n=11 | test_f1: 0.35714 |best_f1: 0.73889\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0207\tTop_Loss: 0.0376\tBottom_Loss: 0.0364\tLoss: 0.0947\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0309\tTop_Loss: 0.1310\tBottom_Loss: 0.0537\tLoss: 0.2156\t\n",
      "Subject: 19, n=11 | test_f1: 0.61667 |best_f1: 0.73889\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0159\tTop_Loss: 0.0420\tBottom_Loss: 0.0391\tLoss: 0.0970\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0248\tTop_Loss: 0.0776\tBottom_Loss: 0.0405\tLoss: 0.1429\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 19, n=11 | test_f1: 0.53896 |best_f1: 0.73889\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1016\tTop_Loss: 0.1865\tBottom_Loss: 0.1458\tLoss: 0.4339\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0299\tTop_Loss: 0.1153\tBottom_Loss: 0.0866\tLoss: 0.2317\t\n",
      "Subject: 19, n=11 | test_f1: 0.45 |best_f1: 0.73889\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0381\tTop_Loss: 0.0807\tBottom_Loss: 0.0715\tLoss: 0.1903\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0357\tTop_Loss: 0.1088\tBottom_Loss: 0.0585\tLoss: 0.2029\t\n",
      "Subject: 19, n=11 | test_f1: 0.72222 |best_f1: 0.73889\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0475\tTop_Loss: 0.1899\tBottom_Loss: 0.0531\tLoss: 0.2905\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0259\tTop_Loss: 0.0649\tBottom_Loss: 0.0360\tLoss: 0.1268\t\n",
      "Subject: 19, n=11 | test_f1: 0.27778 |best_f1: 0.73889\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0107\tTop_Loss: 0.0273\tBottom_Loss: 0.0274\tLoss: 0.0654\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0177\tTop_Loss: 0.0779\tBottom_Loss: 0.0308\tLoss: 0.1263\t\n",
      "Subject: 19, n=11 | test_f1: 0.52381 |best_f1: 0.73889\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0300\tTop_Loss: 0.0861\tBottom_Loss: 0.0420\tLoss: 0.1581\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0299\tTop_Loss: 0.0787\tBottom_Loss: 0.0476\tLoss: 0.1562\t\n",
      "Subject: 19, n=11 | test_f1: 0.35714 |best_f1: 0.73889\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0254\tTop_Loss: 0.0971\tBottom_Loss: 0.0762\tLoss: 0.1987\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0382\tTop_Loss: 0.1686\tBottom_Loss: 0.0577\tLoss: 0.2645\t\n",
      "Subject: 19, n=11 | test_f1: 0.35714 |best_f1: 0.73889\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0334\tTop_Loss: 0.1014\tBottom_Loss: 0.0538\tLoss: 0.1886\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0636\tTop_Loss: 0.1383\tBottom_Loss: 0.1077\tLoss: 0.3095\t\n",
      "Subject: 19, n=11 | test_f1: 0.5963 |best_f1: 0.73889\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1683\tTop_Loss: 0.1775\tBottom_Loss: 0.3212\tLoss: 0.6670\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0101\tTop_Loss: 0.0381\tBottom_Loss: 0.0364\tLoss: 0.0846\t\n",
      "Subject: 19, n=11 | test_f1: 0.43182 |best_f1: 0.73889\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0420\tTop_Loss: 0.0678\tBottom_Loss: 0.1033\tLoss: 0.2131\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0359\tTop_Loss: 0.1138\tBottom_Loss: 0.0484\tLoss: 0.1981\t\n",
      "Subject: 19, n=11 | test_f1: 0.26496 |best_f1: 0.73889\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0098\tTop_Loss: 0.0510\tBottom_Loss: 0.0233\tLoss: 0.0841\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0164\tTop_Loss: 0.0781\tBottom_Loss: 0.0327\tLoss: 0.1272\t\n",
      "Subject: 19, n=11 | test_f1: 0.44444 |best_f1: 0.73889\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0117\tTop_Loss: 0.0274\tBottom_Loss: 0.0671\tLoss: 0.1062\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0651\tTop_Loss: 0.1878\tBottom_Loss: 0.0829\tLoss: 0.3358\t\n",
      "Subject: 19, n=11 | test_f1: 0.35714 |best_f1: 0.73889\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0092\tTop_Loss: 0.0172\tBottom_Loss: 0.0252\tLoss: 0.0516\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0266\tTop_Loss: 0.0460\tBottom_Loss: 0.0780\tLoss: 0.1507\t\n",
      "Subject: 19, n=11 | test_f1: 0.26496 |best_f1: 0.73889\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0136\tTop_Loss: 0.0351\tBottom_Loss: 0.0317\tLoss: 0.0804\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0165\tTop_Loss: 0.0276\tBottom_Loss: 0.0373\tLoss: 0.0814\t\n",
      "Subject: 19, n=11 | test_f1: 0.35714 |best_f1: 0.73889\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0095\tTop_Loss: 0.0342\tBottom_Loss: 0.0263\tLoss: 0.0700\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0076\tTop_Loss: 0.0331\tBottom_Loss: 0.0322\tLoss: 0.0729\t\n",
      "Subject: 19, n=11 | test_f1: 0.37229 |best_f1: 0.73889\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0111\tTop_Loss: 0.0224\tBottom_Loss: 0.0789\tLoss: 0.1123\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0444\tTop_Loss: 0.0694\tBottom_Loss: 0.0445\tLoss: 0.1583\t\n",
      "Subject: 19, n=11 | test_f1: 0.52381 |best_f1: 0.73889\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0287\tTop_Loss: 0.0289\tBottom_Loss: 0.0604\tLoss: 0.1180\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0297\tTop_Loss: 0.0888\tBottom_Loss: 0.0548\tLoss: 0.1733\t\n",
      "Subject: 19, n=11 | test_f1: 0.61667 |best_f1: 0.73889\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0120\tTop_Loss: 0.0493\tBottom_Loss: 0.0322\tLoss: 0.0935\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0070\tTop_Loss: 0.0246\tBottom_Loss: 0.0378\tLoss: 0.0694\t\n",
      "Subject: 19, n=11 | test_f1: 0.26496 |best_f1: 0.73889\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0200\tTop_Loss: 0.0711\tBottom_Loss: 0.0577\tLoss: 0.1488\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0534\tTop_Loss: 0.1387\tBottom_Loss: 0.1050\tLoss: 0.2971\t\n",
      "Subject: 19, n=11 | test_f1: 0.61667 |best_f1: 0.73889\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0070\tTop_Loss: 0.0113\tBottom_Loss: 0.0122\tLoss: 0.0305\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0128\tTop_Loss: 0.0556\tBottom_Loss: 0.0178\tLoss: 0.0861\t\n",
      "Subject: 19, n=11 | test_f1: 0.34848 |best_f1: 0.73889\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0129\tTop_Loss: 0.0327\tBottom_Loss: 0.0436\tLoss: 0.0892\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0150\tTop_Loss: 0.0431\tBottom_Loss: 0.0236\tLoss: 0.0817\t\n",
      "Subject: 19, n=11 | test_f1: 0.42222 |best_f1: 0.73889\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0601\tTop_Loss: 0.0724\tBottom_Loss: 0.0757\tLoss: 0.2081\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0190\tTop_Loss: 0.0511\tBottom_Loss: 0.0473\tLoss: 0.1174\t\n",
      "Subject: 19, n=11 | test_f1: 0.30556 |best_f1: 0.73889\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0051\tTop_Loss: 0.0239\tBottom_Loss: 0.0176\tLoss: 0.0465\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0263\tTop_Loss: 0.0840\tBottom_Loss: 0.0177\tLoss: 0.1280\t\n",
      "Subject: 19, n=11 | test_f1: 0.53896 |best_f1: 0.73889\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.406\tLabel_Loss: 1.4837\tTop_Loss: 1.5145\tBottom_Loss: 1.2706\tLoss: 4.2688\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.344\tLabel_Loss: 1.1737\tTop_Loss: 1.3353\tBottom_Loss: 1.3061\tLoss: 3.8151\t\n",
      "Subject: 20, n=02 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.375\tLabel_Loss: 1.0988\tTop_Loss: 1.0995\tBottom_Loss: 1.0152\tLoss: 3.2136\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8389\tTop_Loss: 0.8844\tBottom_Loss: 0.8436\tLoss: 2.5669\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.531\tLabel_Loss: 0.8243\tTop_Loss: 0.8892\tBottom_Loss: 0.7573\tLoss: 2.4707\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.438\tLabel_Loss: 1.2726\tTop_Loss: 1.1655\tBottom_Loss: 1.1125\tLoss: 3.5506\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.469\tLabel_Loss: 1.0106\tTop_Loss: 1.0190\tBottom_Loss: 1.0158\tLoss: 3.0454\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.688\tLabel_Loss: 0.8282\tTop_Loss: 0.9491\tBottom_Loss: 0.9328\tLoss: 2.7100\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8486\tTop_Loss: 0.9163\tBottom_Loss: 0.9276\tLoss: 2.6925\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.469\tLabel_Loss: 1.0125\tTop_Loss: 0.9011\tBottom_Loss: 0.8782\tLoss: 2.7918\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.438\tLabel_Loss: 0.9249\tTop_Loss: 0.9375\tBottom_Loss: 1.0748\tLoss: 2.9372\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7460\tTop_Loss: 0.8073\tBottom_Loss: 0.7801\tLoss: 2.3335\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8048\tTop_Loss: 0.9484\tBottom_Loss: 0.8485\tLoss: 2.6017\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.500\tLabel_Loss: 0.8498\tTop_Loss: 0.7977\tBottom_Loss: 0.8415\tLoss: 2.4891\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8093\tTop_Loss: 0.7026\tBottom_Loss: 0.7855\tLoss: 2.2975\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.625\tLabel_Loss: 0.6758\tTop_Loss: 0.6676\tBottom_Loss: 0.8347\tLoss: 2.1781\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7171\tTop_Loss: 0.8695\tBottom_Loss: 0.9271\tLoss: 2.5137\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.719\tLabel_Loss: 0.8832\tTop_Loss: 0.9937\tBottom_Loss: 0.8306\tLoss: 2.7076\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.656\tLabel_Loss: 0.6808\tTop_Loss: 0.8195\tBottom_Loss: 0.7017\tLoss: 2.2020\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8150\tTop_Loss: 0.8142\tBottom_Loss: 0.8458\tLoss: 2.4751\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5257\tTop_Loss: 0.7289\tBottom_Loss: 0.6780\tLoss: 1.9326\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.531\tLabel_Loss: 0.9931\tTop_Loss: 1.0865\tBottom_Loss: 0.8889\tLoss: 2.9684\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5689\tTop_Loss: 0.7706\tBottom_Loss: 0.7803\tLoss: 2.1198\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5231\tTop_Loss: 0.5306\tBottom_Loss: 0.6116\tLoss: 1.6653\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.688\tLabel_Loss: 0.5734\tTop_Loss: 0.7011\tBottom_Loss: 0.6504\tLoss: 1.9249\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6099\tTop_Loss: 0.6630\tBottom_Loss: 0.5628\tLoss: 1.8357\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3884\tTop_Loss: 0.6087\tBottom_Loss: 0.5266\tLoss: 1.5237\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8274\tTop_Loss: 0.8855\tBottom_Loss: 0.6973\tLoss: 2.4103\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6641\tTop_Loss: 0.8489\tBottom_Loss: 0.6099\tLoss: 2.1229\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7720\tTop_Loss: 0.7971\tBottom_Loss: 0.7727\tLoss: 2.3418\t\n",
      "Subject: 20, n=02 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4209\tTop_Loss: 0.6115\tBottom_Loss: 0.4675\tLoss: 1.4999\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4614\tTop_Loss: 0.6965\tBottom_Loss: 0.4469\tLoss: 1.6048\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6119\tTop_Loss: 0.6044\tBottom_Loss: 0.6237\tLoss: 1.8400\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5225\tTop_Loss: 0.6008\tBottom_Loss: 0.7360\tLoss: 1.8593\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4872\tTop_Loss: 0.6058\tBottom_Loss: 0.6287\tLoss: 1.7217\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.875\tLabel_Loss: 0.5111\tTop_Loss: 0.6033\tBottom_Loss: 0.5564\tLoss: 1.6708\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5653\tTop_Loss: 0.8599\tBottom_Loss: 0.7025\tLoss: 2.1277\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3682\tTop_Loss: 0.5361\tBottom_Loss: 0.6243\tLoss: 1.5286\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4888\tTop_Loss: 0.7376\tBottom_Loss: 0.8229\tLoss: 2.0493\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4058\tTop_Loss: 0.5882\tBottom_Loss: 0.4190\tLoss: 1.4130\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.656\tLabel_Loss: 0.5460\tTop_Loss: 0.6657\tBottom_Loss: 0.7297\tLoss: 1.9414\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.719\tLabel_Loss: 0.7073\tTop_Loss: 0.9324\tBottom_Loss: 0.6741\tLoss: 2.3138\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4644\tTop_Loss: 0.6379\tBottom_Loss: 0.6496\tLoss: 1.7519\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4690\tTop_Loss: 0.5947\tBottom_Loss: 0.5734\tLoss: 1.6371\t\n",
      "Subject: 20, n=02 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3817\tTop_Loss: 0.5934\tBottom_Loss: 0.4154\tLoss: 1.3905\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3984\tTop_Loss: 0.6533\tBottom_Loss: 0.5104\tLoss: 1.5622\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4154\tTop_Loss: 0.4837\tBottom_Loss: 0.6326\tLoss: 1.5317\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4528\tTop_Loss: 0.5560\tBottom_Loss: 0.5358\tLoss: 1.5447\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3903\tTop_Loss: 0.5323\tBottom_Loss: 0.4951\tLoss: 1.4176\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.906\tLabel_Loss: 0.4134\tTop_Loss: 0.5497\tBottom_Loss: 0.5141\tLoss: 1.4772\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2917\tTop_Loss: 0.6540\tBottom_Loss: 0.3646\tLoss: 1.3103\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3363\tTop_Loss: 0.6394\tBottom_Loss: 0.3676\tLoss: 1.3432\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5395\tTop_Loss: 0.6693\tBottom_Loss: 0.5830\tLoss: 1.7918\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4775\tTop_Loss: 0.6590\tBottom_Loss: 0.4484\tLoss: 1.5849\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.906\tLabel_Loss: 0.4037\tTop_Loss: 0.5961\tBottom_Loss: 0.4935\tLoss: 1.4934\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4934\tTop_Loss: 0.5480\tBottom_Loss: 0.5561\tLoss: 1.5975\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4160\tTop_Loss: 0.5594\tBottom_Loss: 0.4774\tLoss: 1.4528\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3125\tTop_Loss: 0.6405\tBottom_Loss: 0.3659\tLoss: 1.3189\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3343\tTop_Loss: 0.6325\tBottom_Loss: 0.4376\tLoss: 1.4043\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3741\tTop_Loss: 0.5839\tBottom_Loss: 0.5560\tLoss: 1.5140\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2460\tTop_Loss: 0.3909\tBottom_Loss: 0.3278\tLoss: 0.9648\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3747\tTop_Loss: 0.5257\tBottom_Loss: 0.4399\tLoss: 1.3404\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2422\tTop_Loss: 0.4040\tBottom_Loss: 0.3403\tLoss: 0.9864\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2401\tTop_Loss: 0.3630\tBottom_Loss: 0.4350\tLoss: 1.0381\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4291\tTop_Loss: 0.6310\tBottom_Loss: 0.5308\tLoss: 1.5909\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2564\tTop_Loss: 0.4845\tBottom_Loss: 0.4425\tLoss: 1.1834\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1963\tTop_Loss: 0.3638\tBottom_Loss: 0.4247\tLoss: 0.9848\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1381\tTop_Loss: 0.2684\tBottom_Loss: 0.2508\tLoss: 0.6573\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1206\tTop_Loss: 0.3605\tBottom_Loss: 0.1895\tLoss: 0.6705\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2468\tTop_Loss: 0.4236\tBottom_Loss: 0.3554\tLoss: 1.0258\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2233\tTop_Loss: 0.3202\tBottom_Loss: 0.4746\tLoss: 1.0181\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1703\tTop_Loss: 0.3599\tBottom_Loss: 0.3369\tLoss: 0.8670\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2434\tTop_Loss: 0.5064\tBottom_Loss: 0.3058\tLoss: 1.0555\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2807\tTop_Loss: 0.4760\tBottom_Loss: 0.3540\tLoss: 1.1107\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2042\tTop_Loss: 0.4097\tBottom_Loss: 0.3605\tLoss: 0.9744\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2115\tTop_Loss: 0.4286\tBottom_Loss: 0.4154\tLoss: 1.0555\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2235\tTop_Loss: 0.4638\tBottom_Loss: 0.2811\tLoss: 0.9685\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2211\tTop_Loss: 0.2811\tBottom_Loss: 0.3172\tLoss: 0.8195\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2559\tTop_Loss: 0.4198\tBottom_Loss: 0.1864\tLoss: 0.8621\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3058\tTop_Loss: 0.4833\tBottom_Loss: 0.4988\tLoss: 1.2879\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3077\tTop_Loss: 0.4204\tBottom_Loss: 0.3205\tLoss: 1.0486\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1658\tTop_Loss: 0.2866\tBottom_Loss: 0.2688\tLoss: 0.7212\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2970\tTop_Loss: 0.4483\tBottom_Loss: 0.4400\tLoss: 1.1853\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1153\tTop_Loss: 0.2817\tBottom_Loss: 0.1938\tLoss: 0.5909\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1860\tTop_Loss: 0.4288\tBottom_Loss: 0.2103\tLoss: 0.8251\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1386\tTop_Loss: 0.4012\tBottom_Loss: 0.1993\tLoss: 0.7391\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1863\tTop_Loss: 0.3017\tBottom_Loss: 0.2467\tLoss: 0.7347\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1702\tTop_Loss: 0.3095\tBottom_Loss: 0.2855\tLoss: 0.7652\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2330\tTop_Loss: 0.5552\tBottom_Loss: 0.2743\tLoss: 1.0626\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0602\tTop_Loss: 0.2716\tBottom_Loss: 0.1260\tLoss: 0.4577\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1355\tTop_Loss: 0.3258\tBottom_Loss: 0.2630\tLoss: 0.7243\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1035\tTop_Loss: 0.1409\tBottom_Loss: 0.3346\tLoss: 0.5790\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0641\tTop_Loss: 0.2159\tBottom_Loss: 0.1175\tLoss: 0.3974\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0841\tTop_Loss: 0.2189\tBottom_Loss: 0.1937\tLoss: 0.4967\t\n",
      "Subject: 20, n=02 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1397\tTop_Loss: 0.2275\tBottom_Loss: 0.1474\tLoss: 0.5146\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0704\tTop_Loss: 0.2342\tBottom_Loss: 0.1261\tLoss: 0.4307\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1231\tTop_Loss: 0.2348\tBottom_Loss: 0.2362\tLoss: 0.5942\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0655\tTop_Loss: 0.2237\tBottom_Loss: 0.1512\tLoss: 0.4403\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0959\tTop_Loss: 0.3535\tBottom_Loss: 0.1802\tLoss: 0.6297\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0707\tTop_Loss: 0.1997\tBottom_Loss: 0.1643\tLoss: 0.4347\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1405\tTop_Loss: 0.3147\tBottom_Loss: 0.1666\tLoss: 0.6217\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2404\tTop_Loss: 0.2938\tBottom_Loss: 0.2892\tLoss: 0.8235\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2096\tTop_Loss: 0.3066\tBottom_Loss: 0.2589\tLoss: 0.7750\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0760\tTop_Loss: 0.2432\tBottom_Loss: 0.1522\tLoss: 0.4714\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0700\tTop_Loss: 0.2354\tBottom_Loss: 0.1689\tLoss: 0.4743\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0742\tTop_Loss: 0.2253\tBottom_Loss: 0.1300\tLoss: 0.4294\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0543\tTop_Loss: 0.2848\tBottom_Loss: 0.1257\tLoss: 0.4648\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0642\tTop_Loss: 0.2021\tBottom_Loss: 0.1262\tLoss: 0.3926\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0811\tTop_Loss: 0.2003\tBottom_Loss: 0.1186\tLoss: 0.4000\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0759\tTop_Loss: 0.2221\tBottom_Loss: 0.1590\tLoss: 0.4570\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0796\tTop_Loss: 0.2583\tBottom_Loss: 0.1277\tLoss: 0.4656\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0235\tTop_Loss: 0.1306\tBottom_Loss: 0.0560\tLoss: 0.2101\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0990\tTop_Loss: 0.2162\tBottom_Loss: 0.1494\tLoss: 0.4646\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0404\tTop_Loss: 0.1630\tBottom_Loss: 0.1307\tLoss: 0.3341\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1609\tTop_Loss: 0.2330\tBottom_Loss: 0.2253\tLoss: 0.6192\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0478\tTop_Loss: 0.2611\tBottom_Loss: 0.1623\tLoss: 0.4711\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0347\tTop_Loss: 0.2142\tBottom_Loss: 0.0831\tLoss: 0.3320\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0861\tTop_Loss: 0.1772\tBottom_Loss: 0.0753\tLoss: 0.3387\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1080\tTop_Loss: 0.2388\tBottom_Loss: 0.2177\tLoss: 0.5645\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0411\tTop_Loss: 0.1054\tBottom_Loss: 0.1097\tLoss: 0.2562\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0255\tTop_Loss: 0.1405\tBottom_Loss: 0.0435\tLoss: 0.2095\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1300\tTop_Loss: 0.2818\tBottom_Loss: 0.2246\tLoss: 0.6364\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0838\tTop_Loss: 0.1725\tBottom_Loss: 0.1500\tLoss: 0.4063\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0805\tTop_Loss: 0.2203\tBottom_Loss: 0.0944\tLoss: 0.3952\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0670\tTop_Loss: 0.1603\tBottom_Loss: 0.1256\tLoss: 0.3529\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0614\tTop_Loss: 0.2347\tBottom_Loss: 0.1407\tLoss: 0.4367\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0554\tTop_Loss: 0.1799\tBottom_Loss: 0.1482\tLoss: 0.3835\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1296\tTop_Loss: 0.1741\tBottom_Loss: 0.1674\tLoss: 0.4711\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0569\tTop_Loss: 0.1805\tBottom_Loss: 0.2114\tLoss: 0.4487\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0436\tTop_Loss: 0.1798\tBottom_Loss: 0.1247\tLoss: 0.3480\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0338\tTop_Loss: 0.1024\tBottom_Loss: 0.1127\tLoss: 0.2489\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0397\tTop_Loss: 0.1352\tBottom_Loss: 0.1057\tLoss: 0.2807\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0986\tTop_Loss: 0.2287\tBottom_Loss: 0.1847\tLoss: 0.5120\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0424\tTop_Loss: 0.2027\tBottom_Loss: 0.1368\tLoss: 0.3819\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 0.938\tLabel_Loss: 0.0926\tTop_Loss: 0.2664\tBottom_Loss: 0.1348\tLoss: 0.4938\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0254\tTop_Loss: 0.1096\tBottom_Loss: 0.0810\tLoss: 0.2161\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0442\tTop_Loss: 0.1557\tBottom_Loss: 0.0558\tLoss: 0.2557\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0279\tTop_Loss: 0.1203\tBottom_Loss: 0.0693\tLoss: 0.2175\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0215\tTop_Loss: 0.1011\tBottom_Loss: 0.0417\tLoss: 0.1643\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0139\tTop_Loss: 0.0494\tBottom_Loss: 0.0823\tLoss: 0.1456\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0461\tTop_Loss: 0.1145\tBottom_Loss: 0.0807\tLoss: 0.2413\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0245\tTop_Loss: 0.1588\tBottom_Loss: 0.0465\tLoss: 0.2298\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0355\tTop_Loss: 0.2041\tBottom_Loss: 0.0385\tLoss: 0.2781\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0503\tTop_Loss: 0.1772\tBottom_Loss: 0.0922\tLoss: 0.3197\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0309\tTop_Loss: 0.1126\tBottom_Loss: 0.0564\tLoss: 0.1999\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0390\tTop_Loss: 0.0840\tBottom_Loss: 0.1366\tLoss: 0.2596\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0451\tTop_Loss: 0.2093\tBottom_Loss: 0.1073\tLoss: 0.3616\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0121\tTop_Loss: 0.0961\tBottom_Loss: 0.0544\tLoss: 0.1627\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0208\tTop_Loss: 0.0737\tBottom_Loss: 0.0714\tLoss: 0.1659\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0315\tTop_Loss: 0.0856\tBottom_Loss: 0.0512\tLoss: 0.1683\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0235\tTop_Loss: 0.1089\tBottom_Loss: 0.0477\tLoss: 0.1802\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0069\tTop_Loss: 0.0508\tBottom_Loss: 0.0175\tLoss: 0.0751\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0167\tTop_Loss: 0.0677\tBottom_Loss: 0.0470\tLoss: 0.1315\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0223\tTop_Loss: 0.1490\tBottom_Loss: 0.0684\tLoss: 0.2397\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0441\tTop_Loss: 0.1237\tBottom_Loss: 0.0880\tLoss: 0.2558\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0113\tTop_Loss: 0.0337\tBottom_Loss: 0.0247\tLoss: 0.0697\t\n",
      "Subject: 20, n=02 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0061\tTop_Loss: 0.0775\tBottom_Loss: 0.0141\tLoss: 0.0977\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0254\tTop_Loss: 0.1817\tBottom_Loss: 0.1052\tLoss: 0.3124\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0141\tTop_Loss: 0.0723\tBottom_Loss: 0.0433\tLoss: 0.1296\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0793\tTop_Loss: 0.1159\tBottom_Loss: 0.0821\tLoss: 0.2772\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0594\tTop_Loss: 0.0494\tBottom_Loss: 0.1331\tLoss: 0.2419\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0317\tTop_Loss: 0.1159\tBottom_Loss: 0.0908\tLoss: 0.2383\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0125\tTop_Loss: 0.0546\tBottom_Loss: 0.0344\tLoss: 0.1015\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0104\tTop_Loss: 0.0641\tBottom_Loss: 0.0319\tLoss: 0.1064\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0171\tTop_Loss: 0.0716\tBottom_Loss: 0.0388\tLoss: 0.1276\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0094\tTop_Loss: 0.0812\tBottom_Loss: 0.0362\tLoss: 0.1268\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0465\tTop_Loss: 0.1066\tBottom_Loss: 0.1214\tLoss: 0.2745\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0472\tTop_Loss: 0.1426\tBottom_Loss: 0.1318\tLoss: 0.3216\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0185\tTop_Loss: 0.0810\tBottom_Loss: 0.0641\tLoss: 0.1636\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0073\tTop_Loss: 0.0479\tBottom_Loss: 0.0377\tLoss: 0.0930\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0630\tTop_Loss: 0.0659\tBottom_Loss: 0.0871\tLoss: 0.2160\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0118\tTop_Loss: 0.0359\tBottom_Loss: 0.0381\tLoss: 0.0858\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0172\tTop_Loss: 0.0557\tBottom_Loss: 0.0456\tLoss: 0.1184\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0207\tTop_Loss: 0.1381\tBottom_Loss: 0.0509\tLoss: 0.2097\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0067\tTop_Loss: 0.0658\tBottom_Loss: 0.0292\tLoss: 0.1018\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0137\tTop_Loss: 0.0591\tBottom_Loss: 0.0755\tLoss: 0.1484\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0113\tTop_Loss: 0.0858\tBottom_Loss: 0.0289\tLoss: 0.1260\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0101\tTop_Loss: 0.0552\tBottom_Loss: 0.0289\tLoss: 0.0942\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0119\tTop_Loss: 0.0834\tBottom_Loss: 0.0353\tLoss: 0.1306\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0285\tTop_Loss: 0.1530\tBottom_Loss: 0.1240\tLoss: 0.3054\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0105\tTop_Loss: 0.0777\tBottom_Loss: 0.0458\tLoss: 0.1341\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0526\tTop_Loss: 0.1511\tBottom_Loss: 0.0507\tLoss: 0.2545\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0430\tTop_Loss: 0.1401\tBottom_Loss: 0.0303\tLoss: 0.2134\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0376\tTop_Loss: 0.0560\tBottom_Loss: 0.1161\tLoss: 0.2098\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0101\tTop_Loss: 0.0406\tBottom_Loss: 0.0443\tLoss: 0.0950\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0111\tTop_Loss: 0.1279\tBottom_Loss: 0.0360\tLoss: 0.1750\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0454\tTop_Loss: 0.1051\tBottom_Loss: 0.0732\tLoss: 0.2237\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0070\tTop_Loss: 0.0683\tBottom_Loss: 0.0272\tLoss: 0.1025\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0407\tTop_Loss: 0.0590\tBottom_Loss: 0.0683\tLoss: 0.1680\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0047\tTop_Loss: 0.0661\tBottom_Loss: 0.0137\tLoss: 0.0845\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0047\tTop_Loss: 0.0366\tBottom_Loss: 0.0223\tLoss: 0.0636\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0040\tTop_Loss: 0.0214\tBottom_Loss: 0.0253\tLoss: 0.0506\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0166\tTop_Loss: 0.0552\tBottom_Loss: 0.0275\tLoss: 0.0994\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0122\tTop_Loss: 0.0635\tBottom_Loss: 0.0196\tLoss: 0.0952\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0063\tTop_Loss: 0.0551\tBottom_Loss: 0.0094\tLoss: 0.0708\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0037\tTop_Loss: 0.0192\tBottom_Loss: 0.0096\tLoss: 0.0325\t\n",
      "Subject: 20, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0093\tTop_Loss: 0.0393\tBottom_Loss: 0.0328\tLoss: 0.0814\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0199\tTop_Loss: 0.0298\tBottom_Loss: 0.0514\tLoss: 0.1011\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0623\tTop_Loss: 0.0268\tBottom_Loss: 0.0483\tLoss: 0.1374\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0070\tTop_Loss: 0.0349\tBottom_Loss: 0.0201\tLoss: 0.0619\t\n",
      "Subject: 20, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.438\tLabel_Loss: 1.2164\tTop_Loss: 1.4346\tBottom_Loss: 2.0653\tLoss: 4.7164\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.406\tLabel_Loss: 1.0559\tTop_Loss: 1.2214\tBottom_Loss: 1.3260\tLoss: 3.6033\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8765\tTop_Loss: 0.9609\tBottom_Loss: 0.7440\tLoss: 2.5814\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.500\tLabel_Loss: 1.0272\tTop_Loss: 0.8367\tBottom_Loss: 0.8314\tLoss: 2.6953\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.500\tLabel_Loss: 1.0343\tTop_Loss: 1.0212\tBottom_Loss: 0.9101\tLoss: 2.9656\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.469\tLabel_Loss: 1.0885\tTop_Loss: 1.0454\tBottom_Loss: 1.1645\tLoss: 3.2984\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.500\tLabel_Loss: 1.0650\tTop_Loss: 1.0760\tBottom_Loss: 1.0589\tLoss: 3.1998\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.562\tLabel_Loss: 0.8496\tTop_Loss: 0.9125\tBottom_Loss: 0.8786\tLoss: 2.6407\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.562\tLabel_Loss: 1.0712\tTop_Loss: 1.0929\tBottom_Loss: 0.9931\tLoss: 3.1572\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.469\tLabel_Loss: 0.9865\tTop_Loss: 0.8917\tBottom_Loss: 0.9927\tLoss: 2.8709\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.469\tLabel_Loss: 0.9923\tTop_Loss: 1.0651\tBottom_Loss: 1.0737\tLoss: 3.1311\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.562\tLabel_Loss: 0.8340\tTop_Loss: 1.0137\tBottom_Loss: 0.8783\tLoss: 2.7260\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.656\tLabel_Loss: 0.6638\tTop_Loss: 0.7212\tBottom_Loss: 0.6833\tLoss: 2.0683\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.562\tLabel_Loss: 1.0261\tTop_Loss: 0.8463\tBottom_Loss: 1.0312\tLoss: 2.9037\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6946\tTop_Loss: 0.9472\tBottom_Loss: 0.7365\tLoss: 2.3783\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7098\tTop_Loss: 0.8360\tBottom_Loss: 0.6980\tLoss: 2.2438\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7149\tTop_Loss: 0.7368\tBottom_Loss: 0.7662\tLoss: 2.2178\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.719\tLabel_Loss: 0.7922\tTop_Loss: 0.9505\tBottom_Loss: 0.9911\tLoss: 2.7338\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8830\tTop_Loss: 0.7569\tBottom_Loss: 0.7641\tLoss: 2.4040\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7466\tTop_Loss: 0.8084\tBottom_Loss: 0.6950\tLoss: 2.2499\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7312\tTop_Loss: 0.7741\tBottom_Loss: 0.8132\tLoss: 2.3184\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.562\tLabel_Loss: 0.8109\tTop_Loss: 0.9064\tBottom_Loss: 0.8003\tLoss: 2.5175\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8576\tTop_Loss: 0.9053\tBottom_Loss: 0.8461\tLoss: 2.6090\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.656\tLabel_Loss: 0.6886\tTop_Loss: 0.8425\tBottom_Loss: 0.9228\tLoss: 2.4538\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7952\tTop_Loss: 0.8841\tBottom_Loss: 0.9226\tLoss: 2.6019\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6921\tTop_Loss: 0.8247\tBottom_Loss: 0.7068\tLoss: 2.2236\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6689\tTop_Loss: 0.7596\tBottom_Loss: 0.6617\tLoss: 2.0902\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6782\tTop_Loss: 0.6226\tBottom_Loss: 0.7774\tLoss: 2.0782\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6881\tTop_Loss: 0.7119\tBottom_Loss: 0.8374\tLoss: 2.2375\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5980\tTop_Loss: 0.8234\tBottom_Loss: 0.7443\tLoss: 2.1657\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6240\tTop_Loss: 0.6240\tBottom_Loss: 0.6603\tLoss: 1.9082\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.906\tLabel_Loss: 0.4458\tTop_Loss: 0.5446\tBottom_Loss: 0.5353\tLoss: 1.5257\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5216\tTop_Loss: 0.7614\tBottom_Loss: 0.6207\tLoss: 1.9037\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5250\tTop_Loss: 0.6617\tBottom_Loss: 0.5123\tLoss: 1.6989\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.625\tLabel_Loss: 0.9641\tTop_Loss: 0.8176\tBottom_Loss: 0.8377\tLoss: 2.6193\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6359\tTop_Loss: 0.6503\tBottom_Loss: 0.5993\tLoss: 1.8855\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5917\tTop_Loss: 0.6240\tBottom_Loss: 0.6857\tLoss: 1.9014\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3818\tTop_Loss: 0.4856\tBottom_Loss: 0.4766\tLoss: 1.3440\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.656\tLabel_Loss: 0.6440\tTop_Loss: 0.7011\tBottom_Loss: 0.5532\tLoss: 1.8984\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4383\tTop_Loss: 0.6531\tBottom_Loss: 0.5490\tLoss: 1.6404\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3646\tTop_Loss: 0.5232\tBottom_Loss: 0.5047\tLoss: 1.3925\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5469\tTop_Loss: 0.5994\tBottom_Loss: 0.6551\tLoss: 1.8015\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5448\tTop_Loss: 0.6829\tBottom_Loss: 0.8357\tLoss: 2.0634\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5671\tTop_Loss: 0.7648\tBottom_Loss: 0.6953\tLoss: 2.0273\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3646\tTop_Loss: 0.5582\tBottom_Loss: 0.4619\tLoss: 1.3848\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4098\tTop_Loss: 0.5811\tBottom_Loss: 0.3841\tLoss: 1.3750\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4958\tTop_Loss: 0.6368\tBottom_Loss: 0.6152\tLoss: 1.7477\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3647\tTop_Loss: 0.5558\tBottom_Loss: 0.4864\tLoss: 1.4069\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4705\tTop_Loss: 0.5587\tBottom_Loss: 0.5823\tLoss: 1.6115\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3372\tTop_Loss: 0.5892\tBottom_Loss: 0.4781\tLoss: 1.4045\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3338\tTop_Loss: 0.4256\tBottom_Loss: 0.4556\tLoss: 1.2151\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6858\tTop_Loss: 0.9134\tBottom_Loss: 0.8028\tLoss: 2.4019\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4891\tTop_Loss: 0.6834\tBottom_Loss: 0.4174\tLoss: 1.5899\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4036\tTop_Loss: 0.7567\tBottom_Loss: 0.5847\tLoss: 1.7450\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4569\tTop_Loss: 0.5753\tBottom_Loss: 0.4207\tLoss: 1.4528\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3383\tTop_Loss: 0.4348\tBottom_Loss: 0.4606\tLoss: 1.2337\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2988\tTop_Loss: 0.4405\tBottom_Loss: 0.4972\tLoss: 1.2365\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5155\tTop_Loss: 0.5917\tBottom_Loss: 0.5757\tLoss: 1.6829\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2980\tTop_Loss: 0.4492\tBottom_Loss: 0.3133\tLoss: 1.0606\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3247\tTop_Loss: 0.5298\tBottom_Loss: 0.4750\tLoss: 1.3295\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3532\tTop_Loss: 0.6388\tBottom_Loss: 0.4173\tLoss: 1.4093\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2685\tTop_Loss: 0.5112\tBottom_Loss: 0.3838\tLoss: 1.1634\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4057\tTop_Loss: 0.4401\tBottom_Loss: 0.3846\tLoss: 1.2304\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3040\tTop_Loss: 0.5146\tBottom_Loss: 0.3731\tLoss: 1.1917\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3217\tTop_Loss: 0.3581\tBottom_Loss: 0.3246\tLoss: 1.0044\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3122\tTop_Loss: 0.5715\tBottom_Loss: 0.3653\tLoss: 1.2490\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3104\tTop_Loss: 0.3709\tBottom_Loss: 0.4491\tLoss: 1.1304\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.812\tLabel_Loss: 0.2690\tTop_Loss: 0.5124\tBottom_Loss: 0.3276\tLoss: 1.1089\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2012\tTop_Loss: 0.3953\tBottom_Loss: 0.2955\tLoss: 0.8919\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4317\tTop_Loss: 0.6151\tBottom_Loss: 0.3830\tLoss: 1.4299\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3054\tTop_Loss: 0.4304\tBottom_Loss: 0.3112\tLoss: 1.0470\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2483\tTop_Loss: 0.6128\tBottom_Loss: 0.2549\tLoss: 1.1160\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3233\tTop_Loss: 0.4979\tBottom_Loss: 0.2829\tLoss: 1.1041\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2130\tTop_Loss: 0.3719\tBottom_Loss: 0.2332\tLoss: 0.8182\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4429\tTop_Loss: 0.4224\tBottom_Loss: 0.3810\tLoss: 1.2463\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2004\tTop_Loss: 0.2949\tBottom_Loss: 0.2310\tLoss: 0.7263\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2991\tTop_Loss: 0.4143\tBottom_Loss: 0.3830\tLoss: 1.0963\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.844\tLabel_Loss: 0.2834\tTop_Loss: 0.3532\tBottom_Loss: 0.2858\tLoss: 0.9223\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2554\tTop_Loss: 0.4455\tBottom_Loss: 0.2999\tLoss: 1.0008\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1603\tTop_Loss: 0.3383\tBottom_Loss: 0.2699\tLoss: 0.7686\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2555\tTop_Loss: 0.5828\tBottom_Loss: 0.1991\tLoss: 1.0375\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1919\tTop_Loss: 0.2649\tBottom_Loss: 0.2049\tLoss: 0.6617\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2036\tTop_Loss: 0.4561\tBottom_Loss: 0.2087\tLoss: 0.8684\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2034\tTop_Loss: 0.2673\tBottom_Loss: 0.2814\tLoss: 0.7521\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1833\tTop_Loss: 0.3264\tBottom_Loss: 0.1919\tLoss: 0.7016\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1646\tTop_Loss: 0.3128\tBottom_Loss: 0.2389\tLoss: 0.7163\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1243\tTop_Loss: 0.3294\tBottom_Loss: 0.1419\tLoss: 0.5957\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1001\tTop_Loss: 0.2099\tBottom_Loss: 0.1529\tLoss: 0.4629\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1406\tTop_Loss: 0.1453\tBottom_Loss: 0.2790\tLoss: 0.5649\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1637\tTop_Loss: 0.2370\tBottom_Loss: 0.2159\tLoss: 0.6165\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1043\tTop_Loss: 0.3092\tBottom_Loss: 0.1544\tLoss: 0.5678\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2579\tTop_Loss: 0.2334\tBottom_Loss: 0.2445\tLoss: 0.7358\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1495\tTop_Loss: 0.2615\tBottom_Loss: 0.1731\tLoss: 0.5841\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2845\tTop_Loss: 0.4320\tBottom_Loss: 0.3977\tLoss: 1.1142\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.844\tLabel_Loss: 0.2437\tTop_Loss: 0.3116\tBottom_Loss: 0.3479\tLoss: 0.9032\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0898\tTop_Loss: 0.2012\tBottom_Loss: 0.1871\tLoss: 0.4780\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0692\tTop_Loss: 0.2486\tBottom_Loss: 0.1161\tLoss: 0.4339\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.844\tLabel_Loss: 0.2969\tTop_Loss: 0.3424\tBottom_Loss: 0.2762\tLoss: 0.9155\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0572\tTop_Loss: 0.2058\tBottom_Loss: 0.1295\tLoss: 0.3924\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1326\tTop_Loss: 0.2288\tBottom_Loss: 0.2590\tLoss: 0.6203\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1374\tTop_Loss: 0.1973\tBottom_Loss: 0.2821\tLoss: 0.6167\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0736\tTop_Loss: 0.1889\tBottom_Loss: 0.1707\tLoss: 0.4332\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1013\tTop_Loss: 0.3377\tBottom_Loss: 0.1623\tLoss: 0.6013\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1561\tTop_Loss: 0.3367\tBottom_Loss: 0.2243\tLoss: 0.7170\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1116\tTop_Loss: 0.3303\tBottom_Loss: 0.1752\tLoss: 0.6171\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2198\tTop_Loss: 0.3805\tBottom_Loss: 0.2203\tLoss: 0.8206\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0838\tTop_Loss: 0.2716\tBottom_Loss: 0.0990\tLoss: 0.4544\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0537\tTop_Loss: 0.1748\tBottom_Loss: 0.0870\tLoss: 0.3155\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1116\tTop_Loss: 0.2313\tBottom_Loss: 0.1271\tLoss: 0.4699\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0674\tTop_Loss: 0.1485\tBottom_Loss: 0.1755\tLoss: 0.3914\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1318\tTop_Loss: 0.2235\tBottom_Loss: 0.1249\tLoss: 0.4802\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2153\tTop_Loss: 0.4377\tBottom_Loss: 0.1833\tLoss: 0.8362\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0862\tTop_Loss: 0.1701\tBottom_Loss: 0.1139\tLoss: 0.3702\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0724\tTop_Loss: 0.1956\tBottom_Loss: 0.1184\tLoss: 0.3864\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0699\tTop_Loss: 0.2285\tBottom_Loss: 0.0936\tLoss: 0.3919\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1066\tTop_Loss: 0.3359\tBottom_Loss: 0.1150\tLoss: 0.5576\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0367\tTop_Loss: 0.1429\tBottom_Loss: 0.1086\tLoss: 0.2883\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0550\tTop_Loss: 0.1155\tBottom_Loss: 0.0854\tLoss: 0.2559\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0718\tTop_Loss: 0.1589\tBottom_Loss: 0.1702\tLoss: 0.4008\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0749\tTop_Loss: 0.1884\tBottom_Loss: 0.0577\tLoss: 0.3210\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 0.938\tLabel_Loss: 0.0988\tTop_Loss: 0.2370\tBottom_Loss: 0.1370\tLoss: 0.4728\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0321\tTop_Loss: 0.1371\tBottom_Loss: 0.1178\tLoss: 0.2870\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0368\tTop_Loss: 0.1026\tBottom_Loss: 0.0965\tLoss: 0.2360\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1300\tTop_Loss: 0.2368\tBottom_Loss: 0.1323\tLoss: 0.4991\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0312\tTop_Loss: 0.2423\tBottom_Loss: 0.0539\tLoss: 0.3274\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1649\tTop_Loss: 0.1549\tBottom_Loss: 0.2155\tLoss: 0.5353\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0524\tTop_Loss: 0.1737\tBottom_Loss: 0.0913\tLoss: 0.3174\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2293\tTop_Loss: 0.2583\tBottom_Loss: 0.2650\tLoss: 0.7526\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0155\tTop_Loss: 0.0673\tBottom_Loss: 0.0432\tLoss: 0.1260\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2596\tTop_Loss: 0.1339\tBottom_Loss: 0.3323\tLoss: 0.7258\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0293\tTop_Loss: 0.0995\tBottom_Loss: 0.0479\tLoss: 0.1767\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0827\tTop_Loss: 0.2217\tBottom_Loss: 0.1951\tLoss: 0.4995\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0445\tTop_Loss: 0.1540\tBottom_Loss: 0.0423\tLoss: 0.2408\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1750\tTop_Loss: 0.2196\tBottom_Loss: 0.2166\tLoss: 0.6113\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0517\tTop_Loss: 0.1381\tBottom_Loss: 0.0954\tLoss: 0.2851\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0262\tTop_Loss: 0.0540\tBottom_Loss: 0.0447\tLoss: 0.1250\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0585\tTop_Loss: 0.1115\tBottom_Loss: 0.0934\tLoss: 0.2633\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1174\tTop_Loss: 0.1427\tBottom_Loss: 0.2010\tLoss: 0.4611\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0264\tTop_Loss: 0.1835\tBottom_Loss: 0.0440\tLoss: 0.2540\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0291\tTop_Loss: 0.1351\tBottom_Loss: 0.0638\tLoss: 0.2279\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0451\tTop_Loss: 0.2478\tBottom_Loss: 0.0654\tLoss: 0.3583\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0502\tTop_Loss: 0.1115\tBottom_Loss: 0.0937\tLoss: 0.2554\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0327\tTop_Loss: 0.1245\tBottom_Loss: 0.0639\tLoss: 0.2211\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0304\tTop_Loss: 0.1186\tBottom_Loss: 0.0651\tLoss: 0.2141\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0219\tTop_Loss: 0.0820\tBottom_Loss: 0.0394\tLoss: 0.1433\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0654\tTop_Loss: 0.1112\tBottom_Loss: 0.1493\tLoss: 0.3259\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0188\tTop_Loss: 0.0610\tBottom_Loss: 0.0329\tLoss: 0.1126\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0361\tTop_Loss: 0.0805\tBottom_Loss: 0.0559\tLoss: 0.1726\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0502\tTop_Loss: 0.1155\tBottom_Loss: 0.0861\tLoss: 0.2519\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0827\tTop_Loss: 0.1040\tBottom_Loss: 0.0995\tLoss: 0.2861\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0362\tTop_Loss: 0.1150\tBottom_Loss: 0.0463\tLoss: 0.1974\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0655\tTop_Loss: 0.1805\tBottom_Loss: 0.0995\tLoss: 0.3455\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0455\tTop_Loss: 0.1347\tBottom_Loss: 0.0507\tLoss: 0.2309\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0520\tTop_Loss: 0.1544\tBottom_Loss: 0.1274\tLoss: 0.3338\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0641\tTop_Loss: 0.1245\tBottom_Loss: 0.0715\tLoss: 0.2601\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0703\tTop_Loss: 0.1479\tBottom_Loss: 0.1267\tLoss: 0.3449\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0185\tTop_Loss: 0.0784\tBottom_Loss: 0.0265\tLoss: 0.1233\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0779\tTop_Loss: 0.0564\tBottom_Loss: 0.1299\tLoss: 0.2642\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0625\tTop_Loss: 0.1400\tBottom_Loss: 0.0952\tLoss: 0.2977\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0375\tTop_Loss: 0.1509\tBottom_Loss: 0.0463\tLoss: 0.2347\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0179\tTop_Loss: 0.0365\tBottom_Loss: 0.0544\tLoss: 0.1088\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1378\tTop_Loss: 0.1996\tBottom_Loss: 0.0795\tLoss: 0.4169\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0608\tTop_Loss: 0.0782\tBottom_Loss: 0.0739\tLoss: 0.2129\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0232\tTop_Loss: 0.0394\tBottom_Loss: 0.0272\tLoss: 0.0898\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0462\tTop_Loss: 0.0730\tBottom_Loss: 0.0839\tLoss: 0.2031\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0204\tTop_Loss: 0.0285\tBottom_Loss: 0.0651\tLoss: 0.1140\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0339\tTop_Loss: 0.0736\tBottom_Loss: 0.0537\tLoss: 0.1612\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0199\tTop_Loss: 0.0763\tBottom_Loss: 0.0319\tLoss: 0.1282\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0640\tTop_Loss: 0.2197\tBottom_Loss: 0.1136\tLoss: 0.3973\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0343\tTop_Loss: 0.0291\tBottom_Loss: 0.0721\tLoss: 0.1355\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0089\tTop_Loss: 0.0961\tBottom_Loss: 0.0221\tLoss: 0.1271\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0086\tTop_Loss: 0.0579\tBottom_Loss: 0.0191\tLoss: 0.0856\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0221\tTop_Loss: 0.1300\tBottom_Loss: 0.0464\tLoss: 0.1984\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0094\tTop_Loss: 0.0507\tBottom_Loss: 0.0203\tLoss: 0.0804\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0153\tTop_Loss: 0.0905\tBottom_Loss: 0.0386\tLoss: 0.1444\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0118\tTop_Loss: 0.0267\tBottom_Loss: 0.0307\tLoss: 0.0693\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0210\tTop_Loss: 0.0951\tBottom_Loss: 0.0305\tLoss: 0.1466\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0522\tTop_Loss: 0.0494\tBottom_Loss: 0.1084\tLoss: 0.2100\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0189\tTop_Loss: 0.0377\tBottom_Loss: 0.0394\tLoss: 0.0961\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0093\tTop_Loss: 0.0378\tBottom_Loss: 0.0228\tLoss: 0.0699\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0074\tTop_Loss: 0.0230\tBottom_Loss: 0.0636\tLoss: 0.0939\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0064\tTop_Loss: 0.0237\tBottom_Loss: 0.0116\tLoss: 0.0418\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0146\tTop_Loss: 0.0571\tBottom_Loss: 0.0184\tLoss: 0.0901\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0291\tTop_Loss: 0.0436\tBottom_Loss: 0.0675\tLoss: 0.1402\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0170\tTop_Loss: 0.0879\tBottom_Loss: 0.0270\tLoss: 0.1320\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0167\tTop_Loss: 0.0507\tBottom_Loss: 0.0275\tLoss: 0.0950\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0242\tTop_Loss: 0.0471\tBottom_Loss: 0.0407\tLoss: 0.1120\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1219\tTop_Loss: 0.1591\tBottom_Loss: 0.1028\tLoss: 0.3838\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0146\tTop_Loss: 0.0298\tBottom_Loss: 0.0422\tLoss: 0.0865\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0143\tTop_Loss: 0.0268\tBottom_Loss: 0.0330\tLoss: 0.0741\t\n",
      "Subject: 21, n=01 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0059\tTop_Loss: 0.0228\tBottom_Loss: 0.0162\tLoss: 0.0449\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0220\tTop_Loss: 0.0656\tBottom_Loss: 0.0286\tLoss: 0.1162\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0085\tTop_Loss: 0.0397\tBottom_Loss: 0.0224\tLoss: 0.0705\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0131\tTop_Loss: 0.0729\tBottom_Loss: 0.0359\tLoss: 0.1219\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0082\tTop_Loss: 0.0357\tBottom_Loss: 0.0167\tLoss: 0.0606\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0098\tTop_Loss: 0.1433\tBottom_Loss: 0.0139\tLoss: 0.1670\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0095\tTop_Loss: 0.0550\tBottom_Loss: 0.0180\tLoss: 0.0824\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0188\tTop_Loss: 0.1120\tBottom_Loss: 0.0193\tLoss: 0.1501\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0025\tTop_Loss: 0.0176\tBottom_Loss: 0.0072\tLoss: 0.0273\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0023\tTop_Loss: 0.0134\tBottom_Loss: 0.0056\tLoss: 0.0213\t\n",
      "Subject: 21, n=01 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.500\tLabel_Loss: 1.1722\tTop_Loss: 1.4796\tBottom_Loss: 1.3060\tLoss: 3.9577\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.375\tLabel_Loss: 1.2940\tTop_Loss: 1.1056\tBottom_Loss: 1.0392\tLoss: 3.4387\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.469\tLabel_Loss: 1.3777\tTop_Loss: 1.2517\tBottom_Loss: 1.1051\tLoss: 3.7344\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.438\tLabel_Loss: 1.0669\tTop_Loss: 1.0323\tBottom_Loss: 1.0642\tLoss: 3.1634\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.531\tLabel_Loss: 0.9739\tTop_Loss: 1.0472\tBottom_Loss: 0.8235\tLoss: 2.8446\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.625\tLabel_Loss: 0.9301\tTop_Loss: 0.9428\tBottom_Loss: 1.0309\tLoss: 2.9038\t\n",
      "Subject: 22, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.562\tLabel_Loss: 0.8944\tTop_Loss: 0.7759\tBottom_Loss: 0.9883\tLoss: 2.6586\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.562\tLabel_Loss: 0.8918\tTop_Loss: 1.0787\tBottom_Loss: 0.9924\tLoss: 2.9630\t\n",
      "Subject: 22, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.531\tLabel_Loss: 0.9185\tTop_Loss: 0.9414\tBottom_Loss: 0.8169\tLoss: 2.6768\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.375\tLabel_Loss: 1.0378\tTop_Loss: 0.8568\tBottom_Loss: 0.8775\tLoss: 2.7722\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.656\tLabel_Loss: 0.8471\tTop_Loss: 0.8828\tBottom_Loss: 0.9274\tLoss: 2.6573\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.656\tLabel_Loss: 0.8342\tTop_Loss: 0.9490\tBottom_Loss: 0.8886\tLoss: 2.6717\t\n",
      "Subject: 22, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.594\tLabel_Loss: 0.9465\tTop_Loss: 0.8260\tBottom_Loss: 0.9133\tLoss: 2.6858\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8871\tTop_Loss: 0.9433\tBottom_Loss: 0.8310\tLoss: 2.6613\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8907\tTop_Loss: 0.8615\tBottom_Loss: 0.8777\tLoss: 2.6299\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.500\tLabel_Loss: 0.9802\tTop_Loss: 1.0632\tBottom_Loss: 0.9238\tLoss: 2.9672\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.594\tLabel_Loss: 1.0169\tTop_Loss: 0.8405\tBottom_Loss: 0.8353\tLoss: 2.6927\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.531\tLabel_Loss: 0.8896\tTop_Loss: 1.0234\tBottom_Loss: 1.0151\tLoss: 2.9281\t\n",
      "Subject: 22, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6851\tTop_Loss: 0.8082\tBottom_Loss: 0.7544\tLoss: 2.2478\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7381\tTop_Loss: 0.6718\tBottom_Loss: 0.8246\tLoss: 2.2345\t\n",
      "Subject: 22, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.594\tLabel_Loss: 0.7201\tTop_Loss: 0.6642\tBottom_Loss: 0.7863\tLoss: 2.1706\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.750\tLabel_Loss: 0.7658\tTop_Loss: 0.7438\tBottom_Loss: 0.8036\tLoss: 2.3132\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8355\tTop_Loss: 0.9372\tBottom_Loss: 0.8036\tLoss: 2.5763\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.656\tLabel_Loss: 0.6813\tTop_Loss: 0.6035\tBottom_Loss: 0.7698\tLoss: 2.0546\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6595\tTop_Loss: 0.7071\tBottom_Loss: 0.6805\tLoss: 2.0471\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6577\tTop_Loss: 0.8100\tBottom_Loss: 0.8789\tLoss: 2.3466\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6565\tTop_Loss: 0.7487\tBottom_Loss: 0.7762\tLoss: 2.1814\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5541\tTop_Loss: 0.7198\tBottom_Loss: 0.6764\tLoss: 1.9503\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.906\tLabel_Loss: 0.5128\tTop_Loss: 0.5067\tBottom_Loss: 0.6462\tLoss: 1.6657\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6835\tTop_Loss: 0.7057\tBottom_Loss: 0.9109\tLoss: 2.3001\t\n",
      "Subject: 22, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5696\tTop_Loss: 0.6915\tBottom_Loss: 0.6401\tLoss: 1.9012\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5483\tTop_Loss: 0.6707\tBottom_Loss: 0.6864\tLoss: 1.9054\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.750\tLabel_Loss: 0.4854\tTop_Loss: 0.6009\tBottom_Loss: 0.5535\tLoss: 1.6398\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4210\tTop_Loss: 0.5577\tBottom_Loss: 0.4761\tLoss: 1.4548\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4714\tTop_Loss: 0.5118\tBottom_Loss: 0.6419\tLoss: 1.6251\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6404\tTop_Loss: 0.6850\tBottom_Loss: 0.8491\tLoss: 2.1745\t\n",
      "Subject: 22, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5542\tTop_Loss: 0.5297\tBottom_Loss: 0.5722\tLoss: 1.6561\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.688\tLabel_Loss: 0.5761\tTop_Loss: 0.6975\tBottom_Loss: 0.6457\tLoss: 1.9192\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5997\tTop_Loss: 0.5752\tBottom_Loss: 0.5888\tLoss: 1.7636\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.625\tLabel_Loss: 0.6321\tTop_Loss: 0.5181\tBottom_Loss: 0.6078\tLoss: 1.7581\t\n",
      "Subject: 22, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5238\tTop_Loss: 0.5335\tBottom_Loss: 0.7012\tLoss: 1.7585\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4150\tTop_Loss: 0.4903\tBottom_Loss: 0.6535\tLoss: 1.5588\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3717\tTop_Loss: 0.6055\tBottom_Loss: 0.4659\tLoss: 1.4431\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4477\tTop_Loss: 0.5257\tBottom_Loss: 0.5510\tLoss: 1.5244\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4459\tTop_Loss: 0.5691\tBottom_Loss: 0.4592\tLoss: 1.4742\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5081\tTop_Loss: 0.5039\tBottom_Loss: 0.6772\tLoss: 1.6892\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4581\tTop_Loss: 0.6415\tBottom_Loss: 0.4461\tLoss: 1.5457\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3559\tTop_Loss: 0.4669\tBottom_Loss: 0.5665\tLoss: 1.3893\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3724\tTop_Loss: 0.5636\tBottom_Loss: 0.4441\tLoss: 1.3801\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3927\tTop_Loss: 0.5250\tBottom_Loss: 0.5457\tLoss: 1.4633\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.688\tLabel_Loss: 0.4825\tTop_Loss: 0.6144\tBottom_Loss: 0.6048\tLoss: 1.7017\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.938\tLabel_Loss: 0.3931\tTop_Loss: 0.6161\tBottom_Loss: 0.4826\tLoss: 1.4918\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2360\tTop_Loss: 0.3875\tBottom_Loss: 0.2875\tLoss: 0.9110\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3868\tTop_Loss: 0.4951\tBottom_Loss: 0.3634\tLoss: 1.2454\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3305\tTop_Loss: 0.4318\tBottom_Loss: 0.4030\tLoss: 1.1652\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.938\tLabel_Loss: 0.3039\tTop_Loss: 0.4765\tBottom_Loss: 0.4373\tLoss: 1.2177\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3115\tTop_Loss: 0.4546\tBottom_Loss: 0.4478\tLoss: 1.2139\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4165\tTop_Loss: 0.5638\tBottom_Loss: 0.7215\tLoss: 1.7018\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1874\tTop_Loss: 0.3798\tBottom_Loss: 0.3379\tLoss: 0.9052\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2000\tTop_Loss: 0.3742\tBottom_Loss: 0.2993\tLoss: 0.8735\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3196\tTop_Loss: 0.5029\tBottom_Loss: 0.3844\tLoss: 1.2069\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2614\tTop_Loss: 0.4228\tBottom_Loss: 0.3360\tLoss: 1.0201\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2452\tTop_Loss: 0.4406\tBottom_Loss: 0.5071\tLoss: 1.1929\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2040\tTop_Loss: 0.3205\tBottom_Loss: 0.4176\tLoss: 0.9421\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3090\tTop_Loss: 0.2982\tBottom_Loss: 0.4713\tLoss: 1.0785\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2339\tTop_Loss: 0.3533\tBottom_Loss: 0.3680\tLoss: 0.9553\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1965\tTop_Loss: 0.3822\tBottom_Loss: 0.3713\tLoss: 0.9500\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2607\tTop_Loss: 0.4556\tBottom_Loss: 0.4293\tLoss: 1.1455\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2946\tTop_Loss: 0.4087\tBottom_Loss: 0.6037\tLoss: 1.3069\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1843\tTop_Loss: 0.3164\tBottom_Loss: 0.3954\tLoss: 0.8961\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4030\tTop_Loss: 0.3279\tBottom_Loss: 0.4933\tLoss: 1.2242\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3254\tTop_Loss: 0.5275\tBottom_Loss: 0.3933\tLoss: 1.2462\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1799\tTop_Loss: 0.2762\tBottom_Loss: 0.3042\tLoss: 0.7603\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3481\tTop_Loss: 0.3942\tBottom_Loss: 0.3034\tLoss: 1.0457\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3855\tTop_Loss: 0.4526\tBottom_Loss: 0.4108\tLoss: 1.2490\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1622\tTop_Loss: 0.2630\tBottom_Loss: 0.3651\tLoss: 0.7904\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2702\tTop_Loss: 0.2594\tBottom_Loss: 0.5622\tLoss: 1.0918\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3419\tTop_Loss: 0.4420\tBottom_Loss: 0.4066\tLoss: 1.1904\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1350\tTop_Loss: 0.2125\tBottom_Loss: 0.3561\tLoss: 0.7035\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3107\tTop_Loss: 0.3294\tBottom_Loss: 0.4465\tLoss: 1.0866\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1682\tTop_Loss: 0.3221\tBottom_Loss: 0.4121\tLoss: 0.9024\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2368\tTop_Loss: 0.4155\tBottom_Loss: 0.3273\tLoss: 0.9796\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2253\tTop_Loss: 0.3301\tBottom_Loss: 0.2926\tLoss: 0.8481\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1720\tTop_Loss: 0.3224\tBottom_Loss: 0.2006\tLoss: 0.6949\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2465\tTop_Loss: 0.3235\tBottom_Loss: 0.2752\tLoss: 0.8451\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1426\tTop_Loss: 0.2768\tBottom_Loss: 0.1872\tLoss: 0.6065\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2833\tTop_Loss: 0.4482\tBottom_Loss: 0.3222\tLoss: 1.0537\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1203\tTop_Loss: 0.2156\tBottom_Loss: 0.2534\tLoss: 0.5893\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1586\tTop_Loss: 0.1698\tBottom_Loss: 0.2494\tLoss: 0.5778\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1810\tTop_Loss: 0.4338\tBottom_Loss: 0.2875\tLoss: 0.9022\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2091\tTop_Loss: 0.3542\tBottom_Loss: 0.4093\tLoss: 0.9726\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0940\tTop_Loss: 0.2519\tBottom_Loss: 0.1567\tLoss: 0.5025\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1586\tTop_Loss: 0.2143\tBottom_Loss: 0.2795\tLoss: 0.6523\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0804\tTop_Loss: 0.1460\tBottom_Loss: 0.1743\tLoss: 0.4008\t\n",
      "Subject: 22, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1451\tTop_Loss: 0.2055\tBottom_Loss: 0.2340\tLoss: 0.5845\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2373\tTop_Loss: 0.3483\tBottom_Loss: 0.2612\tLoss: 0.8468\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1287\tTop_Loss: 0.2268\tBottom_Loss: 0.2502\tLoss: 0.6057\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1153\tTop_Loss: 0.2884\tBottom_Loss: 0.2428\tLoss: 0.6466\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1233\tTop_Loss: 0.1927\tBottom_Loss: 0.2053\tLoss: 0.5212\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1599\tTop_Loss: 0.2690\tBottom_Loss: 0.3197\tLoss: 0.7486\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1154\tTop_Loss: 0.1304\tBottom_Loss: 0.2238\tLoss: 0.4696\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1057\tTop_Loss: 0.3230\tBottom_Loss: 0.1288\tLoss: 0.5575\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1177\tTop_Loss: 0.2349\tBottom_Loss: 0.1275\tLoss: 0.4801\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0931\tTop_Loss: 0.2091\tBottom_Loss: 0.2498\tLoss: 0.5519\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1056\tTop_Loss: 0.1806\tBottom_Loss: 0.2675\tLoss: 0.5538\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1344\tTop_Loss: 0.2871\tBottom_Loss: 0.2244\tLoss: 0.6460\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0754\tTop_Loss: 0.1587\tBottom_Loss: 0.1119\tLoss: 0.3460\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1596\tTop_Loss: 0.2250\tBottom_Loss: 0.2888\tLoss: 0.6734\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0637\tTop_Loss: 0.1587\tBottom_Loss: 0.2325\tLoss: 0.4549\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1331\tTop_Loss: 0.2305\tBottom_Loss: 0.1727\tLoss: 0.5362\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0983\tTop_Loss: 0.1708\tBottom_Loss: 0.1048\tLoss: 0.3738\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2362\tTop_Loss: 0.3984\tBottom_Loss: 0.2196\tLoss: 0.8543\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0729\tTop_Loss: 0.1849\tBottom_Loss: 0.1330\tLoss: 0.3908\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0466\tTop_Loss: 0.1377\tBottom_Loss: 0.0682\tLoss: 0.2524\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0966\tTop_Loss: 0.1474\tBottom_Loss: 0.2285\tLoss: 0.4726\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0657\tTop_Loss: 0.1619\tBottom_Loss: 0.1534\tLoss: 0.3810\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[58][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0543\tTop_Loss: 0.1353\tBottom_Loss: 0.1030\tLoss: 0.2926\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1589\tTop_Loss: 0.2505\tBottom_Loss: 0.3496\tLoss: 0.7590\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0699\tTop_Loss: 0.1270\tBottom_Loss: 0.1973\tLoss: 0.3942\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1420\tTop_Loss: 0.2238\tBottom_Loss: 0.2839\tLoss: 0.6496\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0794\tTop_Loss: 0.2829\tBottom_Loss: 0.1554\tLoss: 0.5177\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 0.938\tLabel_Loss: 0.0981\tTop_Loss: 0.1896\tBottom_Loss: 0.1280\tLoss: 0.4157\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1007\tTop_Loss: 0.2278\tBottom_Loss: 0.1859\tLoss: 0.5144\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0257\tTop_Loss: 0.0873\tBottom_Loss: 0.0923\tLoss: 0.2053\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0613\tTop_Loss: 0.1549\tBottom_Loss: 0.1260\tLoss: 0.3422\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1167\tTop_Loss: 0.2869\tBottom_Loss: 0.1193\tLoss: 0.5228\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0392\tTop_Loss: 0.1484\tBottom_Loss: 0.1110\tLoss: 0.2985\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0718\tTop_Loss: 0.1107\tBottom_Loss: 0.1471\tLoss: 0.3296\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1474\tTop_Loss: 0.3908\tBottom_Loss: 0.1725\tLoss: 0.7107\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0870\tTop_Loss: 0.2436\tBottom_Loss: 0.1769\tLoss: 0.5076\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0756\tTop_Loss: 0.1977\tBottom_Loss: 0.1601\tLoss: 0.4333\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0845\tTop_Loss: 0.1323\tBottom_Loss: 0.1760\tLoss: 0.3927\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0831\tTop_Loss: 0.2441\tBottom_Loss: 0.1121\tLoss: 0.4392\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0355\tTop_Loss: 0.0777\tBottom_Loss: 0.1001\tLoss: 0.2133\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0244\tTop_Loss: 0.0558\tBottom_Loss: 0.0679\tLoss: 0.1480\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0271\tTop_Loss: 0.1062\tBottom_Loss: 0.1551\tLoss: 0.2884\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1054\tTop_Loss: 0.2487\tBottom_Loss: 0.0588\tLoss: 0.4129\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1425\tTop_Loss: 0.1449\tBottom_Loss: 0.2081\tLoss: 0.4954\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0579\tTop_Loss: 0.1644\tBottom_Loss: 0.0842\tLoss: 0.3065\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0406\tTop_Loss: 0.1764\tBottom_Loss: 0.0754\tLoss: 0.2924\t\n",
      "Subject: 22, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0595\tTop_Loss: 0.0983\tBottom_Loss: 0.1043\tLoss: 0.2621\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0621\tTop_Loss: 0.1373\tBottom_Loss: 0.0654\tLoss: 0.2648\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0548\tTop_Loss: 0.1421\tBottom_Loss: 0.0521\tLoss: 0.2490\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0437\tTop_Loss: 0.0719\tBottom_Loss: 0.0932\tLoss: 0.2088\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0526\tTop_Loss: 0.0692\tBottom_Loss: 0.1558\tLoss: 0.2777\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0358\tTop_Loss: 0.0826\tBottom_Loss: 0.0804\tLoss: 0.1988\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0474\tTop_Loss: 0.1070\tBottom_Loss: 0.0918\tLoss: 0.2462\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0624\tTop_Loss: 0.0755\tBottom_Loss: 0.1955\tLoss: 0.3333\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0802\tTop_Loss: 0.0692\tBottom_Loss: 0.1659\tLoss: 0.3153\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0388\tTop_Loss: 0.0847\tBottom_Loss: 0.0792\tLoss: 0.2027\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0975\tTop_Loss: 0.1117\tBottom_Loss: 0.1055\tLoss: 0.3147\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0231\tTop_Loss: 0.0690\tBottom_Loss: 0.0851\tLoss: 0.1772\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0499\tTop_Loss: 0.0934\tBottom_Loss: 0.1429\tLoss: 0.2862\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0292\tTop_Loss: 0.2127\tBottom_Loss: 0.0555\tLoss: 0.2974\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0253\tTop_Loss: 0.1431\tBottom_Loss: 0.0483\tLoss: 0.2167\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0201\tTop_Loss: 0.0587\tBottom_Loss: 0.0695\tLoss: 0.1483\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0554\tTop_Loss: 0.0638\tBottom_Loss: 0.1236\tLoss: 0.2428\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0547\tTop_Loss: 0.1220\tBottom_Loss: 0.0360\tLoss: 0.2128\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0418\tTop_Loss: 0.0917\tBottom_Loss: 0.0860\tLoss: 0.2195\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0233\tTop_Loss: 0.0919\tBottom_Loss: 0.0472\tLoss: 0.1624\t\n",
      "Subject: 22, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0501\tTop_Loss: 0.0878\tBottom_Loss: 0.0715\tLoss: 0.2094\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0121\tTop_Loss: 0.0447\tBottom_Loss: 0.0400\tLoss: 0.0968\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0290\tTop_Loss: 0.1008\tBottom_Loss: 0.0387\tLoss: 0.1685\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0261\tTop_Loss: 0.1231\tBottom_Loss: 0.0456\tLoss: 0.1948\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0202\tTop_Loss: 0.0603\tBottom_Loss: 0.0688\tLoss: 0.1493\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0070\tTop_Loss: 0.0350\tBottom_Loss: 0.0264\tLoss: 0.0684\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0199\tTop_Loss: 0.0401\tBottom_Loss: 0.0343\tLoss: 0.0943\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0364\tTop_Loss: 0.0809\tBottom_Loss: 0.0477\tLoss: 0.1650\t\n",
      "Subject: 22, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0121\tTop_Loss: 0.0194\tBottom_Loss: 0.0609\tLoss: 0.0924\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0217\tTop_Loss: 0.0882\tBottom_Loss: 0.0488\tLoss: 0.1586\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0309\tTop_Loss: 0.0529\tBottom_Loss: 0.0786\tLoss: 0.1625\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0125\tTop_Loss: 0.0601\tBottom_Loss: 0.0362\tLoss: 0.1088\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0324\tTop_Loss: 0.1604\tBottom_Loss: 0.0626\tLoss: 0.2554\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0130\tTop_Loss: 0.0293\tBottom_Loss: 0.0347\tLoss: 0.0769\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0095\tTop_Loss: 0.0397\tBottom_Loss: 0.0532\tLoss: 0.1024\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0116\tTop_Loss: 0.1141\tBottom_Loss: 0.0245\tLoss: 0.1502\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0542\tTop_Loss: 0.1479\tBottom_Loss: 0.0943\tLoss: 0.2964\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0133\tTop_Loss: 0.0281\tBottom_Loss: 0.0565\tLoss: 0.0980\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0160\tTop_Loss: 0.0868\tBottom_Loss: 0.0371\tLoss: 0.1400\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0107\tTop_Loss: 0.0327\tBottom_Loss: 0.0323\tLoss: 0.0758\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0289\tTop_Loss: 0.0478\tBottom_Loss: 0.0710\tLoss: 0.1477\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0534\tTop_Loss: 0.0763\tBottom_Loss: 0.0939\tLoss: 0.2235\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0358\tTop_Loss: 0.1053\tBottom_Loss: 0.0265\tLoss: 0.1676\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1061\tTop_Loss: 0.1773\tBottom_Loss: 0.1108\tLoss: 0.3942\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0152\tTop_Loss: 0.0909\tBottom_Loss: 0.0529\tLoss: 0.1590\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0092\tTop_Loss: 0.0209\tBottom_Loss: 0.0287\tLoss: 0.0587\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0175\tTop_Loss: 0.0614\tBottom_Loss: 0.0401\tLoss: 0.1190\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0119\tTop_Loss: 0.0325\tBottom_Loss: 0.0682\tLoss: 0.1125\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0238\tTop_Loss: 0.0332\tBottom_Loss: 0.0740\tLoss: 0.1311\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0101\tTop_Loss: 0.0304\tBottom_Loss: 0.0614\tLoss: 0.1019\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0369\tTop_Loss: 0.0976\tBottom_Loss: 0.0726\tLoss: 0.2070\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0108\tTop_Loss: 0.0559\tBottom_Loss: 0.0134\tLoss: 0.0800\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0128\tTop_Loss: 0.0185\tBottom_Loss: 0.0586\tLoss: 0.0899\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0087\tTop_Loss: 0.0395\tBottom_Loss: 0.0356\tLoss: 0.0838\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0145\tTop_Loss: 0.0302\tBottom_Loss: 0.0656\tLoss: 0.1103\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0195\tTop_Loss: 0.0455\tBottom_Loss: 0.0450\tLoss: 0.1100\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0072\tTop_Loss: 0.0217\tBottom_Loss: 0.0243\tLoss: 0.0532\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0055\tTop_Loss: 0.0143\tBottom_Loss: 0.0309\tLoss: 0.0506\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0263\tTop_Loss: 0.0273\tBottom_Loss: 0.0597\tLoss: 0.1133\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0068\tTop_Loss: 0.0236\tBottom_Loss: 0.0179\tLoss: 0.0483\t\n",
      "Subject: 22, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.312\tLabel_Loss: 1.8879\tTop_Loss: 1.1604\tBottom_Loss: 1.1127\tLoss: 4.1611\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.594\tLabel_Loss: 0.9217\tTop_Loss: 0.8779\tBottom_Loss: 1.0030\tLoss: 2.8025\t\n",
      "Subject: 23, n=08 | test_f1: 0.13333 |best_f1: 0.13333\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.375\tLabel_Loss: 1.1126\tTop_Loss: 1.0324\tBottom_Loss: 1.3064\tLoss: 3.4514\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.469\tLabel_Loss: 1.3155\tTop_Loss: 1.2853\tBottom_Loss: 1.0530\tLoss: 3.6538\t\n",
      "Subject: 23, n=08 | test_f1: 0.22222 |best_f1: 0.22222\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8517\tTop_Loss: 0.9531\tBottom_Loss: 0.9887\tLoss: 2.7935\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8529\tTop_Loss: 0.9691\tBottom_Loss: 0.7137\tLoss: 2.5357\t\n",
      "Subject: 23, n=08 | test_f1: 0.38462 |best_f1: 0.38462\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6874\tTop_Loss: 0.9204\tBottom_Loss: 0.8150\tLoss: 2.4228\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.562\tLabel_Loss: 1.0083\tTop_Loss: 0.9446\tBottom_Loss: 1.0201\tLoss: 2.9730\t\n",
      "Subject: 23, n=08 | test_f1: 0.25641 |best_f1: 0.38462\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8567\tTop_Loss: 0.7905\tBottom_Loss: 0.8227\tLoss: 2.4699\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.625\tLabel_Loss: 0.9622\tTop_Loss: 0.9496\tBottom_Loss: 0.8716\tLoss: 2.7835\t\n",
      "Subject: 23, n=08 | test_f1: 0.28148 |best_f1: 0.38462\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.750\tLabel_Loss: 0.7004\tTop_Loss: 0.7774\tBottom_Loss: 0.8717\tLoss: 2.3495\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8572\tTop_Loss: 0.9409\tBottom_Loss: 0.9301\tLoss: 2.7282\t\n",
      "Subject: 23, n=08 | test_f1: 0.22222 |best_f1: 0.38462\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8324\tTop_Loss: 0.8445\tBottom_Loss: 0.8836\tLoss: 2.5605\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.656\tLabel_Loss: 0.6805\tTop_Loss: 0.7236\tBottom_Loss: 0.7948\tLoss: 2.1989\t\n",
      "Subject: 23, n=08 | test_f1: 0.25641 |best_f1: 0.38462\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.531\tLabel_Loss: 0.8578\tTop_Loss: 0.8113\tBottom_Loss: 0.8121\tLoss: 2.4812\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7891\tTop_Loss: 0.8507\tBottom_Loss: 0.8836\tLoss: 2.5234\t\n",
      "Subject: 23, n=08 | test_f1: 0.18182 |best_f1: 0.38462\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7486\tTop_Loss: 0.7947\tBottom_Loss: 0.8534\tLoss: 2.3966\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.469\tLabel_Loss: 0.9410\tTop_Loss: 0.8784\tBottom_Loss: 0.8859\tLoss: 2.7052\t\n",
      "Subject: 23, n=08 | test_f1: 0.25641 |best_f1: 0.38462\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.812\tLabel_Loss: 0.6013\tTop_Loss: 0.6728\tBottom_Loss: 0.7651\tLoss: 2.0392\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7657\tTop_Loss: 0.7853\tBottom_Loss: 0.7490\tLoss: 2.2999\t\n",
      "Subject: 23, n=08 | test_f1: 0.36667 |best_f1: 0.38462\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.594\tLabel_Loss: 0.7816\tTop_Loss: 0.7242\tBottom_Loss: 0.8121\tLoss: 2.3179\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.719\tLabel_Loss: 0.7314\tTop_Loss: 0.8390\tBottom_Loss: 0.6429\tLoss: 2.2133\t\n",
      "Subject: 23, n=08 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.719\tLabel_Loss: 0.7683\tTop_Loss: 0.9437\tBottom_Loss: 1.0061\tLoss: 2.7181\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7739\tTop_Loss: 0.7940\tBottom_Loss: 0.7391\tLoss: 2.3070\t\n",
      "Subject: 23, n=08 | test_f1: 0.22222 |best_f1: 0.46667\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5999\tTop_Loss: 0.6524\tBottom_Loss: 0.6163\tLoss: 1.8686\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.656\tLabel_Loss: 0.6511\tTop_Loss: 0.7323\tBottom_Loss: 0.7285\tLoss: 2.1119\t\n",
      "Subject: 23, n=08 | test_f1: 0.64103 |best_f1: 0.64103\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.625\tLabel_Loss: 0.6616\tTop_Loss: 0.6433\tBottom_Loss: 0.6987\tLoss: 2.0036\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7058\tTop_Loss: 0.9005\tBottom_Loss: 0.9696\tLoss: 2.5759\t\n",
      "Subject: 23, n=08 | test_f1: 0.38462 |best_f1: 0.64103\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5133\tTop_Loss: 0.6822\tBottom_Loss: 0.6015\tLoss: 1.7970\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7134\tTop_Loss: 0.6809\tBottom_Loss: 0.7802\tLoss: 2.1745\t\n",
      "Subject: 23, n=08 | test_f1: 0.38462 |best_f1: 0.64103\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6810\tTop_Loss: 0.8817\tBottom_Loss: 0.8561\tLoss: 2.4189\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6356\tTop_Loss: 0.7240\tBottom_Loss: 0.8117\tLoss: 2.1713\t\n",
      "Subject: 23, n=08 | test_f1: 0.38462 |best_f1: 0.64103\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.594\tLabel_Loss: 0.7349\tTop_Loss: 0.7343\tBottom_Loss: 0.8694\tLoss: 2.3387\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3583\tTop_Loss: 0.4055\tBottom_Loss: 0.5492\tLoss: 1.3131\t\n",
      "Subject: 23, n=08 | test_f1: 0.22222 |best_f1: 0.64103\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6158\tTop_Loss: 0.6130\tBottom_Loss: 0.5465\tLoss: 1.7753\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6285\tTop_Loss: 0.5951\tBottom_Loss: 0.7585\tLoss: 1.9821\t\n",
      "Subject: 23, n=08 | test_f1: 0.38462 |best_f1: 0.64103\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5363\tTop_Loss: 0.7472\tBottom_Loss: 0.6499\tLoss: 1.9334\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4171\tTop_Loss: 0.6048\tBottom_Loss: 0.5582\tLoss: 1.5800\t\n",
      "Subject: 23, n=08 | test_f1: 0.2 |best_f1: 0.64103\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.688\tLabel_Loss: 0.5525\tTop_Loss: 0.6840\tBottom_Loss: 0.6255\tLoss: 1.8621\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6846\tTop_Loss: 0.7346\tBottom_Loss: 0.9341\tLoss: 2.3533\t\n",
      "Subject: 23, n=08 | test_f1: 0.22222 |best_f1: 0.64103\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4325\tTop_Loss: 0.5123\tBottom_Loss: 0.6088\tLoss: 1.5536\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3118\tTop_Loss: 0.4677\tBottom_Loss: 0.4833\tLoss: 1.2629\t\n",
      "Subject: 23, n=08 | test_f1: 0.40909 |best_f1: 0.64103\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6889\tTop_Loss: 0.7909\tBottom_Loss: 0.7650\tLoss: 2.2448\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5159\tTop_Loss: 0.6381\tBottom_Loss: 0.6064\tLoss: 1.7604\t\n",
      "Subject: 23, n=08 | test_f1: 0.22222 |best_f1: 0.64103\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.656\tLabel_Loss: 0.5816\tTop_Loss: 0.6116\tBottom_Loss: 0.7385\tLoss: 1.9316\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.719\tLabel_Loss: 0.5904\tTop_Loss: 0.6320\tBottom_Loss: 0.6031\tLoss: 1.8254\t\n",
      "Subject: 23, n=08 | test_f1: 0.18182 |best_f1: 0.64103\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.781\tLabel_Loss: 0.6985\tTop_Loss: 0.5858\tBottom_Loss: 0.6751\tLoss: 1.9595\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3739\tTop_Loss: 0.6372\tBottom_Loss: 0.4657\tLoss: 1.4769\t\n",
      "Subject: 23, n=08 | test_f1: 0.18182 |best_f1: 0.64103\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3835\tTop_Loss: 0.6794\tBottom_Loss: 0.4848\tLoss: 1.5477\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5617\tTop_Loss: 0.7493\tBottom_Loss: 0.6368\tLoss: 1.9479\t\n",
      "Subject: 23, n=08 | test_f1: 0.18182 |best_f1: 0.64103\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3139\tTop_Loss: 0.5676\tBottom_Loss: 0.4973\tLoss: 1.3788\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2831\tTop_Loss: 0.4758\tBottom_Loss: 0.4627\tLoss: 1.2217\t\n",
      "Subject: 23, n=08 | test_f1: 0.38462 |best_f1: 0.64103\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4134\tTop_Loss: 0.5335\tBottom_Loss: 0.5407\tLoss: 1.4876\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3687\tTop_Loss: 0.5397\tBottom_Loss: 0.4775\tLoss: 1.3859\t\n",
      "Subject: 23, n=08 | test_f1: 0.64103 |best_f1: 0.64103\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2956\tTop_Loss: 0.3542\tBottom_Loss: 0.5106\tLoss: 1.1604\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4440\tTop_Loss: 0.6941\tBottom_Loss: 0.6554\tLoss: 1.7935\t\n",
      "Subject: 23, n=08 | test_f1: 0.38462 |best_f1: 0.64103\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3957\tTop_Loss: 0.5204\tBottom_Loss: 0.4614\tLoss: 1.3775\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3628\tTop_Loss: 0.4148\tBottom_Loss: 0.4697\tLoss: 1.2473\t\n",
      "Subject: 23, n=08 | test_f1: 0.22222 |best_f1: 0.64103\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3482\tTop_Loss: 0.5141\tBottom_Loss: 0.4708\tLoss: 1.3331\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2519\tTop_Loss: 0.3220\tBottom_Loss: 0.4580\tLoss: 1.0319\t\n",
      "Subject: 23, n=08 | test_f1: 0.66667 |best_f1: 0.66667\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3722\tTop_Loss: 0.3848\tBottom_Loss: 0.5198\tLoss: 1.2768\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3130\tTop_Loss: 0.4697\tBottom_Loss: 0.4780\tLoss: 1.2607\t\n",
      "Subject: 23, n=08 | test_f1: 0.22222 |best_f1: 0.66667\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2515\tTop_Loss: 0.4016\tBottom_Loss: 0.5105\tLoss: 1.1636\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3454\tTop_Loss: 0.4488\tBottom_Loss: 0.4063\tLoss: 1.2005\t\n",
      "Subject: 23, n=08 | test_f1: 0.18182 |best_f1: 0.66667\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2628\tTop_Loss: 0.3329\tBottom_Loss: 0.3764\tLoss: 0.9722\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2588\tTop_Loss: 0.4202\tBottom_Loss: 0.3606\tLoss: 1.0395\t\n",
      "Subject: 23, n=08 | test_f1: 0.38462 |best_f1: 0.66667\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1726\tTop_Loss: 0.3789\tBottom_Loss: 0.2536\tLoss: 0.8050\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4062\tTop_Loss: 0.5110\tBottom_Loss: 0.4935\tLoss: 1.4108\t\n",
      "Subject: 23, n=08 | test_f1: 0.38462 |best_f1: 0.66667\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2434\tTop_Loss: 0.4317\tBottom_Loss: 0.2909\tLoss: 0.9660\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2326\tTop_Loss: 0.4199\tBottom_Loss: 0.3361\tLoss: 0.9887\t\n",
      "Subject: 23, n=08 | test_f1: 0.22222 |best_f1: 0.66667\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3600\tTop_Loss: 0.5581\tBottom_Loss: 0.4049\tLoss: 1.3230\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2478\tTop_Loss: 0.4359\tBottom_Loss: 0.3787\tLoss: 1.0624\t\n",
      "Subject: 23, n=08 | test_f1: 0.13333 |best_f1: 0.66667\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2657\tTop_Loss: 0.3841\tBottom_Loss: 0.2734\tLoss: 0.9232\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.938\tLabel_Loss: 0.3601\tTop_Loss: 0.4907\tBottom_Loss: 0.5644\tLoss: 1.4151\t\n",
      "Subject: 23, n=08 | test_f1: 0.22222 |best_f1: 0.66667\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1810\tTop_Loss: 0.3897\tBottom_Loss: 0.3257\tLoss: 0.8963\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0863\tTop_Loss: 0.2824\tBottom_Loss: 0.2067\tLoss: 0.5754\t\n",
      "Subject: 23, n=08 | test_f1: 0.42857 |best_f1: 0.66667\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2022\tTop_Loss: 0.3132\tBottom_Loss: 0.3462\tLoss: 0.8616\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1649\tTop_Loss: 0.2947\tBottom_Loss: 0.2759\tLoss: 0.7354\t\n",
      "Subject: 23, n=08 | test_f1: 0.42857 |best_f1: 0.66667\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1897\tTop_Loss: 0.3118\tBottom_Loss: 0.2997\tLoss: 0.8013\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2274\tTop_Loss: 0.4266\tBottom_Loss: 0.3124\tLoss: 0.9664\t\n",
      "Subject: 23, n=08 | test_f1: 0.25641 |best_f1: 0.66667\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1795\tTop_Loss: 0.3260\tBottom_Loss: 0.3339\tLoss: 0.8395\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1366\tTop_Loss: 0.2804\tBottom_Loss: 0.3522\tLoss: 0.7692\t\n",
      "Subject: 23, n=08 | test_f1: 0.27778 |best_f1: 0.66667\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2261\tTop_Loss: 0.4112\tBottom_Loss: 0.3400\tLoss: 0.9773\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3015\tTop_Loss: 0.3515\tBottom_Loss: 0.3462\tLoss: 0.9991\t\n",
      "Subject: 23, n=08 | test_f1: 0.22222 |best_f1: 0.66667\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1813\tTop_Loss: 0.2634\tBottom_Loss: 0.2924\tLoss: 0.7371\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1810\tTop_Loss: 0.3999\tBottom_Loss: 0.2371\tLoss: 0.8180\t\n",
      "Subject: 23, n=08 | test_f1: 0.28571 |best_f1: 0.66667\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0977\tTop_Loss: 0.2292\tBottom_Loss: 0.2429\tLoss: 0.5698\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2300\tTop_Loss: 0.2717\tBottom_Loss: 0.3568\tLoss: 0.8585\t\n",
      "Subject: 23, n=08 | test_f1: 0.22222 |best_f1: 0.66667\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1391\tTop_Loss: 0.3562\tBottom_Loss: 0.1757\tLoss: 0.6710\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1931\tTop_Loss: 0.4094\tBottom_Loss: 0.2385\tLoss: 0.8410\t\n",
      "Subject: 23, n=08 | test_f1: 0.24242 |best_f1: 0.66667\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1552\tTop_Loss: 0.4013\tBottom_Loss: 0.2522\tLoss: 0.8088\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1719\tTop_Loss: 0.2413\tBottom_Loss: 0.3508\tLoss: 0.7640\t\n",
      "Subject: 23, n=08 | test_f1: 0.25641 |best_f1: 0.66667\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1006\tTop_Loss: 0.3034\tBottom_Loss: 0.2043\tLoss: 0.6083\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1523\tTop_Loss: 0.3009\tBottom_Loss: 0.2866\tLoss: 0.7398\t\n",
      "Subject: 23, n=08 | test_f1: 0.25641 |best_f1: 0.66667\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1064\tTop_Loss: 0.2708\tBottom_Loss: 0.2888\tLoss: 0.6659\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1179\tTop_Loss: 0.3039\tBottom_Loss: 0.1947\tLoss: 0.6165\t\n",
      "Subject: 23, n=08 | test_f1: 0.33333 |best_f1: 0.66667\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1207\tTop_Loss: 0.2138\tBottom_Loss: 0.1640\tLoss: 0.4985\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1638\tTop_Loss: 0.3144\tBottom_Loss: 0.3278\tLoss: 0.8060\t\n",
      "Subject: 23, n=08 | test_f1: 0.25641 |best_f1: 0.66667\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0368\tTop_Loss: 0.1044\tBottom_Loss: 0.1414\tLoss: 0.2827\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2053\tTop_Loss: 0.2719\tBottom_Loss: 0.3196\tLoss: 0.7967\t\n",
      "Subject: 23, n=08 | test_f1: 0.25641 |best_f1: 0.66667\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1208\tTop_Loss: 0.1560\tBottom_Loss: 0.1164\tLoss: 0.3932\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0729\tTop_Loss: 0.2185\tBottom_Loss: 0.1302\tLoss: 0.4216\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 23, n=08 | test_f1: 0.18182 |best_f1: 0.66667\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1574\tTop_Loss: 0.2867\tBottom_Loss: 0.2829\tLoss: 0.7270\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1983\tTop_Loss: 0.2909\tBottom_Loss: 0.2418\tLoss: 0.7310\t\n",
      "Subject: 23, n=08 | test_f1: 0.27778 |best_f1: 0.66667\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0638\tTop_Loss: 0.2346\tBottom_Loss: 0.1218\tLoss: 0.4202\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1181\tTop_Loss: 0.2336\tBottom_Loss: 0.2827\tLoss: 0.6344\t\n",
      "Subject: 23, n=08 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0527\tTop_Loss: 0.2184\tBottom_Loss: 0.1160\tLoss: 0.3871\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1788\tTop_Loss: 0.2107\tBottom_Loss: 0.2770\tLoss: 0.6665\t\n",
      "Subject: 23, n=08 | test_f1: 0.25641 |best_f1: 1.0\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1240\tTop_Loss: 0.2048\tBottom_Loss: 0.0991\tLoss: 0.4280\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1008\tTop_Loss: 0.1947\tBottom_Loss: 0.1720\tLoss: 0.4675\t\n",
      "Subject: 23, n=08 | test_f1: 0.24242 |best_f1: 1.0\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1113\tTop_Loss: 0.1825\tBottom_Loss: 0.2017\tLoss: 0.4955\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0573\tTop_Loss: 0.1617\tBottom_Loss: 0.1304\tLoss: 0.3494\t\n",
      "Subject: 23, n=08 | test_f1: 0.24242 |best_f1: 1.0\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0648\tTop_Loss: 0.1944\tBottom_Loss: 0.1317\tLoss: 0.3909\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0779\tTop_Loss: 0.1852\tBottom_Loss: 0.1350\tLoss: 0.3981\t\n",
      "Subject: 23, n=08 | test_f1: 0.28571 |best_f1: 1.0\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0918\tTop_Loss: 0.1835\tBottom_Loss: 0.1860\tLoss: 0.4612\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1040\tTop_Loss: 0.1872\tBottom_Loss: 0.2108\tLoss: 0.5020\t\n",
      "Subject: 23, n=08 | test_f1: 0.38462 |best_f1: 1.0\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1084\tTop_Loss: 0.1833\tBottom_Loss: 0.2087\tLoss: 0.5004\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0838\tTop_Loss: 0.2115\tBottom_Loss: 0.1381\tLoss: 0.4334\t\n",
      "Subject: 23, n=08 | test_f1: 0.38462 |best_f1: 1.0\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0507\tTop_Loss: 0.2029\tBottom_Loss: 0.1203\tLoss: 0.3739\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0831\tTop_Loss: 0.2130\tBottom_Loss: 0.1419\tLoss: 0.4380\t\n",
      "Subject: 23, n=08 | test_f1: 0.5 |best_f1: 1.0\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0353\tTop_Loss: 0.1149\tBottom_Loss: 0.1231\tLoss: 0.2733\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1340\tTop_Loss: 0.2643\tBottom_Loss: 0.1864\tLoss: 0.5846\t\n",
      "Subject: 23, n=08 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0630\tTop_Loss: 0.1168\tBottom_Loss: 0.1430\tLoss: 0.3227\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0433\tTop_Loss: 0.1649\tBottom_Loss: 0.0610\tLoss: 0.2691\t\n",
      "Subject: 23, n=08 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0535\tTop_Loss: 0.1315\tBottom_Loss: 0.0818\tLoss: 0.2668\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0633\tTop_Loss: 0.1820\tBottom_Loss: 0.0920\tLoss: 0.3373\t\n",
      "Subject: 23, n=08 | test_f1: 0.25641 |best_f1: 1.0\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0206\tTop_Loss: 0.0616\tBottom_Loss: 0.0691\tLoss: 0.1512\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1152\tTop_Loss: 0.3003\tBottom_Loss: 0.1874\tLoss: 0.6030\t\n",
      "Subject: 23, n=08 | test_f1: 0.27778 |best_f1: 1.0\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0993\tTop_Loss: 0.0911\tBottom_Loss: 0.1354\tLoss: 0.3257\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0494\tTop_Loss: 0.0637\tBottom_Loss: 0.0784\tLoss: 0.1915\t\n",
      "Subject: 23, n=08 | test_f1: 0.2 |best_f1: 1.0\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0285\tTop_Loss: 0.1227\tBottom_Loss: 0.0634\tLoss: 0.2145\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0801\tTop_Loss: 0.1165\tBottom_Loss: 0.0689\tLoss: 0.2655\t\n",
      "Subject: 23, n=08 | test_f1: 0.18182 |best_f1: 1.0\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0781\tTop_Loss: 0.1164\tBottom_Loss: 0.1673\tLoss: 0.3618\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0419\tTop_Loss: 0.1203\tBottom_Loss: 0.1088\tLoss: 0.2710\t\n",
      "Subject: 23, n=08 | test_f1: 0.38462 |best_f1: 1.0\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0372\tTop_Loss: 0.0933\tBottom_Loss: 0.0804\tLoss: 0.2109\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0419\tTop_Loss: 0.0993\tBottom_Loss: 0.1087\tLoss: 0.2500\t\n",
      "Subject: 23, n=08 | test_f1: 0.38462 |best_f1: 1.0\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0325\tTop_Loss: 0.0969\tBottom_Loss: 0.0631\tLoss: 0.1925\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0730\tTop_Loss: 0.1289\tBottom_Loss: 0.1213\tLoss: 0.3233\t\n",
      "Subject: 23, n=08 | test_f1: 0.25641 |best_f1: 1.0\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0576\tTop_Loss: 0.1521\tBottom_Loss: 0.0998\tLoss: 0.3095\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0542\tTop_Loss: 0.1981\tBottom_Loss: 0.1610\tLoss: 0.4134\t\n",
      "Subject: 23, n=08 | test_f1: 0.46465 |best_f1: 1.0\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0317\tTop_Loss: 0.0969\tBottom_Loss: 0.0778\tLoss: 0.2064\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0163\tTop_Loss: 0.1153\tBottom_Loss: 0.0456\tLoss: 0.1772\t\n",
      "Subject: 23, n=08 | test_f1: 0.5 |best_f1: 1.0\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0478\tTop_Loss: 0.1310\tBottom_Loss: 0.0630\tLoss: 0.2418\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0344\tTop_Loss: 0.0959\tBottom_Loss: 0.1324\tLoss: 0.2627\t\n",
      "Subject: 23, n=08 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0244\tTop_Loss: 0.0464\tBottom_Loss: 0.1112\tLoss: 0.1820\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0511\tTop_Loss: 0.0992\tBottom_Loss: 0.0883\tLoss: 0.2386\t\n",
      "Subject: 23, n=08 | test_f1: 0.79487 |best_f1: 1.0\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0628\tTop_Loss: 0.1348\tBottom_Loss: 0.1102\tLoss: 0.3078\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1402\tTop_Loss: 0.3342\tBottom_Loss: 0.1500\tLoss: 0.6244\t\n",
      "Subject: 23, n=08 | test_f1: 0.18182 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0337\tTop_Loss: 0.1261\tBottom_Loss: 0.0434\tLoss: 0.2032\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0218\tTop_Loss: 0.0690\tBottom_Loss: 0.1056\tLoss: 0.1964\t\n",
      "Subject: 23, n=08 | test_f1: 0.38462 |best_f1: 1.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0179\tTop_Loss: 0.0944\tBottom_Loss: 0.0545\tLoss: 0.1669\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0296\tTop_Loss: 0.0699\tBottom_Loss: 0.0744\tLoss: 0.1739\t\n",
      "Subject: 23, n=08 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0342\tTop_Loss: 0.0822\tBottom_Loss: 0.0616\tLoss: 0.1781\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0309\tTop_Loss: 0.1176\tBottom_Loss: 0.0495\tLoss: 0.1980\t\n",
      "Subject: 23, n=08 | test_f1: 0.27778 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0247\tTop_Loss: 0.0685\tBottom_Loss: 0.0340\tLoss: 0.1272\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0208\tTop_Loss: 0.0756\tBottom_Loss: 0.0642\tLoss: 0.1606\t\n",
      "Subject: 23, n=08 | test_f1: 0.30769 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0189\tTop_Loss: 0.0734\tBottom_Loss: 0.0423\tLoss: 0.1346\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0415\tTop_Loss: 0.0959\tBottom_Loss: 0.1150\tLoss: 0.2524\t\n",
      "Subject: 23, n=08 | test_f1: 0.25641 |best_f1: 1.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0231\tTop_Loss: 0.0755\tBottom_Loss: 0.0454\tLoss: 0.1439\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0158\tTop_Loss: 0.0752\tBottom_Loss: 0.0421\tLoss: 0.1332\t\n",
      "Subject: 23, n=08 | test_f1: 0.46667 |best_f1: 1.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0245\tTop_Loss: 0.0873\tBottom_Loss: 0.0766\tLoss: 0.1885\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0379\tTop_Loss: 0.1181\tBottom_Loss: 0.0684\tLoss: 0.2244\t\n",
      "Subject: 23, n=08 | test_f1: 0.38462 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0154\tTop_Loss: 0.0522\tBottom_Loss: 0.0594\tLoss: 0.1269\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0417\tTop_Loss: 0.1286\tBottom_Loss: 0.0467\tLoss: 0.2171\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 23, n=08 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0239\tTop_Loss: 0.0877\tBottom_Loss: 0.0825\tLoss: 0.1942\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0201\tTop_Loss: 0.0797\tBottom_Loss: 0.0529\tLoss: 0.1528\t\n",
      "Subject: 23, n=08 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0085\tTop_Loss: 0.0269\tBottom_Loss: 0.0708\tLoss: 0.1062\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0102\tTop_Loss: 0.0334\tBottom_Loss: 0.0269\tLoss: 0.0705\t\n",
      "Subject: 23, n=08 | test_f1: 0.24242 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0076\tTop_Loss: 0.0343\tBottom_Loss: 0.0306\tLoss: 0.0725\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0170\tTop_Loss: 0.0598\tBottom_Loss: 0.0429\tLoss: 0.1197\t\n",
      "Subject: 23, n=08 | test_f1: 0.66667 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0163\tTop_Loss: 0.0390\tBottom_Loss: 0.0470\tLoss: 0.1023\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0123\tTop_Loss: 0.0479\tBottom_Loss: 0.0367\tLoss: 0.0969\t\n",
      "Subject: 23, n=08 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0693\tTop_Loss: 0.1173\tBottom_Loss: 0.0897\tLoss: 0.2763\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0114\tTop_Loss: 0.0559\tBottom_Loss: 0.0649\tLoss: 0.1323\t\n",
      "Subject: 23, n=08 | test_f1: 0.2 |best_f1: 1.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0075\tTop_Loss: 0.0215\tBottom_Loss: 0.0251\tLoss: 0.0541\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0303\tTop_Loss: 0.1091\tBottom_Loss: 0.0610\tLoss: 0.2004\t\n",
      "Subject: 23, n=08 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0093\tTop_Loss: 0.0968\tBottom_Loss: 0.0393\tLoss: 0.1454\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0164\tTop_Loss: 0.0392\tBottom_Loss: 0.0358\tLoss: 0.0914\t\n",
      "Subject: 23, n=08 | test_f1: 0.28571 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0238\tTop_Loss: 0.0616\tBottom_Loss: 0.0209\tLoss: 0.1063\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0439\tTop_Loss: 0.0689\tBottom_Loss: 0.0972\tLoss: 0.2100\t\n",
      "Subject: 23, n=08 | test_f1: 0.25641 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0077\tTop_Loss: 0.0485\tBottom_Loss: 0.0188\tLoss: 0.0750\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0343\tTop_Loss: 0.0470\tBottom_Loss: 0.0402\tLoss: 0.1215\t\n",
      "Subject: 23, n=08 | test_f1: 0.30769 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0276\tTop_Loss: 0.0425\tBottom_Loss: 0.0415\tLoss: 0.1117\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0085\tTop_Loss: 0.0533\tBottom_Loss: 0.0362\tLoss: 0.0980\t\n",
      "Subject: 23, n=08 | test_f1: 0.27778 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0097\tTop_Loss: 0.0431\tBottom_Loss: 0.0545\tLoss: 0.1073\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0412\tTop_Loss: 0.0568\tBottom_Loss: 0.0977\tLoss: 0.1956\t\n",
      "Subject: 23, n=08 | test_f1: 0.66667 |best_f1: 1.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0202\tTop_Loss: 0.0825\tBottom_Loss: 0.0280\tLoss: 0.1306\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0186\tTop_Loss: 0.0457\tBottom_Loss: 0.0446\tLoss: 0.1089\t\n",
      "Subject: 23, n=08 | test_f1: 0.5 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0072\tTop_Loss: 0.0343\tBottom_Loss: 0.0418\tLoss: 0.0834\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0075\tTop_Loss: 0.0521\tBottom_Loss: 0.0142\tLoss: 0.0738\t\n",
      "Subject: 23, n=08 | test_f1: 0.61111 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0192\tTop_Loss: 0.0451\tBottom_Loss: 0.0388\tLoss: 0.1032\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0081\tTop_Loss: 0.0278\tBottom_Loss: 0.0151\tLoss: 0.0510\t\n",
      "Subject: 23, n=08 | test_f1: 0.27778 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0060\tTop_Loss: 0.0545\tBottom_Loss: 0.0108\tLoss: 0.0712\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 0.938\tLabel_Loss: 0.0722\tTop_Loss: 0.0941\tBottom_Loss: 0.1210\tLoss: 0.2872\t\n",
      "Subject: 23, n=08 | test_f1: 0.42857 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0072\tTop_Loss: 0.0201\tBottom_Loss: 0.0167\tLoss: 0.0440\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0061\tTop_Loss: 0.0451\tBottom_Loss: 0.0141\tLoss: 0.0653\t\n",
      "Subject: 23, n=08 | test_f1: 0.66667 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0081\tTop_Loss: 0.0492\tBottom_Loss: 0.0151\tLoss: 0.0724\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0174\tTop_Loss: 0.0408\tBottom_Loss: 0.0272\tLoss: 0.0854\t\n",
      "Subject: 23, n=08 | test_f1: 0.30769 |best_f1: 1.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0080\tTop_Loss: 0.0208\tBottom_Loss: 0.0242\tLoss: 0.0530\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0080\tTop_Loss: 0.0384\tBottom_Loss: 0.0206\tLoss: 0.0670\t\n",
      "Subject: 23, n=08 | test_f1: 0.25641 |best_f1: 1.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.406\tLabel_Loss: 1.2322\tTop_Loss: 1.7601\tBottom_Loss: 1.2323\tLoss: 4.2246\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.406\tLabel_Loss: 1.2025\tTop_Loss: 1.2981\tBottom_Loss: 1.1155\tLoss: 3.6162\t\n",
      "Subject: 24, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.500\tLabel_Loss: 1.1515\tTop_Loss: 1.1229\tBottom_Loss: 1.0932\tLoss: 3.3675\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.656\tLabel_Loss: 0.8917\tTop_Loss: 0.8614\tBottom_Loss: 0.7591\tLoss: 2.5122\t\n",
      "Subject: 24, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.531\tLabel_Loss: 0.9234\tTop_Loss: 1.0487\tBottom_Loss: 0.8489\tLoss: 2.8210\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.688\tLabel_Loss: 0.8449\tTop_Loss: 0.9769\tBottom_Loss: 0.8188\tLoss: 2.6405\t\n",
      "Subject: 24, n=03 | test_f1: 0.4 |best_f1: 0.4\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7924\tTop_Loss: 0.8149\tBottom_Loss: 0.9006\tLoss: 2.5078\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.438\tLabel_Loss: 1.2933\tTop_Loss: 1.0514\tBottom_Loss: 1.0530\tLoss: 3.3977\t\n",
      "Subject: 24, n=03 | test_f1: 0.22222 |best_f1: 0.4\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.562\tLabel_Loss: 0.8219\tTop_Loss: 0.9732\tBottom_Loss: 0.9233\tLoss: 2.7184\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8238\tTop_Loss: 0.7607\tBottom_Loss: 0.8036\tLoss: 2.3881\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 0.55556\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.656\tLabel_Loss: 0.6331\tTop_Loss: 0.8184\tBottom_Loss: 0.7106\tLoss: 2.1621\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8056\tTop_Loss: 0.8000\tBottom_Loss: 0.8169\tLoss: 2.4224\t\n",
      "Subject: 24, n=03 | test_f1: 0.16667 |best_f1: 0.55556\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.531\tLabel_Loss: 1.0645\tTop_Loss: 1.0019\tBottom_Loss: 1.0927\tLoss: 3.1591\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7706\tTop_Loss: 0.6839\tBottom_Loss: 0.8676\tLoss: 2.3221\t\n",
      "Subject: 24, n=03 | test_f1: 0.25 |best_f1: 0.55556\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.781\tLabel_Loss: 0.7211\tTop_Loss: 0.8163\tBottom_Loss: 0.7496\tLoss: 2.2870\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7950\tTop_Loss: 0.8430\tBottom_Loss: 0.9646\tLoss: 2.6026\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 0.55556\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.656\tLabel_Loss: 0.8523\tTop_Loss: 0.8926\tBottom_Loss: 0.8968\tLoss: 2.6418\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.625\tLabel_Loss: 0.9646\tTop_Loss: 0.9749\tBottom_Loss: 0.9019\tLoss: 2.8415\t\n",
      "Subject: 24, n=03 | test_f1: 0.4 |best_f1: 0.55556\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8818\tTop_Loss: 0.7509\tBottom_Loss: 0.9134\tLoss: 2.5461\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.562\tLabel_Loss: 0.8063\tTop_Loss: 0.8832\tBottom_Loss: 0.8038\tLoss: 2.4934\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 0.55556\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7980\tTop_Loss: 1.0878\tBottom_Loss: 0.8187\tLoss: 2.7045\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.656\tLabel_Loss: 0.8835\tTop_Loss: 0.9372\tBottom_Loss: 0.8312\tLoss: 2.6519\t\n",
      "Subject: 24, n=03 | test_f1: 0.16667 |best_f1: 0.55556\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5371\tTop_Loss: 0.5882\tBottom_Loss: 0.7344\tLoss: 1.8597\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5469\tTop_Loss: 0.6651\tBottom_Loss: 0.6623\tLoss: 1.8744\t\n",
      "Subject: 24, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6529\tTop_Loss: 0.7213\tBottom_Loss: 0.8320\tLoss: 2.2062\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6606\tTop_Loss: 0.7843\tBottom_Loss: 0.6767\tLoss: 2.1216\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 24, n=03 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.781\tLabel_Loss: 0.6079\tTop_Loss: 0.6754\tBottom_Loss: 0.7944\tLoss: 2.0777\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6938\tTop_Loss: 0.6207\tBottom_Loss: 0.7795\tLoss: 2.0940\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6197\tTop_Loss: 0.7405\tBottom_Loss: 0.7113\tLoss: 2.0715\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7816\tTop_Loss: 0.8731\tBottom_Loss: 0.8731\tLoss: 2.5277\t\n",
      "Subject: 24, n=03 | test_f1: 0.66667 |best_f1: 1.0\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6322\tTop_Loss: 0.6816\tBottom_Loss: 0.6829\tLoss: 1.9966\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4843\tTop_Loss: 0.5875\tBottom_Loss: 0.7275\tLoss: 1.7993\t\n",
      "Subject: 24, n=03 | test_f1: 0.66667 |best_f1: 1.0\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8968\tTop_Loss: 1.0568\tBottom_Loss: 0.8859\tLoss: 2.8395\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.594\tLabel_Loss: 0.6751\tTop_Loss: 0.8142\tBottom_Loss: 0.9032\tLoss: 2.3925\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.844\tLabel_Loss: 0.5022\tTop_Loss: 0.8391\tBottom_Loss: 0.8322\tLoss: 2.1735\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4770\tTop_Loss: 0.5911\tBottom_Loss: 0.6933\tLoss: 1.7614\t\n",
      "Subject: 24, n=03 | test_f1: 0.66667 |best_f1: 1.0\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5040\tTop_Loss: 0.5190\tBottom_Loss: 0.5624\tLoss: 1.5855\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4193\tTop_Loss: 0.5312\tBottom_Loss: 0.5088\tLoss: 1.4593\t\n",
      "Subject: 24, n=03 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4593\tTop_Loss: 0.5063\tBottom_Loss: 0.5501\tLoss: 1.5157\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.719\tLabel_Loss: 0.5246\tTop_Loss: 0.5491\tBottom_Loss: 0.6401\tLoss: 1.7138\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5752\tTop_Loss: 0.6251\tBottom_Loss: 0.7319\tLoss: 1.9323\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5266\tTop_Loss: 0.6230\tBottom_Loss: 0.7900\tLoss: 1.9396\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4862\tTop_Loss: 0.5957\tBottom_Loss: 0.6609\tLoss: 1.7428\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.781\tLabel_Loss: 0.6235\tTop_Loss: 0.7873\tBottom_Loss: 0.6989\tLoss: 2.1097\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3277\tTop_Loss: 0.5229\tBottom_Loss: 0.5225\tLoss: 1.3730\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5059\tTop_Loss: 0.7396\tBottom_Loss: 0.5090\tLoss: 1.7545\t\n",
      "Subject: 24, n=03 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5351\tTop_Loss: 0.6810\tBottom_Loss: 0.5173\tLoss: 1.7334\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.625\tLabel_Loss: 0.6668\tTop_Loss: 0.8088\tBottom_Loss: 0.7354\tLoss: 2.2110\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3721\tTop_Loss: 0.5752\tBottom_Loss: 0.5017\tLoss: 1.4490\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.656\tLabel_Loss: 0.5902\tTop_Loss: 0.6181\tBottom_Loss: 0.6169\tLoss: 1.8252\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3036\tTop_Loss: 0.5144\tBottom_Loss: 0.4386\tLoss: 1.2566\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4218\tTop_Loss: 0.6481\tBottom_Loss: 0.5136\tLoss: 1.5835\t\n",
      "Subject: 24, n=03 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4214\tTop_Loss: 0.5473\tBottom_Loss: 0.5562\tLoss: 1.5249\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3153\tTop_Loss: 0.4393\tBottom_Loss: 0.3959\tLoss: 1.1505\t\n",
      "Subject: 24, n=03 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3372\tTop_Loss: 0.3870\tBottom_Loss: 0.4981\tLoss: 1.2223\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.781\tLabel_Loss: 0.3963\tTop_Loss: 0.5320\tBottom_Loss: 0.5760\tLoss: 1.5042\t\n",
      "Subject: 24, n=03 | test_f1: 0.66667 |best_f1: 1.0\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2149\tTop_Loss: 0.4321\tBottom_Loss: 0.4123\tLoss: 1.0594\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3597\tTop_Loss: 0.3997\tBottom_Loss: 0.5011\tLoss: 1.2605\t\n",
      "Subject: 24, n=03 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2885\tTop_Loss: 0.4279\tBottom_Loss: 0.3704\tLoss: 1.0868\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3948\tTop_Loss: 0.6190\tBottom_Loss: 0.4573\tLoss: 1.4712\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3251\tTop_Loss: 0.4180\tBottom_Loss: 0.3363\tLoss: 1.0795\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3619\tTop_Loss: 0.4249\tBottom_Loss: 0.4663\tLoss: 1.2532\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5055\tTop_Loss: 0.4813\tBottom_Loss: 0.6018\tLoss: 1.5886\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2830\tTop_Loss: 0.3666\tBottom_Loss: 0.4242\tLoss: 1.0737\t\n",
      "Subject: 24, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2833\tTop_Loss: 0.5625\tBottom_Loss: 0.5103\tLoss: 1.3561\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3177\tTop_Loss: 0.3807\tBottom_Loss: 0.4372\tLoss: 1.1356\t\n",
      "Subject: 24, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3590\tTop_Loss: 0.5828\tBottom_Loss: 0.6053\tLoss: 1.5471\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3130\tTop_Loss: 0.4449\tBottom_Loss: 0.3384\tLoss: 1.0963\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1850\tTop_Loss: 0.4325\tBottom_Loss: 0.3597\tLoss: 0.9772\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1617\tTop_Loss: 0.3823\tBottom_Loss: 0.2803\tLoss: 0.8243\t\n",
      "Subject: 24, n=03 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3860\tTop_Loss: 0.4243\tBottom_Loss: 0.5452\tLoss: 1.3555\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3239\tTop_Loss: 0.5413\tBottom_Loss: 0.3075\tLoss: 1.1727\t\n",
      "Subject: 24, n=03 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1322\tTop_Loss: 0.3079\tBottom_Loss: 0.1911\tLoss: 0.6312\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2661\tTop_Loss: 0.4607\tBottom_Loss: 0.2680\tLoss: 0.9949\t\n",
      "Subject: 24, n=03 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2580\tTop_Loss: 0.4145\tBottom_Loss: 0.3331\tLoss: 1.0056\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1892\tTop_Loss: 0.3222\tBottom_Loss: 0.2471\tLoss: 0.7585\t\n",
      "Subject: 24, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2526\tTop_Loss: 0.4300\tBottom_Loss: 0.3313\tLoss: 1.0138\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1502\tTop_Loss: 0.3859\tBottom_Loss: 0.3121\tLoss: 0.8482\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2471\tTop_Loss: 0.4513\tBottom_Loss: 0.2761\tLoss: 0.9744\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1754\tTop_Loss: 0.3611\tBottom_Loss: 0.3080\tLoss: 0.8445\t\n",
      "Subject: 24, n=03 | test_f1: 0.66667 |best_f1: 1.0\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2788\tTop_Loss: 0.4379\tBottom_Loss: 0.3392\tLoss: 1.0559\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1170\tTop_Loss: 0.2418\tBottom_Loss: 0.1974\tLoss: 0.5562\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1469\tTop_Loss: 0.2373\tBottom_Loss: 0.2328\tLoss: 0.6170\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1241\tTop_Loss: 0.3452\tBottom_Loss: 0.1705\tLoss: 0.6398\t\n",
      "Subject: 24, n=03 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1158\tTop_Loss: 0.2710\tBottom_Loss: 0.1930\tLoss: 0.5799\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2550\tTop_Loss: 0.3053\tBottom_Loss: 0.5112\tLoss: 1.0715\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1515\tTop_Loss: 0.2882\tBottom_Loss: 0.2218\tLoss: 0.6615\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0977\tTop_Loss: 0.1686\tBottom_Loss: 0.2048\tLoss: 0.4711\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1154\tTop_Loss: 0.2986\tBottom_Loss: 0.1735\tLoss: 0.5876\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2086\tTop_Loss: 0.3516\tBottom_Loss: 0.3307\tLoss: 0.8908\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1676\tTop_Loss: 0.2812\tBottom_Loss: 0.2471\tLoss: 0.6958\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2000\tTop_Loss: 0.4051\tBottom_Loss: 0.2818\tLoss: 0.8869\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1611\tTop_Loss: 0.2315\tBottom_Loss: 0.2298\tLoss: 0.6224\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1439\tTop_Loss: 0.3181\tBottom_Loss: 0.2400\tLoss: 0.7019\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1201\tTop_Loss: 0.3171\tBottom_Loss: 0.1494\tLoss: 0.5866\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0424\tTop_Loss: 0.2014\tBottom_Loss: 0.0943\tLoss: 0.3381\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1135\tTop_Loss: 0.1960\tBottom_Loss: 0.1954\tLoss: 0.5049\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1400\tTop_Loss: 0.3858\tBottom_Loss: 0.2147\tLoss: 0.7404\t\n",
      "Subject: 24, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1503\tTop_Loss: 0.2810\tBottom_Loss: 0.3009\tLoss: 0.7322\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1474\tTop_Loss: 0.2525\tBottom_Loss: 0.1912\tLoss: 0.5911\t\n",
      "Subject: 24, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1608\tTop_Loss: 0.1849\tBottom_Loss: 0.2464\tLoss: 0.5921\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1014\tTop_Loss: 0.2385\tBottom_Loss: 0.1566\tLoss: 0.4965\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1168\tTop_Loss: 0.1294\tBottom_Loss: 0.2315\tLoss: 0.4776\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1207\tTop_Loss: 0.2388\tBottom_Loss: 0.2230\tLoss: 0.5825\t\n",
      "Subject: 24, n=03 | test_f1: 0.66667 |best_f1: 1.0\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2669\tTop_Loss: 0.4202\tBottom_Loss: 0.3548\tLoss: 1.0419\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1921\tTop_Loss: 0.2182\tBottom_Loss: 0.2884\tLoss: 0.6988\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.938\tLabel_Loss: 0.0989\tTop_Loss: 0.2219\tBottom_Loss: 0.1847\tLoss: 0.5055\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0847\tTop_Loss: 0.1454\tBottom_Loss: 0.1264\tLoss: 0.3565\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0649\tTop_Loss: 0.2307\tBottom_Loss: 0.1084\tLoss: 0.4041\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0557\tTop_Loss: 0.1111\tBottom_Loss: 0.1408\tLoss: 0.3075\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1149\tTop_Loss: 0.1833\tBottom_Loss: 0.1974\tLoss: 0.4956\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0825\tTop_Loss: 0.3160\tBottom_Loss: 0.1244\tLoss: 0.5228\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0971\tTop_Loss: 0.2720\tBottom_Loss: 0.0904\tLoss: 0.4595\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1282\tTop_Loss: 0.1580\tBottom_Loss: 0.2570\tLoss: 0.5433\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1105\tTop_Loss: 0.2062\tBottom_Loss: 0.1219\tLoss: 0.4386\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1182\tTop_Loss: 0.2567\tBottom_Loss: 0.1693\tLoss: 0.5442\t\n",
      "Subject: 24, n=03 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0679\tTop_Loss: 0.1367\tBottom_Loss: 0.1572\tLoss: 0.3618\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1152\tTop_Loss: 0.1504\tBottom_Loss: 0.1098\tLoss: 0.3754\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0893\tTop_Loss: 0.1551\tBottom_Loss: 0.0986\tLoss: 0.3429\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1541\tTop_Loss: 0.2125\tBottom_Loss: 0.1437\tLoss: 0.5104\t\n",
      "Subject: 24, n=03 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1913\tTop_Loss: 0.3352\tBottom_Loss: 0.2408\tLoss: 0.7673\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0576\tTop_Loss: 0.1619\tBottom_Loss: 0.0805\tLoss: 0.3001\t\n",
      "Subject: 24, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0579\tTop_Loss: 0.1667\tBottom_Loss: 0.1041\tLoss: 0.3287\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1354\tTop_Loss: 0.2210\tBottom_Loss: 0.1461\tLoss: 0.5026\t\n",
      "Subject: 24, n=03 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0901\tTop_Loss: 0.1443\tBottom_Loss: 0.1728\tLoss: 0.4073\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0350\tTop_Loss: 0.0996\tBottom_Loss: 0.1032\tLoss: 0.2378\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1426\tTop_Loss: 0.2003\tBottom_Loss: 0.2229\tLoss: 0.5658\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1155\tTop_Loss: 0.2296\tBottom_Loss: 0.1211\tLoss: 0.4662\t\n",
      "Subject: 24, n=03 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0568\tTop_Loss: 0.1626\tBottom_Loss: 0.1441\tLoss: 0.3634\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0373\tTop_Loss: 0.1109\tBottom_Loss: 0.0687\tLoss: 0.2170\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0716\tTop_Loss: 0.1200\tBottom_Loss: 0.1418\tLoss: 0.3335\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0507\tTop_Loss: 0.1839\tBottom_Loss: 0.1316\tLoss: 0.3662\t\n",
      "Subject: 24, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0798\tTop_Loss: 0.1012\tBottom_Loss: 0.1103\tLoss: 0.2914\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0346\tTop_Loss: 0.1471\tBottom_Loss: 0.0657\tLoss: 0.2473\t\n",
      "Subject: 24, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0494\tTop_Loss: 0.1047\tBottom_Loss: 0.1025\tLoss: 0.2566\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0864\tTop_Loss: 0.2430\tBottom_Loss: 0.1061\tLoss: 0.4355\t\n",
      "Subject: 24, n=03 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0450\tTop_Loss: 0.1981\tBottom_Loss: 0.0703\tLoss: 0.3133\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0177\tTop_Loss: 0.0678\tBottom_Loss: 0.0278\tLoss: 0.1133\t\n",
      "Subject: 24, n=03 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0816\tTop_Loss: 0.0777\tBottom_Loss: 0.0910\tLoss: 0.2503\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1502\tTop_Loss: 0.1511\tBottom_Loss: 0.1496\tLoss: 0.4508\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0476\tTop_Loss: 0.1216\tBottom_Loss: 0.0558\tLoss: 0.2251\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0613\tTop_Loss: 0.2204\tBottom_Loss: 0.1038\tLoss: 0.3855\t\n",
      "Subject: 24, n=03 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0298\tTop_Loss: 0.1310\tBottom_Loss: 0.0564\tLoss: 0.2173\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0448\tTop_Loss: 0.1675\tBottom_Loss: 0.0618\tLoss: 0.2741\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0242\tTop_Loss: 0.1758\tBottom_Loss: 0.0670\tLoss: 0.2670\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0203\tTop_Loss: 0.0642\tBottom_Loss: 0.0890\tLoss: 0.1735\t\n",
      "Subject: 24, n=03 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0230\tTop_Loss: 0.0692\tBottom_Loss: 0.0522\tLoss: 0.1445\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0303\tTop_Loss: 0.0792\tBottom_Loss: 0.0965\tLoss: 0.2060\t\n",
      "Subject: 24, n=03 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0575\tTop_Loss: 0.1807\tBottom_Loss: 0.1219\tLoss: 0.3601\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0279\tTop_Loss: 0.1302\tBottom_Loss: 0.0379\tLoss: 0.1960\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0332\tTop_Loss: 0.0848\tBottom_Loss: 0.0946\tLoss: 0.2125\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0179\tTop_Loss: 0.0954\tBottom_Loss: 0.0628\tLoss: 0.1761\t\n",
      "Subject: 24, n=03 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0434\tTop_Loss: 0.1084\tBottom_Loss: 0.0977\tLoss: 0.2495\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0168\tTop_Loss: 0.0319\tBottom_Loss: 0.0485\tLoss: 0.0972\t\n",
      "Subject: 24, n=03 | test_f1: 0.25 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0433\tTop_Loss: 0.1990\tBottom_Loss: 0.0629\tLoss: 0.3051\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0203\tTop_Loss: 0.1106\tBottom_Loss: 0.0388\tLoss: 0.1697\t\n",
      "Subject: 24, n=03 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0451\tTop_Loss: 0.0720\tBottom_Loss: 0.0607\tLoss: 0.1778\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0218\tTop_Loss: 0.1264\tBottom_Loss: 0.0393\tLoss: 0.1875\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0564\tTop_Loss: 0.0730\tBottom_Loss: 0.1491\tLoss: 0.2784\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0451\tTop_Loss: 0.2643\tBottom_Loss: 0.0458\tLoss: 0.3552\t\n",
      "Subject: 24, n=03 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0224\tTop_Loss: 0.0763\tBottom_Loss: 0.0429\tLoss: 0.1417\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0367\tTop_Loss: 0.0909\tBottom_Loss: 0.0321\tLoss: 0.1597\t\n",
      "Subject: 24, n=03 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0497\tTop_Loss: 0.0829\tBottom_Loss: 0.0547\tLoss: 0.1874\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0124\tTop_Loss: 0.0468\tBottom_Loss: 0.0278\tLoss: 0.0870\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0778\tTop_Loss: 0.0620\tBottom_Loss: 0.2041\tLoss: 0.3439\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0131\tTop_Loss: 0.0355\tBottom_Loss: 0.0265\tLoss: 0.0750\t\n",
      "Subject: 24, n=03 | test_f1: 0.66667 |best_f1: 1.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0207\tTop_Loss: 0.0798\tBottom_Loss: 0.0660\tLoss: 0.1664\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0199\tTop_Loss: 0.0291\tBottom_Loss: 0.0383\tLoss: 0.0873\t\n",
      "Subject: 24, n=03 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0204\tTop_Loss: 0.0863\tBottom_Loss: 0.0468\tLoss: 0.1534\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0202\tTop_Loss: 0.0500\tBottom_Loss: 0.0343\tLoss: 0.1046\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0244\tTop_Loss: 0.1112\tBottom_Loss: 0.0541\tLoss: 0.1897\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0266\tTop_Loss: 0.0591\tBottom_Loss: 0.0302\tLoss: 0.1160\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0651\tTop_Loss: 0.0911\tBottom_Loss: 0.1016\tLoss: 0.2577\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0167\tTop_Loss: 0.0658\tBottom_Loss: 0.0290\tLoss: 0.1115\t\n",
      "Subject: 24, n=03 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0108\tTop_Loss: 0.0373\tBottom_Loss: 0.0272\tLoss: 0.0753\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0066\tTop_Loss: 0.0383\tBottom_Loss: 0.0229\tLoss: 0.0678\t\n",
      "Subject: 24, n=03 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0159\tTop_Loss: 0.0351\tBottom_Loss: 0.0351\tLoss: 0.0862\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0085\tTop_Loss: 0.0329\tBottom_Loss: 0.0359\tLoss: 0.0773\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0406\tTop_Loss: 0.0483\tBottom_Loss: 0.0832\tLoss: 0.1721\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0131\tTop_Loss: 0.0297\tBottom_Loss: 0.0287\tLoss: 0.0716\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0415\tTop_Loss: 0.1437\tBottom_Loss: 0.0592\tLoss: 0.2445\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0163\tTop_Loss: 0.0357\tBottom_Loss: 0.0277\tLoss: 0.0797\t\n",
      "Subject: 24, n=03 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0243\tTop_Loss: 0.0927\tBottom_Loss: 0.0236\tLoss: 0.1406\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0083\tTop_Loss: 0.0209\tBottom_Loss: 0.0275\tLoss: 0.0567\t\n",
      "Subject: 24, n=03 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0123\tTop_Loss: 0.0331\tBottom_Loss: 0.0205\tLoss: 0.0659\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0125\tTop_Loss: 0.0889\tBottom_Loss: 0.0333\tLoss: 0.1347\t\n",
      "Subject: 24, n=03 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0236\tTop_Loss: 0.0650\tBottom_Loss: 0.0215\tLoss: 0.1102\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0197\tTop_Loss: 0.0560\tBottom_Loss: 0.0216\tLoss: 0.0973\t\n",
      "Subject: 24, n=03 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0084\tTop_Loss: 0.0368\tBottom_Loss: 0.0159\tLoss: 0.0610\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0064\tTop_Loss: 0.0301\tBottom_Loss: 0.0230\tLoss: 0.0596\t\n",
      "Subject: 24, n=03 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0284\tTop_Loss: 0.0664\tBottom_Loss: 0.0293\tLoss: 0.1240\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0129\tTop_Loss: 0.0636\tBottom_Loss: 0.0381\tLoss: 0.1146\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0141\tTop_Loss: 0.0393\tBottom_Loss: 0.0293\tLoss: 0.0827\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0142\tTop_Loss: 0.1040\tBottom_Loss: 0.0330\tLoss: 0.1513\t\n",
      "Subject: 24, n=03 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0063\tTop_Loss: 0.0660\tBottom_Loss: 0.0085\tLoss: 0.0808\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1163\tTop_Loss: 0.0724\tBottom_Loss: 0.2628\tLoss: 0.4515\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0390\tTop_Loss: 0.0443\tBottom_Loss: 0.0767\tLoss: 0.1600\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0052\tTop_Loss: 0.0255\tBottom_Loss: 0.0143\tLoss: 0.0450\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0099\tTop_Loss: 0.0163\tBottom_Loss: 0.0325\tLoss: 0.0587\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0175\tTop_Loss: 0.0782\tBottom_Loss: 0.0530\tLoss: 0.1487\t\n",
      "Subject: 24, n=03 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.344\tLabel_Loss: 1.1349\tTop_Loss: 2.0629\tBottom_Loss: 1.2322\tLoss: 4.4300\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.438\tLabel_Loss: 1.1285\tTop_Loss: 1.3076\tBottom_Loss: 1.1972\tLoss: 3.6334\t\n",
      "Subject: 25, n=05 | test_f1: 0.375 |best_f1: 0.375\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.406\tLabel_Loss: 1.1476\tTop_Loss: 1.0060\tBottom_Loss: 1.0090\tLoss: 3.1627\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.531\tLabel_Loss: 0.9152\tTop_Loss: 0.8457\tBottom_Loss: 1.0776\tLoss: 2.8386\t\n",
      "Subject: 25, n=05 | test_f1: 0.7619 |best_f1: 0.7619\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8077\tTop_Loss: 0.9608\tBottom_Loss: 0.9259\tLoss: 2.6945\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.594\tLabel_Loss: 1.0190\tTop_Loss: 1.1733\tBottom_Loss: 0.9834\tLoss: 3.1757\t\n",
      "Subject: 25, n=05 | test_f1: 0.7619 |best_f1: 0.7619\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.594\tLabel_Loss: 0.9442\tTop_Loss: 1.0932\tBottom_Loss: 1.0647\tLoss: 3.1022\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.594\tLabel_Loss: 0.9035\tTop_Loss: 0.8510\tBottom_Loss: 0.9700\tLoss: 2.7246\t\n",
      "Subject: 25, n=05 | test_f1: 0.28571 |best_f1: 0.7619\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.562\tLabel_Loss: 0.7933\tTop_Loss: 0.8120\tBottom_Loss: 0.9015\tLoss: 2.5068\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.406\tLabel_Loss: 0.9009\tTop_Loss: 0.9039\tBottom_Loss: 0.8979\tLoss: 2.7027\t\n",
      "Subject: 25, n=05 | test_f1: 0.28571 |best_f1: 0.7619\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8557\tTop_Loss: 0.9408\tBottom_Loss: 0.7665\tLoss: 2.5629\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.656\tLabel_Loss: 0.8492\tTop_Loss: 0.9448\tBottom_Loss: 0.9824\tLoss: 2.7764\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 25, n=05 | test_f1: 0.375 |best_f1: 0.7619\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.750\tLabel_Loss: 0.8073\tTop_Loss: 0.8511\tBottom_Loss: 0.7782\tLoss: 2.4366\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.562\tLabel_Loss: 0.9534\tTop_Loss: 0.8244\tBottom_Loss: 0.8299\tLoss: 2.6077\t\n",
      "Subject: 25, n=05 | test_f1: 0.16667 |best_f1: 0.7619\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6736\tTop_Loss: 0.9688\tBottom_Loss: 0.7337\tLoss: 2.3762\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8358\tTop_Loss: 0.8675\tBottom_Loss: 0.9133\tLoss: 2.6166\t\n",
      "Subject: 25, n=05 | test_f1: 0.58333 |best_f1: 0.7619\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6999\tTop_Loss: 0.9382\tBottom_Loss: 0.7868\tLoss: 2.4248\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.562\tLabel_Loss: 0.8753\tTop_Loss: 0.8675\tBottom_Loss: 0.6911\tLoss: 2.4339\t\n",
      "Subject: 25, n=05 | test_f1: 0.44444 |best_f1: 0.7619\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7547\tTop_Loss: 0.7664\tBottom_Loss: 0.8264\tLoss: 2.3475\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.531\tLabel_Loss: 0.8225\tTop_Loss: 0.9215\tBottom_Loss: 0.9414\tLoss: 2.6854\t\n",
      "Subject: 25, n=05 | test_f1: 0.13333 |best_f1: 0.7619\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8395\tTop_Loss: 0.9006\tBottom_Loss: 0.8224\tLoss: 2.5625\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5321\tTop_Loss: 0.7846\tBottom_Loss: 0.7050\tLoss: 2.0217\t\n",
      "Subject: 25, n=05 | test_f1: 0.8 |best_f1: 0.8\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8954\tTop_Loss: 1.0836\tBottom_Loss: 0.9531\tLoss: 2.9321\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5196\tTop_Loss: 0.5460\tBottom_Loss: 0.6406\tLoss: 1.7062\t\n",
      "Subject: 25, n=05 | test_f1: 0.35556 |best_f1: 0.8\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5970\tTop_Loss: 0.6697\tBottom_Loss: 0.7277\tLoss: 1.9943\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.562\tLabel_Loss: 0.8432\tTop_Loss: 0.9441\tBottom_Loss: 0.9364\tLoss: 2.7237\t\n",
      "Subject: 25, n=05 | test_f1: 0.375 |best_f1: 0.8\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5254\tTop_Loss: 0.6208\tBottom_Loss: 0.7009\tLoss: 1.8471\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7822\tTop_Loss: 0.7560\tBottom_Loss: 0.8519\tLoss: 2.3901\t\n",
      "Subject: 25, n=05 | test_f1: 0.43333 |best_f1: 0.8\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.656\tLabel_Loss: 0.6837\tTop_Loss: 0.7693\tBottom_Loss: 0.9052\tLoss: 2.3582\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7807\tTop_Loss: 0.7685\tBottom_Loss: 0.8072\tLoss: 2.3564\t\n",
      "Subject: 25, n=05 | test_f1: 0.7619 |best_f1: 0.8\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8325\tTop_Loss: 0.9314\tBottom_Loss: 0.8036\tLoss: 2.5674\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7980\tTop_Loss: 0.8318\tBottom_Loss: 0.9436\tLoss: 2.5734\t\n",
      "Subject: 25, n=05 | test_f1: 0.33333 |best_f1: 0.8\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6161\tTop_Loss: 0.7448\tBottom_Loss: 0.7763\tLoss: 2.1373\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4935\tTop_Loss: 0.5935\tBottom_Loss: 0.7038\tLoss: 1.7908\t\n",
      "Subject: 25, n=05 | test_f1: 0.28571 |best_f1: 0.8\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5299\tTop_Loss: 0.6435\tBottom_Loss: 0.6831\tLoss: 1.8565\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.625\tLabel_Loss: 0.6368\tTop_Loss: 0.6611\tBottom_Loss: 0.8881\tLoss: 2.1860\t\n",
      "Subject: 25, n=05 | test_f1: 0.58333 |best_f1: 0.8\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3952\tTop_Loss: 0.5418\tBottom_Loss: 0.5858\tLoss: 1.5228\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4616\tTop_Loss: 0.5008\tBottom_Loss: 0.6518\tLoss: 1.6143\t\n",
      "Subject: 25, n=05 | test_f1: 0.58333 |best_f1: 0.8\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7664\tTop_Loss: 0.9391\tBottom_Loss: 0.7703\tLoss: 2.4759\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5443\tTop_Loss: 0.8085\tBottom_Loss: 0.7221\tLoss: 2.0749\t\n",
      "Subject: 25, n=05 | test_f1: 0.58333 |best_f1: 0.8\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3738\tTop_Loss: 0.5950\tBottom_Loss: 0.5579\tLoss: 1.5268\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5010\tTop_Loss: 0.6159\tBottom_Loss: 0.5318\tLoss: 1.6487\t\n",
      "Subject: 25, n=05 | test_f1: 0.43333 |best_f1: 0.8\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4592\tTop_Loss: 0.5793\tBottom_Loss: 0.5997\tLoss: 1.6383\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5015\tTop_Loss: 0.6286\tBottom_Loss: 0.6426\tLoss: 1.7727\t\n",
      "Subject: 25, n=05 | test_f1: 0.43333 |best_f1: 0.8\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2034\tTop_Loss: 0.3216\tBottom_Loss: 0.4986\tLoss: 1.0236\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.688\tLabel_Loss: 0.5815\tTop_Loss: 0.6897\tBottom_Loss: 0.8043\tLoss: 2.0756\t\n",
      "Subject: 25, n=05 | test_f1: 0.7619 |best_f1: 0.8\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.844\tLabel_Loss: 0.5426\tTop_Loss: 0.7267\tBottom_Loss: 0.7776\tLoss: 2.0469\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.969\tLabel_Loss: 0.3688\tTop_Loss: 0.5303\tBottom_Loss: 0.5531\tLoss: 1.4522\t\n",
      "Subject: 25, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5550\tTop_Loss: 0.5154\tBottom_Loss: 0.6132\tLoss: 1.6836\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3926\tTop_Loss: 0.5926\tBottom_Loss: 0.5126\tLoss: 1.4979\t\n",
      "Subject: 25, n=05 | test_f1: 0.8 |best_f1: 1.0\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3478\tTop_Loss: 0.3912\tBottom_Loss: 0.5801\tLoss: 1.3191\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3939\tTop_Loss: 0.5942\tBottom_Loss: 0.4504\tLoss: 1.4385\t\n",
      "Subject: 25, n=05 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4440\tTop_Loss: 0.5959\tBottom_Loss: 0.6092\tLoss: 1.6492\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3640\tTop_Loss: 0.4167\tBottom_Loss: 0.5849\tLoss: 1.3657\t\n",
      "Subject: 25, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3592\tTop_Loss: 0.4206\tBottom_Loss: 0.5284\tLoss: 1.3081\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3696\tTop_Loss: 0.4816\tBottom_Loss: 0.4482\tLoss: 1.2995\t\n",
      "Subject: 25, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2712\tTop_Loss: 0.6251\tBottom_Loss: 0.4934\tLoss: 1.3897\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3439\tTop_Loss: 0.5670\tBottom_Loss: 0.4742\tLoss: 1.3851\t\n",
      "Subject: 25, n=05 | test_f1: 0.58333 |best_f1: 1.0\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3037\tTop_Loss: 0.2931\tBottom_Loss: 0.4886\tLoss: 1.0854\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2877\tTop_Loss: 0.4785\tBottom_Loss: 0.4509\tLoss: 1.2170\t\n",
      "Subject: 25, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3230\tTop_Loss: 0.5461\tBottom_Loss: 0.4367\tLoss: 1.3059\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3379\tTop_Loss: 0.4285\tBottom_Loss: 0.4484\tLoss: 1.2148\t\n",
      "Subject: 25, n=05 | test_f1: 0.8 |best_f1: 1.0\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4000\tTop_Loss: 0.6891\tBottom_Loss: 0.5167\tLoss: 1.6059\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4150\tTop_Loss: 0.5306\tBottom_Loss: 0.3841\tLoss: 1.3296\t\n",
      "Subject: 25, n=05 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1702\tTop_Loss: 0.3501\tBottom_Loss: 0.3226\tLoss: 0.8429\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3787\tTop_Loss: 0.5513\tBottom_Loss: 0.4169\tLoss: 1.3469\t\n",
      "Subject: 25, n=05 | test_f1: 0.58333 |best_f1: 1.0\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2623\tTop_Loss: 0.4087\tBottom_Loss: 0.2990\tLoss: 0.9700\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2202\tTop_Loss: 0.4614\tBottom_Loss: 0.4484\tLoss: 1.1300\t\n",
      "Subject: 25, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2705\tTop_Loss: 0.4279\tBottom_Loss: 0.4362\tLoss: 1.1347\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1458\tTop_Loss: 0.2691\tBottom_Loss: 0.2503\tLoss: 0.6652\t\n",
      "Subject: 25, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2150\tTop_Loss: 0.5258\tBottom_Loss: 0.3544\tLoss: 1.0952\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3259\tTop_Loss: 0.5270\tBottom_Loss: 0.4950\tLoss: 1.3479\t\n",
      "Subject: 25, n=05 | test_f1: 0.43333 |best_f1: 1.0\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2242\tTop_Loss: 0.4226\tBottom_Loss: 0.3532\tLoss: 1.0000\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4031\tTop_Loss: 0.5896\tBottom_Loss: 0.4564\tLoss: 1.4491\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 25, n=05 | test_f1: 0.58333 |best_f1: 1.0\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1374\tTop_Loss: 0.3587\tBottom_Loss: 0.2492\tLoss: 0.7454\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3895\tTop_Loss: 0.4771\tBottom_Loss: 0.4601\tLoss: 1.3268\t\n",
      "Subject: 25, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2201\tTop_Loss: 0.3392\tBottom_Loss: 0.4103\tLoss: 0.9696\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2011\tTop_Loss: 0.3858\tBottom_Loss: 0.3890\tLoss: 0.9759\t\n",
      "Subject: 25, n=05 | test_f1: 0.375 |best_f1: 1.0\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1741\tTop_Loss: 0.2571\tBottom_Loss: 0.3672\tLoss: 0.7983\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2519\tTop_Loss: 0.3923\tBottom_Loss: 0.3309\tLoss: 0.9751\t\n",
      "Subject: 25, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2224\tTop_Loss: 0.3104\tBottom_Loss: 0.3230\tLoss: 0.8558\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2420\tTop_Loss: 0.5417\tBottom_Loss: 0.3647\tLoss: 1.1484\t\n",
      "Subject: 25, n=05 | test_f1: 0.8 |best_f1: 1.0\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1570\tTop_Loss: 0.3104\tBottom_Loss: 0.3594\tLoss: 0.8267\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2649\tTop_Loss: 0.2921\tBottom_Loss: 0.3148\tLoss: 0.8718\t\n",
      "Subject: 25, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1577\tTop_Loss: 0.3058\tBottom_Loss: 0.2782\tLoss: 0.7417\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1774\tTop_Loss: 0.4058\tBottom_Loss: 0.2742\tLoss: 0.8574\t\n",
      "Subject: 25, n=05 | test_f1: 0.28571 |best_f1: 1.0\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1753\tTop_Loss: 0.3282\tBottom_Loss: 0.2521\tLoss: 0.7556\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1552\tTop_Loss: 0.3671\tBottom_Loss: 0.3043\tLoss: 0.8266\t\n",
      "Subject: 25, n=05 | test_f1: 0.8 |best_f1: 1.0\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1899\tTop_Loss: 0.4267\tBottom_Loss: 0.3519\tLoss: 0.9686\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1337\tTop_Loss: 0.3847\tBottom_Loss: 0.3442\tLoss: 0.8626\t\n",
      "Subject: 25, n=05 | test_f1: 0.8 |best_f1: 1.0\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1062\tTop_Loss: 0.3796\tBottom_Loss: 0.1665\tLoss: 0.6523\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2154\tTop_Loss: 0.3042\tBottom_Loss: 0.2198\tLoss: 0.7394\t\n",
      "Subject: 25, n=05 | test_f1: 0.8 |best_f1: 1.0\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1933\tTop_Loss: 0.3586\tBottom_Loss: 0.3525\tLoss: 0.9044\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0975\tTop_Loss: 0.2855\tBottom_Loss: 0.2229\tLoss: 0.6058\t\n",
      "Subject: 25, n=05 | test_f1: 0.3 |best_f1: 1.0\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0773\tTop_Loss: 0.3206\tBottom_Loss: 0.1876\tLoss: 0.5855\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1225\tTop_Loss: 0.1880\tBottom_Loss: 0.1767\tLoss: 0.4872\t\n",
      "Subject: 25, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1581\tTop_Loss: 0.3539\tBottom_Loss: 0.2311\tLoss: 0.7432\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0604\tTop_Loss: 0.2381\tBottom_Loss: 0.1616\tLoss: 0.4601\t\n",
      "Subject: 25, n=05 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1326\tTop_Loss: 0.3997\tBottom_Loss: 0.1515\tLoss: 0.6837\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1499\tTop_Loss: 0.2838\tBottom_Loss: 0.1873\tLoss: 0.6210\t\n",
      "Subject: 25, n=05 | test_f1: 0.8 |best_f1: 1.0\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0919\tTop_Loss: 0.1455\tBottom_Loss: 0.1934\tLoss: 0.4308\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1501\tTop_Loss: 0.2470\tBottom_Loss: 0.2764\tLoss: 0.6735\t\n",
      "Subject: 25, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1207\tTop_Loss: 0.2321\tBottom_Loss: 0.1796\tLoss: 0.5324\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0640\tTop_Loss: 0.1899\tBottom_Loss: 0.1245\tLoss: 0.3783\t\n",
      "Subject: 25, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3317\tTop_Loss: 0.5048\tBottom_Loss: 0.3588\tLoss: 1.1953\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0766\tTop_Loss: 0.1710\tBottom_Loss: 0.1567\tLoss: 0.4043\t\n",
      "Subject: 25, n=05 | test_f1: 0.8 |best_f1: 1.0\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1101\tTop_Loss: 0.1473\tBottom_Loss: 0.3956\tLoss: 0.6530\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0446\tTop_Loss: 0.1925\tBottom_Loss: 0.0605\tLoss: 0.2976\t\n",
      "Subject: 25, n=05 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0803\tTop_Loss: 0.1925\tBottom_Loss: 0.1958\tLoss: 0.4686\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0821\tTop_Loss: 0.2070\tBottom_Loss: 0.1470\tLoss: 0.4361\t\n",
      "Subject: 25, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1422\tTop_Loss: 0.3656\tBottom_Loss: 0.1551\tLoss: 0.6629\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0989\tTop_Loss: 0.1995\tBottom_Loss: 0.2000\tLoss: 0.4985\t\n",
      "Subject: 25, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0467\tTop_Loss: 0.1141\tBottom_Loss: 0.1245\tLoss: 0.2853\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0315\tTop_Loss: 0.1264\tBottom_Loss: 0.0729\tLoss: 0.2307\t\n",
      "Subject: 25, n=05 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0899\tTop_Loss: 0.1821\tBottom_Loss: 0.1916\tLoss: 0.4636\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1118\tTop_Loss: 0.2075\tBottom_Loss: 0.1261\tLoss: 0.4455\t\n",
      "Subject: 25, n=05 | test_f1: 0.3 |best_f1: 1.0\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0672\tTop_Loss: 0.1917\tBottom_Loss: 0.1116\tLoss: 0.3705\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0287\tTop_Loss: 0.1464\tBottom_Loss: 0.0737\tLoss: 0.2488\t\n",
      "Subject: 25, n=05 | test_f1: 0.8 |best_f1: 1.0\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0470\tTop_Loss: 0.1450\tBottom_Loss: 0.0768\tLoss: 0.2688\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0773\tTop_Loss: 0.2161\tBottom_Loss: 0.1773\tLoss: 0.4708\t\n",
      "Subject: 25, n=05 | test_f1: 0.8 |best_f1: 1.0\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1243\tTop_Loss: 0.3256\tBottom_Loss: 0.1527\tLoss: 0.6026\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0713\tTop_Loss: 0.1653\tBottom_Loss: 0.2026\tLoss: 0.4393\t\n",
      "Subject: 25, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0619\tTop_Loss: 0.1108\tBottom_Loss: 0.1770\tLoss: 0.3496\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0532\tTop_Loss: 0.1229\tBottom_Loss: 0.0770\tLoss: 0.2531\t\n",
      "Subject: 25, n=05 | test_f1: 0.28571 |best_f1: 1.0\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1517\tTop_Loss: 0.2434\tBottom_Loss: 0.2477\tLoss: 0.6429\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0462\tTop_Loss: 0.1824\tBottom_Loss: 0.0943\tLoss: 0.3229\t\n",
      "Subject: 25, n=05 | test_f1: 0.4 |best_f1: 1.0\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0494\tTop_Loss: 0.2234\tBottom_Loss: 0.0983\tLoss: 0.3711\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0876\tTop_Loss: 0.1844\tBottom_Loss: 0.1780\tLoss: 0.4500\t\n",
      "Subject: 25, n=05 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0515\tTop_Loss: 0.0793\tBottom_Loss: 0.1356\tLoss: 0.2664\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0176\tTop_Loss: 0.0747\tBottom_Loss: 0.0482\tLoss: 0.1406\t\n",
      "Subject: 25, n=05 | test_f1: 0.58333 |best_f1: 1.0\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0406\tTop_Loss: 0.1403\tBottom_Loss: 0.0795\tLoss: 0.2604\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0303\tTop_Loss: 0.1894\tBottom_Loss: 0.0589\tLoss: 0.2786\t\n",
      "Subject: 25, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0691\tTop_Loss: 0.1666\tBottom_Loss: 0.1550\tLoss: 0.3907\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0796\tTop_Loss: 0.1928\tBottom_Loss: 0.1092\tLoss: 0.3817\t\n",
      "Subject: 25, n=05 | test_f1: 0.28571 |best_f1: 1.0\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0291\tTop_Loss: 0.0990\tBottom_Loss: 0.1261\tLoss: 0.2542\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0722\tTop_Loss: 0.2181\tBottom_Loss: 0.0790\tLoss: 0.3694\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 25, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0502\tTop_Loss: 0.1149\tBottom_Loss: 0.1053\tLoss: 0.2704\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0323\tTop_Loss: 0.1396\tBottom_Loss: 0.0601\tLoss: 0.2319\t\n",
      "Subject: 25, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1346\tTop_Loss: 0.1531\tBottom_Loss: 0.1958\tLoss: 0.4834\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0301\tTop_Loss: 0.0831\tBottom_Loss: 0.1295\tLoss: 0.2427\t\n",
      "Subject: 25, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0252\tTop_Loss: 0.1137\tBottom_Loss: 0.0549\tLoss: 0.1938\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0453\tTop_Loss: 0.1133\tBottom_Loss: 0.1025\tLoss: 0.2611\t\n",
      "Subject: 25, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 0.938\tLabel_Loss: 0.0989\tTop_Loss: 0.2238\tBottom_Loss: 0.0889\tLoss: 0.4117\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0490\tTop_Loss: 0.2036\tBottom_Loss: 0.0295\tLoss: 0.2822\t\n",
      "Subject: 25, n=05 | test_f1: 0.58333 |best_f1: 1.0\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0287\tTop_Loss: 0.0537\tBottom_Loss: 0.1193\tLoss: 0.2017\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0359\tTop_Loss: 0.0820\tBottom_Loss: 0.0872\tLoss: 0.2051\t\n",
      "Subject: 25, n=05 | test_f1: 0.58333 |best_f1: 1.0\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0154\tTop_Loss: 0.1025\tBottom_Loss: 0.0357\tLoss: 0.1536\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0326\tTop_Loss: 0.1136\tBottom_Loss: 0.0692\tLoss: 0.2153\t\n",
      "Subject: 25, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0219\tTop_Loss: 0.1705\tBottom_Loss: 0.0557\tLoss: 0.2481\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0383\tTop_Loss: 0.0879\tBottom_Loss: 0.1156\tLoss: 0.2417\t\n",
      "Subject: 25, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0414\tTop_Loss: 0.1455\tBottom_Loss: 0.0552\tLoss: 0.2420\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0648\tTop_Loss: 0.2258\tBottom_Loss: 0.0820\tLoss: 0.3726\t\n",
      "Subject: 25, n=05 | test_f1: 0.58333 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0434\tTop_Loss: 0.1796\tBottom_Loss: 0.0796\tLoss: 0.3026\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0486\tTop_Loss: 0.1623\tBottom_Loss: 0.1099\tLoss: 0.3208\t\n",
      "Subject: 25, n=05 | test_f1: 0.8 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0248\tTop_Loss: 0.1265\tBottom_Loss: 0.1104\tLoss: 0.2617\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0300\tTop_Loss: 0.0863\tBottom_Loss: 0.0454\tLoss: 0.1618\t\n",
      "Subject: 25, n=05 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0476\tTop_Loss: 0.1042\tBottom_Loss: 0.0987\tLoss: 0.2505\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0109\tTop_Loss: 0.1048\tBottom_Loss: 0.0319\tLoss: 0.1475\t\n",
      "Subject: 25, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0165\tTop_Loss: 0.0427\tBottom_Loss: 0.0653\tLoss: 0.1245\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0285\tTop_Loss: 0.0573\tBottom_Loss: 0.1133\tLoss: 0.1991\t\n",
      "Subject: 25, n=05 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0122\tTop_Loss: 0.0545\tBottom_Loss: 0.0315\tLoss: 0.0982\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0132\tTop_Loss: 0.0900\tBottom_Loss: 0.0303\tLoss: 0.1335\t\n",
      "Subject: 25, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0160\tTop_Loss: 0.0764\tBottom_Loss: 0.0326\tLoss: 0.1249\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0638\tTop_Loss: 0.1328\tBottom_Loss: 0.0878\tLoss: 0.2843\t\n",
      "Subject: 25, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0162\tTop_Loss: 0.0479\tBottom_Loss: 0.0452\tLoss: 0.1092\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0140\tTop_Loss: 0.0454\tBottom_Loss: 0.0438\tLoss: 0.1032\t\n",
      "Subject: 25, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0221\tTop_Loss: 0.0651\tBottom_Loss: 0.0794\tLoss: 0.1667\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0180\tTop_Loss: 0.0573\tBottom_Loss: 0.0466\tLoss: 0.1218\t\n",
      "Subject: 25, n=05 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0120\tTop_Loss: 0.0695\tBottom_Loss: 0.0406\tLoss: 0.1222\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0323\tTop_Loss: 0.0880\tBottom_Loss: 0.0998\tLoss: 0.2200\t\n",
      "Subject: 25, n=05 | test_f1: 0.28571 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0152\tTop_Loss: 0.0687\tBottom_Loss: 0.0252\tLoss: 0.1092\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0324\tTop_Loss: 0.0552\tBottom_Loss: 0.0723\tLoss: 0.1600\t\n",
      "Subject: 25, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0318\tTop_Loss: 0.0708\tBottom_Loss: 0.0417\tLoss: 0.1443\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0242\tTop_Loss: 0.0919\tBottom_Loss: 0.0804\tLoss: 0.1965\t\n",
      "Subject: 25, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0222\tTop_Loss: 0.0722\tBottom_Loss: 0.0853\tLoss: 0.1797\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0086\tTop_Loss: 0.0619\tBottom_Loss: 0.0225\tLoss: 0.0930\t\n",
      "Subject: 25, n=05 | test_f1: 0.58333 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0189\tTop_Loss: 0.0744\tBottom_Loss: 0.0329\tLoss: 0.1263\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0097\tTop_Loss: 0.0314\tBottom_Loss: 0.0452\tLoss: 0.0863\t\n",
      "Subject: 25, n=05 | test_f1: 0.8 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0160\tTop_Loss: 0.0568\tBottom_Loss: 0.0604\tLoss: 0.1332\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0170\tTop_Loss: 0.0756\tBottom_Loss: 0.0614\tLoss: 0.1540\t\n",
      "Subject: 25, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0083\tTop_Loss: 0.0182\tBottom_Loss: 0.0538\tLoss: 0.0804\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0186\tTop_Loss: 0.0653\tBottom_Loss: 0.0833\tLoss: 0.1672\t\n",
      "Subject: 25, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0103\tTop_Loss: 0.0500\tBottom_Loss: 0.0571\tLoss: 0.1173\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0134\tTop_Loss: 0.0633\tBottom_Loss: 0.0713\tLoss: 0.1480\t\n",
      "Subject: 25, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0294\tTop_Loss: 0.0290\tBottom_Loss: 0.0304\tLoss: 0.0888\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0308\tTop_Loss: 0.0407\tBottom_Loss: 0.0662\tLoss: 0.1377\t\n",
      "Subject: 25, n=05 | test_f1: 0.58333 |best_f1: 1.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0103\tTop_Loss: 0.0359\tBottom_Loss: 0.0275\tLoss: 0.0737\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0395\tTop_Loss: 0.0720\tBottom_Loss: 0.0997\tLoss: 0.2112\t\n",
      "Subject: 25, n=05 | test_f1: 0.28571 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0074\tTop_Loss: 0.0361\tBottom_Loss: 0.0253\tLoss: 0.0687\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0139\tTop_Loss: 0.0410\tBottom_Loss: 0.0261\tLoss: 0.0810\t\n",
      "Subject: 25, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0100\tTop_Loss: 0.0515\tBottom_Loss: 0.0405\tLoss: 0.1020\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0060\tTop_Loss: 0.0266\tBottom_Loss: 0.0535\tLoss: 0.0861\t\n",
      "Subject: 25, n=05 | test_f1: 0.58333 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0153\tTop_Loss: 0.0852\tBottom_Loss: 0.0277\tLoss: 0.1283\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0061\tTop_Loss: 0.0619\tBottom_Loss: 0.0209\tLoss: 0.0889\t\n",
      "Subject: 25, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0106\tTop_Loss: 0.0694\tBottom_Loss: 0.0259\tLoss: 0.1059\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0042\tTop_Loss: 0.0166\tBottom_Loss: 0.0118\tLoss: 0.0325\t\n",
      "Subject: 25, n=05 | test_f1: 0.7619 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0024\tTop_Loss: 0.0141\tBottom_Loss: 0.0116\tLoss: 0.0281\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0058\tTop_Loss: 0.0249\tBottom_Loss: 0.0362\tLoss: 0.0668\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 25, n=05 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0105\tTop_Loss: 0.0173\tBottom_Loss: 0.0407\tLoss: 0.0685\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0135\tTop_Loss: 0.0268\tBottom_Loss: 0.0763\tLoss: 0.1166\t\n",
      "Subject: 25, n=05 | test_f1: 0.58333 |best_f1: 1.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.594\tLabel_Loss: 0.9567\tTop_Loss: 2.3322\tBottom_Loss: 1.2727\tLoss: 4.5616\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.438\tLabel_Loss: 1.1263\tTop_Loss: 1.1922\tBottom_Loss: 1.0835\tLoss: 3.4020\t\n",
      "Subject: 26, n=11 | test_f1: 0.42105 |best_f1: 0.42105\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.531\tLabel_Loss: 1.0193\tTop_Loss: 0.9423\tBottom_Loss: 1.0671\tLoss: 3.0286\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.531\tLabel_Loss: 1.1465\tTop_Loss: 0.9293\tBottom_Loss: 1.0180\tLoss: 3.0939\t\n",
      "Subject: 26, n=11 | test_f1: 0.26667 |best_f1: 0.42105\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.531\tLabel_Loss: 0.9261\tTop_Loss: 0.9410\tBottom_Loss: 0.9311\tLoss: 2.7982\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.625\tLabel_Loss: 0.9387\tTop_Loss: 1.0424\tBottom_Loss: 1.0158\tLoss: 2.9969\t\n",
      "Subject: 26, n=11 | test_f1: 0.25926 |best_f1: 0.42105\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.562\tLabel_Loss: 1.0058\tTop_Loss: 0.9844\tBottom_Loss: 1.1038\tLoss: 3.0939\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8089\tTop_Loss: 0.9234\tBottom_Loss: 0.8516\tLoss: 2.5839\t\n",
      "Subject: 26, n=11 | test_f1: 0.80702 |best_f1: 0.80702\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.594\tLabel_Loss: 0.9450\tTop_Loss: 1.0831\tBottom_Loss: 1.1618\tLoss: 3.1899\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.562\tLabel_Loss: 0.9732\tTop_Loss: 0.9404\tBottom_Loss: 0.9071\tLoss: 2.8207\t\n",
      "Subject: 26, n=11 | test_f1: 0.2807 |best_f1: 0.80702\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7978\tTop_Loss: 0.9880\tBottom_Loss: 1.0459\tLoss: 2.8316\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7999\tTop_Loss: 0.7525\tBottom_Loss: 0.8899\tLoss: 2.4423\t\n",
      "Subject: 26, n=11 | test_f1: 0.2807 |best_f1: 0.80702\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.781\tLabel_Loss: 0.6582\tTop_Loss: 0.5794\tBottom_Loss: 0.8057\tLoss: 2.0433\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.625\tLabel_Loss: 0.9260\tTop_Loss: 0.9685\tBottom_Loss: 0.9246\tLoss: 2.8191\t\n",
      "Subject: 26, n=11 | test_f1: 0.49673 |best_f1: 0.80702\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.688\tLabel_Loss: 0.8753\tTop_Loss: 0.9071\tBottom_Loss: 0.8584\tLoss: 2.6407\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.562\tLabel_Loss: 0.9561\tTop_Loss: 0.9960\tBottom_Loss: 1.0232\tLoss: 2.9753\t\n",
      "Subject: 26, n=11 | test_f1: 0.51852 |best_f1: 0.80702\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.750\tLabel_Loss: 0.7143\tTop_Loss: 0.7588\tBottom_Loss: 0.6983\tLoss: 2.1714\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7872\tTop_Loss: 0.7176\tBottom_Loss: 0.9764\tLoss: 2.4812\t\n",
      "Subject: 26, n=11 | test_f1: 0.51852 |best_f1: 0.80702\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5647\tTop_Loss: 0.6316\tBottom_Loss: 0.6620\tLoss: 1.8583\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.625\tLabel_Loss: 0.6754\tTop_Loss: 0.8170\tBottom_Loss: 0.8592\tLoss: 2.3516\t\n",
      "Subject: 26, n=11 | test_f1: 0.2807 |best_f1: 0.80702\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6164\tTop_Loss: 0.6807\tBottom_Loss: 0.6520\tLoss: 1.9491\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6624\tTop_Loss: 0.7252\tBottom_Loss: 0.6579\tLoss: 2.0455\t\n",
      "Subject: 26, n=11 | test_f1: 0.45 |best_f1: 0.80702\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6947\tTop_Loss: 0.7828\tBottom_Loss: 0.7193\tLoss: 2.1967\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5877\tTop_Loss: 0.6523\tBottom_Loss: 0.5818\tLoss: 1.8218\t\n",
      "Subject: 26, n=11 | test_f1: 0.45 |best_f1: 0.80702\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5184\tTop_Loss: 0.5884\tBottom_Loss: 0.6148\tLoss: 1.7216\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.562\tLabel_Loss: 0.7514\tTop_Loss: 0.8508\tBottom_Loss: 0.7712\tLoss: 2.3733\t\n",
      "Subject: 26, n=11 | test_f1: 0.44118 |best_f1: 0.80702\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6498\tTop_Loss: 0.7194\tBottom_Loss: 0.7580\tLoss: 2.1271\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6406\tTop_Loss: 0.5569\tBottom_Loss: 0.6801\tLoss: 1.8777\t\n",
      "Subject: 26, n=11 | test_f1: 0.45 |best_f1: 0.80702\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.625\tLabel_Loss: 0.6440\tTop_Loss: 0.9668\tBottom_Loss: 0.7153\tLoss: 2.3261\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.594\tLabel_Loss: 0.7527\tTop_Loss: 0.7021\tBottom_Loss: 0.8388\tLoss: 2.2935\t\n",
      "Subject: 26, n=11 | test_f1: 0.80702 |best_f1: 0.80702\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3684\tTop_Loss: 0.5053\tBottom_Loss: 0.5530\tLoss: 1.4267\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.656\tLabel_Loss: 0.6548\tTop_Loss: 0.8191\tBottom_Loss: 0.8247\tLoss: 2.2986\t\n",
      "Subject: 26, n=11 | test_f1: 0.625 |best_f1: 0.80702\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5399\tTop_Loss: 0.7550\tBottom_Loss: 0.5113\tLoss: 1.8062\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.688\tLabel_Loss: 0.5681\tTop_Loss: 0.6293\tBottom_Loss: 0.7302\tLoss: 1.9276\t\n",
      "Subject: 26, n=11 | test_f1: 0.51852 |best_f1: 0.80702\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7926\tTop_Loss: 0.7611\tBottom_Loss: 1.1372\tLoss: 2.6909\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.906\tLabel_Loss: 0.4169\tTop_Loss: 0.5810\tBottom_Loss: 0.6390\tLoss: 1.6369\t\n",
      "Subject: 26, n=11 | test_f1: 0.2807 |best_f1: 0.80702\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5149\tTop_Loss: 0.7149\tBottom_Loss: 0.5401\tLoss: 1.7700\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5053\tTop_Loss: 0.4985\tBottom_Loss: 0.6156\tLoss: 1.6194\t\n",
      "Subject: 26, n=11 | test_f1: 0.51852 |best_f1: 0.80702\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4752\tTop_Loss: 0.5192\tBottom_Loss: 0.7022\tLoss: 1.6966\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.812\tLabel_Loss: 0.6668\tTop_Loss: 0.8227\tBottom_Loss: 0.5761\tLoss: 2.0656\t\n",
      "Subject: 26, n=11 | test_f1: 0.80702 |best_f1: 0.80702\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5422\tTop_Loss: 0.6736\tBottom_Loss: 0.6063\tLoss: 1.8221\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.719\tLabel_Loss: 0.5285\tTop_Loss: 0.8212\tBottom_Loss: 0.6879\tLoss: 2.0376\t\n",
      "Subject: 26, n=11 | test_f1: 0.51852 |best_f1: 0.80702\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5172\tTop_Loss: 0.6004\tBottom_Loss: 0.6230\tLoss: 1.7406\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5270\tTop_Loss: 0.6943\tBottom_Loss: 0.5854\tLoss: 1.8067\t\n",
      "Subject: 26, n=11 | test_f1: 0.51852 |best_f1: 0.80702\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4421\tTop_Loss: 0.5529\tBottom_Loss: 0.5546\tLoss: 1.5496\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4776\tTop_Loss: 0.5085\tBottom_Loss: 0.6429\tLoss: 1.6289\t\n",
      "Subject: 26, n=11 | test_f1: 0.23529 |best_f1: 0.80702\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4982\tTop_Loss: 0.5489\tBottom_Loss: 0.6382\tLoss: 1.6852\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3723\tTop_Loss: 0.4704\tBottom_Loss: 0.4820\tLoss: 1.3247\t\n",
      "Subject: 26, n=11 | test_f1: 0.51852 |best_f1: 0.80702\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2831\tTop_Loss: 0.4510\tBottom_Loss: 0.4444\tLoss: 1.1785\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4923\tTop_Loss: 0.4459\tBottom_Loss: 0.5695\tLoss: 1.5077\t\n",
      "Subject: 26, n=11 | test_f1: 0.80702 |best_f1: 0.80702\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4050\tTop_Loss: 0.4872\tBottom_Loss: 0.5424\tLoss: 1.4347\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.656\tLabel_Loss: 0.6656\tTop_Loss: 0.6902\tBottom_Loss: 0.8461\tLoss: 2.2019\t\n",
      "Subject: 26, n=11 | test_f1: 0.49673 |best_f1: 0.80702\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4208\tTop_Loss: 0.7665\tBottom_Loss: 0.4525\tLoss: 1.6397\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.750\tLabel_Loss: 0.4807\tTop_Loss: 0.6668\tBottom_Loss: 0.5223\tLoss: 1.6698\t\n",
      "Subject: 26, n=11 | test_f1: 0.45 |best_f1: 0.80702\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4646\tTop_Loss: 0.6917\tBottom_Loss: 0.5799\tLoss: 1.7362\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4455\tTop_Loss: 0.5610\tBottom_Loss: 0.6380\tLoss: 1.6444\t\n",
      "Subject: 26, n=11 | test_f1: 0.31579 |best_f1: 0.80702\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2267\tTop_Loss: 0.5712\tBottom_Loss: 0.3006\tLoss: 1.0985\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4086\tTop_Loss: 0.4937\tBottom_Loss: 0.6164\tLoss: 1.5187\t\n",
      "Subject: 26, n=11 | test_f1: 0.51852 |best_f1: 0.80702\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2779\tTop_Loss: 0.4070\tBottom_Loss: 0.3840\tLoss: 1.0689\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2935\tTop_Loss: 0.4472\tBottom_Loss: 0.4317\tLoss: 1.1724\t\n",
      "Subject: 26, n=11 | test_f1: 0.69444 |best_f1: 0.80702\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4351\tTop_Loss: 0.5017\tBottom_Loss: 0.5284\tLoss: 1.4652\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.969\tLabel_Loss: 0.3158\tTop_Loss: 0.4963\tBottom_Loss: 0.4267\tLoss: 1.2388\t\n",
      "Subject: 26, n=11 | test_f1: 0.45 |best_f1: 0.80702\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2395\tTop_Loss: 0.5935\tBottom_Loss: 0.3823\tLoss: 1.2154\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3771\tTop_Loss: 0.5422\tBottom_Loss: 0.4749\tLoss: 1.3942\t\n",
      "Subject: 26, n=11 | test_f1: 0.47222 |best_f1: 0.80702\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1658\tTop_Loss: 0.5026\tBottom_Loss: 0.2214\tLoss: 0.8898\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3479\tTop_Loss: 0.5371\tBottom_Loss: 0.5401\tLoss: 1.4251\t\n",
      "Subject: 26, n=11 | test_f1: 0.77083 |best_f1: 0.80702\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3057\tTop_Loss: 0.4245\tBottom_Loss: 0.3018\tLoss: 1.0320\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2434\tTop_Loss: 0.4500\tBottom_Loss: 0.4388\tLoss: 1.1322\t\n",
      "Subject: 26, n=11 | test_f1: 0.51852 |best_f1: 0.80702\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2744\tTop_Loss: 0.4826\tBottom_Loss: 0.4770\tLoss: 1.2340\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3418\tTop_Loss: 0.6073\tBottom_Loss: 0.3781\tLoss: 1.3272\t\n",
      "Subject: 26, n=11 | test_f1: 0.2807 |best_f1: 0.80702\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2661\tTop_Loss: 0.3931\tBottom_Loss: 0.3735\tLoss: 1.0327\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.938\tLabel_Loss: 0.3037\tTop_Loss: 0.3887\tBottom_Loss: 0.4525\tLoss: 1.1448\t\n",
      "Subject: 26, n=11 | test_f1: 0.49673 |best_f1: 0.80702\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2638\tTop_Loss: 0.5637\tBottom_Loss: 0.2743\tLoss: 1.1019\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1401\tTop_Loss: 0.3744\tBottom_Loss: 0.3000\tLoss: 0.8145\t\n",
      "Subject: 26, n=11 | test_f1: 0.2807 |best_f1: 0.80702\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3364\tTop_Loss: 0.4510\tBottom_Loss: 0.3546\tLoss: 1.1419\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2382\tTop_Loss: 0.1788\tBottom_Loss: 0.3662\tLoss: 0.7832\t\n",
      "Subject: 26, n=11 | test_f1: 0.51852 |best_f1: 0.80702\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1348\tTop_Loss: 0.3138\tBottom_Loss: 0.2375\tLoss: 0.6862\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3786\tTop_Loss: 0.5523\tBottom_Loss: 0.4696\tLoss: 1.4006\t\n",
      "Subject: 26, n=11 | test_f1: 0.49673 |best_f1: 0.80702\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1387\tTop_Loss: 0.3323\tBottom_Loss: 0.1694\tLoss: 0.6404\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2419\tTop_Loss: 0.4092\tBottom_Loss: 0.3003\tLoss: 0.9515\t\n",
      "Subject: 26, n=11 | test_f1: 0.2807 |best_f1: 0.80702\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2742\tTop_Loss: 0.3887\tBottom_Loss: 0.4413\tLoss: 1.1042\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2871\tTop_Loss: 0.3908\tBottom_Loss: 0.2423\tLoss: 0.9202\t\n",
      "Subject: 26, n=11 | test_f1: 0.51852 |best_f1: 0.80702\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1553\tTop_Loss: 0.2805\tBottom_Loss: 0.3030\tLoss: 0.7388\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2299\tTop_Loss: 0.3186\tBottom_Loss: 0.4410\tLoss: 0.9896\t\n",
      "Subject: 26, n=11 | test_f1: 0.51852 |best_f1: 0.80702\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1634\tTop_Loss: 0.2774\tBottom_Loss: 0.3584\tLoss: 0.7992\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1123\tTop_Loss: 0.1790\tBottom_Loss: 0.2569\tLoss: 0.5482\t\n",
      "Subject: 26, n=11 | test_f1: 0.51852 |best_f1: 0.80702\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2866\tTop_Loss: 0.4526\tBottom_Loss: 0.2739\tLoss: 1.0131\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1397\tTop_Loss: 0.2775\tBottom_Loss: 0.2347\tLoss: 0.6519\t\n",
      "Subject: 26, n=11 | test_f1: 0.51852 |best_f1: 0.80702\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1865\tTop_Loss: 0.3022\tBottom_Loss: 0.2733\tLoss: 0.7619\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2818\tTop_Loss: 0.4094\tBottom_Loss: 0.3502\tLoss: 1.0414\t\n",
      "Subject: 26, n=11 | test_f1: 0.51852 |best_f1: 0.80702\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1218\tTop_Loss: 0.3353\tBottom_Loss: 0.1631\tLoss: 0.6202\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1173\tTop_Loss: 0.5130\tBottom_Loss: 0.1438\tLoss: 0.7740\t\n",
      "Subject: 26, n=11 | test_f1: 0.2807 |best_f1: 0.80702\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1867\tTop_Loss: 0.2861\tBottom_Loss: 0.2480\tLoss: 0.7208\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2170\tTop_Loss: 0.3031\tBottom_Loss: 0.3025\tLoss: 0.8227\t\n",
      "Subject: 26, n=11 | test_f1: 0.49673 |best_f1: 0.80702\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0672\tTop_Loss: 0.2103\tBottom_Loss: 0.1428\tLoss: 0.4202\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1355\tTop_Loss: 0.2240\tBottom_Loss: 0.2703\tLoss: 0.6298\t\n",
      "Subject: 26, n=11 | test_f1: 0.42105 |best_f1: 0.80702\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1925\tTop_Loss: 0.3639\tBottom_Loss: 0.2164\tLoss: 0.7728\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0652\tTop_Loss: 0.2531\tBottom_Loss: 0.2033\tLoss: 0.5216\t\n",
      "Subject: 26, n=11 | test_f1: 0.69444 |best_f1: 0.80702\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1405\tTop_Loss: 0.3420\tBottom_Loss: 0.2226\tLoss: 0.7052\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1422\tTop_Loss: 0.2548\tBottom_Loss: 0.2192\tLoss: 0.6162\t\n",
      "Subject: 26, n=11 | test_f1: 0.44118 |best_f1: 0.80702\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3007\tTop_Loss: 0.4039\tBottom_Loss: 0.2905\tLoss: 0.9951\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0741\tTop_Loss: 0.1799\tBottom_Loss: 0.2121\tLoss: 0.4661\t\n",
      "Subject: 26, n=11 | test_f1: 0.45 |best_f1: 0.80702\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0822\tTop_Loss: 0.2249\tBottom_Loss: 0.1432\tLoss: 0.4503\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0933\tTop_Loss: 0.1481\tBottom_Loss: 0.2063\tLoss: 0.4477\t\n",
      "Subject: 26, n=11 | test_f1: 0.2807 |best_f1: 0.80702\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1336\tTop_Loss: 0.3074\tBottom_Loss: 0.1888\tLoss: 0.6298\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1442\tTop_Loss: 0.2550\tBottom_Loss: 0.1869\tLoss: 0.5861\t\n",
      "Subject: 26, n=11 | test_f1: 0.80702 |best_f1: 0.80702\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1199\tTop_Loss: 0.2740\tBottom_Loss: 0.1406\tLoss: 0.5344\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1050\tTop_Loss: 0.3392\tBottom_Loss: 0.2092\tLoss: 0.6534\t\n",
      "Subject: 26, n=11 | test_f1: 0.45 |best_f1: 0.80702\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1558\tTop_Loss: 0.2494\tBottom_Loss: 0.2488\tLoss: 0.6540\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0604\tTop_Loss: 0.2570\tBottom_Loss: 0.1147\tLoss: 0.4321\t\n",
      "Subject: 26, n=11 | test_f1: 0.51852 |best_f1: 0.80702\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1243\tTop_Loss: 0.2154\tBottom_Loss: 0.2477\tLoss: 0.5875\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1046\tTop_Loss: 0.2987\tBottom_Loss: 0.1683\tLoss: 0.5716\t\n",
      "Subject: 26, n=11 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0853\tTop_Loss: 0.2376\tBottom_Loss: 0.1248\tLoss: 0.4478\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0758\tTop_Loss: 0.1475\tBottom_Loss: 0.1874\tLoss: 0.4107\t\n",
      "Subject: 26, n=11 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1227\tTop_Loss: 0.3989\tBottom_Loss: 0.2429\tLoss: 0.7645\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0406\tTop_Loss: 0.1447\tBottom_Loss: 0.0732\tLoss: 0.2586\t\n",
      "Subject: 26, n=11 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0693\tTop_Loss: 0.1822\tBottom_Loss: 0.1087\tLoss: 0.3601\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1051\tTop_Loss: 0.2206\tBottom_Loss: 0.1028\tLoss: 0.4284\t\n",
      "Subject: 26, n=11 | test_f1: 0.38889 |best_f1: 1.0\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0646\tTop_Loss: 0.2011\tBottom_Loss: 0.1349\tLoss: 0.4006\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0513\tTop_Loss: 0.1153\tBottom_Loss: 0.0782\tLoss: 0.2448\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 26, n=11 | test_f1: 0.51852 |best_f1: 1.0\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0668\tTop_Loss: 0.2432\tBottom_Loss: 0.0996\tLoss: 0.4096\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0933\tTop_Loss: 0.2274\tBottom_Loss: 0.1023\tLoss: 0.4230\t\n",
      "Subject: 26, n=11 | test_f1: 0.51852 |best_f1: 1.0\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0452\tTop_Loss: 0.1249\tBottom_Loss: 0.1212\tLoss: 0.2913\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1483\tTop_Loss: 0.1719\tBottom_Loss: 0.2314\tLoss: 0.5517\t\n",
      "Subject: 26, n=11 | test_f1: 0.69444 |best_f1: 1.0\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0418\tTop_Loss: 0.1422\tBottom_Loss: 0.1028\tLoss: 0.2868\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0617\tTop_Loss: 0.1053\tBottom_Loss: 0.0978\tLoss: 0.2648\t\n",
      "Subject: 26, n=11 | test_f1: 0.80702 |best_f1: 1.0\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0720\tTop_Loss: 0.2282\tBottom_Loss: 0.0971\tLoss: 0.3973\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1884\tTop_Loss: 0.2618\tBottom_Loss: 0.1997\tLoss: 0.6499\t\n",
      "Subject: 26, n=11 | test_f1: 0.2807 |best_f1: 1.0\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0221\tTop_Loss: 0.1020\tBottom_Loss: 0.0648\tLoss: 0.1889\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0504\tTop_Loss: 0.1282\tBottom_Loss: 0.1000\tLoss: 0.2786\t\n",
      "Subject: 26, n=11 | test_f1: 0.80702 |best_f1: 1.0\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0839\tTop_Loss: 0.1404\tBottom_Loss: 0.2688\tLoss: 0.4931\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0607\tTop_Loss: 0.1524\tBottom_Loss: 0.1489\tLoss: 0.3619\t\n",
      "Subject: 26, n=11 | test_f1: 0.45 |best_f1: 1.0\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0399\tTop_Loss: 0.1430\tBottom_Loss: 0.0446\tLoss: 0.2276\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0843\tTop_Loss: 0.2038\tBottom_Loss: 0.1449\tLoss: 0.4330\t\n",
      "Subject: 26, n=11 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0790\tTop_Loss: 0.2061\tBottom_Loss: 0.0754\tLoss: 0.3606\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0520\tTop_Loss: 0.1131\tBottom_Loss: 0.1064\tLoss: 0.2715\t\n",
      "Subject: 26, n=11 | test_f1: 0.44118 |best_f1: 1.0\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0261\tTop_Loss: 0.0342\tBottom_Loss: 0.1494\tLoss: 0.2098\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0473\tTop_Loss: 0.2017\tBottom_Loss: 0.0787\tLoss: 0.3277\t\n",
      "Subject: 26, n=11 | test_f1: 0.51852 |best_f1: 1.0\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0728\tTop_Loss: 0.1409\tBottom_Loss: 0.1442\tLoss: 0.3580\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0489\tTop_Loss: 0.0941\tBottom_Loss: 0.1419\tLoss: 0.2849\t\n",
      "Subject: 26, n=11 | test_f1: 0.69444 |best_f1: 1.0\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0288\tTop_Loss: 0.1159\tBottom_Loss: 0.0601\tLoss: 0.2048\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0476\tTop_Loss: 0.1064\tBottom_Loss: 0.1125\tLoss: 0.2664\t\n",
      "Subject: 26, n=11 | test_f1: 0.25926 |best_f1: 1.0\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0474\tTop_Loss: 0.0948\tBottom_Loss: 0.1213\tLoss: 0.2635\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0319\tTop_Loss: 0.0901\tBottom_Loss: 0.0811\tLoss: 0.2031\t\n",
      "Subject: 26, n=11 | test_f1: 0.45 |best_f1: 1.0\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0209\tTop_Loss: 0.0962\tBottom_Loss: 0.0508\tLoss: 0.1678\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 0.938\tLabel_Loss: 0.0895\tTop_Loss: 0.1863\tBottom_Loss: 0.1595\tLoss: 0.4353\t\n",
      "Subject: 26, n=11 | test_f1: 0.2807 |best_f1: 1.0\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0138\tTop_Loss: 0.0472\tBottom_Loss: 0.0443\tLoss: 0.1053\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0497\tTop_Loss: 0.1209\tBottom_Loss: 0.0760\tLoss: 0.2466\t\n",
      "Subject: 26, n=11 | test_f1: 0.80702 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0141\tTop_Loss: 0.0694\tBottom_Loss: 0.0511\tLoss: 0.1347\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0867\tTop_Loss: 0.2008\tBottom_Loss: 0.0991\tLoss: 0.3866\t\n",
      "Subject: 26, n=11 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1334\tTop_Loss: 0.2637\tBottom_Loss: 0.0897\tLoss: 0.4869\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0259\tTop_Loss: 0.1845\tBottom_Loss: 0.0468\tLoss: 0.2573\t\n",
      "Subject: 26, n=11 | test_f1: 0.80702 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0559\tTop_Loss: 0.1602\tBottom_Loss: 0.0617\tLoss: 0.2778\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0699\tTop_Loss: 0.1123\tBottom_Loss: 0.0454\tLoss: 0.2276\t\n",
      "Subject: 26, n=11 | test_f1: 0.64706 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0137\tTop_Loss: 0.0516\tBottom_Loss: 0.0735\tLoss: 0.1388\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0774\tTop_Loss: 0.1592\tBottom_Loss: 0.1407\tLoss: 0.3773\t\n",
      "Subject: 26, n=11 | test_f1: 0.23529 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0873\tTop_Loss: 0.1020\tBottom_Loss: 0.1951\tLoss: 0.3844\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0110\tTop_Loss: 0.0760\tBottom_Loss: 0.0312\tLoss: 0.1182\t\n",
      "Subject: 26, n=11 | test_f1: 0.2807 |best_f1: 1.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0490\tTop_Loss: 0.1256\tBottom_Loss: 0.0573\tLoss: 0.2320\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0266\tTop_Loss: 0.1425\tBottom_Loss: 0.0369\tLoss: 0.2061\t\n",
      "Subject: 26, n=11 | test_f1: 0.45 |best_f1: 1.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0203\tTop_Loss: 0.0901\tBottom_Loss: 0.0636\tLoss: 0.1741\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0362\tTop_Loss: 0.0484\tBottom_Loss: 0.0583\tLoss: 0.1429\t\n",
      "Subject: 26, n=11 | test_f1: 0.80702 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0260\tTop_Loss: 0.1579\tBottom_Loss: 0.0484\tLoss: 0.2323\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0470\tTop_Loss: 0.0908\tBottom_Loss: 0.1378\tLoss: 0.2756\t\n",
      "Subject: 26, n=11 | test_f1: 0.2807 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0316\tTop_Loss: 0.0410\tBottom_Loss: 0.0809\tLoss: 0.1535\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0247\tTop_Loss: 0.1227\tBottom_Loss: 0.0460\tLoss: 0.1934\t\n",
      "Subject: 26, n=11 | test_f1: 0.2807 |best_f1: 1.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0127\tTop_Loss: 0.0475\tBottom_Loss: 0.0540\tLoss: 0.1142\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0436\tTop_Loss: 0.0524\tBottom_Loss: 0.0466\tLoss: 0.1425\t\n",
      "Subject: 26, n=11 | test_f1: 0.80702 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0266\tTop_Loss: 0.0918\tBottom_Loss: 0.0254\tLoss: 0.1439\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0242\tTop_Loss: 0.0739\tBottom_Loss: 0.0530\tLoss: 0.1511\t\n",
      "Subject: 26, n=11 | test_f1: 0.45 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0484\tTop_Loss: 0.0471\tBottom_Loss: 0.0746\tLoss: 0.1700\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0182\tTop_Loss: 0.0529\tBottom_Loss: 0.0548\tLoss: 0.1259\t\n",
      "Subject: 26, n=11 | test_f1: 0.51852 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0531\tTop_Loss: 0.0722\tBottom_Loss: 0.1170\tLoss: 0.2423\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0189\tTop_Loss: 0.0525\tBottom_Loss: 0.0571\tLoss: 0.1285\t\n",
      "Subject: 26, n=11 | test_f1: 0.64706 |best_f1: 1.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0142\tTop_Loss: 0.0726\tBottom_Loss: 0.0297\tLoss: 0.1165\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0120\tTop_Loss: 0.0706\tBottom_Loss: 0.0413\tLoss: 0.1239\t\n",
      "Subject: 26, n=11 | test_f1: 0.25926 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0580\tTop_Loss: 0.1021\tBottom_Loss: 0.0327\tLoss: 0.1928\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0211\tTop_Loss: 0.0733\tBottom_Loss: 0.0689\tLoss: 0.1633\t\n",
      "Subject: 26, n=11 | test_f1: 0.51852 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0536\tTop_Loss: 0.1493\tBottom_Loss: 0.0867\tLoss: 0.2896\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0238\tTop_Loss: 0.0452\tBottom_Loss: 0.0507\tLoss: 0.1197\t\n",
      "Subject: 26, n=11 | test_f1: 0.64706 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0063\tTop_Loss: 0.0191\tBottom_Loss: 0.0212\tLoss: 0.0466\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0101\tTop_Loss: 0.0340\tBottom_Loss: 0.0355\tLoss: 0.0796\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 26, n=11 | test_f1: 0.2807 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0172\tTop_Loss: 0.0760\tBottom_Loss: 0.0252\tLoss: 0.1183\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0125\tTop_Loss: 0.0529\tBottom_Loss: 0.0175\tLoss: 0.0829\t\n",
      "Subject: 26, n=11 | test_f1: 0.51852 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0225\tTop_Loss: 0.0625\tBottom_Loss: 0.0631\tLoss: 0.1480\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0228\tTop_Loss: 0.0408\tBottom_Loss: 0.1250\tLoss: 0.1886\t\n",
      "Subject: 26, n=11 | test_f1: 0.80702 |best_f1: 1.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0139\tTop_Loss: 0.0801\tBottom_Loss: 0.0272\tLoss: 0.1212\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0042\tTop_Loss: 0.0238\tBottom_Loss: 0.0173\tLoss: 0.0454\t\n",
      "Subject: 26, n=11 | test_f1: 0.2807 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0105\tTop_Loss: 0.0837\tBottom_Loss: 0.0280\tLoss: 0.1221\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0065\tTop_Loss: 0.0200\tBottom_Loss: 0.0375\tLoss: 0.0640\t\n",
      "Subject: 26, n=11 | test_f1: 0.80702 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0110\tTop_Loss: 0.0279\tBottom_Loss: 0.0519\tLoss: 0.0907\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0054\tTop_Loss: 0.0305\tBottom_Loss: 0.0165\tLoss: 0.0524\t\n",
      "Subject: 26, n=11 | test_f1: 0.45 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0095\tTop_Loss: 0.0463\tBottom_Loss: 0.0533\tLoss: 0.1091\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0202\tTop_Loss: 0.0480\tBottom_Loss: 0.0384\tLoss: 0.1066\t\n",
      "Subject: 26, n=11 | test_f1: 0.51852 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0115\tTop_Loss: 0.0275\tBottom_Loss: 0.0338\tLoss: 0.0727\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0066\tTop_Loss: 0.0269\tBottom_Loss: 0.0140\tLoss: 0.0475\t\n",
      "Subject: 26, n=11 | test_f1: 0.64706 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0038\tTop_Loss: 0.0129\tBottom_Loss: 0.0072\tLoss: 0.0239\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0423\tTop_Loss: 0.0362\tBottom_Loss: 0.1042\tLoss: 0.1826\t\n",
      "Subject: 26, n=11 | test_f1: 0.80702 |best_f1: 1.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0166\tTop_Loss: 0.0424\tBottom_Loss: 0.0249\tLoss: 0.0839\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0052\tTop_Loss: 0.0259\tBottom_Loss: 0.0103\tLoss: 0.0415\t\n",
      "Subject: 26, n=11 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.438\tLabel_Loss: 1.3530\tTop_Loss: 1.5302\tBottom_Loss: 1.2511\tLoss: 4.1344\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.500\tLabel_Loss: 1.1604\tTop_Loss: 1.0538\tBottom_Loss: 1.2366\tLoss: 3.4508\t\n",
      "Subject: s1, n=06 | test_f1: 0.22222 |best_f1: 0.22222\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.531\tLabel_Loss: 0.9519\tTop_Loss: 1.1080\tBottom_Loss: 0.9472\tLoss: 3.0071\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.500\tLabel_Loss: 1.0552\tTop_Loss: 1.0012\tBottom_Loss: 1.0935\tLoss: 3.1499\t\n",
      "Subject: s1, n=06 | test_f1: 0.095238 |best_f1: 0.22222\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.375\tLabel_Loss: 1.0464\tTop_Loss: 1.1283\tBottom_Loss: 1.0547\tLoss: 3.2295\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.656\tLabel_Loss: 0.9290\tTop_Loss: 0.8512\tBottom_Loss: 0.9705\tLoss: 2.7507\t\n",
      "Subject: s1, n=06 | test_f1: 0.22222 |best_f1: 0.22222\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.594\tLabel_Loss: 0.9779\tTop_Loss: 1.1589\tBottom_Loss: 0.9836\tLoss: 3.1204\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.594\tLabel_Loss: 1.0582\tTop_Loss: 0.9774\tBottom_Loss: 0.9295\tLoss: 2.9651\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.22222\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.406\tLabel_Loss: 1.1506\tTop_Loss: 1.1035\tBottom_Loss: 1.0814\tLoss: 3.3355\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.469\tLabel_Loss: 1.0242\tTop_Loss: 0.9327\tBottom_Loss: 0.9113\tLoss: 2.8682\t\n",
      "Subject: s1, n=06 | test_f1: 0.19048 |best_f1: 0.22222\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.625\tLabel_Loss: 0.9189\tTop_Loss: 0.8235\tBottom_Loss: 0.7584\tLoss: 2.5009\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7802\tTop_Loss: 0.8193\tBottom_Loss: 0.8798\tLoss: 2.4793\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.22222\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.438\tLabel_Loss: 0.9877\tTop_Loss: 0.9874\tBottom_Loss: 1.0289\tLoss: 3.0040\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7334\tTop_Loss: 0.9166\tBottom_Loss: 0.9308\tLoss: 2.5808\t\n",
      "Subject: s1, n=06 | test_f1: 0.22222 |best_f1: 0.22222\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7595\tTop_Loss: 0.8881\tBottom_Loss: 0.7923\tLoss: 2.4399\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.531\tLabel_Loss: 0.9552\tTop_Loss: 0.9184\tBottom_Loss: 0.9318\tLoss: 2.8054\t\n",
      "Subject: s1, n=06 | test_f1: 0.11111 |best_f1: 0.22222\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8646\tTop_Loss: 0.8226\tBottom_Loss: 0.8157\tLoss: 2.5029\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.531\tLabel_Loss: 0.9092\tTop_Loss: 0.8803\tBottom_Loss: 0.9679\tLoss: 2.7573\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.22222\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.531\tLabel_Loss: 1.0840\tTop_Loss: 1.0401\tBottom_Loss: 1.1290\tLoss: 3.2531\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5624\tTop_Loss: 0.5214\tBottom_Loss: 0.6887\tLoss: 1.7725\t\n",
      "Subject: s1, n=06 | test_f1: 0.19048 |best_f1: 0.22222\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.594\tLabel_Loss: 0.7901\tTop_Loss: 0.9029\tBottom_Loss: 0.9456\tLoss: 2.6386\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6158\tTop_Loss: 0.6187\tBottom_Loss: 0.6188\tLoss: 1.8533\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.22222\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4889\tTop_Loss: 0.6872\tBottom_Loss: 0.6773\tLoss: 1.8535\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5066\tTop_Loss: 0.5548\tBottom_Loss: 0.6943\tLoss: 1.7556\t\n",
      "Subject: s1, n=06 | test_f1: 0.26667 |best_f1: 0.26667\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6435\tTop_Loss: 0.6763\tBottom_Loss: 0.8363\tLoss: 2.1561\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5721\tTop_Loss: 0.7043\tBottom_Loss: 0.7712\tLoss: 2.0476\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.26667\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.656\tLabel_Loss: 0.6782\tTop_Loss: 0.6252\tBottom_Loss: 0.8711\tLoss: 2.1745\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8229\tTop_Loss: 0.9955\tBottom_Loss: 0.7687\tLoss: 2.5872\t\n",
      "Subject: s1, n=06 | test_f1: 0.11111 |best_f1: 0.26667\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.812\tLabel_Loss: 0.7157\tTop_Loss: 0.8748\tBottom_Loss: 0.7087\tLoss: 2.2992\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5992\tTop_Loss: 0.4843\tBottom_Loss: 0.8231\tLoss: 1.9067\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.26667\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.562\tLabel_Loss: 0.7745\tTop_Loss: 0.8771\tBottom_Loss: 0.9393\tLoss: 2.5909\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5819\tTop_Loss: 0.5698\tBottom_Loss: 0.7560\tLoss: 1.9076\t\n",
      "Subject: s1, n=06 | test_f1: 0.22222 |best_f1: 0.26667\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6119\tTop_Loss: 0.4964\tBottom_Loss: 0.5584\tLoss: 1.6666\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6117\tTop_Loss: 0.6660\tBottom_Loss: 0.5895\tLoss: 1.8672\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.26667\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3994\tTop_Loss: 0.4598\tBottom_Loss: 0.4842\tLoss: 1.3435\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4613\tTop_Loss: 0.5800\tBottom_Loss: 0.5451\tLoss: 1.5864\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.26667\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.844\tLabel_Loss: 0.5902\tTop_Loss: 0.6481\tBottom_Loss: 0.6322\tLoss: 1.8705\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6364\tTop_Loss: 0.7306\tBottom_Loss: 0.7901\tLoss: 2.1570\t\n",
      "Subject: s1, n=06 | test_f1: 0.4127 |best_f1: 0.4127\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.875\tLabel_Loss: 0.5448\tTop_Loss: 0.7695\tBottom_Loss: 0.7018\tLoss: 2.0161\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5337\tTop_Loss: 0.7499\tBottom_Loss: 0.5300\tLoss: 1.8137\t\n",
      "Subject: s1, n=06 | test_f1: 0.19048 |best_f1: 0.4127\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5015\tTop_Loss: 0.6623\tBottom_Loss: 0.5700\tLoss: 1.7339\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4825\tTop_Loss: 0.7010\tBottom_Loss: 0.5818\tLoss: 1.7653\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.4127\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.938\tLabel_Loss: 0.3290\tTop_Loss: 0.6274\tBottom_Loss: 0.3881\tLoss: 1.3445\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4183\tTop_Loss: 0.6265\tBottom_Loss: 0.5119\tLoss: 1.5567\t\n",
      "Subject: s1, n=06 | test_f1: 0.4127 |best_f1: 0.4127\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5502\tTop_Loss: 0.5075\tBottom_Loss: 0.5363\tLoss: 1.5940\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4536\tTop_Loss: 0.5000\tBottom_Loss: 0.4859\tLoss: 1.4395\t\n",
      "Subject: s1, n=06 | test_f1: 0.19048 |best_f1: 0.4127\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2718\tTop_Loss: 0.5090\tBottom_Loss: 0.4526\tLoss: 1.2334\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4222\tTop_Loss: 0.4374\tBottom_Loss: 0.4586\tLoss: 1.3182\t\n",
      "Subject: s1, n=06 | test_f1: 0.4127 |best_f1: 0.4127\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5720\tTop_Loss: 0.8253\tBottom_Loss: 0.5992\tLoss: 1.9966\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4040\tTop_Loss: 0.5541\tBottom_Loss: 0.4928\tLoss: 1.4508\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.4127\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3883\tTop_Loss: 0.5690\tBottom_Loss: 0.6845\tLoss: 1.6419\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3600\tTop_Loss: 0.4962\tBottom_Loss: 0.4700\tLoss: 1.3262\t\n",
      "Subject: s1, n=06 | test_f1: 0.22222 |best_f1: 0.4127\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4229\tTop_Loss: 0.4423\tBottom_Loss: 0.6529\tLoss: 1.5180\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3381\tTop_Loss: 0.4624\tBottom_Loss: 0.5307\tLoss: 1.3311\t\n",
      "Subject: s1, n=06 | test_f1: 0.72222 |best_f1: 0.72222\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4074\tTop_Loss: 0.4582\tBottom_Loss: 0.4956\tLoss: 1.3613\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2545\tTop_Loss: 0.4712\tBottom_Loss: 0.3333\tLoss: 1.0590\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3152\tTop_Loss: 0.4076\tBottom_Loss: 0.4054\tLoss: 1.1282\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3283\tTop_Loss: 0.4200\tBottom_Loss: 0.4954\tLoss: 1.2437\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2565\tTop_Loss: 0.3307\tBottom_Loss: 0.3986\tLoss: 0.9857\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2791\tTop_Loss: 0.5745\tBottom_Loss: 0.3188\tLoss: 1.1724\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2561\tTop_Loss: 0.3722\tBottom_Loss: 0.3776\tLoss: 1.0058\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4418\tTop_Loss: 0.4441\tBottom_Loss: 0.6417\tLoss: 1.5276\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3805\tTop_Loss: 0.5128\tBottom_Loss: 0.4485\tLoss: 1.3418\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3312\tTop_Loss: 0.5018\tBottom_Loss: 0.4138\tLoss: 1.2467\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4085\tTop_Loss: 0.5653\tBottom_Loss: 0.5283\tLoss: 1.5021\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2583\tTop_Loss: 0.4048\tBottom_Loss: 0.3966\tLoss: 1.0598\t\n",
      "Subject: s1, n=06 | test_f1: 0.4127 |best_f1: 0.72222\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2229\tTop_Loss: 0.3495\tBottom_Loss: 0.3211\tLoss: 0.8934\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3665\tTop_Loss: 0.3621\tBottom_Loss: 0.4333\tLoss: 1.1619\t\n",
      "Subject: s1, n=06 | test_f1: 0.33333 |best_f1: 0.72222\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4186\tTop_Loss: 0.3897\tBottom_Loss: 0.3745\tLoss: 1.1829\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1048\tTop_Loss: 0.2994\tBottom_Loss: 0.1771\tLoss: 0.5812\t\n",
      "Subject: s1, n=06 | test_f1: 0.095238 |best_f1: 0.72222\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2288\tTop_Loss: 0.3433\tBottom_Loss: 0.3486\tLoss: 0.9207\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2322\tTop_Loss: 0.2771\tBottom_Loss: 0.3449\tLoss: 0.8542\t\n",
      "Subject: s1, n=06 | test_f1: 0.25 |best_f1: 0.72222\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2713\tTop_Loss: 0.3953\tBottom_Loss: 0.4440\tLoss: 1.1106\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2515\tTop_Loss: 0.3291\tBottom_Loss: 0.2377\tLoss: 0.8184\t\n",
      "Subject: s1, n=06 | test_f1: 0.11111 |best_f1: 0.72222\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1695\tTop_Loss: 0.3220\tBottom_Loss: 0.3112\tLoss: 0.8028\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2004\tTop_Loss: 0.3362\tBottom_Loss: 0.3342\tLoss: 0.8708\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2204\tTop_Loss: 0.3670\tBottom_Loss: 0.3296\tLoss: 0.9169\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2128\tTop_Loss: 0.3190\tBottom_Loss: 0.3465\tLoss: 0.8783\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2075\tTop_Loss: 0.3248\tBottom_Loss: 0.3264\tLoss: 0.8588\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1847\tTop_Loss: 0.3612\tBottom_Loss: 0.2226\tLoss: 0.7685\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2369\tTop_Loss: 0.2772\tBottom_Loss: 0.4289\tLoss: 0.9430\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1917\tTop_Loss: 0.2507\tBottom_Loss: 0.2853\tLoss: 0.7277\t\n",
      "Subject: s1, n=06 | test_f1: 0.27778 |best_f1: 0.72222\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1081\tTop_Loss: 0.1901\tBottom_Loss: 0.2021\tLoss: 0.5003\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0804\tTop_Loss: 0.2277\tBottom_Loss: 0.1958\tLoss: 0.5039\t\n",
      "Subject: s1, n=06 | test_f1: 0.11111 |best_f1: 0.72222\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1116\tTop_Loss: 0.2744\tBottom_Loss: 0.2053\tLoss: 0.5912\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1822\tTop_Loss: 0.5851\tBottom_Loss: 0.2537\tLoss: 1.0209\t\n",
      "Subject: s1, n=06 | test_f1: 0.095238 |best_f1: 0.72222\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0833\tTop_Loss: 0.1580\tBottom_Loss: 0.1880\tLoss: 0.4293\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2255\tTop_Loss: 0.3504\tBottom_Loss: 0.2888\tLoss: 0.8647\t\n",
      "Subject: s1, n=06 | test_f1: 0.47222 |best_f1: 0.72222\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1042\tTop_Loss: 0.2867\tBottom_Loss: 0.2181\tLoss: 0.6090\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1414\tTop_Loss: 0.3818\tBottom_Loss: 0.2392\tLoss: 0.7624\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2083\tTop_Loss: 0.3389\tBottom_Loss: 0.2084\tLoss: 0.7557\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1727\tTop_Loss: 0.4013\tBottom_Loss: 0.3280\tLoss: 0.9021\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1925\tTop_Loss: 0.3511\tBottom_Loss: 0.2528\tLoss: 0.7964\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2398\tTop_Loss: 0.2730\tBottom_Loss: 0.2775\tLoss: 0.7904\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1029\tTop_Loss: 0.3027\tBottom_Loss: 0.1930\tLoss: 0.5986\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0929\tTop_Loss: 0.1578\tBottom_Loss: 0.1962\tLoss: 0.4469\t\n",
      "Subject: s1, n=06 | test_f1: 0.25 |best_f1: 0.72222\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1606\tTop_Loss: 0.2475\tBottom_Loss: 0.2513\tLoss: 0.6594\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1109\tTop_Loss: 0.2975\tBottom_Loss: 0.1862\tLoss: 0.5946\t\n",
      "Subject: s1, n=06 | test_f1: 0.22222 |best_f1: 0.72222\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1140\tTop_Loss: 0.3615\tBottom_Loss: 0.1793\tLoss: 0.6549\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0550\tTop_Loss: 0.2069\tBottom_Loss: 0.0874\tLoss: 0.3493\t\n",
      "Subject: s1, n=06 | test_f1: 0.52381 |best_f1: 0.72222\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2434\tTop_Loss: 0.3251\tBottom_Loss: 0.2390\tLoss: 0.8075\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1021\tTop_Loss: 0.2675\tBottom_Loss: 0.0989\tLoss: 0.4684\t\n",
      "Subject: s1, n=06 | test_f1: 0.11111 |best_f1: 0.72222\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1218\tTop_Loss: 0.2899\tBottom_Loss: 0.1685\tLoss: 0.5803\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0352\tTop_Loss: 0.1204\tBottom_Loss: 0.1086\tLoss: 0.2641\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: s1, n=06 | test_f1: 0.24444 |best_f1: 0.72222\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1248\tTop_Loss: 0.1871\tBottom_Loss: 0.1704\tLoss: 0.4823\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1457\tTop_Loss: 0.2189\tBottom_Loss: 0.3179\tLoss: 0.6826\t\n",
      "Subject: s1, n=06 | test_f1: 0.47222 |best_f1: 0.72222\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0708\tTop_Loss: 0.0957\tBottom_Loss: 0.1725\tLoss: 0.3390\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0436\tTop_Loss: 0.1550\tBottom_Loss: 0.1184\tLoss: 0.3169\t\n",
      "Subject: s1, n=06 | test_f1: 0.4127 |best_f1: 0.72222\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0914\tTop_Loss: 0.2627\tBottom_Loss: 0.1550\tLoss: 0.5091\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0460\tTop_Loss: 0.1367\tBottom_Loss: 0.1067\tLoss: 0.2894\t\n",
      "Subject: s1, n=06 | test_f1: 0.095238 |best_f1: 0.72222\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1885\tTop_Loss: 0.2752\tBottom_Loss: 0.2762\tLoss: 0.7399\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0691\tTop_Loss: 0.1888\tBottom_Loss: 0.0993\tLoss: 0.3572\t\n",
      "Subject: s1, n=06 | test_f1: 0.22222 |best_f1: 0.72222\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1462\tTop_Loss: 0.2604\tBottom_Loss: 0.2760\tLoss: 0.6826\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1878\tTop_Loss: 0.2726\tBottom_Loss: 0.2569\tLoss: 0.7173\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0259\tTop_Loss: 0.0668\tBottom_Loss: 0.0881\tLoss: 0.1808\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0877\tTop_Loss: 0.1226\tBottom_Loss: 0.1458\tLoss: 0.3560\t\n",
      "Subject: s1, n=06 | test_f1: 0.4127 |best_f1: 0.72222\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0386\tTop_Loss: 0.1083\tBottom_Loss: 0.0735\tLoss: 0.2204\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0324\tTop_Loss: 0.1167\tBottom_Loss: 0.1044\tLoss: 0.2536\t\n",
      "Subject: s1, n=06 | test_f1: 0.4127 |best_f1: 0.72222\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1249\tTop_Loss: 0.2120\tBottom_Loss: 0.1755\tLoss: 0.5124\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0771\tTop_Loss: 0.1863\tBottom_Loss: 0.1893\tLoss: 0.4527\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1599\tTop_Loss: 0.3249\tBottom_Loss: 0.1952\tLoss: 0.6800\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0804\tTop_Loss: 0.1516\tBottom_Loss: 0.1741\tLoss: 0.4060\t\n",
      "Subject: s1, n=06 | test_f1: 0.22222 |best_f1: 0.72222\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0242\tTop_Loss: 0.0791\tBottom_Loss: 0.0717\tLoss: 0.1750\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1108\tTop_Loss: 0.1844\tBottom_Loss: 0.2269\tLoss: 0.5220\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0928\tTop_Loss: 0.1898\tBottom_Loss: 0.1828\tLoss: 0.4653\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0352\tTop_Loss: 0.1242\tBottom_Loss: 0.0873\tLoss: 0.2466\t\n",
      "Subject: s1, n=06 | test_f1: 0.095238 |best_f1: 0.72222\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0562\tTop_Loss: 0.0966\tBottom_Loss: 0.1296\tLoss: 0.2824\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0837\tTop_Loss: 0.2312\tBottom_Loss: 0.1209\tLoss: 0.4357\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1678\tTop_Loss: 0.1776\tBottom_Loss: 0.1626\tLoss: 0.5079\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0325\tTop_Loss: 0.0532\tBottom_Loss: 0.0690\tLoss: 0.1547\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0345\tTop_Loss: 0.0425\tBottom_Loss: 0.0545\tLoss: 0.1314\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0270\tTop_Loss: 0.0832\tBottom_Loss: 0.0711\tLoss: 0.1813\t\n",
      "Subject: s1, n=06 | test_f1: 0.22222 |best_f1: 0.72222\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0487\tTop_Loss: 0.1303\tBottom_Loss: 0.1097\tLoss: 0.2887\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0297\tTop_Loss: 0.0741\tBottom_Loss: 0.0851\tLoss: 0.1889\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0678\tTop_Loss: 0.1576\tBottom_Loss: 0.1925\tLoss: 0.4179\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0366\tTop_Loss: 0.1539\tBottom_Loss: 0.1033\tLoss: 0.2937\t\n",
      "Subject: s1, n=06 | test_f1: 0.095238 |best_f1: 0.72222\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0440\tTop_Loss: 0.2455\tBottom_Loss: 0.0536\tLoss: 0.3431\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0467\tTop_Loss: 0.1228\tBottom_Loss: 0.0764\tLoss: 0.2459\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0191\tTop_Loss: 0.0891\tBottom_Loss: 0.0644\tLoss: 0.1726\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0653\tTop_Loss: 0.1089\tBottom_Loss: 0.1329\tLoss: 0.3071\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0311\tTop_Loss: 0.1331\tBottom_Loss: 0.0831\tLoss: 0.2473\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0637\tTop_Loss: 0.1677\tBottom_Loss: 0.0791\tLoss: 0.3106\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0217\tTop_Loss: 0.0794\tBottom_Loss: 0.0403\tLoss: 0.1415\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0865\tTop_Loss: 0.0924\tBottom_Loss: 0.1640\tLoss: 0.3429\t\n",
      "Subject: s1, n=06 | test_f1: 0.25 |best_f1: 0.72222\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0540\tTop_Loss: 0.1826\tBottom_Loss: 0.1299\tLoss: 0.3666\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0655\tTop_Loss: 0.0685\tBottom_Loss: 0.1922\tLoss: 0.3262\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0868\tTop_Loss: 0.1579\tBottom_Loss: 0.2326\tLoss: 0.4774\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0238\tTop_Loss: 0.0653\tBottom_Loss: 0.0477\tLoss: 0.1367\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0286\tTop_Loss: 0.0541\tBottom_Loss: 0.0437\tLoss: 0.1264\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0354\tTop_Loss: 0.0957\tBottom_Loss: 0.0855\tLoss: 0.2166\t\n",
      "Subject: s1, n=06 | test_f1: 0.095238 |best_f1: 0.72222\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0287\tTop_Loss: 0.0535\tBottom_Loss: 0.0608\tLoss: 0.1430\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0289\tTop_Loss: 0.0588\tBottom_Loss: 0.0657\tLoss: 0.1533\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0509\tTop_Loss: 0.0902\tBottom_Loss: 0.1075\tLoss: 0.2485\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0433\tTop_Loss: 0.1205\tBottom_Loss: 0.0543\tLoss: 0.2181\t\n",
      "Subject: s1, n=06 | test_f1: 0.11111 |best_f1: 0.72222\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0242\tTop_Loss: 0.0420\tBottom_Loss: 0.0578\tLoss: 0.1240\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0423\tTop_Loss: 0.0635\tBottom_Loss: 0.0620\tLoss: 0.1678\t\n",
      "Subject: s1, n=06 | test_f1: 0.095238 |best_f1: 0.72222\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0484\tTop_Loss: 0.0913\tBottom_Loss: 0.0796\tLoss: 0.2193\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0730\tTop_Loss: 0.1619\tBottom_Loss: 0.1119\tLoss: 0.3468\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0332\tTop_Loss: 0.0294\tBottom_Loss: 0.0464\tLoss: 0.1090\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0567\tTop_Loss: 0.0767\tBottom_Loss: 0.0958\tLoss: 0.2292\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0097\tTop_Loss: 0.0928\tBottom_Loss: 0.0199\tLoss: 0.1224\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0435\tTop_Loss: 0.0699\tBottom_Loss: 0.0716\tLoss: 0.1850\t\n",
      "Subject: s1, n=06 | test_f1: 0.4127 |best_f1: 0.72222\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0325\tTop_Loss: 0.1681\tBottom_Loss: 0.0620\tLoss: 0.2626\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0566\tTop_Loss: 0.0519\tBottom_Loss: 0.1596\tLoss: 0.2681\t\n",
      "Subject: s1, n=06 | test_f1: 0.19048 |best_f1: 0.72222\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0630\tTop_Loss: 0.0660\tBottom_Loss: 0.1258\tLoss: 0.2548\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0164\tTop_Loss: 0.0284\tBottom_Loss: 0.0520\tLoss: 0.0968\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0676\tTop_Loss: 0.2348\tBottom_Loss: 0.0380\tLoss: 0.3403\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0230\tTop_Loss: 0.0542\tBottom_Loss: 0.0381\tLoss: 0.1153\t\n",
      "Subject: s1, n=06 | test_f1: 0.4127 |best_f1: 0.72222\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0120\tTop_Loss: 0.0244\tBottom_Loss: 0.0465\tLoss: 0.0828\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0102\tTop_Loss: 0.0243\tBottom_Loss: 0.0346\tLoss: 0.0691\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0116\tTop_Loss: 0.0313\tBottom_Loss: 0.0233\tLoss: 0.0662\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0147\tTop_Loss: 0.0346\tBottom_Loss: 0.0274\tLoss: 0.0767\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0075\tTop_Loss: 0.0215\tBottom_Loss: 0.0182\tLoss: 0.0471\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0130\tTop_Loss: 0.0240\tBottom_Loss: 0.0230\tLoss: 0.0600\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0051\tTop_Loss: 0.0216\tBottom_Loss: 0.0157\tLoss: 0.0424\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0157\tTop_Loss: 0.0381\tBottom_Loss: 0.0388\tLoss: 0.0927\t\n",
      "Subject: s1, n=06 | test_f1: 0.66667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0237\tTop_Loss: 0.0956\tBottom_Loss: 0.0461\tLoss: 0.1654\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0101\tTop_Loss: 0.0391\tBottom_Loss: 0.0188\tLoss: 0.0680\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0094\tTop_Loss: 0.0325\tBottom_Loss: 0.0369\tLoss: 0.0788\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0214\tTop_Loss: 0.0743\tBottom_Loss: 0.0584\tLoss: 0.1542\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0179\tTop_Loss: 0.0345\tBottom_Loss: 0.0577\tLoss: 0.1101\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0093\tTop_Loss: 0.0298\tBottom_Loss: 0.0229\tLoss: 0.0620\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0080\tTop_Loss: 0.0349\tBottom_Loss: 0.0141\tLoss: 0.0570\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0179\tTop_Loss: 0.0392\tBottom_Loss: 0.0331\tLoss: 0.0902\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0177\tTop_Loss: 0.1354\tBottom_Loss: 0.0250\tLoss: 0.1781\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0570\tTop_Loss: 0.0895\tBottom_Loss: 0.0510\tLoss: 0.1975\t\n",
      "Subject: s1, n=06 | test_f1: 0.095238 |best_f1: 0.72222\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0147\tTop_Loss: 0.1027\tBottom_Loss: 0.0399\tLoss: 0.1573\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0329\tTop_Loss: 0.0471\tBottom_Loss: 0.0469\tLoss: 0.1270\t\n",
      "Subject: s1, n=06 | test_f1: 0.27778 |best_f1: 0.72222\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0063\tTop_Loss: 0.0312\tBottom_Loss: 0.0235\tLoss: 0.0610\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0064\tTop_Loss: 0.0288\tBottom_Loss: 0.0128\tLoss: 0.0479\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0471\tTop_Loss: 0.1338\tBottom_Loss: 0.0310\tLoss: 0.2119\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0407\tTop_Loss: 0.0324\tBottom_Loss: 0.0458\tLoss: 0.1189\t\n",
      "Subject: s1, n=06 | test_f1: 0.22222 |best_f1: 0.72222\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0248\tTop_Loss: 0.0351\tBottom_Loss: 0.1710\tLoss: 0.2309\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0151\tTop_Loss: 0.0573\tBottom_Loss: 0.0498\tLoss: 0.1222\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0062\tTop_Loss: 0.0277\tBottom_Loss: 0.0306\tLoss: 0.0646\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0169\tTop_Loss: 0.0217\tBottom_Loss: 0.0355\tLoss: 0.0742\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0096\tTop_Loss: 0.0656\tBottom_Loss: 0.0245\tLoss: 0.0997\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0092\tTop_Loss: 0.0411\tBottom_Loss: 0.0312\tLoss: 0.0815\t\n",
      "Subject: s1, n=06 | test_f1: 0.16667 |best_f1: 0.72222\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0111\tTop_Loss: 0.0380\tBottom_Loss: 0.0268\tLoss: 0.0759\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0063\tTop_Loss: 0.0336\tBottom_Loss: 0.0110\tLoss: 0.0509\t\n",
      "Subject: s1, n=06 | test_f1: 0.4127 |best_f1: 0.72222\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.219\tLabel_Loss: 1.3883\tTop_Loss: 1.1874\tBottom_Loss: 1.5270\tLoss: 4.1027\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.406\tLabel_Loss: 1.3184\tTop_Loss: 1.2774\tBottom_Loss: 1.1684\tLoss: 3.7643\t\n",
      "Subject: s11, n=07 | test_f1: 0.16667 |best_f1: 0.16667\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.562\tLabel_Loss: 0.9165\tTop_Loss: 1.1570\tBottom_Loss: 1.3067\tLoss: 3.3802\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.469\tLabel_Loss: 1.0229\tTop_Loss: 1.0046\tBottom_Loss: 1.0444\tLoss: 3.0719\t\n",
      "Subject: s11, n=07 | test_f1: 0.38889 |best_f1: 0.38889\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7774\tTop_Loss: 0.9721\tBottom_Loss: 0.7959\tLoss: 2.5454\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.562\tLabel_Loss: 0.9415\tTop_Loss: 1.0427\tBottom_Loss: 1.0250\tLoss: 3.0093\t\n",
      "Subject: s11, n=07 | test_f1: 0.51667 |best_f1: 0.51667\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8608\tTop_Loss: 0.9966\tBottom_Loss: 1.0264\tLoss: 2.8838\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.531\tLabel_Loss: 0.9620\tTop_Loss: 0.9974\tBottom_Loss: 1.0438\tLoss: 3.0032\t\n",
      "Subject: s11, n=07 | test_f1: 0.2 |best_f1: 0.51667\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8733\tTop_Loss: 0.8172\tBottom_Loss: 0.8008\tLoss: 2.4912\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.656\tLabel_Loss: 0.9423\tTop_Loss: 1.1125\tBottom_Loss: 0.8418\tLoss: 2.8965\t\n",
      "Subject: s11, n=07 | test_f1: 0.4127 |best_f1: 0.51667\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.656\tLabel_Loss: 0.8907\tTop_Loss: 0.8779\tBottom_Loss: 1.0173\tLoss: 2.7859\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.594\tLabel_Loss: 0.9656\tTop_Loss: 0.9075\tBottom_Loss: 0.8623\tLoss: 2.7354\t\n",
      "Subject: s11, n=07 | test_f1: 0.44444 |best_f1: 0.51667\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7755\tTop_Loss: 0.8469\tBottom_Loss: 0.7977\tLoss: 2.4202\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.531\tLabel_Loss: 0.8890\tTop_Loss: 1.0691\tBottom_Loss: 0.8192\tLoss: 2.7772\t\n",
      "Subject: s11, n=07 | test_f1: 0.33333 |best_f1: 0.51667\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.750\tLabel_Loss: 0.7253\tTop_Loss: 0.7533\tBottom_Loss: 0.6601\tLoss: 2.1387\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6453\tTop_Loss: 0.8719\tBottom_Loss: 0.9198\tLoss: 2.4369\t\n",
      "Subject: s11, n=07 | test_f1: 0.61905 |best_f1: 0.61905\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7023\tTop_Loss: 0.7825\tBottom_Loss: 0.8729\tLoss: 2.3577\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7745\tTop_Loss: 0.8620\tBottom_Loss: 0.8040\tLoss: 2.4405\t\n",
      "Subject: s11, n=07 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.812\tLabel_Loss: 0.6591\tTop_Loss: 0.8969\tBottom_Loss: 0.8422\tLoss: 2.3981\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.781\tLabel_Loss: 0.6294\tTop_Loss: 0.8178\tBottom_Loss: 0.7699\tLoss: 2.2171\t\n",
      "Subject: s11, n=07 | test_f1: 0.51667 |best_f1: 1.0\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.719\tLabel_Loss: 0.7189\tTop_Loss: 0.7864\tBottom_Loss: 0.7878\tLoss: 2.2931\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7402\tTop_Loss: 0.8815\tBottom_Loss: 0.7565\tLoss: 2.3782\t\n",
      "Subject: s11, n=07 | test_f1: 0.88571 |best_f1: 1.0\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6636\tTop_Loss: 0.8907\tBottom_Loss: 1.0107\tLoss: 2.5650\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5531\tTop_Loss: 0.6670\tBottom_Loss: 0.7875\tLoss: 2.0076\t\n",
      "Subject: s11, n=07 | test_f1: 0.61905 |best_f1: 1.0\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5901\tTop_Loss: 0.6760\tBottom_Loss: 0.5910\tLoss: 1.8570\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6263\tTop_Loss: 0.8785\tBottom_Loss: 0.8899\tLoss: 2.3947\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: s11, n=07 | test_f1: 0.88571 |best_f1: 1.0\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.656\tLabel_Loss: 0.6690\tTop_Loss: 0.6981\tBottom_Loss: 0.6257\tLoss: 1.9928\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6701\tTop_Loss: 0.8246\tBottom_Loss: 0.7842\tLoss: 2.2789\t\n",
      "Subject: s11, n=07 | test_f1: 0.88571 |best_f1: 1.0\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5509\tTop_Loss: 0.6728\tBottom_Loss: 0.7510\tLoss: 1.9747\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6097\tTop_Loss: 0.7759\tBottom_Loss: 0.9653\tLoss: 2.3509\t\n",
      "Subject: s11, n=07 | test_f1: 0.45714 |best_f1: 1.0\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5401\tTop_Loss: 0.5747\tBottom_Loss: 0.6626\tLoss: 1.7774\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5784\tTop_Loss: 0.7283\tBottom_Loss: 0.6648\tLoss: 1.9715\t\n",
      "Subject: s11, n=07 | test_f1: 0.51667 |best_f1: 1.0\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5273\tTop_Loss: 0.6795\tBottom_Loss: 0.6907\tLoss: 1.8975\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.812\tLabel_Loss: 0.6168\tTop_Loss: 0.6910\tBottom_Loss: 0.6523\tLoss: 1.9601\t\n",
      "Subject: s11, n=07 | test_f1: 0.38889 |best_f1: 1.0\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6503\tTop_Loss: 0.9237\tBottom_Loss: 0.8157\tLoss: 2.3897\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4939\tTop_Loss: 0.5234\tBottom_Loss: 0.6702\tLoss: 1.6875\t\n",
      "Subject: s11, n=07 | test_f1: 0.88571 |best_f1: 1.0\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4717\tTop_Loss: 0.5613\tBottom_Loss: 0.6429\tLoss: 1.6759\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5265\tTop_Loss: 0.6581\tBottom_Loss: 0.5431\tLoss: 1.7278\t\n",
      "Subject: s11, n=07 | test_f1: 0.88571 |best_f1: 1.0\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4367\tTop_Loss: 0.5553\tBottom_Loss: 0.6029\tLoss: 1.5949\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5714\tTop_Loss: 0.7961\tBottom_Loss: 0.6081\tLoss: 1.9755\t\n",
      "Subject: s11, n=07 | test_f1: 0.88571 |best_f1: 1.0\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5515\tTop_Loss: 0.6157\tBottom_Loss: 0.6852\tLoss: 1.8524\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3853\tTop_Loss: 0.6663\tBottom_Loss: 0.4978\tLoss: 1.5494\t\n",
      "Subject: s11, n=07 | test_f1: 0.38889 |best_f1: 1.0\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5458\tTop_Loss: 0.5139\tBottom_Loss: 0.6647\tLoss: 1.7243\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.906\tLabel_Loss: 0.4347\tTop_Loss: 0.6475\tBottom_Loss: 0.5294\tLoss: 1.6117\t\n",
      "Subject: s11, n=07 | test_f1: 0.51667 |best_f1: 1.0\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3105\tTop_Loss: 0.5968\tBottom_Loss: 0.4627\tLoss: 1.3700\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3772\tTop_Loss: 0.5519\tBottom_Loss: 0.3976\tLoss: 1.3267\t\n",
      "Subject: s11, n=07 | test_f1: 0.38889 |best_f1: 1.0\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4089\tTop_Loss: 0.5950\tBottom_Loss: 0.4471\tLoss: 1.4510\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3668\tTop_Loss: 0.6009\tBottom_Loss: 0.3706\tLoss: 1.3383\t\n",
      "Subject: s11, n=07 | test_f1: 0.88571 |best_f1: 1.0\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4226\tTop_Loss: 0.5108\tBottom_Loss: 0.4828\tLoss: 1.4162\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3224\tTop_Loss: 0.5082\tBottom_Loss: 0.3004\tLoss: 1.1310\t\n",
      "Subject: s11, n=07 | test_f1: 0.51667 |best_f1: 1.0\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5427\tTop_Loss: 0.6309\tBottom_Loss: 0.7049\tLoss: 1.8786\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4861\tTop_Loss: 0.6729\tBottom_Loss: 0.6607\tLoss: 1.8197\t\n",
      "Subject: s11, n=07 | test_f1: 0.51667 |best_f1: 1.0\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.750\tLabel_Loss: 0.4893\tTop_Loss: 0.6489\tBottom_Loss: 0.6909\tLoss: 1.8291\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4951\tTop_Loss: 0.6110\tBottom_Loss: 0.5188\tLoss: 1.6250\t\n",
      "Subject: s11, n=07 | test_f1: 0.51667 |best_f1: 1.0\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4225\tTop_Loss: 0.5352\tBottom_Loss: 0.6219\tLoss: 1.5796\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.781\tLabel_Loss: 0.3441\tTop_Loss: 0.4571\tBottom_Loss: 0.5056\tLoss: 1.3068\t\n",
      "Subject: s11, n=07 | test_f1: 0.51667 |best_f1: 1.0\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3520\tTop_Loss: 0.4833\tBottom_Loss: 0.4479\tLoss: 1.2832\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5264\tTop_Loss: 0.6738\tBottom_Loss: 0.6104\tLoss: 1.8106\t\n",
      "Subject: s11, n=07 | test_f1: 0.88571 |best_f1: 1.0\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.781\tLabel_Loss: 0.3951\tTop_Loss: 0.4857\tBottom_Loss: 0.5113\tLoss: 1.3921\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4709\tTop_Loss: 0.4967\tBottom_Loss: 0.7042\tLoss: 1.6718\t\n",
      "Subject: s11, n=07 | test_f1: 0.50794 |best_f1: 1.0\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1850\tTop_Loss: 0.5259\tBottom_Loss: 0.2389\tLoss: 0.9499\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3024\tTop_Loss: 0.5436\tBottom_Loss: 0.4039\tLoss: 1.2500\t\n",
      "Subject: s11, n=07 | test_f1: 0.75 |best_f1: 1.0\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2836\tTop_Loss: 0.4381\tBottom_Loss: 0.3536\tLoss: 1.0754\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3569\tTop_Loss: 0.5426\tBottom_Loss: 0.5198\tLoss: 1.4193\t\n",
      "Subject: s11, n=07 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2936\tTop_Loss: 0.5894\tBottom_Loss: 0.2696\tLoss: 1.1526\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1701\tTop_Loss: 0.3222\tBottom_Loss: 0.2843\tLoss: 0.7766\t\n",
      "Subject: s11, n=07 | test_f1: 0.51667 |best_f1: 1.0\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1742\tTop_Loss: 0.3723\tBottom_Loss: 0.2069\tLoss: 0.7534\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2109\tTop_Loss: 0.3836\tBottom_Loss: 0.3413\tLoss: 0.9358\t\n",
      "Subject: s11, n=07 | test_f1: 0.51667 |best_f1: 1.0\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1455\tTop_Loss: 0.3175\tBottom_Loss: 0.2004\tLoss: 0.6634\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3800\tTop_Loss: 0.3812\tBottom_Loss: 0.4189\tLoss: 1.1801\t\n",
      "Subject: s11, n=07 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1889\tTop_Loss: 0.3727\tBottom_Loss: 0.2952\tLoss: 0.8567\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3160\tTop_Loss: 0.3904\tBottom_Loss: 0.3873\tLoss: 1.0937\t\n",
      "Subject: s11, n=07 | test_f1: 0.51667 |best_f1: 1.0\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2326\tTop_Loss: 0.4422\tBottom_Loss: 0.3714\tLoss: 1.0462\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3596\tTop_Loss: 0.5389\tBottom_Loss: 0.5168\tLoss: 1.4153\t\n",
      "Subject: s11, n=07 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3564\tTop_Loss: 0.5280\tBottom_Loss: 0.4300\tLoss: 1.3145\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2038\tTop_Loss: 0.4069\tBottom_Loss: 0.2304\tLoss: 0.8412\t\n",
      "Subject: s11, n=07 | test_f1: 0.51667 |best_f1: 1.0\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2207\tTop_Loss: 0.4079\tBottom_Loss: 0.3627\tLoss: 0.9913\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1548\tTop_Loss: 0.3861\tBottom_Loss: 0.2763\tLoss: 0.8172\t\n",
      "Subject: s11, n=07 | test_f1: 0.88571 |best_f1: 1.0\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3788\tTop_Loss: 0.3666\tBottom_Loss: 0.6277\tLoss: 1.3731\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1559\tTop_Loss: 0.4443\tBottom_Loss: 0.2774\tLoss: 0.8777\t\n",
      "Subject: s11, n=07 | test_f1: 0.51667 |best_f1: 1.0\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2570\tTop_Loss: 0.4426\tBottom_Loss: 0.3249\tLoss: 1.0244\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1992\tTop_Loss: 0.3243\tBottom_Loss: 0.3157\tLoss: 0.8392\t\n",
      "Subject: s11, n=07 | test_f1: 0.61905 |best_f1: 1.0\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1953\tTop_Loss: 0.3426\tBottom_Loss: 0.3648\tLoss: 0.9027\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0943\tTop_Loss: 0.2549\tBottom_Loss: 0.2303\tLoss: 0.5796\t\n",
      "Subject: s11, n=07 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1116\tTop_Loss: 0.3575\tBottom_Loss: 0.1982\tLoss: 0.6673\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3104\tTop_Loss: 0.5370\tBottom_Loss: 0.3074\tLoss: 1.1547\t\n",
      "Subject: s11, n=07 | test_f1: 0.71111 |best_f1: 1.0\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1743\tTop_Loss: 0.3310\tBottom_Loss: 0.2923\tLoss: 0.7976\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1873\tTop_Loss: 0.4198\tBottom_Loss: 0.1862\tLoss: 0.7932\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: s11, n=07 | test_f1: 0.51667 |best_f1: 1.0\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1952\tTop_Loss: 0.3953\tBottom_Loss: 0.2723\tLoss: 0.8629\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1412\tTop_Loss: 0.2631\tBottom_Loss: 0.2407\tLoss: 0.6450\t\n",
      "Subject: s11, n=07 | test_f1: 0.51667 |best_f1: 1.0\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1567\tTop_Loss: 0.2567\tBottom_Loss: 0.3749\tLoss: 0.7882\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1075\tTop_Loss: 0.3276\tBottom_Loss: 0.1658\tLoss: 0.6010\t\n",
      "Subject: s11, n=07 | test_f1: 0.88571 |best_f1: 1.0\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0831\tTop_Loss: 0.2466\tBottom_Loss: 0.2119\tLoss: 0.5416\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2686\tTop_Loss: 0.4280\tBottom_Loss: 0.3143\tLoss: 1.0109\t\n",
      "Subject: s11, n=07 | test_f1: 0.51667 |best_f1: 1.0\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2587\tTop_Loss: 0.4041\tBottom_Loss: 0.2625\tLoss: 0.9252\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0847\tTop_Loss: 0.2888\tBottom_Loss: 0.1162\tLoss: 0.4896\t\n",
      "Subject: s11, n=07 | test_f1: 0.51667 |best_f1: 1.0\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1134\tTop_Loss: 0.3586\tBottom_Loss: 0.1155\tLoss: 0.5876\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2036\tTop_Loss: 0.2565\tBottom_Loss: 0.3715\tLoss: 0.8316\t\n",
      "Subject: s11, n=07 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1049\tTop_Loss: 0.2262\tBottom_Loss: 0.3117\tLoss: 0.6427\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1572\tTop_Loss: 0.2087\tBottom_Loss: 0.1659\tLoss: 0.5318\t\n",
      "Subject: s11, n=07 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0990\tTop_Loss: 0.1736\tBottom_Loss: 0.2426\tLoss: 0.5151\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1187\tTop_Loss: 0.2495\tBottom_Loss: 0.1500\tLoss: 0.5182\t\n",
      "Subject: s11, n=07 | test_f1: 0.88571 |best_f1: 1.0\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1213\tTop_Loss: 0.3266\tBottom_Loss: 0.1293\tLoss: 0.5771\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1116\tTop_Loss: 0.2655\tBottom_Loss: 0.1716\tLoss: 0.5487\t\n",
      "Subject: s11, n=07 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2146\tTop_Loss: 0.4356\tBottom_Loss: 0.3251\tLoss: 0.9753\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0883\tTop_Loss: 0.2132\tBottom_Loss: 0.1147\tLoss: 0.4162\t\n",
      "Subject: s11, n=07 | test_f1: 0.71111 |best_f1: 1.0\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1092\tTop_Loss: 0.2774\tBottom_Loss: 0.2200\tLoss: 0.6066\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3992\tTop_Loss: 0.4238\tBottom_Loss: 0.4662\tLoss: 1.2893\t\n",
      "Subject: s11, n=07 | test_f1: 0.88571 |best_f1: 1.0\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0693\tTop_Loss: 0.1387\tBottom_Loss: 0.1662\tLoss: 0.3741\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1058\tTop_Loss: 0.2311\tBottom_Loss: 0.2002\tLoss: 0.5371\t\n",
      "Subject: s11, n=07 | test_f1: 0.51667 |best_f1: 1.0\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1177\tTop_Loss: 0.2271\tBottom_Loss: 0.1446\tLoss: 0.4894\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1272\tTop_Loss: 0.2836\tBottom_Loss: 0.1889\tLoss: 0.5997\t\n",
      "Subject: s11, n=07 | test_f1: 0.88571 |best_f1: 1.0\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0955\tTop_Loss: 0.2174\tBottom_Loss: 0.1466\tLoss: 0.4596\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0554\tTop_Loss: 0.0860\tBottom_Loss: 0.1891\tLoss: 0.3305\t\n",
      "Subject: s11, n=07 | test_f1: 0.88571 |best_f1: 1.0\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2488\tTop_Loss: 0.3227\tBottom_Loss: 0.2420\tLoss: 0.8135\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0423\tTop_Loss: 0.0990\tBottom_Loss: 0.0887\tLoss: 0.2299\t\n",
      "Subject: s11, n=07 | test_f1: 0.51667 |best_f1: 1.0\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1162\tTop_Loss: 0.2063\tBottom_Loss: 0.2229\tLoss: 0.5454\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0981\tTop_Loss: 0.1800\tBottom_Loss: 0.1084\tLoss: 0.3866\t\n",
      "Subject: s11, n=07 | test_f1: 0.51667 |best_f1: 1.0\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1511\tTop_Loss: 0.1697\tBottom_Loss: 0.2596\tLoss: 0.5804\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0597\tTop_Loss: 0.2054\tBottom_Loss: 0.0683\tLoss: 0.3334\t\n",
      "Subject: s11, n=07 | test_f1: 0.51667 |best_f1: 1.0\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0691\tTop_Loss: 0.2229\tBottom_Loss: 0.1566\tLoss: 0.4486\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0554\tTop_Loss: 0.2198\tBottom_Loss: 0.0886\tLoss: 0.3639\t\n",
      "Subject: s11, n=07 | test_f1: 0.75 |best_f1: 1.0\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0464\tTop_Loss: 0.2125\tBottom_Loss: 0.0710\tLoss: 0.3299\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1495\tTop_Loss: 0.1832\tBottom_Loss: 0.1433\tLoss: 0.4761\t\n",
      "Subject: s11, n=07 | test_f1: 0.88571 |best_f1: 1.0\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0811\tTop_Loss: 0.2010\tBottom_Loss: 0.1240\tLoss: 0.4061\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0458\tTop_Loss: 0.1875\tBottom_Loss: 0.0916\tLoss: 0.3249\t\n",
      "Subject: s11, n=07 | test_f1: 0.38889 |best_f1: 1.0\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1065\tTop_Loss: 0.2105\tBottom_Loss: 0.0870\tLoss: 0.4039\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0414\tTop_Loss: 0.2099\tBottom_Loss: 0.0677\tLoss: 0.3190\t\n",
      "Subject: s11, n=07 | test_f1: 0.51667 |best_f1: 1.0\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1115\tTop_Loss: 0.2104\tBottom_Loss: 0.1056\tLoss: 0.4275\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1483\tTop_Loss: 0.3255\tBottom_Loss: 0.1861\tLoss: 0.6599\t\n",
      "Subject: s11, n=07 | test_f1: 0.45714 |best_f1: 1.0\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0654\tTop_Loss: 0.2009\tBottom_Loss: 0.0923\tLoss: 0.3586\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0313\tTop_Loss: 0.1458\tBottom_Loss: 0.0944\tLoss: 0.2714\t\n",
      "Subject: s11, n=07 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0373\tTop_Loss: 0.0756\tBottom_Loss: 0.1057\tLoss: 0.2186\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0388\tTop_Loss: 0.0850\tBottom_Loss: 0.0383\tLoss: 0.1621\t\n",
      "Subject: s11, n=07 | test_f1: 0.82222 |best_f1: 1.0\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0188\tTop_Loss: 0.0752\tBottom_Loss: 0.0447\tLoss: 0.1387\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0302\tTop_Loss: 0.1552\tBottom_Loss: 0.0853\tLoss: 0.2707\t\n",
      "Subject: s11, n=07 | test_f1: 0.45714 |best_f1: 1.0\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0335\tTop_Loss: 0.1266\tBottom_Loss: 0.0676\tLoss: 0.2277\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0915\tTop_Loss: 0.2827\tBottom_Loss: 0.1128\tLoss: 0.4870\t\n",
      "Subject: s11, n=07 | test_f1: 0.75 |best_f1: 1.0\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0239\tTop_Loss: 0.1032\tBottom_Loss: 0.0524\tLoss: 0.1795\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0278\tTop_Loss: 0.1141\tBottom_Loss: 0.0673\tLoss: 0.2092\t\n",
      "Subject: s11, n=07 | test_f1: 0.38889 |best_f1: 1.0\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0300\tTop_Loss: 0.0882\tBottom_Loss: 0.0581\tLoss: 0.1763\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1512\tTop_Loss: 0.3125\tBottom_Loss: 0.2464\tLoss: 0.7101\t\n",
      "Subject: s11, n=07 | test_f1: 0.82222 |best_f1: 1.0\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0469\tTop_Loss: 0.1714\tBottom_Loss: 0.0395\tLoss: 0.2578\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0394\tTop_Loss: 0.1714\tBottom_Loss: 0.0901\tLoss: 0.3010\t\n",
      "Subject: s11, n=07 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0321\tTop_Loss: 0.0732\tBottom_Loss: 0.0436\tLoss: 0.1489\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0435\tTop_Loss: 0.1664\tBottom_Loss: 0.1241\tLoss: 0.3340\t\n",
      "Subject: s11, n=07 | test_f1: 0.88571 |best_f1: 1.0\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0234\tTop_Loss: 0.0439\tBottom_Loss: 0.0298\tLoss: 0.0972\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0363\tTop_Loss: 0.0935\tBottom_Loss: 0.0350\tLoss: 0.1647\t\n",
      "Subject: s11, n=07 | test_f1: 0.71111 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0171\tTop_Loss: 0.0742\tBottom_Loss: 0.0541\tLoss: 0.1454\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0497\tTop_Loss: 0.0930\tBottom_Loss: 0.0768\tLoss: 0.2195\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: s11, n=07 | test_f1: 0.38889 |best_f1: 1.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0149\tTop_Loss: 0.0744\tBottom_Loss: 0.0255\tLoss: 0.1149\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0167\tTop_Loss: 0.0984\tBottom_Loss: 0.0231\tLoss: 0.1382\t\n",
      "Subject: s11, n=07 | test_f1: 0.38333 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0185\tTop_Loss: 0.0632\tBottom_Loss: 0.0703\tLoss: 0.1521\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0503\tTop_Loss: 0.1559\tBottom_Loss: 0.0510\tLoss: 0.2571\t\n",
      "Subject: s11, n=07 | test_f1: 0.61905 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0681\tTop_Loss: 0.2350\tBottom_Loss: 0.0880\tLoss: 0.3911\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0425\tTop_Loss: 0.1077\tBottom_Loss: 0.0393\tLoss: 0.1895\t\n",
      "Subject: s11, n=07 | test_f1: 0.55238 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0323\tTop_Loss: 0.0931\tBottom_Loss: 0.0408\tLoss: 0.1662\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0272\tTop_Loss: 0.0734\tBottom_Loss: 0.0440\tLoss: 0.1446\t\n",
      "Subject: s11, n=07 | test_f1: 0.88571 |best_f1: 1.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0188\tTop_Loss: 0.1471\tBottom_Loss: 0.0158\tLoss: 0.1817\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0117\tTop_Loss: 0.0943\tBottom_Loss: 0.0252\tLoss: 0.1312\t\n",
      "Subject: s11, n=07 | test_f1: 0.82222 |best_f1: 1.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0435\tTop_Loss: 0.1235\tBottom_Loss: 0.0703\tLoss: 0.2374\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0185\tTop_Loss: 0.0595\tBottom_Loss: 0.0407\tLoss: 0.1187\t\n",
      "Subject: s11, n=07 | test_f1: 0.38889 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0122\tTop_Loss: 0.0358\tBottom_Loss: 0.0302\tLoss: 0.0782\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0251\tTop_Loss: 0.0711\tBottom_Loss: 0.0886\tLoss: 0.1849\t\n",
      "Subject: s11, n=07 | test_f1: 0.61905 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0267\tTop_Loss: 0.1396\tBottom_Loss: 0.0162\tLoss: 0.1824\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0214\tTop_Loss: 0.1223\tBottom_Loss: 0.0661\tLoss: 0.2098\t\n",
      "Subject: s11, n=07 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0376\tTop_Loss: 0.0965\tBottom_Loss: 0.0262\tLoss: 0.1603\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0289\tTop_Loss: 0.0912\tBottom_Loss: 0.0607\tLoss: 0.1808\t\n",
      "Subject: s11, n=07 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0178\tTop_Loss: 0.0978\tBottom_Loss: 0.0470\tLoss: 0.1626\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0129\tTop_Loss: 0.0632\tBottom_Loss: 0.0438\tLoss: 0.1199\t\n",
      "Subject: s11, n=07 | test_f1: 0.88571 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0227\tTop_Loss: 0.0603\tBottom_Loss: 0.1079\tLoss: 0.1909\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0104\tTop_Loss: 0.0611\tBottom_Loss: 0.0168\tLoss: 0.0883\t\n",
      "Subject: s11, n=07 | test_f1: 0.71111 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0099\tTop_Loss: 0.0567\tBottom_Loss: 0.0155\tLoss: 0.0821\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0316\tTop_Loss: 0.0607\tBottom_Loss: 0.0806\tLoss: 0.1729\t\n",
      "Subject: s11, n=07 | test_f1: 0.61905 |best_f1: 1.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0149\tTop_Loss: 0.0469\tBottom_Loss: 0.0269\tLoss: 0.0887\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0427\tTop_Loss: 0.0861\tBottom_Loss: 0.0881\tLoss: 0.2169\t\n",
      "Subject: s11, n=07 | test_f1: 0.51667 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0144\tTop_Loss: 0.0359\tBottom_Loss: 0.0246\tLoss: 0.0748\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0142\tTop_Loss: 0.0526\tBottom_Loss: 0.0402\tLoss: 0.1070\t\n",
      "Subject: s11, n=07 | test_f1: 0.71111 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0059\tTop_Loss: 0.0249\tBottom_Loss: 0.0117\tLoss: 0.0426\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0190\tTop_Loss: 0.0408\tBottom_Loss: 0.0349\tLoss: 0.0947\t\n",
      "Subject: s11, n=07 | test_f1: 0.88571 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0106\tTop_Loss: 0.0456\tBottom_Loss: 0.0381\tLoss: 0.0944\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0186\tTop_Loss: 0.0736\tBottom_Loss: 0.0202\tLoss: 0.1125\t\n",
      "Subject: s11, n=07 | test_f1: 0.57937 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0571\tTop_Loss: 0.0938\tBottom_Loss: 0.1227\tLoss: 0.2736\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0083\tTop_Loss: 0.0441\tBottom_Loss: 0.0198\tLoss: 0.0722\t\n",
      "Subject: s11, n=07 | test_f1: 0.88571 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0483\tTop_Loss: 0.1074\tBottom_Loss: 0.1107\tLoss: 0.2663\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0120\tTop_Loss: 0.0580\tBottom_Loss: 0.0121\tLoss: 0.0821\t\n",
      "Subject: s11, n=07 | test_f1: 0.45714 |best_f1: 1.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0452\tTop_Loss: 0.1275\tBottom_Loss: 0.0858\tLoss: 0.2585\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0186\tTop_Loss: 0.0508\tBottom_Loss: 0.0380\tLoss: 0.1074\t\n",
      "Subject: s11, n=07 | test_f1: 0.51667 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0105\tTop_Loss: 0.0505\tBottom_Loss: 0.0333\tLoss: 0.0942\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0193\tTop_Loss: 0.0346\tBottom_Loss: 0.0281\tLoss: 0.0820\t\n",
      "Subject: s11, n=07 | test_f1: 0.38889 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0070\tTop_Loss: 0.0237\tBottom_Loss: 0.0141\tLoss: 0.0449\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0271\tTop_Loss: 0.1220\tBottom_Loss: 0.0283\tLoss: 0.1773\t\n",
      "Subject: s11, n=07 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0090\tTop_Loss: 0.0427\tBottom_Loss: 0.0393\tLoss: 0.0911\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0258\tTop_Loss: 0.0625\tBottom_Loss: 0.1106\tLoss: 0.1988\t\n",
      "Subject: s11, n=07 | test_f1: 0.71111 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0536\tTop_Loss: 0.1189\tBottom_Loss: 0.0352\tLoss: 0.2077\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0105\tTop_Loss: 0.0416\tBottom_Loss: 0.0330\tLoss: 0.0852\t\n",
      "Subject: s11, n=07 | test_f1: 0.45714 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0050\tTop_Loss: 0.0218\tBottom_Loss: 0.0072\tLoss: 0.0340\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0091\tTop_Loss: 0.0438\tBottom_Loss: 0.0282\tLoss: 0.0811\t\n",
      "Subject: s11, n=07 | test_f1: 0.88571 |best_f1: 1.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0083\tTop_Loss: 0.0391\tBottom_Loss: 0.0126\tLoss: 0.0601\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0467\tTop_Loss: 0.0725\tBottom_Loss: 0.0278\tLoss: 0.1470\t\n",
      "Subject: s11, n=07 | test_f1: 0.51667 |best_f1: 1.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.188\tLabel_Loss: 1.7541\tTop_Loss: 1.5510\tBottom_Loss: 1.1396\tLoss: 4.4447\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.375\tLabel_Loss: 1.0399\tTop_Loss: 1.1396\tBottom_Loss: 1.1258\tLoss: 3.3053\t\n",
      "Subject: s12, n=09 | test_f1: 0.074074 |best_f1: 0.074074\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.469\tLabel_Loss: 1.1856\tTop_Loss: 1.1914\tBottom_Loss: 1.3309\tLoss: 3.7079\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8396\tTop_Loss: 0.7681\tBottom_Loss: 0.7777\tLoss: 2.3854\t\n",
      "Subject: s12, n=09 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.500\tLabel_Loss: 1.1833\tTop_Loss: 1.0817\tBottom_Loss: 1.0637\tLoss: 3.3287\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.625\tLabel_Loss: 0.9130\tTop_Loss: 1.0607\tBottom_Loss: 1.2076\tLoss: 3.1813\t\n",
      "Subject: s12, n=09 | test_f1: 0.0 |best_f1: 0.46667\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8944\tTop_Loss: 0.7936\tBottom_Loss: 0.9176\tLoss: 2.6056\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.469\tLabel_Loss: 0.9777\tTop_Loss: 0.9925\tBottom_Loss: 1.2311\tLoss: 3.2013\t\n",
      "Subject: s12, n=09 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.562\tLabel_Loss: 0.9104\tTop_Loss: 0.9469\tBottom_Loss: 0.9102\tLoss: 2.7675\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8787\tTop_Loss: 0.8985\tBottom_Loss: 1.0600\tLoss: 2.8372\t\n",
      "Subject: s12, n=09 | test_f1: 0.0 |best_f1: 0.46667\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.844\tLabel_Loss: 0.5655\tTop_Loss: 0.6136\tBottom_Loss: 0.7199\tLoss: 1.8990\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.531\tLabel_Loss: 0.8895\tTop_Loss: 0.9155\tBottom_Loss: 0.9997\tLoss: 2.8047\t\n",
      "Subject: s12, n=09 | test_f1: 0.0 |best_f1: 0.46667\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7944\tTop_Loss: 0.8262\tBottom_Loss: 0.8338\tLoss: 2.4544\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8044\tTop_Loss: 0.6687\tBottom_Loss: 0.9760\tLoss: 2.4491\t\n",
      "Subject: s12, n=09 | test_f1: 0.22222 |best_f1: 0.46667\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.656\tLabel_Loss: 0.6715\tTop_Loss: 0.8092\tBottom_Loss: 0.7010\tLoss: 2.1817\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.562\tLabel_Loss: 0.9374\tTop_Loss: 0.9880\tBottom_Loss: 1.1582\tLoss: 3.0836\t\n",
      "Subject: s12, n=09 | test_f1: 0.0 |best_f1: 0.46667\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6460\tTop_Loss: 0.6878\tBottom_Loss: 0.7078\tLoss: 2.0417\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7907\tTop_Loss: 0.8699\tBottom_Loss: 0.9436\tLoss: 2.6042\t\n",
      "Subject: s12, n=09 | test_f1: 0.33333 |best_f1: 0.46667\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6810\tTop_Loss: 0.7359\tBottom_Loss: 0.6764\tLoss: 2.0933\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.562\tLabel_Loss: 0.9553\tTop_Loss: 1.0029\tBottom_Loss: 1.0835\tLoss: 3.0417\t\n",
      "Subject: s12, n=09 | test_f1: 0.18182 |best_f1: 0.46667\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.531\tLabel_Loss: 0.9274\tTop_Loss: 0.9887\tBottom_Loss: 0.7857\tLoss: 2.7018\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.594\tLabel_Loss: 0.7355\tTop_Loss: 0.8824\tBottom_Loss: 0.8783\tLoss: 2.4962\t\n",
      "Subject: s12, n=09 | test_f1: 0.074074 |best_f1: 0.46667\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.656\tLabel_Loss: 0.6628\tTop_Loss: 0.8052\tBottom_Loss: 0.8734\tLoss: 2.3413\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6305\tTop_Loss: 0.6691\tBottom_Loss: 0.6953\tLoss: 1.9948\t\n",
      "Subject: s12, n=09 | test_f1: 0.074074 |best_f1: 0.46667\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.781\tLabel_Loss: 0.6424\tTop_Loss: 0.6613\tBottom_Loss: 0.7340\tLoss: 2.0377\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7147\tTop_Loss: 0.7745\tBottom_Loss: 0.8551\tLoss: 2.3444\t\n",
      "Subject: s12, n=09 | test_f1: 0.18182 |best_f1: 0.46667\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.656\tLabel_Loss: 0.6063\tTop_Loss: 0.6975\tBottom_Loss: 0.8168\tLoss: 2.1206\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4461\tTop_Loss: 0.6253\tBottom_Loss: 0.5824\tLoss: 1.6538\t\n",
      "Subject: s12, n=09 | test_f1: 0.13333 |best_f1: 0.46667\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.656\tLabel_Loss: 0.5890\tTop_Loss: 0.7227\tBottom_Loss: 0.7919\tLoss: 2.1036\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4817\tTop_Loss: 0.5025\tBottom_Loss: 0.6304\tLoss: 1.6145\t\n",
      "Subject: s12, n=09 | test_f1: 0.2963 |best_f1: 0.46667\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5330\tTop_Loss: 0.7218\tBottom_Loss: 0.5699\tLoss: 1.8246\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7110\tTop_Loss: 0.8575\tBottom_Loss: 0.7399\tLoss: 2.3084\t\n",
      "Subject: s12, n=09 | test_f1: 0.074074 |best_f1: 0.46667\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5306\tTop_Loss: 0.6534\tBottom_Loss: 0.5983\tLoss: 1.7823\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6072\tTop_Loss: 0.7271\tBottom_Loss: 0.6126\tLoss: 1.9469\t\n",
      "Subject: s12, n=09 | test_f1: 0.25641 |best_f1: 0.46667\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6087\tTop_Loss: 0.6287\tBottom_Loss: 0.8323\tLoss: 2.0696\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.719\tLabel_Loss: 0.5702\tTop_Loss: 0.5749\tBottom_Loss: 0.6140\tLoss: 1.7591\t\n",
      "Subject: s12, n=09 | test_f1: 0.25641 |best_f1: 0.46667\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3559\tTop_Loss: 0.5029\tBottom_Loss: 0.4413\tLoss: 1.3001\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.938\tLabel_Loss: 0.3518\tTop_Loss: 0.5089\tBottom_Loss: 0.5275\tLoss: 1.3882\t\n",
      "Subject: s12, n=09 | test_f1: 0.074074 |best_f1: 0.46667\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4244\tTop_Loss: 0.5707\tBottom_Loss: 0.5047\tLoss: 1.4998\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5438\tTop_Loss: 0.6997\tBottom_Loss: 0.5884\tLoss: 1.8320\t\n",
      "Subject: s12, n=09 | test_f1: 0.22222 |best_f1: 0.46667\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3602\tTop_Loss: 0.5809\tBottom_Loss: 0.4644\tLoss: 1.4055\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3942\tTop_Loss: 0.5162\tBottom_Loss: 0.6277\tLoss: 1.5381\t\n",
      "Subject: s12, n=09 | test_f1: 0.18182 |best_f1: 0.46667\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.594\tLabel_Loss: 0.7155\tTop_Loss: 0.8399\tBottom_Loss: 0.7747\tLoss: 2.3301\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4019\tTop_Loss: 0.6238\tBottom_Loss: 0.4711\tLoss: 1.4968\t\n",
      "Subject: s12, n=09 | test_f1: 0.074074 |best_f1: 0.46667\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5130\tTop_Loss: 0.6235\tBottom_Loss: 0.5763\tLoss: 1.7128\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6430\tTop_Loss: 0.5526\tBottom_Loss: 0.6972\tLoss: 1.8928\t\n",
      "Subject: s12, n=09 | test_f1: 0.55556 |best_f1: 0.55556\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5030\tTop_Loss: 0.6714\tBottom_Loss: 0.5040\tLoss: 1.6784\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5548\tTop_Loss: 0.5845\tBottom_Loss: 0.5394\tLoss: 1.6787\t\n",
      "Subject: s12, n=09 | test_f1: 0.18182 |best_f1: 0.55556\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3225\tTop_Loss: 0.5554\tBottom_Loss: 0.5658\tLoss: 1.4437\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4472\tTop_Loss: 0.4719\tBottom_Loss: 0.5953\tLoss: 1.5143\t\n",
      "Subject: s12, n=09 | test_f1: 0.074074 |best_f1: 0.55556\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3695\tTop_Loss: 0.3782\tBottom_Loss: 0.4727\tLoss: 1.2203\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1994\tTop_Loss: 0.4364\tBottom_Loss: 0.3381\tLoss: 0.9738\t\n",
      "Subject: s12, n=09 | test_f1: 0.22222 |best_f1: 0.55556\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3751\tTop_Loss: 0.4400\tBottom_Loss: 0.5451\tLoss: 1.3602\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5272\tTop_Loss: 0.6625\tBottom_Loss: 0.6859\tLoss: 1.8756\t\n",
      "Subject: s12, n=09 | test_f1: 0.44444 |best_f1: 0.55556\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.531\tLabel_Loss: 0.8003\tTop_Loss: 0.9253\tBottom_Loss: 0.8938\tLoss: 2.6194\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.906\tLabel_Loss: 0.5198\tTop_Loss: 0.6007\tBottom_Loss: 0.8249\tLoss: 1.9455\t\n",
      "Subject: s12, n=09 | test_f1: 0.22222 |best_f1: 0.55556\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3137\tTop_Loss: 0.6139\tBottom_Loss: 0.3811\tLoss: 1.3087\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3270\tTop_Loss: 0.4605\tBottom_Loss: 0.4454\tLoss: 1.2329\t\n",
      "Subject: s12, n=09 | test_f1: 0.18182 |best_f1: 0.55556\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3748\tTop_Loss: 0.5833\tBottom_Loss: 0.4094\tLoss: 1.3675\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2644\tTop_Loss: 0.4607\tBottom_Loss: 0.3520\tLoss: 1.0772\t\n",
      "Subject: s12, n=09 | test_f1: 0.13333 |best_f1: 0.55556\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2426\tTop_Loss: 0.4025\tBottom_Loss: 0.3298\tLoss: 0.9749\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2741\tTop_Loss: 0.4184\tBottom_Loss: 0.4150\tLoss: 1.1076\t\n",
      "Subject: s12, n=09 | test_f1: 0.22222 |best_f1: 0.55556\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3812\tTop_Loss: 0.5297\tBottom_Loss: 0.4978\tLoss: 1.4087\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 1.000\tLabel_Loss: 0.2145\tTop_Loss: 0.2996\tBottom_Loss: 0.3426\tLoss: 0.8566\t\n",
      "Subject: s12, n=09 | test_f1: 0.13333 |best_f1: 0.55556\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2404\tTop_Loss: 0.2779\tBottom_Loss: 0.4619\tLoss: 0.9801\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1796\tTop_Loss: 0.2788\tBottom_Loss: 0.2837\tLoss: 0.7422\t\n",
      "Subject: s12, n=09 | test_f1: 0.13333 |best_f1: 0.55556\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4204\tTop_Loss: 0.4411\tBottom_Loss: 0.5595\tLoss: 1.4210\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2771\tTop_Loss: 0.4024\tBottom_Loss: 0.3830\tLoss: 1.0624\t\n",
      "Subject: s12, n=09 | test_f1: 0.13333 |best_f1: 0.55556\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4225\tTop_Loss: 0.4916\tBottom_Loss: 0.5645\tLoss: 1.4786\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0985\tTop_Loss: 0.2857\tBottom_Loss: 0.2085\tLoss: 0.5927\t\n",
      "Subject: s12, n=09 | test_f1: 0.18182 |best_f1: 0.55556\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2585\tTop_Loss: 0.4654\tBottom_Loss: 0.3396\tLoss: 1.0635\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2479\tTop_Loss: 0.4545\tBottom_Loss: 0.5049\tLoss: 1.2072\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: s12, n=09 | test_f1: 0.13333 |best_f1: 0.55556\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2761\tTop_Loss: 0.3322\tBottom_Loss: 0.4001\tLoss: 1.0084\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2782\tTop_Loss: 0.4298\tBottom_Loss: 0.4147\tLoss: 1.1226\t\n",
      "Subject: s12, n=09 | test_f1: 0.25641 |best_f1: 0.55556\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1976\tTop_Loss: 0.3110\tBottom_Loss: 0.3667\tLoss: 0.8752\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0977\tTop_Loss: 0.3329\tBottom_Loss: 0.2708\tLoss: 0.7015\t\n",
      "Subject: s12, n=09 | test_f1: 0.22222 |best_f1: 0.55556\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2000\tTop_Loss: 0.3892\tBottom_Loss: 0.3489\tLoss: 0.9381\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2128\tTop_Loss: 0.3347\tBottom_Loss: 0.4065\tLoss: 0.9540\t\n",
      "Subject: s12, n=09 | test_f1: 0.16667 |best_f1: 0.55556\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1044\tTop_Loss: 0.2730\tBottom_Loss: 0.2137\tLoss: 0.5911\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2279\tTop_Loss: 0.5005\tBottom_Loss: 0.2703\tLoss: 0.9987\t\n",
      "Subject: s12, n=09 | test_f1: 0.22222 |best_f1: 0.55556\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1882\tTop_Loss: 0.3337\tBottom_Loss: 0.2073\tLoss: 0.7292\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1012\tTop_Loss: 0.1982\tBottom_Loss: 0.1855\tLoss: 0.4849\t\n",
      "Subject: s12, n=09 | test_f1: 0.18182 |best_f1: 0.55556\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1105\tTop_Loss: 0.3110\tBottom_Loss: 0.2246\tLoss: 0.6461\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2288\tTop_Loss: 0.4230\tBottom_Loss: 0.3136\tLoss: 0.9654\t\n",
      "Subject: s12, n=09 | test_f1: 0.22222 |best_f1: 0.55556\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2064\tTop_Loss: 0.3280\tBottom_Loss: 0.2960\tLoss: 0.8304\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1928\tTop_Loss: 0.2830\tBottom_Loss: 0.3586\tLoss: 0.8344\t\n",
      "Subject: s12, n=09 | test_f1: 0.51515 |best_f1: 0.55556\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1870\tTop_Loss: 0.3046\tBottom_Loss: 0.3910\tLoss: 0.8826\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1522\tTop_Loss: 0.1907\tBottom_Loss: 0.2976\tLoss: 0.6406\t\n",
      "Subject: s12, n=09 | test_f1: 0.18182 |best_f1: 0.55556\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2586\tTop_Loss: 0.4284\tBottom_Loss: 0.3007\tLoss: 0.9876\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1376\tTop_Loss: 0.2457\tBottom_Loss: 0.2976\tLoss: 0.6809\t\n",
      "Subject: s12, n=09 | test_f1: 0.22222 |best_f1: 0.55556\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1074\tTop_Loss: 0.2706\tBottom_Loss: 0.2383\tLoss: 0.6163\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0754\tTop_Loss: 0.2518\tBottom_Loss: 0.1075\tLoss: 0.4347\t\n",
      "Subject: s12, n=09 | test_f1: 0.25641 |best_f1: 0.55556\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1928\tTop_Loss: 0.3219\tBottom_Loss: 0.2387\tLoss: 0.7534\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0662\tTop_Loss: 0.2082\tBottom_Loss: 0.1052\tLoss: 0.3797\t\n",
      "Subject: s12, n=09 | test_f1: 0.18182 |best_f1: 0.55556\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1238\tTop_Loss: 0.2137\tBottom_Loss: 0.2782\tLoss: 0.6157\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1828\tTop_Loss: 0.2703\tBottom_Loss: 0.4747\tLoss: 0.9278\t\n",
      "Subject: s12, n=09 | test_f1: 0.44444 |best_f1: 0.55556\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1204\tTop_Loss: 0.3206\tBottom_Loss: 0.2299\tLoss: 0.6710\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1000\tTop_Loss: 0.2285\tBottom_Loss: 0.2113\tLoss: 0.5398\t\n",
      "Subject: s12, n=09 | test_f1: 0.18182 |best_f1: 0.55556\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0752\tTop_Loss: 0.2217\tBottom_Loss: 0.1594\tLoss: 0.4562\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0848\tTop_Loss: 0.2596\tBottom_Loss: 0.2066\tLoss: 0.5510\t\n",
      "Subject: s12, n=09 | test_f1: 0.25641 |best_f1: 0.55556\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0783\tTop_Loss: 0.1854\tBottom_Loss: 0.1236\tLoss: 0.3873\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0694\tTop_Loss: 0.1737\tBottom_Loss: 0.1875\tLoss: 0.4305\t\n",
      "Subject: s12, n=09 | test_f1: 0.18182 |best_f1: 0.55556\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1036\tTop_Loss: 0.1618\tBottom_Loss: 0.1255\tLoss: 0.3909\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0701\tTop_Loss: 0.1485\tBottom_Loss: 0.1372\tLoss: 0.3559\t\n",
      "Subject: s12, n=09 | test_f1: 0.51515 |best_f1: 0.55556\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0648\tTop_Loss: 0.2015\tBottom_Loss: 0.1592\tLoss: 0.4255\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1033\tTop_Loss: 0.1559\tBottom_Loss: 0.1271\tLoss: 0.3863\t\n",
      "Subject: s12, n=09 | test_f1: 0.58974 |best_f1: 0.58974\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1207\tTop_Loss: 0.1571\tBottom_Loss: 0.2018\tLoss: 0.4796\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0648\tTop_Loss: 0.2075\tBottom_Loss: 0.1333\tLoss: 0.4056\t\n",
      "Subject: s12, n=09 | test_f1: 0.50794 |best_f1: 0.58974\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0849\tTop_Loss: 0.1511\tBottom_Loss: 0.1710\tLoss: 0.4070\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1179\tTop_Loss: 0.2311\tBottom_Loss: 0.1235\tLoss: 0.4725\t\n",
      "Subject: s12, n=09 | test_f1: 0.22222 |best_f1: 0.58974\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0539\tTop_Loss: 0.1407\tBottom_Loss: 0.0891\tLoss: 0.2836\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0913\tTop_Loss: 0.2537\tBottom_Loss: 0.2483\tLoss: 0.5933\t\n",
      "Subject: s12, n=09 | test_f1: 0.22222 |best_f1: 0.58974\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0542\tTop_Loss: 0.2854\tBottom_Loss: 0.0922\tLoss: 0.4318\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0914\tTop_Loss: 0.1356\tBottom_Loss: 0.2316\tLoss: 0.4585\t\n",
      "Subject: s12, n=09 | test_f1: 0.13333 |best_f1: 0.58974\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0530\tTop_Loss: 0.1253\tBottom_Loss: 0.0972\tLoss: 0.2755\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1055\tTop_Loss: 0.1977\tBottom_Loss: 0.1465\tLoss: 0.4497\t\n",
      "Subject: s12, n=09 | test_f1: 0.22222 |best_f1: 0.58974\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0803\tTop_Loss: 0.2186\tBottom_Loss: 0.1021\tLoss: 0.4011\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0401\tTop_Loss: 0.1122\tBottom_Loss: 0.1423\tLoss: 0.2947\t\n",
      "Subject: s12, n=09 | test_f1: 0.28571 |best_f1: 0.58974\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0618\tTop_Loss: 0.1640\tBottom_Loss: 0.1414\tLoss: 0.3672\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1545\tTop_Loss: 0.2278\tBottom_Loss: 0.2767\tLoss: 0.6590\t\n",
      "Subject: s12, n=09 | test_f1: 0.22222 |best_f1: 0.58974\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0644\tTop_Loss: 0.1197\tBottom_Loss: 0.1488\tLoss: 0.3328\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0687\tTop_Loss: 0.1439\tBottom_Loss: 0.1634\tLoss: 0.3760\t\n",
      "Subject: s12, n=09 | test_f1: 0.35556 |best_f1: 0.58974\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0950\tTop_Loss: 0.2478\tBottom_Loss: 0.1048\tLoss: 0.4476\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0503\tTop_Loss: 0.2334\tBottom_Loss: 0.2030\tLoss: 0.4867\t\n",
      "Subject: s12, n=09 | test_f1: 0.13333 |best_f1: 0.58974\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0566\tTop_Loss: 0.1089\tBottom_Loss: 0.1862\tLoss: 0.3517\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1198\tTop_Loss: 0.1632\tBottom_Loss: 0.1883\tLoss: 0.4714\t\n",
      "Subject: s12, n=09 | test_f1: 0.13333 |best_f1: 0.58974\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0338\tTop_Loss: 0.1744\tBottom_Loss: 0.0670\tLoss: 0.2752\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0505\tTop_Loss: 0.1832\tBottom_Loss: 0.0898\tLoss: 0.3235\t\n",
      "Subject: s12, n=09 | test_f1: 0.074074 |best_f1: 0.58974\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1295\tTop_Loss: 0.1827\tBottom_Loss: 0.2475\tLoss: 0.5597\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0488\tTop_Loss: 0.1997\tBottom_Loss: 0.0890\tLoss: 0.3375\t\n",
      "Subject: s12, n=09 | test_f1: 0.44444 |best_f1: 0.58974\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0359\tTop_Loss: 0.1167\tBottom_Loss: 0.0770\tLoss: 0.2296\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0334\tTop_Loss: 0.1483\tBottom_Loss: 0.1732\tLoss: 0.3549\t\n",
      "Subject: s12, n=09 | test_f1: 0.28571 |best_f1: 0.58974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0501\tTop_Loss: 0.1193\tBottom_Loss: 0.1570\tLoss: 0.3264\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0477\tTop_Loss: 0.1151\tBottom_Loss: 0.1917\tLoss: 0.3545\t\n",
      "Subject: s12, n=09 | test_f1: 0.46667 |best_f1: 0.58974\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0499\tTop_Loss: 0.1341\tBottom_Loss: 0.0894\tLoss: 0.2734\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1354\tTop_Loss: 0.1635\tBottom_Loss: 0.1330\tLoss: 0.4319\t\n",
      "Subject: s12, n=09 | test_f1: 0.13333 |best_f1: 0.58974\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0271\tTop_Loss: 0.1206\tBottom_Loss: 0.0417\tLoss: 0.1894\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1013\tTop_Loss: 0.1198\tBottom_Loss: 0.1240\tLoss: 0.3452\t\n",
      "Subject: s12, n=09 | test_f1: 0.28571 |best_f1: 0.58974\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0126\tTop_Loss: 0.0395\tBottom_Loss: 0.0472\tLoss: 0.0992\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0329\tTop_Loss: 0.1706\tBottom_Loss: 0.1583\tLoss: 0.3618\t\n",
      "Subject: s12, n=09 | test_f1: 0.51515 |best_f1: 0.58974\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0403\tTop_Loss: 0.1081\tBottom_Loss: 0.0729\tLoss: 0.2213\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1541\tTop_Loss: 0.2739\tBottom_Loss: 0.1141\tLoss: 0.5420\t\n",
      "Subject: s12, n=09 | test_f1: 0.51515 |best_f1: 0.58974\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0123\tTop_Loss: 0.0679\tBottom_Loss: 0.0365\tLoss: 0.1167\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0471\tTop_Loss: 0.1556\tBottom_Loss: 0.0548\tLoss: 0.2575\t\n",
      "Subject: s12, n=09 | test_f1: 0.40404 |best_f1: 0.58974\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0894\tTop_Loss: 0.1621\tBottom_Loss: 0.1063\tLoss: 0.3578\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0452\tTop_Loss: 0.0590\tBottom_Loss: 0.0718\tLoss: 0.1759\t\n",
      "Subject: s12, n=09 | test_f1: 0.22222 |best_f1: 0.58974\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0222\tTop_Loss: 0.0546\tBottom_Loss: 0.0656\tLoss: 0.1423\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0173\tTop_Loss: 0.1267\tBottom_Loss: 0.0588\tLoss: 0.2028\t\n",
      "Subject: s12, n=09 | test_f1: 0.12121 |best_f1: 0.58974\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0567\tTop_Loss: 0.0762\tBottom_Loss: 0.2229\tLoss: 0.3558\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0147\tTop_Loss: 0.0716\tBottom_Loss: 0.0200\tLoss: 0.1063\t\n",
      "Subject: s12, n=09 | test_f1: 0.22222 |best_f1: 0.58974\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0357\tTop_Loss: 0.0853\tBottom_Loss: 0.0877\tLoss: 0.2087\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0115\tTop_Loss: 0.0425\tBottom_Loss: 0.0392\tLoss: 0.0933\t\n",
      "Subject: s12, n=09 | test_f1: 0.22222 |best_f1: 0.58974\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0475\tTop_Loss: 0.0983\tBottom_Loss: 0.0775\tLoss: 0.2233\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0074\tTop_Loss: 0.0357\tBottom_Loss: 0.0332\tLoss: 0.0763\t\n",
      "Subject: s12, n=09 | test_f1: 0.18182 |best_f1: 0.58974\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0220\tTop_Loss: 0.0787\tBottom_Loss: 0.0692\tLoss: 0.1699\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0401\tTop_Loss: 0.1176\tBottom_Loss: 0.0655\tLoss: 0.2232\t\n",
      "Subject: s12, n=09 | test_f1: 0.18182 |best_f1: 0.58974\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0073\tTop_Loss: 0.0260\tBottom_Loss: 0.0146\tLoss: 0.0479\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0368\tTop_Loss: 0.0861\tBottom_Loss: 0.0772\tLoss: 0.2001\t\n",
      "Subject: s12, n=09 | test_f1: 0.18182 |best_f1: 0.58974\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0340\tTop_Loss: 0.0521\tBottom_Loss: 0.1595\tLoss: 0.2455\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0177\tTop_Loss: 0.0734\tBottom_Loss: 0.0653\tLoss: 0.1564\t\n",
      "Subject: s12, n=09 | test_f1: 0.18182 |best_f1: 0.58974\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0498\tTop_Loss: 0.0674\tBottom_Loss: 0.0726\tLoss: 0.1898\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0112\tTop_Loss: 0.0371\tBottom_Loss: 0.0236\tLoss: 0.0719\t\n",
      "Subject: s12, n=09 | test_f1: 0.18182 |best_f1: 0.58974\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0632\tTop_Loss: 0.0914\tBottom_Loss: 0.1235\tLoss: 0.2782\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0119\tTop_Loss: 0.0444\tBottom_Loss: 0.0471\tLoss: 0.1035\t\n",
      "Subject: s12, n=09 | test_f1: 0.51515 |best_f1: 0.58974\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0118\tTop_Loss: 0.0364\tBottom_Loss: 0.0303\tLoss: 0.0784\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1860\tTop_Loss: 0.2475\tBottom_Loss: 0.2064\tLoss: 0.6398\t\n",
      "Subject: s12, n=09 | test_f1: 0.13333 |best_f1: 0.58974\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0222\tTop_Loss: 0.0867\tBottom_Loss: 0.0546\tLoss: 0.1636\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0221\tTop_Loss: 0.0404\tBottom_Loss: 0.0321\tLoss: 0.0947\t\n",
      "Subject: s12, n=09 | test_f1: 0.13333 |best_f1: 0.58974\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0149\tTop_Loss: 0.0521\tBottom_Loss: 0.0381\tLoss: 0.1050\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0095\tTop_Loss: 0.0298\tBottom_Loss: 0.0314\tLoss: 0.0707\t\n",
      "Subject: s12, n=09 | test_f1: 0.18182 |best_f1: 0.58974\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0399\tTop_Loss: 0.1176\tBottom_Loss: 0.0547\tLoss: 0.2121\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0068\tTop_Loss: 0.0322\tBottom_Loss: 0.0428\tLoss: 0.0818\t\n",
      "Subject: s12, n=09 | test_f1: 0.51515 |best_f1: 0.58974\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0074\tTop_Loss: 0.0685\tBottom_Loss: 0.0346\tLoss: 0.1105\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0163\tTop_Loss: 0.0706\tBottom_Loss: 0.0555\tLoss: 0.1424\t\n",
      "Subject: s12, n=09 | test_f1: 0.18182 |best_f1: 0.58974\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0270\tTop_Loss: 0.0315\tBottom_Loss: 0.0699\tLoss: 0.1285\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0046\tTop_Loss: 0.0207\tBottom_Loss: 0.0164\tLoss: 0.0417\t\n",
      "Subject: s12, n=09 | test_f1: 0.22222 |best_f1: 0.58974\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0283\tTop_Loss: 0.1061\tBottom_Loss: 0.0377\tLoss: 0.1721\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2708\tTop_Loss: 0.2206\tBottom_Loss: 0.2121\tLoss: 0.7035\t\n",
      "Subject: s12, n=09 | test_f1: 0.25641 |best_f1: 0.58974\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0108\tTop_Loss: 0.0346\tBottom_Loss: 0.0797\tLoss: 0.1250\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0219\tTop_Loss: 0.1453\tBottom_Loss: 0.0285\tLoss: 0.1957\t\n",
      "Subject: s12, n=09 | test_f1: 0.22222 |best_f1: 0.58974\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0193\tTop_Loss: 0.0281\tBottom_Loss: 0.0672\tLoss: 0.1146\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0363\tTop_Loss: 0.0564\tBottom_Loss: 0.0488\tLoss: 0.1415\t\n",
      "Subject: s12, n=09 | test_f1: 0.22222 |best_f1: 0.58974\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0186\tTop_Loss: 0.0309\tBottom_Loss: 0.0279\tLoss: 0.0774\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0101\tTop_Loss: 0.0810\tBottom_Loss: 0.0144\tLoss: 0.1055\t\n",
      "Subject: s12, n=09 | test_f1: 0.25641 |best_f1: 0.58974\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0085\tTop_Loss: 0.0452\tBottom_Loss: 0.0241\tLoss: 0.0778\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0281\tTop_Loss: 0.1153\tBottom_Loss: 0.0911\tLoss: 0.2345\t\n",
      "Subject: s12, n=09 | test_f1: 0.25641 |best_f1: 0.58974\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0142\tTop_Loss: 0.0492\tBottom_Loss: 0.0406\tLoss: 0.1040\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0119\tTop_Loss: 0.0328\tBottom_Loss: 0.0270\tLoss: 0.0716\t\n",
      "Subject: s12, n=09 | test_f1: 0.18182 |best_f1: 0.58974\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0379\tTop_Loss: 0.0684\tBottom_Loss: 0.0460\tLoss: 0.1523\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0415\tTop_Loss: 0.0824\tBottom_Loss: 0.0596\tLoss: 0.1835\t\n",
      "Subject: s12, n=09 | test_f1: 0.51515 |best_f1: 0.58974\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0176\tTop_Loss: 0.0348\tBottom_Loss: 0.0767\tLoss: 0.1291\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0147\tTop_Loss: 0.1388\tBottom_Loss: 0.0212\tLoss: 0.1747\t\n",
      "Subject: s12, n=09 | test_f1: 0.18182 |best_f1: 0.58974\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0287\tTop_Loss: 0.0315\tBottom_Loss: 0.0988\tLoss: 0.1590\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0238\tTop_Loss: 0.0607\tBottom_Loss: 0.0320\tLoss: 0.1164\t\n",
      "Subject: s12, n=09 | test_f1: 0.40404 |best_f1: 0.58974\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0035\tTop_Loss: 0.0109\tBottom_Loss: 0.0229\tLoss: 0.0373\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0143\tTop_Loss: 0.0174\tBottom_Loss: 0.0268\tLoss: 0.0584\t\n",
      "Subject: s12, n=09 | test_f1: 0.18182 |best_f1: 0.58974\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0094\tTop_Loss: 0.0449\tBottom_Loss: 0.0227\tLoss: 0.0771\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0086\tTop_Loss: 0.0239\tBottom_Loss: 0.0273\tLoss: 0.0598\t\n",
      "Subject: s12, n=09 | test_f1: 0.46667 |best_f1: 0.58974\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0059\tTop_Loss: 0.0125\tBottom_Loss: 0.0214\tLoss: 0.0398\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0078\tTop_Loss: 0.0245\tBottom_Loss: 0.0186\tLoss: 0.0509\t\n",
      "Subject: s12, n=09 | test_f1: 0.18182 |best_f1: 0.58974\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.438\tLabel_Loss: 1.4065\tTop_Loss: 1.2498\tBottom_Loss: 1.1956\tLoss: 3.8518\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.625\tLabel_Loss: 0.9414\tTop_Loss: 0.7762\tBottom_Loss: 0.9486\tLoss: 2.6662\t\n",
      "Subject: s13, n=10 | test_f1: 0.2963 |best_f1: 0.2963\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.500\tLabel_Loss: 0.9225\tTop_Loss: 0.8485\tBottom_Loss: 0.9169\tLoss: 2.6879\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.531\tLabel_Loss: 0.9773\tTop_Loss: 0.8951\tBottom_Loss: 0.7937\tLoss: 2.6661\t\n",
      "Subject: s13, n=10 | test_f1: 0.0 |best_f1: 0.2963\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.625\tLabel_Loss: 1.1100\tTop_Loss: 1.0812\tBottom_Loss: 0.9843\tLoss: 3.1755\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.531\tLabel_Loss: 0.8585\tTop_Loss: 0.9735\tBottom_Loss: 1.0314\tLoss: 2.8634\t\n",
      "Subject: s13, n=10 | test_f1: 0.090909 |best_f1: 0.2963\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.500\tLabel_Loss: 1.0786\tTop_Loss: 0.8986\tBottom_Loss: 1.0279\tLoss: 3.0051\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8357\tTop_Loss: 0.9502\tBottom_Loss: 1.1304\tLoss: 2.9163\t\n",
      "Subject: s13, n=10 | test_f1: 0.15385 |best_f1: 0.2963\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7680\tTop_Loss: 0.7602\tBottom_Loss: 0.7214\tLoss: 2.2496\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.500\tLabel_Loss: 0.9951\tTop_Loss: 0.9920\tBottom_Loss: 1.0433\tLoss: 3.0303\t\n",
      "Subject: s13, n=10 | test_f1: 0.090909 |best_f1: 0.2963\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6504\tTop_Loss: 0.6840\tBottom_Loss: 0.7484\tLoss: 2.0827\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.469\tLabel_Loss: 1.0301\tTop_Loss: 1.2106\tBottom_Loss: 1.0107\tLoss: 3.2514\t\n",
      "Subject: s13, n=10 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8463\tTop_Loss: 0.8402\tBottom_Loss: 0.8838\tLoss: 2.5703\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.656\tLabel_Loss: 0.8030\tTop_Loss: 0.7793\tBottom_Loss: 0.8747\tLoss: 2.4570\t\n",
      "Subject: s13, n=10 | test_f1: 0.11111 |best_f1: 0.33333\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.562\tLabel_Loss: 0.9043\tTop_Loss: 0.8454\tBottom_Loss: 0.8651\tLoss: 2.6149\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8092\tTop_Loss: 0.8366\tBottom_Loss: 0.7739\tLoss: 2.4197\t\n",
      "Subject: s13, n=10 | test_f1: 0.15385 |best_f1: 0.33333\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6553\tTop_Loss: 0.7443\tBottom_Loss: 0.7064\tLoss: 2.1061\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6381\tTop_Loss: 0.7165\tBottom_Loss: 0.8207\tLoss: 2.1753\t\n",
      "Subject: s13, n=10 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.656\tLabel_Loss: 0.6910\tTop_Loss: 0.7712\tBottom_Loss: 0.9181\tLoss: 2.3804\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6589\tTop_Loss: 0.7223\tBottom_Loss: 0.6937\tLoss: 2.0749\t\n",
      "Subject: s13, n=10 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5143\tTop_Loss: 0.6283\tBottom_Loss: 0.5457\tLoss: 1.6883\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.500\tLabel_Loss: 0.8929\tTop_Loss: 1.0020\tBottom_Loss: 0.9289\tLoss: 2.8238\t\n",
      "Subject: s13, n=10 | test_f1: 0.19048 |best_f1: 0.33333\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.688\tLabel_Loss: 0.5994\tTop_Loss: 0.8475\tBottom_Loss: 0.7189\tLoss: 2.1657\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7247\tTop_Loss: 0.8558\tBottom_Loss: 0.7586\tLoss: 2.3391\t\n",
      "Subject: s13, n=10 | test_f1: 0.15385 |best_f1: 0.33333\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7600\tTop_Loss: 0.7102\tBottom_Loss: 0.6805\tLoss: 2.1507\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.562\tLabel_Loss: 0.8484\tTop_Loss: 0.8693\tBottom_Loss: 0.8666\tLoss: 2.5843\t\n",
      "Subject: s13, n=10 | test_f1: 0.23077 |best_f1: 0.33333\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5920\tTop_Loss: 0.6249\tBottom_Loss: 0.7368\tLoss: 1.9537\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6633\tTop_Loss: 0.9052\tBottom_Loss: 0.6468\tLoss: 2.2153\t\n",
      "Subject: s13, n=10 | test_f1: 0.16667 |best_f1: 0.33333\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6179\tTop_Loss: 0.6703\tBottom_Loss: 0.7111\tLoss: 1.9993\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6650\tTop_Loss: 0.7613\tBottom_Loss: 0.9149\tLoss: 2.3412\t\n",
      "Subject: s13, n=10 | test_f1: 0.28571 |best_f1: 0.33333\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6511\tTop_Loss: 0.7245\tBottom_Loss: 0.6597\tLoss: 2.0353\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7066\tTop_Loss: 0.6860\tBottom_Loss: 0.8479\tLoss: 2.2406\t\n",
      "Subject: s13, n=10 | test_f1: 0.19048 |best_f1: 0.33333\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4564\tTop_Loss: 0.6005\tBottom_Loss: 0.5701\tLoss: 1.6270\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6650\tTop_Loss: 0.7001\tBottom_Loss: 0.8532\tLoss: 2.2183\t\n",
      "Subject: s13, n=10 | test_f1: 0.090909 |best_f1: 0.33333\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4364\tTop_Loss: 0.5591\tBottom_Loss: 0.5821\tLoss: 1.5777\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.719\tLabel_Loss: 0.7900\tTop_Loss: 0.9050\tBottom_Loss: 0.6517\tLoss: 2.3467\t\n",
      "Subject: s13, n=10 | test_f1: 0.090909 |best_f1: 0.33333\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4141\tTop_Loss: 0.5769\tBottom_Loss: 0.6766\tLoss: 1.6677\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6238\tTop_Loss: 0.6166\tBottom_Loss: 0.6835\tLoss: 1.9239\t\n",
      "Subject: s13, n=10 | test_f1: 0.28571 |best_f1: 0.33333\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.844\tLabel_Loss: 0.5154\tTop_Loss: 0.6253\tBottom_Loss: 0.5336\tLoss: 1.6743\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4433\tTop_Loss: 0.6287\tBottom_Loss: 0.5966\tLoss: 1.6687\t\n",
      "Subject: s13, n=10 | test_f1: 0.23077 |best_f1: 0.33333\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4817\tTop_Loss: 0.6005\tBottom_Loss: 0.5640\tLoss: 1.6462\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4759\tTop_Loss: 0.5229\tBottom_Loss: 0.4916\tLoss: 1.4904\t\n",
      "Subject: s13, n=10 | test_f1: 0.23077 |best_f1: 0.33333\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3949\tTop_Loss: 0.4808\tBottom_Loss: 0.6913\tLoss: 1.5671\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3946\tTop_Loss: 0.4265\tBottom_Loss: 0.5313\tLoss: 1.3524\t\n",
      "Subject: s13, n=10 | test_f1: 0.19048 |best_f1: 0.33333\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2527\tTop_Loss: 0.3562\tBottom_Loss: 0.4947\tLoss: 1.1035\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5182\tTop_Loss: 0.8153\tBottom_Loss: 0.5823\tLoss: 1.9158\t\n",
      "Subject: s13, n=10 | test_f1: 0.19048 |best_f1: 0.33333\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.844\tLabel_Loss: 0.5268\tTop_Loss: 0.6784\tBottom_Loss: 0.6882\tLoss: 1.8935\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3773\tTop_Loss: 0.5471\tBottom_Loss: 0.5874\tLoss: 1.5118\t\n",
      "Subject: s13, n=10 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2741\tTop_Loss: 0.3349\tBottom_Loss: 0.3224\tLoss: 0.9314\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.875\tLabel_Loss: 0.5123\tTop_Loss: 0.5790\tBottom_Loss: 0.5352\tLoss: 1.6264\t\n",
      "Subject: s13, n=10 | test_f1: 0.375 |best_f1: 0.375\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2508\tTop_Loss: 0.4416\tBottom_Loss: 0.4934\tLoss: 1.1858\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5043\tTop_Loss: 0.5194\tBottom_Loss: 0.6976\tLoss: 1.7213\t\n",
      "Subject: s13, n=10 | test_f1: 0.16667 |best_f1: 0.375\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2795\tTop_Loss: 0.4560\tBottom_Loss: 0.4530\tLoss: 1.1884\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2804\tTop_Loss: 0.4984\tBottom_Loss: 0.4364\tLoss: 1.2152\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: s13, n=10 | test_f1: 0.23077 |best_f1: 0.375\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2424\tTop_Loss: 0.4247\tBottom_Loss: 0.3654\tLoss: 1.0325\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.906\tLabel_Loss: 0.4226\tTop_Loss: 0.5285\tBottom_Loss: 0.5387\tLoss: 1.4898\t\n",
      "Subject: s13, n=10 | test_f1: 0.23077 |best_f1: 0.375\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3687\tTop_Loss: 0.5704\tBottom_Loss: 0.5280\tLoss: 1.4671\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4675\tTop_Loss: 0.6242\tBottom_Loss: 0.5632\tLoss: 1.6549\t\n",
      "Subject: s13, n=10 | test_f1: 0.28571 |best_f1: 0.375\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5733\tTop_Loss: 0.6752\tBottom_Loss: 0.5686\tLoss: 1.8172\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2503\tTop_Loss: 0.4860\tBottom_Loss: 0.3830\tLoss: 1.1193\t\n",
      "Subject: s13, n=10 | test_f1: 0.28571 |best_f1: 0.375\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3392\tTop_Loss: 0.4427\tBottom_Loss: 0.4749\tLoss: 1.2567\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2469\tTop_Loss: 0.3752\tBottom_Loss: 0.4398\tLoss: 1.0619\t\n",
      "Subject: s13, n=10 | test_f1: 0.23077 |best_f1: 0.375\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3717\tTop_Loss: 0.7428\tBottom_Loss: 0.5664\tLoss: 1.6809\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2761\tTop_Loss: 0.4931\tBottom_Loss: 0.5307\tLoss: 1.2998\t\n",
      "Subject: s13, n=10 | test_f1: 0.16667 |best_f1: 0.375\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3113\tTop_Loss: 0.4832\tBottom_Loss: 0.4815\tLoss: 1.2759\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.750\tLabel_Loss: 0.4264\tTop_Loss: 0.5197\tBottom_Loss: 0.4956\tLoss: 1.4417\t\n",
      "Subject: s13, n=10 | test_f1: 0.28571 |best_f1: 0.375\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2709\tTop_Loss: 0.5210\tBottom_Loss: 0.3510\tLoss: 1.1429\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2372\tTop_Loss: 0.3705\tBottom_Loss: 0.5225\tLoss: 1.1302\t\n",
      "Subject: s13, n=10 | test_f1: 0.28571 |best_f1: 0.375\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1453\tTop_Loss: 0.2605\tBottom_Loss: 0.3926\tLoss: 0.7983\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2277\tTop_Loss: 0.3123\tBottom_Loss: 0.3588\tLoss: 0.8988\t\n",
      "Subject: s13, n=10 | test_f1: 0.33333 |best_f1: 0.375\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1950\tTop_Loss: 0.3084\tBottom_Loss: 0.3103\tLoss: 0.8137\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2770\tTop_Loss: 0.4038\tBottom_Loss: 0.4690\tLoss: 1.1498\t\n",
      "Subject: s13, n=10 | test_f1: 0.060606 |best_f1: 0.375\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1729\tTop_Loss: 0.2800\tBottom_Loss: 0.2759\tLoss: 0.7289\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3637\tTop_Loss: 0.4543\tBottom_Loss: 0.4667\tLoss: 1.2846\t\n",
      "Subject: s13, n=10 | test_f1: 0.28571 |best_f1: 0.375\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2089\tTop_Loss: 0.3085\tBottom_Loss: 0.2433\tLoss: 0.7607\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3189\tTop_Loss: 0.4692\tBottom_Loss: 0.3441\tLoss: 1.1322\t\n",
      "Subject: s13, n=10 | test_f1: 0.28571 |best_f1: 0.375\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2845\tTop_Loss: 0.4122\tBottom_Loss: 0.5096\tLoss: 1.2062\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1287\tTop_Loss: 0.2711\tBottom_Loss: 0.2321\tLoss: 0.6319\t\n",
      "Subject: s13, n=10 | test_f1: 0.23077 |best_f1: 0.375\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2026\tTop_Loss: 0.3457\tBottom_Loss: 0.2552\tLoss: 0.8035\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2729\tTop_Loss: 0.3371\tBottom_Loss: 0.3519\tLoss: 0.9619\t\n",
      "Subject: s13, n=10 | test_f1: 0.23077 |best_f1: 0.375\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1188\tTop_Loss: 0.2277\tBottom_Loss: 0.2218\tLoss: 0.5683\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1863\tTop_Loss: 0.3662\tBottom_Loss: 0.3374\tLoss: 0.8899\t\n",
      "Subject: s13, n=10 | test_f1: 0.23077 |best_f1: 0.375\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1970\tTop_Loss: 0.3118\tBottom_Loss: 0.3633\tLoss: 0.8722\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0910\tTop_Loss: 0.2677\tBottom_Loss: 0.2529\tLoss: 0.6115\t\n",
      "Subject: s13, n=10 | test_f1: 0.23077 |best_f1: 0.375\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1985\tTop_Loss: 0.3255\tBottom_Loss: 0.3282\tLoss: 0.8522\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1938\tTop_Loss: 0.1747\tBottom_Loss: 0.3524\tLoss: 0.7209\t\n",
      "Subject: s13, n=10 | test_f1: 0.23077 |best_f1: 0.375\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2964\tTop_Loss: 0.3318\tBottom_Loss: 0.3805\tLoss: 1.0087\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1401\tTop_Loss: 0.2597\tBottom_Loss: 0.3208\tLoss: 0.7206\t\n",
      "Subject: s13, n=10 | test_f1: 0.16667 |best_f1: 0.375\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2736\tTop_Loss: 0.4411\tBottom_Loss: 0.3113\tLoss: 1.0260\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2332\tTop_Loss: 0.3159\tBottom_Loss: 0.3754\tLoss: 0.9245\t\n",
      "Subject: s13, n=10 | test_f1: 0.15385 |best_f1: 0.375\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1109\tTop_Loss: 0.2788\tBottom_Loss: 0.2147\tLoss: 0.6044\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1730\tTop_Loss: 0.2041\tBottom_Loss: 0.2437\tLoss: 0.6208\t\n",
      "Subject: s13, n=10 | test_f1: 0.375 |best_f1: 0.375\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1409\tTop_Loss: 0.1809\tBottom_Loss: 0.3660\tLoss: 0.6878\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1246\tTop_Loss: 0.2576\tBottom_Loss: 0.2165\tLoss: 0.5987\t\n",
      "Subject: s13, n=10 | test_f1: 0.33333 |best_f1: 0.375\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1052\tTop_Loss: 0.2566\tBottom_Loss: 0.1997\tLoss: 0.5615\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1899\tTop_Loss: 0.3480\tBottom_Loss: 0.3287\tLoss: 0.8666\t\n",
      "Subject: s13, n=10 | test_f1: 0.28571 |best_f1: 0.375\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1127\tTop_Loss: 0.2424\tBottom_Loss: 0.2526\tLoss: 0.6077\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1727\tTop_Loss: 0.2457\tBottom_Loss: 0.2783\tLoss: 0.6967\t\n",
      "Subject: s13, n=10 | test_f1: 0.23077 |best_f1: 0.375\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1417\tTop_Loss: 0.2718\tBottom_Loss: 0.2155\tLoss: 0.6291\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2255\tTop_Loss: 0.2571\tBottom_Loss: 0.2184\tLoss: 0.7010\t\n",
      "Subject: s13, n=10 | test_f1: 0.16667 |best_f1: 0.375\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0910\tTop_Loss: 0.1907\tBottom_Loss: 0.2525\tLoss: 0.5341\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0388\tTop_Loss: 0.0986\tBottom_Loss: 0.1597\tLoss: 0.2971\t\n",
      "Subject: s13, n=10 | test_f1: 0.28571 |best_f1: 0.375\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0619\tTop_Loss: 0.2260\tBottom_Loss: 0.1521\tLoss: 0.4400\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1002\tTop_Loss: 0.2462\tBottom_Loss: 0.1568\tLoss: 0.5032\t\n",
      "Subject: s13, n=10 | test_f1: 0.15385 |best_f1: 0.375\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0639\tTop_Loss: 0.1856\tBottom_Loss: 0.1884\tLoss: 0.4379\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2018\tTop_Loss: 0.2027\tBottom_Loss: 0.2862\tLoss: 0.6907\t\n",
      "Subject: s13, n=10 | test_f1: 0.15385 |best_f1: 0.375\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1094\tTop_Loss: 0.3269\tBottom_Loss: 0.2159\tLoss: 0.6522\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1551\tTop_Loss: 0.2810\tBottom_Loss: 0.2041\tLoss: 0.6402\t\n",
      "Subject: s13, n=10 | test_f1: 0.23077 |best_f1: 0.375\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1957\tTop_Loss: 0.3080\tBottom_Loss: 0.2909\tLoss: 0.7945\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1053\tTop_Loss: 0.2146\tBottom_Loss: 0.1622\tLoss: 0.4822\t\n",
      "Subject: s13, n=10 | test_f1: 0.23077 |best_f1: 0.375\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0553\tTop_Loss: 0.1769\tBottom_Loss: 0.1100\tLoss: 0.3421\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0942\tTop_Loss: 0.1339\tBottom_Loss: 0.2463\tLoss: 0.4744\t\n",
      "Subject: s13, n=10 | test_f1: 0.090909 |best_f1: 0.375\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1044\tTop_Loss: 0.1849\tBottom_Loss: 0.1538\tLoss: 0.4431\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0920\tTop_Loss: 0.2029\tBottom_Loss: 0.1779\tLoss: 0.4727\t\n",
      "Subject: s13, n=10 | test_f1: 0.23077 |best_f1: 0.375\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0907\tTop_Loss: 0.2680\tBottom_Loss: 0.1980\tLoss: 0.5567\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[57][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0335\tTop_Loss: 0.1420\tBottom_Loss: 0.1567\tLoss: 0.3323\t\n",
      "Subject: s13, n=10 | test_f1: 0.23077 |best_f1: 0.375\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0836\tTop_Loss: 0.2508\tBottom_Loss: 0.1537\tLoss: 0.4882\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0775\tTop_Loss: 0.1283\tBottom_Loss: 0.1582\tLoss: 0.3641\t\n",
      "Subject: s13, n=10 | test_f1: 0.23077 |best_f1: 0.375\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0702\tTop_Loss: 0.2198\tBottom_Loss: 0.1651\tLoss: 0.4551\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0416\tTop_Loss: 0.0909\tBottom_Loss: 0.1093\tLoss: 0.2419\t\n",
      "Subject: s13, n=10 | test_f1: 0.23077 |best_f1: 0.375\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0218\tTop_Loss: 0.0920\tBottom_Loss: 0.0827\tLoss: 0.1965\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0539\tTop_Loss: 0.1203\tBottom_Loss: 0.1360\tLoss: 0.3102\t\n",
      "Subject: s13, n=10 | test_f1: 0.23077 |best_f1: 0.375\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0880\tTop_Loss: 0.1999\tBottom_Loss: 0.1518\tLoss: 0.4397\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0533\tTop_Loss: 0.1665\tBottom_Loss: 0.1116\tLoss: 0.3315\t\n",
      "Subject: s13, n=10 | test_f1: 0.090909 |best_f1: 0.375\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0302\tTop_Loss: 0.1501\tBottom_Loss: 0.1404\tLoss: 0.3207\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0381\tTop_Loss: 0.1867\tBottom_Loss: 0.1080\tLoss: 0.3328\t\n",
      "Subject: s13, n=10 | test_f1: 0.16667 |best_f1: 0.375\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0869\tTop_Loss: 0.1284\tBottom_Loss: 0.2200\tLoss: 0.4352\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0298\tTop_Loss: 0.0892\tBottom_Loss: 0.0917\tLoss: 0.2108\t\n",
      "Subject: s13, n=10 | test_f1: 0.090909 |best_f1: 0.375\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0450\tTop_Loss: 0.1394\tBottom_Loss: 0.1556\tLoss: 0.3400\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0534\tTop_Loss: 0.1217\tBottom_Loss: 0.1346\tLoss: 0.3097\t\n",
      "Subject: s13, n=10 | test_f1: 0.19048 |best_f1: 0.375\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1007\tTop_Loss: 0.1729\tBottom_Loss: 0.1412\tLoss: 0.4148\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0336\tTop_Loss: 0.1100\tBottom_Loss: 0.0792\tLoss: 0.2228\t\n",
      "Subject: s13, n=10 | test_f1: 0.23077 |best_f1: 0.375\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0391\tTop_Loss: 0.0858\tBottom_Loss: 0.1489\tLoss: 0.2738\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0611\tTop_Loss: 0.1721\tBottom_Loss: 0.1701\tLoss: 0.4033\t\n",
      "Subject: s13, n=10 | test_f1: 0.23077 |best_f1: 0.375\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1453\tTop_Loss: 0.1808\tBottom_Loss: 0.2455\tLoss: 0.5717\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0641\tTop_Loss: 0.1131\tBottom_Loss: 0.1725\tLoss: 0.3497\t\n",
      "Subject: s13, n=10 | test_f1: 0.28571 |best_f1: 0.375\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0449\tTop_Loss: 0.1062\tBottom_Loss: 0.0887\tLoss: 0.2399\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0879\tTop_Loss: 0.0936\tBottom_Loss: 0.1578\tLoss: 0.3393\t\n",
      "Subject: s13, n=10 | test_f1: 0.28571 |best_f1: 0.375\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0438\tTop_Loss: 0.0890\tBottom_Loss: 0.0680\tLoss: 0.2008\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0272\tTop_Loss: 0.1227\tBottom_Loss: 0.0614\tLoss: 0.2113\t\n",
      "Subject: s13, n=10 | test_f1: 0.23077 |best_f1: 0.375\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0219\tTop_Loss: 0.0936\tBottom_Loss: 0.0529\tLoss: 0.1683\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0215\tTop_Loss: 0.0740\tBottom_Loss: 0.0775\tLoss: 0.1730\t\n",
      "Subject: s13, n=10 | test_f1: 0.19048 |best_f1: 0.375\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0284\tTop_Loss: 0.0846\tBottom_Loss: 0.0791\tLoss: 0.1921\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1517\tTop_Loss: 0.1622\tBottom_Loss: 0.1637\tLoss: 0.4776\t\n",
      "Subject: s13, n=10 | test_f1: 0.23077 |best_f1: 0.375\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0322\tTop_Loss: 0.0858\tBottom_Loss: 0.0742\tLoss: 0.1922\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0679\tTop_Loss: 0.1152\tBottom_Loss: 0.1423\tLoss: 0.3254\t\n",
      "Subject: s13, n=10 | test_f1: 0.33333 |best_f1: 0.375\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0267\tTop_Loss: 0.1025\tBottom_Loss: 0.1298\tLoss: 0.2591\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0429\tTop_Loss: 0.1329\tBottom_Loss: 0.0748\tLoss: 0.2506\t\n",
      "Subject: s13, n=10 | test_f1: 0.23077 |best_f1: 0.375\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0476\tTop_Loss: 0.0931\tBottom_Loss: 0.1025\tLoss: 0.2432\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0668\tTop_Loss: 0.1634\tBottom_Loss: 0.1038\tLoss: 0.3340\t\n",
      "Subject: s13, n=10 | test_f1: 0.16667 |best_f1: 0.375\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0185\tTop_Loss: 0.0702\tBottom_Loss: 0.0427\tLoss: 0.1314\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0216\tTop_Loss: 0.0800\tBottom_Loss: 0.0479\tLoss: 0.1495\t\n",
      "Subject: s13, n=10 | test_f1: 0.28571 |best_f1: 0.375\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0490\tTop_Loss: 0.1794\tBottom_Loss: 0.0882\tLoss: 0.3165\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0339\tTop_Loss: 0.0781\tBottom_Loss: 0.1002\tLoss: 0.2122\t\n",
      "Subject: s13, n=10 | test_f1: 0.33333 |best_f1: 0.375\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0500\tTop_Loss: 0.1347\tBottom_Loss: 0.0988\tLoss: 0.2835\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0064\tTop_Loss: 0.0302\tBottom_Loss: 0.0360\tLoss: 0.0726\t\n",
      "Subject: s13, n=10 | test_f1: 0.33333 |best_f1: 0.375\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0150\tTop_Loss: 0.0830\tBottom_Loss: 0.0740\tLoss: 0.1720\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0361\tTop_Loss: 0.0949\tBottom_Loss: 0.0604\tLoss: 0.1914\t\n",
      "Subject: s13, n=10 | test_f1: 0.23077 |best_f1: 0.375\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0253\tTop_Loss: 0.1484\tBottom_Loss: 0.0393\tLoss: 0.2130\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0167\tTop_Loss: 0.0704\tBottom_Loss: 0.0419\tLoss: 0.1290\t\n",
      "Subject: s13, n=10 | test_f1: 0.23077 |best_f1: 0.375\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0820\tTop_Loss: 0.1126\tBottom_Loss: 0.1186\tLoss: 0.3133\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0108\tTop_Loss: 0.0710\tBottom_Loss: 0.0520\tLoss: 0.1338\t\n",
      "Subject: s13, n=10 | test_f1: 0.375 |best_f1: 0.375\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0195\tTop_Loss: 0.0422\tBottom_Loss: 0.0655\tLoss: 0.1272\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0940\tTop_Loss: 0.0698\tBottom_Loss: 0.2227\tLoss: 0.3865\t\n",
      "Subject: s13, n=10 | test_f1: 0.16667 |best_f1: 0.375\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0157\tTop_Loss: 0.0802\tBottom_Loss: 0.0315\tLoss: 0.1274\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0558\tTop_Loss: 0.1618\tBottom_Loss: 0.0655\tLoss: 0.2831\t\n",
      "Subject: s13, n=10 | test_f1: 0.16667 |best_f1: 0.375\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0095\tTop_Loss: 0.0408\tBottom_Loss: 0.0608\tLoss: 0.1111\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0159\tTop_Loss: 0.0502\tBottom_Loss: 0.0860\tLoss: 0.1521\t\n",
      "Subject: s13, n=10 | test_f1: 0.28571 |best_f1: 0.375\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0284\tTop_Loss: 0.0499\tBottom_Loss: 0.0604\tLoss: 0.1387\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0070\tTop_Loss: 0.0244\tBottom_Loss: 0.0287\tLoss: 0.0601\t\n",
      "Subject: s13, n=10 | test_f1: 0.16667 |best_f1: 0.375\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1618\tTop_Loss: 0.1673\tBottom_Loss: 0.1915\tLoss: 0.5206\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0211\tTop_Loss: 0.0537\tBottom_Loss: 0.0943\tLoss: 0.1691\t\n",
      "Subject: s13, n=10 | test_f1: 0.28571 |best_f1: 0.375\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0745\tTop_Loss: 0.0591\tBottom_Loss: 0.1788\tLoss: 0.3125\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0055\tTop_Loss: 0.0211\tBottom_Loss: 0.0479\tLoss: 0.0744\t\n",
      "Subject: s13, n=10 | test_f1: 0.28571 |best_f1: 0.375\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0232\tTop_Loss: 0.0556\tBottom_Loss: 0.0410\tLoss: 0.1199\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0171\tTop_Loss: 0.0350\tBottom_Loss: 0.0495\tLoss: 0.1015\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: s13, n=10 | test_f1: 0.33333 |best_f1: 0.375\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0241\tTop_Loss: 0.0679\tBottom_Loss: 0.0880\tLoss: 0.1800\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0234\tTop_Loss: 0.1055\tBottom_Loss: 0.0469\tLoss: 0.1758\t\n",
      "Subject: s13, n=10 | test_f1: 0.28571 |best_f1: 0.375\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0445\tTop_Loss: 0.0575\tBottom_Loss: 0.1075\tLoss: 0.2095\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0610\tTop_Loss: 0.1319\tBottom_Loss: 0.0393\tLoss: 0.2323\t\n",
      "Subject: s13, n=10 | test_f1: 0.16667 |best_f1: 0.375\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0193\tTop_Loss: 0.0652\tBottom_Loss: 0.0649\tLoss: 0.1495\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0155\tTop_Loss: 0.1853\tBottom_Loss: 0.0219\tLoss: 0.2227\t\n",
      "Subject: s13, n=10 | test_f1: 0.23077 |best_f1: 0.375\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0179\tTop_Loss: 0.0259\tBottom_Loss: 0.0523\tLoss: 0.0961\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0061\tTop_Loss: 0.0309\tBottom_Loss: 0.0337\tLoss: 0.0707\t\n",
      "Subject: s13, n=10 | test_f1: 0.16667 |best_f1: 0.375\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0126\tTop_Loss: 0.0345\tBottom_Loss: 0.0388\tLoss: 0.0859\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0061\tTop_Loss: 0.0219\tBottom_Loss: 0.0322\tLoss: 0.0602\t\n",
      "Subject: s13, n=10 | test_f1: 0.16667 |best_f1: 0.375\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0388\tTop_Loss: 0.0846\tBottom_Loss: 0.0955\tLoss: 0.2190\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0652\tTop_Loss: 0.1239\tBottom_Loss: 0.1390\tLoss: 0.3280\t\n",
      "Subject: s13, n=10 | test_f1: 0.0 |best_f1: 0.375\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0077\tTop_Loss: 0.0996\tBottom_Loss: 0.0162\tLoss: 0.1235\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 0.938\tLabel_Loss: 0.0811\tTop_Loss: 0.1359\tBottom_Loss: 0.0951\tLoss: 0.3122\t\n",
      "Subject: s13, n=10 | test_f1: 0.16667 |best_f1: 0.375\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0192\tTop_Loss: 0.0537\tBottom_Loss: 0.0325\tLoss: 0.1053\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0058\tTop_Loss: 0.0261\tBottom_Loss: 0.0179\tLoss: 0.0497\t\n",
      "Subject: s13, n=10 | test_f1: 0.23077 |best_f1: 0.375\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0414\tTop_Loss: 0.1277\tBottom_Loss: 0.1104\tLoss: 0.2795\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0075\tTop_Loss: 0.0568\tBottom_Loss: 0.0261\tLoss: 0.0904\t\n",
      "Subject: s13, n=10 | test_f1: 0.090909 |best_f1: 0.375\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0211\tTop_Loss: 0.0499\tBottom_Loss: 0.0442\tLoss: 0.1152\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0062\tTop_Loss: 0.0173\tBottom_Loss: 0.0235\tLoss: 0.0470\t\n",
      "Subject: s13, n=10 | test_f1: 0.090909 |best_f1: 0.375\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0059\tTop_Loss: 0.0230\tBottom_Loss: 0.0224\tLoss: 0.0512\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0083\tTop_Loss: 0.0288\tBottom_Loss: 0.0194\tLoss: 0.0564\t\n",
      "Subject: s13, n=10 | test_f1: 0.23077 |best_f1: 0.375\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0300\tTop_Loss: 0.0648\tBottom_Loss: 0.0942\tLoss: 0.1889\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0175\tTop_Loss: 0.0687\tBottom_Loss: 0.0350\tLoss: 0.1213\t\n",
      "Subject: s13, n=10 | test_f1: 0.16667 |best_f1: 0.375\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.281\tLabel_Loss: 1.2446\tTop_Loss: 1.1167\tBottom_Loss: 1.2060\tLoss: 3.5674\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.469\tLabel_Loss: 1.0845\tTop_Loss: 1.1515\tBottom_Loss: 1.0006\tLoss: 3.2366\t\n",
      "Subject: s14, n=10 | test_f1: 0.38889 |best_f1: 0.38889\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.562\tLabel_Loss: 0.9636\tTop_Loss: 1.2155\tBottom_Loss: 1.0763\tLoss: 3.2554\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.500\tLabel_Loss: 1.2539\tTop_Loss: 1.0674\tBottom_Loss: 1.1980\tLoss: 3.5192\t\n",
      "Subject: s14, n=10 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.562\tLabel_Loss: 0.9736\tTop_Loss: 1.0649\tBottom_Loss: 0.9151\tLoss: 2.9536\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.688\tLabel_Loss: 0.8448\tTop_Loss: 0.9851\tBottom_Loss: 0.7950\tLoss: 2.6249\t\n",
      "Subject: s14, n=10 | test_f1: 0.51515 |best_f1: 0.51515\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.438\tLabel_Loss: 1.2103\tTop_Loss: 1.2766\tBottom_Loss: 1.2950\tLoss: 3.7819\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.656\tLabel_Loss: 0.8220\tTop_Loss: 0.9578\tBottom_Loss: 0.8974\tLoss: 2.6772\t\n",
      "Subject: s14, n=10 | test_f1: 0.38889 |best_f1: 0.51515\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.500\tLabel_Loss: 1.0980\tTop_Loss: 0.9919\tBottom_Loss: 1.0897\tLoss: 3.1795\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.688\tLabel_Loss: 0.8081\tTop_Loss: 0.9582\tBottom_Loss: 0.9405\tLoss: 2.7068\t\n",
      "Subject: s14, n=10 | test_f1: 0.51515 |best_f1: 0.51515\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.562\tLabel_Loss: 0.9954\tTop_Loss: 1.0202\tBottom_Loss: 0.9513\tLoss: 2.9669\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.562\tLabel_Loss: 0.9025\tTop_Loss: 0.7841\tBottom_Loss: 0.8939\tLoss: 2.5805\t\n",
      "Subject: s14, n=10 | test_f1: 0.39259 |best_f1: 0.51515\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.500\tLabel_Loss: 0.9342\tTop_Loss: 1.0155\tBottom_Loss: 1.0316\tLoss: 2.9813\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7487\tTop_Loss: 0.7016\tBottom_Loss: 0.7348\tLoss: 2.1851\t\n",
      "Subject: s14, n=10 | test_f1: 0.37037 |best_f1: 0.51515\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6134\tTop_Loss: 0.7988\tBottom_Loss: 0.7209\tLoss: 2.1331\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.656\tLabel_Loss: 0.9463\tTop_Loss: 0.9556\tBottom_Loss: 1.0965\tLoss: 2.9984\t\n",
      "Subject: s14, n=10 | test_f1: 0.69444 |best_f1: 0.69444\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8025\tTop_Loss: 0.8716\tBottom_Loss: 0.8988\tLoss: 2.5730\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7522\tTop_Loss: 0.7820\tBottom_Loss: 0.9106\tLoss: 2.4448\t\n",
      "Subject: s14, n=10 | test_f1: 0.51515 |best_f1: 0.69444\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.688\tLabel_Loss: 0.8042\tTop_Loss: 0.7618\tBottom_Loss: 0.9124\tLoss: 2.4785\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.562\tLabel_Loss: 0.7943\tTop_Loss: 0.7694\tBottom_Loss: 0.8172\tLoss: 2.3809\t\n",
      "Subject: s14, n=10 | test_f1: 0.60317 |best_f1: 0.69444\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4917\tTop_Loss: 0.6049\tBottom_Loss: 0.5163\tLoss: 1.6129\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5988\tTop_Loss: 0.8277\tBottom_Loss: 0.8115\tLoss: 2.2380\t\n",
      "Subject: s14, n=10 | test_f1: 0.2963 |best_f1: 0.69444\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5545\tTop_Loss: 0.7004\tBottom_Loss: 0.6516\tLoss: 1.9065\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.625\tLabel_Loss: 0.6370\tTop_Loss: 0.7273\tBottom_Loss: 0.6799\tLoss: 2.0443\t\n",
      "Subject: s14, n=10 | test_f1: 0.17857 |best_f1: 0.69444\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3713\tTop_Loss: 0.4201\tBottom_Loss: 0.6072\tLoss: 1.3986\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.531\tLabel_Loss: 0.7989\tTop_Loss: 0.8700\tBottom_Loss: 0.9492\tLoss: 2.6180\t\n",
      "Subject: s14, n=10 | test_f1: 0.47778 |best_f1: 0.69444\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4560\tTop_Loss: 0.5582\tBottom_Loss: 0.7300\tLoss: 1.7442\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5496\tTop_Loss: 0.6490\tBottom_Loss: 0.7136\tLoss: 1.9122\t\n",
      "Subject: s14, n=10 | test_f1: 0.27706 |best_f1: 0.69444\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.500\tLabel_Loss: 0.9331\tTop_Loss: 1.1658\tBottom_Loss: 0.9415\tLoss: 3.0404\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6277\tTop_Loss: 0.8001\tBottom_Loss: 0.8196\tLoss: 2.2474\t\n",
      "Subject: s14, n=10 | test_f1: 0.6127 |best_f1: 0.69444\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5839\tTop_Loss: 0.7048\tBottom_Loss: 0.7194\tLoss: 2.0081\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6651\tTop_Loss: 0.7402\tBottom_Loss: 0.7638\tLoss: 2.1691\t\n",
      "Subject: s14, n=10 | test_f1: 0.74603 |best_f1: 0.74603\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.688\tLabel_Loss: 0.8327\tTop_Loss: 0.8613\tBottom_Loss: 0.7629\tLoss: 2.4569\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5946\tTop_Loss: 0.6228\tBottom_Loss: 0.6788\tLoss: 1.8962\t\n",
      "Subject: s14, n=10 | test_f1: 0.33862 |best_f1: 0.74603\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4817\tTop_Loss: 0.7024\tBottom_Loss: 0.6778\tLoss: 1.8620\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5664\tTop_Loss: 0.7321\tBottom_Loss: 0.6976\tLoss: 1.9960\t\n",
      "Subject: s14, n=10 | test_f1: 0.38889 |best_f1: 0.74603\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4887\tTop_Loss: 0.5634\tBottom_Loss: 0.5460\tLoss: 1.5981\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4918\tTop_Loss: 0.6168\tBottom_Loss: 0.5342\tLoss: 1.6428\t\n",
      "Subject: s14, n=10 | test_f1: 0.3 |best_f1: 0.74603\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4642\tTop_Loss: 0.6249\tBottom_Loss: 0.5823\tLoss: 1.6714\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.750\tLabel_Loss: 0.4484\tTop_Loss: 0.6316\tBottom_Loss: 0.7155\tLoss: 1.7954\t\n",
      "Subject: s14, n=10 | test_f1: 0.5 |best_f1: 0.74603\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.688\tLabel_Loss: 0.5392\tTop_Loss: 0.5863\tBottom_Loss: 0.4515\tLoss: 1.5769\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.688\tLabel_Loss: 0.5880\tTop_Loss: 0.5234\tBottom_Loss: 0.6988\tLoss: 1.8102\t\n",
      "Subject: s14, n=10 | test_f1: 0.60317 |best_f1: 0.74603\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4574\tTop_Loss: 0.5329\tBottom_Loss: 0.5923\tLoss: 1.5826\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3554\tTop_Loss: 0.4439\tBottom_Loss: 0.6760\tLoss: 1.4753\t\n",
      "Subject: s14, n=10 | test_f1: 0.39683 |best_f1: 0.74603\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4771\tTop_Loss: 0.6601\tBottom_Loss: 0.4808\tLoss: 1.6181\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.750\tLabel_Loss: 0.4617\tTop_Loss: 0.6708\tBottom_Loss: 0.6092\tLoss: 1.7417\t\n",
      "Subject: s14, n=10 | test_f1: 0.71111 |best_f1: 0.74603\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3743\tTop_Loss: 0.4440\tBottom_Loss: 0.4682\tLoss: 1.2865\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.938\tLabel_Loss: 0.3914\tTop_Loss: 0.4773\tBottom_Loss: 0.5282\tLoss: 1.3969\t\n",
      "Subject: s14, n=10 | test_f1: 0.46667 |best_f1: 0.74603\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4913\tTop_Loss: 0.4537\tBottom_Loss: 0.5166\tLoss: 1.4615\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4292\tTop_Loss: 0.5110\tBottom_Loss: 0.5103\tLoss: 1.4505\t\n",
      "Subject: s14, n=10 | test_f1: 0.60317 |best_f1: 0.74603\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.938\tLabel_Loss: 0.3315\tTop_Loss: 0.6003\tBottom_Loss: 0.5215\tLoss: 1.4532\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4946\tTop_Loss: 0.6336\tBottom_Loss: 0.6066\tLoss: 1.7348\t\n",
      "Subject: s14, n=10 | test_f1: 0.6 |best_f1: 0.74603\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2977\tTop_Loss: 0.3449\tBottom_Loss: 0.4103\tLoss: 1.0528\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2513\tTop_Loss: 0.4902\tBottom_Loss: 0.3301\tLoss: 1.0715\t\n",
      "Subject: s14, n=10 | test_f1: 0.50794 |best_f1: 0.74603\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.844\tLabel_Loss: 0.2841\tTop_Loss: 0.4330\tBottom_Loss: 0.4004\tLoss: 1.1176\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.938\tLabel_Loss: 0.3021\tTop_Loss: 0.3931\tBottom_Loss: 0.4503\tLoss: 1.1455\t\n",
      "Subject: s14, n=10 | test_f1: 0.49048 |best_f1: 0.74603\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2093\tTop_Loss: 0.4766\tBottom_Loss: 0.3838\tLoss: 1.0696\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.781\tLabel_Loss: 0.6027\tTop_Loss: 0.5931\tBottom_Loss: 0.8402\tLoss: 2.0360\t\n",
      "Subject: s14, n=10 | test_f1: 0.51515 |best_f1: 0.74603\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3635\tTop_Loss: 0.4645\tBottom_Loss: 0.4969\tLoss: 1.3248\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4875\tTop_Loss: 0.5436\tBottom_Loss: 0.6447\tLoss: 1.6758\t\n",
      "Subject: s14, n=10 | test_f1: 0.6127 |best_f1: 0.74603\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2370\tTop_Loss: 0.3664\tBottom_Loss: 0.3411\tLoss: 0.9445\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3096\tTop_Loss: 0.3293\tBottom_Loss: 0.4050\tLoss: 1.0439\t\n",
      "Subject: s14, n=10 | test_f1: 0.49048 |best_f1: 0.74603\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2894\tTop_Loss: 0.3931\tBottom_Loss: 0.4163\tLoss: 1.0987\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4526\tTop_Loss: 0.5206\tBottom_Loss: 0.5253\tLoss: 1.4985\t\n",
      "Subject: s14, n=10 | test_f1: 0.57937 |best_f1: 0.74603\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2009\tTop_Loss: 0.5031\tBottom_Loss: 0.2733\tLoss: 0.9773\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1954\tTop_Loss: 0.4030\tBottom_Loss: 0.2674\tLoss: 0.8658\t\n",
      "Subject: s14, n=10 | test_f1: 0.70714 |best_f1: 0.74603\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1974\tTop_Loss: 0.4202\tBottom_Loss: 0.2977\tLoss: 0.9152\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2435\tTop_Loss: 0.3508\tBottom_Loss: 0.3291\tLoss: 0.9234\t\n",
      "Subject: s14, n=10 | test_f1: 0.39259 |best_f1: 0.74603\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1419\tTop_Loss: 0.3511\tBottom_Loss: 0.3366\tLoss: 0.8296\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1862\tTop_Loss: 0.2974\tBottom_Loss: 0.2974\tLoss: 0.7810\t\n",
      "Subject: s14, n=10 | test_f1: 0.58333 |best_f1: 0.74603\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2623\tTop_Loss: 0.5968\tBottom_Loss: 0.2524\tLoss: 1.1115\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4013\tTop_Loss: 0.5102\tBottom_Loss: 0.3311\tLoss: 1.2426\t\n",
      "Subject: s14, n=10 | test_f1: 0.6 |best_f1: 0.74603\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1713\tTop_Loss: 0.2566\tBottom_Loss: 0.3092\tLoss: 0.7371\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1366\tTop_Loss: 0.2716\tBottom_Loss: 0.2397\tLoss: 0.6479\t\n",
      "Subject: s14, n=10 | test_f1: 0.58333 |best_f1: 0.74603\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2257\tTop_Loss: 0.3436\tBottom_Loss: 0.3627\tLoss: 0.9320\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2902\tTop_Loss: 0.6114\tBottom_Loss: 0.3714\tLoss: 1.2729\t\n",
      "Subject: s14, n=10 | test_f1: 0.39524 |best_f1: 0.74603\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2294\tTop_Loss: 0.3391\tBottom_Loss: 0.4164\tLoss: 0.9849\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2803\tTop_Loss: 0.4227\tBottom_Loss: 0.3202\tLoss: 1.0231\t\n",
      "Subject: s14, n=10 | test_f1: 0.69444 |best_f1: 0.74603\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2160\tTop_Loss: 0.4188\tBottom_Loss: 0.2944\tLoss: 0.9292\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1624\tTop_Loss: 0.2008\tBottom_Loss: 0.2212\tLoss: 0.5844\t\n",
      "Subject: s14, n=10 | test_f1: 0.70714 |best_f1: 0.74603\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0731\tTop_Loss: 0.2336\tBottom_Loss: 0.1863\tLoss: 0.4930\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1918\tTop_Loss: 0.3722\tBottom_Loss: 0.4140\tLoss: 0.9781\t\n",
      "Subject: s14, n=10 | test_f1: 0.66667 |best_f1: 0.74603\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0810\tTop_Loss: 0.2284\tBottom_Loss: 0.2641\tLoss: 0.5735\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.875\tLabel_Loss: 0.1925\tTop_Loss: 0.4205\tBottom_Loss: 0.2638\tLoss: 0.8768\t\n",
      "Subject: s14, n=10 | test_f1: 0.49048 |best_f1: 0.74603\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1951\tTop_Loss: 0.3636\tBottom_Loss: 0.2448\tLoss: 0.8035\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1871\tTop_Loss: 0.4190\tBottom_Loss: 0.2516\tLoss: 0.8577\t\n",
      "Subject: s14, n=10 | test_f1: 0.71111 |best_f1: 0.74603\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1667\tTop_Loss: 0.3478\tBottom_Loss: 0.2417\tLoss: 0.7562\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1690\tTop_Loss: 0.2649\tBottom_Loss: 0.3001\tLoss: 0.7339\t\n",
      "Subject: s14, n=10 | test_f1: 0.57381 |best_f1: 0.74603\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1142\tTop_Loss: 0.1988\tBottom_Loss: 0.1883\tLoss: 0.5013\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2244\tTop_Loss: 0.3259\tBottom_Loss: 0.3382\tLoss: 0.8885\t\n",
      "Subject: s14, n=10 | test_f1: 0.61111 |best_f1: 0.74603\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0704\tTop_Loss: 0.2508\tBottom_Loss: 0.1848\tLoss: 0.5060\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1309\tTop_Loss: 0.2841\tBottom_Loss: 0.1894\tLoss: 0.6044\t\n",
      "Subject: s14, n=10 | test_f1: 0.58333 |best_f1: 0.74603\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0896\tTop_Loss: 0.2492\tBottom_Loss: 0.1341\tLoss: 0.4730\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2029\tTop_Loss: 0.3388\tBottom_Loss: 0.3471\tLoss: 0.8889\t\n",
      "Subject: s14, n=10 | test_f1: 0.47778 |best_f1: 0.74603\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1397\tTop_Loss: 0.4086\tBottom_Loss: 0.2368\tLoss: 0.7852\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1936\tTop_Loss: 0.3502\tBottom_Loss: 0.2619\tLoss: 0.8057\t\n",
      "Subject: s14, n=10 | test_f1: 0.48413 |best_f1: 0.74603\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0660\tTop_Loss: 0.2292\tBottom_Loss: 0.1728\tLoss: 0.4681\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0804\tTop_Loss: 0.2975\tBottom_Loss: 0.1812\tLoss: 0.5591\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: s14, n=10 | test_f1: 0.71111 |best_f1: 0.74603\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1625\tTop_Loss: 0.2506\tBottom_Loss: 0.2846\tLoss: 0.6976\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2687\tTop_Loss: 0.3439\tBottom_Loss: 0.2707\tLoss: 0.8832\t\n",
      "Subject: s14, n=10 | test_f1: 0.58571 |best_f1: 0.74603\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0998\tTop_Loss: 0.1712\tBottom_Loss: 0.1499\tLoss: 0.4209\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2587\tTop_Loss: 0.3408\tBottom_Loss: 0.3768\tLoss: 0.9763\t\n",
      "Subject: s14, n=10 | test_f1: 0.8 |best_f1: 0.8\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0802\tTop_Loss: 0.1628\tBottom_Loss: 0.1795\tLoss: 0.4226\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0605\tTop_Loss: 0.1843\tBottom_Loss: 0.1580\tLoss: 0.4029\t\n",
      "Subject: s14, n=10 | test_f1: 0.80238 |best_f1: 0.80238\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0519\tTop_Loss: 0.2216\tBottom_Loss: 0.1335\tLoss: 0.4071\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0800\tTop_Loss: 0.2303\tBottom_Loss: 0.1560\tLoss: 0.4662\t\n",
      "Subject: s14, n=10 | test_f1: 0.5037 |best_f1: 0.80238\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2065\tTop_Loss: 0.2848\tBottom_Loss: 0.1911\tLoss: 0.6825\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1080\tTop_Loss: 0.2714\tBottom_Loss: 0.2123\tLoss: 0.5917\t\n",
      "Subject: s14, n=10 | test_f1: 0.52593 |best_f1: 0.80238\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0549\tTop_Loss: 0.2819\tBottom_Loss: 0.1771\tLoss: 0.5140\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0831\tTop_Loss: 0.2033\tBottom_Loss: 0.3278\tLoss: 0.6142\t\n",
      "Subject: s14, n=10 | test_f1: 0.44848 |best_f1: 0.80238\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0259\tTop_Loss: 0.1233\tBottom_Loss: 0.0686\tLoss: 0.2178\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1140\tTop_Loss: 0.3202\tBottom_Loss: 0.1135\tLoss: 0.5477\t\n",
      "Subject: s14, n=10 | test_f1: 0.33333 |best_f1: 0.80238\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0560\tTop_Loss: 0.1844\tBottom_Loss: 0.1221\tLoss: 0.3625\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0773\tTop_Loss: 0.1470\tBottom_Loss: 0.2155\tLoss: 0.4397\t\n",
      "Subject: s14, n=10 | test_f1: 0.52857 |best_f1: 0.80238\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1040\tTop_Loss: 0.2420\tBottom_Loss: 0.1030\tLoss: 0.4490\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1109\tTop_Loss: 0.2334\tBottom_Loss: 0.1658\tLoss: 0.5100\t\n",
      "Subject: s14, n=10 | test_f1: 0.70714 |best_f1: 0.80238\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1354\tTop_Loss: 0.2444\tBottom_Loss: 0.1606\tLoss: 0.5404\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0743\tTop_Loss: 0.2226\tBottom_Loss: 0.2073\tLoss: 0.5041\t\n",
      "Subject: s14, n=10 | test_f1: 0.46667 |best_f1: 0.80238\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1064\tTop_Loss: 0.1854\tBottom_Loss: 0.1107\tLoss: 0.4025\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0312\tTop_Loss: 0.0999\tBottom_Loss: 0.0917\tLoss: 0.2228\t\n",
      "Subject: s14, n=10 | test_f1: 0.83333 |best_f1: 0.83333\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0931\tTop_Loss: 0.1931\tBottom_Loss: 0.2219\tLoss: 0.5081\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1110\tTop_Loss: 0.2239\tBottom_Loss: 0.1442\tLoss: 0.4790\t\n",
      "Subject: s14, n=10 | test_f1: 0.38889 |best_f1: 0.83333\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1203\tTop_Loss: 0.1935\tBottom_Loss: 0.2048\tLoss: 0.5186\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0600\tTop_Loss: 0.1387\tBottom_Loss: 0.0879\tLoss: 0.2865\t\n",
      "Subject: s14, n=10 | test_f1: 0.49048 |best_f1: 0.83333\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0643\tTop_Loss: 0.1726\tBottom_Loss: 0.0800\tLoss: 0.3169\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0154\tTop_Loss: 0.0922\tBottom_Loss: 0.0484\tLoss: 0.1560\t\n",
      "Subject: s14, n=10 | test_f1: 0.86667 |best_f1: 0.86667\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0728\tTop_Loss: 0.2276\tBottom_Loss: 0.1228\tLoss: 0.4232\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0587\tTop_Loss: 0.1464\tBottom_Loss: 0.1336\tLoss: 0.3387\t\n",
      "Subject: s14, n=10 | test_f1: 0.51515 |best_f1: 0.86667\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0436\tTop_Loss: 0.1352\tBottom_Loss: 0.0753\tLoss: 0.2541\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0931\tTop_Loss: 0.1451\tBottom_Loss: 0.1405\tLoss: 0.3787\t\n",
      "Subject: s14, n=10 | test_f1: 0.57937 |best_f1: 0.86667\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0393\tTop_Loss: 0.1740\tBottom_Loss: 0.0875\tLoss: 0.3008\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0642\tTop_Loss: 0.2280\tBottom_Loss: 0.1049\tLoss: 0.3971\t\n",
      "Subject: s14, n=10 | test_f1: 0.6 |best_f1: 0.86667\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0277\tTop_Loss: 0.0802\tBottom_Loss: 0.1164\tLoss: 0.2243\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0372\tTop_Loss: 0.0960\tBottom_Loss: 0.0397\tLoss: 0.1729\t\n",
      "Subject: s14, n=10 | test_f1: 0.6453 |best_f1: 0.86667\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0368\tTop_Loss: 0.2518\tBottom_Loss: 0.0914\tLoss: 0.3800\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0397\tTop_Loss: 0.1288\tBottom_Loss: 0.1131\tLoss: 0.2816\t\n",
      "Subject: s14, n=10 | test_f1: 0.49206 |best_f1: 0.86667\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0204\tTop_Loss: 0.0987\tBottom_Loss: 0.1007\tLoss: 0.2198\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1543\tTop_Loss: 0.2583\tBottom_Loss: 0.2052\tLoss: 0.6179\t\n",
      "Subject: s14, n=10 | test_f1: 0.41667 |best_f1: 0.86667\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0552\tTop_Loss: 0.2596\tBottom_Loss: 0.0745\tLoss: 0.3893\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0288\tTop_Loss: 0.0915\tBottom_Loss: 0.0615\tLoss: 0.1818\t\n",
      "Subject: s14, n=10 | test_f1: 0.47222 |best_f1: 0.86667\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0187\tTop_Loss: 0.1230\tBottom_Loss: 0.0314\tLoss: 0.1731\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0377\tTop_Loss: 0.0883\tBottom_Loss: 0.1786\tLoss: 0.3046\t\n",
      "Subject: s14, n=10 | test_f1: 0.65556 |best_f1: 0.86667\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1098\tTop_Loss: 0.2908\tBottom_Loss: 0.1247\tLoss: 0.5253\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0685\tTop_Loss: 0.1578\tBottom_Loss: 0.1209\tLoss: 0.3471\t\n",
      "Subject: s14, n=10 | test_f1: 0.57778 |best_f1: 0.86667\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0140\tTop_Loss: 0.0352\tBottom_Loss: 0.0409\tLoss: 0.0901\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0186\tTop_Loss: 0.0682\tBottom_Loss: 0.0352\tLoss: 0.1220\t\n",
      "Subject: s14, n=10 | test_f1: 0.49206 |best_f1: 0.86667\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0453\tTop_Loss: 0.1155\tBottom_Loss: 0.0791\tLoss: 0.2400\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1043\tTop_Loss: 0.2998\tBottom_Loss: 0.0936\tLoss: 0.4977\t\n",
      "Subject: s14, n=10 | test_f1: 0.6 |best_f1: 0.86667\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0439\tTop_Loss: 0.0978\tBottom_Loss: 0.0549\tLoss: 0.1967\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0327\tTop_Loss: 0.0827\tBottom_Loss: 0.1035\tLoss: 0.2189\t\n",
      "Subject: s14, n=10 | test_f1: 0.67937 |best_f1: 0.86667\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0762\tTop_Loss: 0.1819\tBottom_Loss: 0.1641\tLoss: 0.4221\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0420\tTop_Loss: 0.1386\tBottom_Loss: 0.0924\tLoss: 0.2729\t\n",
      "Subject: s14, n=10 | test_f1: 0.50529 |best_f1: 0.86667\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0258\tTop_Loss: 0.0593\tBottom_Loss: 0.0488\tLoss: 0.1340\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0617\tTop_Loss: 0.1538\tBottom_Loss: 0.1220\tLoss: 0.3375\t\n",
      "Subject: s14, n=10 | test_f1: 0.57381 |best_f1: 0.86667\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0403\tTop_Loss: 0.0817\tBottom_Loss: 0.1107\tLoss: 0.2326\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0323\tTop_Loss: 0.1106\tBottom_Loss: 0.0628\tLoss: 0.2057\t\n",
      "Subject: s14, n=10 | test_f1: 0.72222 |best_f1: 0.86667\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0157\tTop_Loss: 0.0753\tBottom_Loss: 0.0366\tLoss: 0.1276\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0183\tTop_Loss: 0.0961\tBottom_Loss: 0.0408\tLoss: 0.1552\t\n",
      "Subject: s14, n=10 | test_f1: 0.57937 |best_f1: 0.86667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0344\tTop_Loss: 0.1196\tBottom_Loss: 0.0601\tLoss: 0.2141\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0244\tTop_Loss: 0.1150\tBottom_Loss: 0.0701\tLoss: 0.2095\t\n",
      "Subject: s14, n=10 | test_f1: 0.54242 |best_f1: 0.86667\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0114\tTop_Loss: 0.0555\tBottom_Loss: 0.0568\tLoss: 0.1238\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0396\tTop_Loss: 0.0846\tBottom_Loss: 0.1593\tLoss: 0.2835\t\n",
      "Subject: s14, n=10 | test_f1: 0.57937 |best_f1: 0.86667\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0287\tTop_Loss: 0.0633\tBottom_Loss: 0.0591\tLoss: 0.1510\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0297\tTop_Loss: 0.0656\tBottom_Loss: 0.0484\tLoss: 0.1437\t\n",
      "Subject: s14, n=10 | test_f1: 0.46667 |best_f1: 0.86667\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0316\tTop_Loss: 0.0422\tBottom_Loss: 0.0759\tLoss: 0.1498\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0314\tTop_Loss: 0.0930\tBottom_Loss: 0.0558\tLoss: 0.1802\t\n",
      "Subject: s14, n=10 | test_f1: 0.46667 |best_f1: 0.86667\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0337\tTop_Loss: 0.0857\tBottom_Loss: 0.0650\tLoss: 0.1844\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0115\tTop_Loss: 0.0683\tBottom_Loss: 0.0389\tLoss: 0.1186\t\n",
      "Subject: s14, n=10 | test_f1: 0.5 |best_f1: 0.86667\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0144\tTop_Loss: 0.0543\tBottom_Loss: 0.0514\tLoss: 0.1201\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0368\tTop_Loss: 0.1521\tBottom_Loss: 0.1094\tLoss: 0.2983\t\n",
      "Subject: s14, n=10 | test_f1: 0.66667 |best_f1: 0.86667\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0179\tTop_Loss: 0.0635\tBottom_Loss: 0.0314\tLoss: 0.1128\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0057\tTop_Loss: 0.0351\tBottom_Loss: 0.0442\tLoss: 0.0850\t\n",
      "Subject: s14, n=10 | test_f1: 0.42222 |best_f1: 0.86667\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0277\tTop_Loss: 0.0810\tBottom_Loss: 0.0754\tLoss: 0.1840\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0409\tTop_Loss: 0.0688\tBottom_Loss: 0.1475\tLoss: 0.2572\t\n",
      "Subject: s14, n=10 | test_f1: 0.8963 |best_f1: 0.8963\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0085\tTop_Loss: 0.0475\tBottom_Loss: 0.0332\tLoss: 0.0892\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0216\tTop_Loss: 0.1295\tBottom_Loss: 0.0496\tLoss: 0.2008\t\n",
      "Subject: s14, n=10 | test_f1: 0.66667 |best_f1: 0.8963\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0070\tTop_Loss: 0.0284\tBottom_Loss: 0.0281\tLoss: 0.0635\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0072\tTop_Loss: 0.0416\tBottom_Loss: 0.0274\tLoss: 0.0762\t\n",
      "Subject: s14, n=10 | test_f1: 0.35354 |best_f1: 0.8963\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0077\tTop_Loss: 0.0405\tBottom_Loss: 0.0176\tLoss: 0.0657\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0068\tTop_Loss: 0.0404\tBottom_Loss: 0.0189\tLoss: 0.0661\t\n",
      "Subject: s14, n=10 | test_f1: 0.61111 |best_f1: 0.8963\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0070\tTop_Loss: 0.0342\tBottom_Loss: 0.0130\tLoss: 0.0542\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0278\tTop_Loss: 0.0940\tBottom_Loss: 0.0544\tLoss: 0.1762\t\n",
      "Subject: s14, n=10 | test_f1: 0.66667 |best_f1: 0.8963\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0101\tTop_Loss: 0.0463\tBottom_Loss: 0.0142\tLoss: 0.0706\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0173\tTop_Loss: 0.0391\tBottom_Loss: 0.0891\tLoss: 0.1455\t\n",
      "Subject: s14, n=10 | test_f1: 0.49206 |best_f1: 0.8963\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0717\tTop_Loss: 0.0648\tBottom_Loss: 0.0516\tLoss: 0.1882\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0097\tTop_Loss: 0.0870\tBottom_Loss: 0.0185\tLoss: 0.1153\t\n",
      "Subject: s14, n=10 | test_f1: 0.82222 |best_f1: 0.8963\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0075\tTop_Loss: 0.0425\tBottom_Loss: 0.0139\tLoss: 0.0639\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0087\tTop_Loss: 0.0361\tBottom_Loss: 0.0184\tLoss: 0.0632\t\n",
      "Subject: s14, n=10 | test_f1: 0.78519 |best_f1: 0.8963\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0112\tTop_Loss: 0.0423\tBottom_Loss: 0.0195\tLoss: 0.0729\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0139\tTop_Loss: 0.0796\tBottom_Loss: 0.0243\tLoss: 0.1178\t\n",
      "Subject: s14, n=10 | test_f1: 0.74603 |best_f1: 0.8963\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0259\tTop_Loss: 0.0464\tBottom_Loss: 0.0855\tLoss: 0.1579\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0216\tTop_Loss: 0.0833\tBottom_Loss: 0.0226\tLoss: 0.1275\t\n",
      "Subject: s14, n=10 | test_f1: 0.67576 |best_f1: 0.8963\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0133\tTop_Loss: 0.0627\tBottom_Loss: 0.0221\tLoss: 0.0981\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0233\tTop_Loss: 0.0708\tBottom_Loss: 0.0207\tLoss: 0.1148\t\n",
      "Subject: s14, n=10 | test_f1: 0.58889 |best_f1: 0.8963\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0067\tTop_Loss: 0.0234\tBottom_Loss: 0.0131\tLoss: 0.0432\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0162\tTop_Loss: 0.0391\tBottom_Loss: 0.0335\tLoss: 0.0888\t\n",
      "Subject: s14, n=10 | test_f1: 0.68687 |best_f1: 0.8963\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0109\tTop_Loss: 0.0279\tBottom_Loss: 0.0522\tLoss: 0.0910\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0023\tTop_Loss: 0.0104\tBottom_Loss: 0.0077\tLoss: 0.0205\t\n",
      "Subject: s14, n=10 | test_f1: 0.39524 |best_f1: 0.8963\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0276\tTop_Loss: 0.0395\tBottom_Loss: 0.0404\tLoss: 0.1075\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0058\tTop_Loss: 0.0376\tBottom_Loss: 0.0088\tLoss: 0.0522\t\n",
      "Subject: s14, n=10 | test_f1: 0.37576 |best_f1: 0.8963\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.375\tLabel_Loss: 1.2286\tTop_Loss: 1.3584\tBottom_Loss: 1.6330\tLoss: 4.2200\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8492\tTop_Loss: 0.8044\tBottom_Loss: 0.8289\tLoss: 2.4825\t\n",
      "Subject: s15, n=04 | test_f1: 0.38889 |best_f1: 0.38889\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.406\tLabel_Loss: 1.3272\tTop_Loss: 1.1963\tBottom_Loss: 1.1244\tLoss: 3.6479\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.375\tLabel_Loss: 1.2242\tTop_Loss: 1.2282\tBottom_Loss: 1.0542\tLoss: 3.5065\t\n",
      "Subject: s15, n=04 | test_f1: 0.16667 |best_f1: 0.38889\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.469\tLabel_Loss: 1.0911\tTop_Loss: 1.0592\tBottom_Loss: 0.9914\tLoss: 3.1417\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.625\tLabel_Loss: 0.9785\tTop_Loss: 0.9378\tBottom_Loss: 0.8311\tLoss: 2.7474\t\n",
      "Subject: s15, n=04 | test_f1: 0.38889 |best_f1: 0.38889\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.625\tLabel_Loss: 0.9153\tTop_Loss: 1.0007\tBottom_Loss: 0.7920\tLoss: 2.7080\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.531\tLabel_Loss: 0.9282\tTop_Loss: 1.0741\tBottom_Loss: 0.9409\tLoss: 2.9432\t\n",
      "Subject: s15, n=04 | test_f1: 0.13333 |best_f1: 0.38889\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.562\tLabel_Loss: 0.8569\tTop_Loss: 0.9691\tBottom_Loss: 1.0110\tLoss: 2.8370\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.500\tLabel_Loss: 0.8816\tTop_Loss: 0.8541\tBottom_Loss: 0.8269\tLoss: 2.5626\t\n",
      "Subject: s15, n=04 | test_f1: 0.44444 |best_f1: 0.44444\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.719\tLabel_Loss: 0.7436\tTop_Loss: 0.7391\tBottom_Loss: 0.8203\tLoss: 2.3030\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.656\tLabel_Loss: 0.8256\tTop_Loss: 0.7887\tBottom_Loss: 0.6689\tLoss: 2.2832\t\n",
      "Subject: s15, n=04 | test_f1: 0.16667 |best_f1: 0.44444\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.531\tLabel_Loss: 0.8961\tTop_Loss: 1.1414\tBottom_Loss: 0.9633\tLoss: 3.0007\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.562\tLabel_Loss: 0.7880\tTop_Loss: 0.8002\tBottom_Loss: 0.8848\tLoss: 2.4730\t\n",
      "Subject: s15, n=04 | test_f1: 0.0 |best_f1: 0.44444\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.656\tLabel_Loss: 0.8526\tTop_Loss: 0.8686\tBottom_Loss: 0.9530\tLoss: 2.6742\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.594\tLabel_Loss: 0.7574\tTop_Loss: 0.8268\tBottom_Loss: 1.0381\tLoss: 2.6224\t\n",
      "Subject: s15, n=04 | test_f1: 0.38889 |best_f1: 0.44444\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8168\tTop_Loss: 0.8823\tBottom_Loss: 0.8257\tLoss: 2.5249\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.594\tLabel_Loss: 0.9690\tTop_Loss: 0.9080\tBottom_Loss: 0.9563\tLoss: 2.8333\t\n",
      "Subject: s15, n=04 | test_f1: 0.38889 |best_f1: 0.44444\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6231\tTop_Loss: 0.7341\tBottom_Loss: 0.7628\tLoss: 2.1200\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.719\tLabel_Loss: 0.7004\tTop_Loss: 0.7449\tBottom_Loss: 0.6301\tLoss: 2.0755\t\n",
      "Subject: s15, n=04 | test_f1: 0.38889 |best_f1: 0.44444\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6562\tTop_Loss: 0.8211\tBottom_Loss: 0.7874\tLoss: 2.2647\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7982\tTop_Loss: 0.8008\tBottom_Loss: 0.6369\tLoss: 2.2359\t\n",
      "Subject: s15, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5912\tTop_Loss: 0.5034\tBottom_Loss: 0.6033\tLoss: 1.6978\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.719\tLabel_Loss: 0.5772\tTop_Loss: 0.6655\tBottom_Loss: 0.7174\tLoss: 1.9601\t\n",
      "Subject: s15, n=04 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.719\tLabel_Loss: 0.7362\tTop_Loss: 0.7911\tBottom_Loss: 0.7679\tLoss: 2.2952\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.625\tLabel_Loss: 0.6598\tTop_Loss: 0.6909\tBottom_Loss: 0.8045\tLoss: 2.1552\t\n",
      "Subject: s15, n=04 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5663\tTop_Loss: 0.6022\tBottom_Loss: 0.7954\tLoss: 1.9639\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.688\tLabel_Loss: 0.8171\tTop_Loss: 0.7020\tBottom_Loss: 0.7296\tLoss: 2.2486\t\n",
      "Subject: s15, n=04 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6193\tTop_Loss: 0.7949\tBottom_Loss: 0.6302\tLoss: 2.0444\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.562\tLabel_Loss: 0.7734\tTop_Loss: 0.9391\tBottom_Loss: 0.9024\tLoss: 2.6149\t\n",
      "Subject: s15, n=04 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5458\tTop_Loss: 0.5365\tBottom_Loss: 0.7926\tLoss: 1.8749\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5715\tTop_Loss: 0.6598\tBottom_Loss: 0.6680\tLoss: 1.8993\t\n",
      "Subject: s15, n=04 | test_f1: 0.38889 |best_f1: 1.0\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7131\tTop_Loss: 0.7704\tBottom_Loss: 0.7053\tLoss: 2.1888\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4130\tTop_Loss: 0.6196\tBottom_Loss: 0.5301\tLoss: 1.5628\t\n",
      "Subject: s15, n=04 | test_f1: 0.38889 |best_f1: 1.0\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.812\tLabel_Loss: 0.6463\tTop_Loss: 0.6866\tBottom_Loss: 0.6781\tLoss: 2.0109\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4345\tTop_Loss: 0.7395\tBottom_Loss: 0.6440\tLoss: 1.8179\t\n",
      "Subject: s15, n=04 | test_f1: 0.13333 |best_f1: 1.0\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.656\tLabel_Loss: 0.5789\tTop_Loss: 0.5875\tBottom_Loss: 0.8236\tLoss: 1.9900\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.656\tLabel_Loss: 0.6554\tTop_Loss: 0.6060\tBottom_Loss: 0.5143\tLoss: 1.7757\t\n",
      "Subject: s15, n=04 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6863\tTop_Loss: 0.6718\tBottom_Loss: 0.7524\tLoss: 2.1106\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4736\tTop_Loss: 0.5883\tBottom_Loss: 0.6028\tLoss: 1.6647\t\n",
      "Subject: s15, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.750\tLabel_Loss: 0.4757\tTop_Loss: 0.5501\tBottom_Loss: 0.5762\tLoss: 1.6020\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4554\tTop_Loss: 0.5283\tBottom_Loss: 0.5261\tLoss: 1.5097\t\n",
      "Subject: s15, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3991\tTop_Loss: 0.4437\tBottom_Loss: 0.5733\tLoss: 1.4161\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3636\tTop_Loss: 0.3611\tBottom_Loss: 0.5517\tLoss: 1.2764\t\n",
      "Subject: s15, n=04 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4571\tTop_Loss: 0.5577\tBottom_Loss: 0.5390\tLoss: 1.5538\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4464\tTop_Loss: 0.5991\tBottom_Loss: 0.7033\tLoss: 1.7488\t\n",
      "Subject: s15, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.656\tLabel_Loss: 0.6384\tTop_Loss: 0.6456\tBottom_Loss: 0.7123\tLoss: 1.9963\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3435\tTop_Loss: 0.6142\tBottom_Loss: 0.5634\tLoss: 1.5211\t\n",
      "Subject: s15, n=04 | test_f1: 0.38889 |best_f1: 1.0\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4434\tTop_Loss: 0.5901\tBottom_Loss: 0.5398\tLoss: 1.5733\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4140\tTop_Loss: 0.4997\tBottom_Loss: 0.5228\tLoss: 1.4366\t\n",
      "Subject: s15, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3020\tTop_Loss: 0.5333\tBottom_Loss: 0.3946\tLoss: 1.2298\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.750\tLabel_Loss: 0.4764\tTop_Loss: 0.5090\tBottom_Loss: 0.5806\tLoss: 1.5660\t\n",
      "Subject: s15, n=04 | test_f1: 0.38889 |best_f1: 1.0\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2807\tTop_Loss: 0.5153\tBottom_Loss: 0.4457\tLoss: 1.2417\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3743\tTop_Loss: 0.6047\tBottom_Loss: 0.5767\tLoss: 1.5557\t\n",
      "Subject: s15, n=04 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2766\tTop_Loss: 0.4782\tBottom_Loss: 0.5081\tLoss: 1.2629\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.906\tLabel_Loss: 0.4427\tTop_Loss: 0.6597\tBottom_Loss: 0.4869\tLoss: 1.5894\t\n",
      "Subject: s15, n=04 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2889\tTop_Loss: 0.3814\tBottom_Loss: 0.4064\tLoss: 1.0767\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.750\tLabel_Loss: 0.3899\tTop_Loss: 0.5479\tBottom_Loss: 0.4623\tLoss: 1.4001\t\n",
      "Subject: s15, n=04 | test_f1: 0.38889 |best_f1: 1.0\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3329\tTop_Loss: 0.5158\tBottom_Loss: 0.4575\tLoss: 1.3062\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2496\tTop_Loss: 0.4420\tBottom_Loss: 0.3831\tLoss: 1.0747\t\n",
      "Subject: s15, n=04 | test_f1: 0.77778 |best_f1: 1.0\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4069\tTop_Loss: 0.4639\tBottom_Loss: 0.4376\tLoss: 1.3085\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3707\tTop_Loss: 0.4832\tBottom_Loss: 0.5726\tLoss: 1.4264\t\n",
      "Subject: s15, n=04 | test_f1: 0.6 |best_f1: 1.0\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2620\tTop_Loss: 0.4107\tBottom_Loss: 0.2940\tLoss: 0.9666\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3803\tTop_Loss: 0.4614\tBottom_Loss: 0.3940\tLoss: 1.2357\t\n",
      "Subject: s15, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3417\tTop_Loss: 0.4708\tBottom_Loss: 0.4042\tLoss: 1.2167\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2134\tTop_Loss: 0.3263\tBottom_Loss: 0.2273\tLoss: 0.7670\t\n",
      "Subject: s15, n=04 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2165\tTop_Loss: 0.3495\tBottom_Loss: 0.2741\tLoss: 0.8401\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3748\tTop_Loss: 0.3551\tBottom_Loss: 0.5104\tLoss: 1.2403\t\n",
      "Subject: s15, n=04 | test_f1: 0.6 |best_f1: 1.0\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3091\tTop_Loss: 0.5975\tBottom_Loss: 0.4702\tLoss: 1.3768\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2438\tTop_Loss: 0.4104\tBottom_Loss: 0.3649\tLoss: 1.0191\t\n",
      "Subject: s15, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2012\tTop_Loss: 0.3070\tBottom_Loss: 0.3177\tLoss: 0.8259\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2548\tTop_Loss: 0.4963\tBottom_Loss: 0.3628\tLoss: 1.1139\t\n",
      "Subject: s15, n=04 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3014\tTop_Loss: 0.3747\tBottom_Loss: 0.3960\tLoss: 1.0721\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1655\tTop_Loss: 0.3136\tBottom_Loss: 0.2440\tLoss: 0.7231\t\n",
      "Subject: s15, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2033\tTop_Loss: 0.3207\tBottom_Loss: 0.2595\tLoss: 0.7836\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1476\tTop_Loss: 0.3256\tBottom_Loss: 0.2438\tLoss: 0.7169\t\n",
      "Subject: s15, n=04 | test_f1: 0.38889 |best_f1: 1.0\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1678\tTop_Loss: 0.2212\tBottom_Loss: 0.3516\tLoss: 0.7406\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1839\tTop_Loss: 0.4465\tBottom_Loss: 0.3699\tLoss: 1.0002\t\n",
      "Subject: s15, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2574\tTop_Loss: 0.4475\tBottom_Loss: 0.3136\tLoss: 1.0185\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1157\tTop_Loss: 0.2097\tBottom_Loss: 0.2824\tLoss: 0.6078\t\n",
      "Subject: s15, n=04 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1753\tTop_Loss: 0.3613\tBottom_Loss: 0.3139\tLoss: 0.8505\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1874\tTop_Loss: 0.2791\tBottom_Loss: 0.3405\tLoss: 0.8070\t\n",
      "Subject: s15, n=04 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1599\tTop_Loss: 0.2624\tBottom_Loss: 0.2262\tLoss: 0.6485\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2204\tTop_Loss: 0.3655\tBottom_Loss: 0.3923\tLoss: 0.9782\t\n",
      "Subject: s15, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2091\tTop_Loss: 0.2824\tBottom_Loss: 0.3519\tLoss: 0.8434\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1054\tTop_Loss: 0.3109\tBottom_Loss: 0.1771\tLoss: 0.5933\t\n",
      "Subject: s15, n=04 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1255\tTop_Loss: 0.2360\tBottom_Loss: 0.1777\tLoss: 0.5392\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1863\tTop_Loss: 0.2502\tBottom_Loss: 0.3706\tLoss: 0.8071\t\n",
      "Subject: s15, n=04 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2427\tTop_Loss: 0.2660\tBottom_Loss: 0.3291\tLoss: 0.8377\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2064\tTop_Loss: 0.2928\tBottom_Loss: 0.4466\tLoss: 0.9458\t\n",
      "Subject: s15, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1809\tTop_Loss: 0.2614\tBottom_Loss: 0.1930\tLoss: 0.6354\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2149\tTop_Loss: 0.2893\tBottom_Loss: 0.4475\tLoss: 0.9518\t\n",
      "Subject: s15, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2522\tTop_Loss: 0.2478\tBottom_Loss: 0.3372\tLoss: 0.8373\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0798\tTop_Loss: 0.1417\tBottom_Loss: 0.2201\tLoss: 0.4417\t\n",
      "Subject: s15, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1083\tTop_Loss: 0.2201\tBottom_Loss: 0.1780\tLoss: 0.5064\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1494\tTop_Loss: 0.2929\tBottom_Loss: 0.3411\tLoss: 0.7834\t\n",
      "Subject: s15, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1114\tTop_Loss: 0.3119\tBottom_Loss: 0.1473\tLoss: 0.5706\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0739\tTop_Loss: 0.2816\tBottom_Loss: 0.1135\tLoss: 0.4690\t\n",
      "Subject: s15, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0684\tTop_Loss: 0.2645\tBottom_Loss: 0.1175\tLoss: 0.4505\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1278\tTop_Loss: 0.3655\tBottom_Loss: 0.2111\tLoss: 0.7044\t\n",
      "Subject: s15, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1211\tTop_Loss: 0.2294\tBottom_Loss: 0.1989\tLoss: 0.5493\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2442\tTop_Loss: 0.4355\tBottom_Loss: 0.3625\tLoss: 1.0422\t\n",
      "Subject: s15, n=04 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0971\tTop_Loss: 0.1968\tBottom_Loss: 0.2161\tLoss: 0.5099\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0839\tTop_Loss: 0.2382\tBottom_Loss: 0.1297\tLoss: 0.4518\t\n",
      "Subject: s15, n=04 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1314\tTop_Loss: 0.2300\tBottom_Loss: 0.1596\tLoss: 0.5210\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1050\tTop_Loss: 0.1874\tBottom_Loss: 0.1683\tLoss: 0.4606\t\n",
      "Subject: s15, n=04 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1635\tTop_Loss: 0.2876\tBottom_Loss: 0.1612\tLoss: 0.6123\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0723\tTop_Loss: 0.1658\tBottom_Loss: 0.1107\tLoss: 0.3488\t\n",
      "Subject: s15, n=04 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1286\tTop_Loss: 0.3069\tBottom_Loss: 0.2377\tLoss: 0.6732\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0652\tTop_Loss: 0.1251\tBottom_Loss: 0.0996\tLoss: 0.2899\t\n",
      "Subject: s15, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1426\tTop_Loss: 0.2454\tBottom_Loss: 0.2581\tLoss: 0.6460\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0748\tTop_Loss: 0.1668\tBottom_Loss: 0.1353\tLoss: 0.3768\t\n",
      "Subject: s15, n=04 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0497\tTop_Loss: 0.1008\tBottom_Loss: 0.0881\tLoss: 0.2387\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0770\tTop_Loss: 0.2069\tBottom_Loss: 0.1117\tLoss: 0.3956\t\n",
      "Subject: s15, n=04 | test_f1: 0.6 |best_f1: 1.0\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1122\tTop_Loss: 0.1858\tBottom_Loss: 0.1576\tLoss: 0.4556\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0420\tTop_Loss: 0.1296\tBottom_Loss: 0.1485\tLoss: 0.3200\t\n",
      "Subject: s15, n=04 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2230\tTop_Loss: 0.2460\tBottom_Loss: 0.3120\tLoss: 0.7809\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1077\tTop_Loss: 0.3882\tBottom_Loss: 0.1079\tLoss: 0.6037\t\n",
      "Subject: s15, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0683\tTop_Loss: 0.1851\tBottom_Loss: 0.1134\tLoss: 0.3667\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0366\tTop_Loss: 0.1527\tBottom_Loss: 0.1167\tLoss: 0.3060\t\n",
      "Subject: s15, n=04 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0313\tTop_Loss: 0.0906\tBottom_Loss: 0.0964\tLoss: 0.2184\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0684\tTop_Loss: 0.1448\tBottom_Loss: 0.0935\tLoss: 0.3068\t\n",
      "Subject: s15, n=04 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1170\tTop_Loss: 0.1484\tBottom_Loss: 0.1269\tLoss: 0.3923\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0963\tTop_Loss: 0.2093\tBottom_Loss: 0.1947\tLoss: 0.5002\t\n",
      "Subject: s15, n=04 | test_f1: 0.5 |best_f1: 1.0\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0561\tTop_Loss: 0.1816\tBottom_Loss: 0.1264\tLoss: 0.3642\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0566\tTop_Loss: 0.1361\tBottom_Loss: 0.1354\tLoss: 0.3281\t\n",
      "Subject: s15, n=04 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0786\tTop_Loss: 0.2078\tBottom_Loss: 0.1007\tLoss: 0.3872\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1260\tTop_Loss: 0.3140\tBottom_Loss: 0.1669\tLoss: 0.6069\t\n",
      "Subject: s15, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0211\tTop_Loss: 0.1507\tBottom_Loss: 0.0467\tLoss: 0.2185\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1111\tTop_Loss: 0.1485\tBottom_Loss: 0.1810\tLoss: 0.4406\t\n",
      "Subject: s15, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0742\tTop_Loss: 0.1216\tBottom_Loss: 0.0888\tLoss: 0.2846\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0357\tTop_Loss: 0.1157\tBottom_Loss: 0.0633\tLoss: 0.2147\t\n",
      "Subject: s15, n=04 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0657\tTop_Loss: 0.1162\tBottom_Loss: 0.1372\tLoss: 0.3191\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0425\tTop_Loss: 0.1020\tBottom_Loss: 0.1120\tLoss: 0.2566\t\n",
      "Subject: s15, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0502\tTop_Loss: 0.1477\tBottom_Loss: 0.1135\tLoss: 0.3114\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0689\tTop_Loss: 0.1903\tBottom_Loss: 0.0583\tLoss: 0.3175\t\n",
      "Subject: s15, n=04 | test_f1: 0.6 |best_f1: 1.0\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1208\tTop_Loss: 0.2306\tBottom_Loss: 0.1566\tLoss: 0.5079\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0174\tTop_Loss: 0.0910\tBottom_Loss: 0.0445\tLoss: 0.1529\t\n",
      "Subject: s15, n=04 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0286\tTop_Loss: 0.0819\tBottom_Loss: 0.0998\tLoss: 0.2103\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0260\tTop_Loss: 0.0610\tBottom_Loss: 0.0510\tLoss: 0.1380\t\n",
      "Subject: s15, n=04 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0480\tTop_Loss: 0.1490\tBottom_Loss: 0.1533\tLoss: 0.3503\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0277\tTop_Loss: 0.0491\tBottom_Loss: 0.0597\tLoss: 0.1365\t\n",
      "Subject: s15, n=04 | test_f1: 0.5 |best_f1: 1.0\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0394\tTop_Loss: 0.0826\tBottom_Loss: 0.1260\tLoss: 0.2480\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0595\tTop_Loss: 0.2092\tBottom_Loss: 0.1657\tLoss: 0.4344\t\n",
      "Subject: s15, n=04 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0335\tTop_Loss: 0.1896\tBottom_Loss: 0.0606\tLoss: 0.2838\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0161\tTop_Loss: 0.0427\tBottom_Loss: 0.0341\tLoss: 0.0929\t\n",
      "Subject: s15, n=04 | test_f1: 0.38889 |best_f1: 1.0\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0594\tTop_Loss: 0.0893\tBottom_Loss: 0.1465\tLoss: 0.2952\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1112\tTop_Loss: 0.1696\tBottom_Loss: 0.1420\tLoss: 0.4228\t\n",
      "Subject: s15, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0292\tTop_Loss: 0.1431\tBottom_Loss: 0.0687\tLoss: 0.2410\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0257\tTop_Loss: 0.0733\tBottom_Loss: 0.0528\tLoss: 0.1518\t\n",
      "Subject: s15, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0090\tTop_Loss: 0.0374\tBottom_Loss: 0.0495\tLoss: 0.0959\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0329\tTop_Loss: 0.0662\tBottom_Loss: 0.1014\tLoss: 0.2005\t\n",
      "Subject: s15, n=04 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0807\tTop_Loss: 0.1348\tBottom_Loss: 0.0988\tLoss: 0.3143\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0164\tTop_Loss: 0.0931\tBottom_Loss: 0.0405\tLoss: 0.1500\t\n",
      "Subject: s15, n=04 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0166\tTop_Loss: 0.1095\tBottom_Loss: 0.0672\tLoss: 0.1933\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0457\tTop_Loss: 0.0809\tBottom_Loss: 0.1180\tLoss: 0.2446\t\n",
      "Subject: s15, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0120\tTop_Loss: 0.0526\tBottom_Loss: 0.0380\tLoss: 0.1026\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0170\tTop_Loss: 0.0393\tBottom_Loss: 0.0766\tLoss: 0.1329\t\n",
      "Subject: s15, n=04 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0574\tTop_Loss: 0.0474\tBottom_Loss: 0.0824\tLoss: 0.1871\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0171\tTop_Loss: 0.0393\tBottom_Loss: 0.0484\tLoss: 0.1048\t\n",
      "Subject: s15, n=04 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0102\tTop_Loss: 0.0346\tBottom_Loss: 0.0574\tLoss: 0.1021\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0208\tTop_Loss: 0.0907\tBottom_Loss: 0.0388\tLoss: 0.1503\t\n",
      "Subject: s15, n=04 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0133\tTop_Loss: 0.1181\tBottom_Loss: 0.0263\tLoss: 0.1577\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0206\tTop_Loss: 0.0907\tBottom_Loss: 0.0789\tLoss: 0.1902\t\n",
      "Subject: s15, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0093\tTop_Loss: 0.0282\tBottom_Loss: 0.0330\tLoss: 0.0706\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0349\tTop_Loss: 0.0617\tBottom_Loss: 0.0510\tLoss: 0.1476\t\n",
      "Subject: s15, n=04 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0192\tTop_Loss: 0.0454\tBottom_Loss: 0.0529\tLoss: 0.1174\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0152\tTop_Loss: 0.0585\tBottom_Loss: 0.0562\tLoss: 0.1299\t\n",
      "Subject: s15, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0115\tTop_Loss: 0.0317\tBottom_Loss: 0.0274\tLoss: 0.0707\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0056\tTop_Loss: 0.0178\tBottom_Loss: 0.0274\tLoss: 0.0507\t\n",
      "Subject: s15, n=04 | test_f1: 0.6 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0394\tTop_Loss: 0.1075\tBottom_Loss: 0.0703\tLoss: 0.2172\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0095\tTop_Loss: 0.0329\tBottom_Loss: 0.0173\tLoss: 0.0597\t\n",
      "Subject: s15, n=04 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0073\tTop_Loss: 0.0620\tBottom_Loss: 0.0209\tLoss: 0.0903\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0094\tTop_Loss: 0.0254\tBottom_Loss: 0.0553\tLoss: 0.0900\t\n",
      "Subject: s15, n=04 | test_f1: 0.38889 |best_f1: 1.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0066\tTop_Loss: 0.0283\tBottom_Loss: 0.0181\tLoss: 0.0530\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0440\tTop_Loss: 0.1181\tBottom_Loss: 0.0866\tLoss: 0.2487\t\n",
      "Subject: s15, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0135\tTop_Loss: 0.0458\tBottom_Loss: 0.0177\tLoss: 0.0770\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0314\tTop_Loss: 0.0852\tBottom_Loss: 0.0967\tLoss: 0.2132\t\n",
      "Subject: s15, n=04 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0863\tTop_Loss: 0.1501\tBottom_Loss: 0.0693\tLoss: 0.3057\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0408\tTop_Loss: 0.0395\tBottom_Loss: 0.0756\tLoss: 0.1559\t\n",
      "Subject: s15, n=04 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0184\tTop_Loss: 0.0826\tBottom_Loss: 0.0567\tLoss: 0.1578\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0287\tTop_Loss: 0.0744\tBottom_Loss: 0.0472\tLoss: 0.1503\t\n",
      "Subject: s15, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0171\tTop_Loss: 0.0740\tBottom_Loss: 0.0344\tLoss: 0.1255\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0082\tTop_Loss: 0.0426\tBottom_Loss: 0.0248\tLoss: 0.0757\t\n",
      "Subject: s15, n=04 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0079\tTop_Loss: 0.0226\tBottom_Loss: 0.0135\tLoss: 0.0440\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0265\tTop_Loss: 0.1227\tBottom_Loss: 0.0171\tLoss: 0.1663\t\n",
      "Subject: s15, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0244\tTop_Loss: 0.0469\tBottom_Loss: 0.0483\tLoss: 0.1196\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0406\tTop_Loss: 0.0362\tBottom_Loss: 0.0439\tLoss: 0.1207\t\n",
      "Subject: s15, n=04 | test_f1: 0.6 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0461\tTop_Loss: 0.1236\tBottom_Loss: 0.0442\tLoss: 0.2139\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0061\tTop_Loss: 0.0234\tBottom_Loss: 0.0229\tLoss: 0.0524\t\n",
      "Subject: s15, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0188\tTop_Loss: 0.0425\tBottom_Loss: 0.0507\tLoss: 0.1120\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0304\tTop_Loss: 0.1374\tBottom_Loss: 0.0231\tLoss: 0.1910\t\n",
      "Subject: s15, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0162\tTop_Loss: 0.0455\tBottom_Loss: 0.0352\tLoss: 0.0969\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0108\tTop_Loss: 0.0874\tBottom_Loss: 0.0357\tLoss: 0.1339\t\n",
      "Subject: s15, n=04 | test_f1: 0.38889 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0603\tTop_Loss: 0.0635\tBottom_Loss: 0.0724\tLoss: 0.1962\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0094\tTop_Loss: 0.0405\tBottom_Loss: 0.0289\tLoss: 0.0788\t\n",
      "Subject: s15, n=04 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0047\tTop_Loss: 0.0279\tBottom_Loss: 0.0140\tLoss: 0.0467\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0130\tTop_Loss: 0.1067\tBottom_Loss: 0.0282\tLoss: 0.1479\t\n",
      "Subject: s15, n=04 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0110\tTop_Loss: 0.0857\tBottom_Loss: 0.0134\tLoss: 0.1101\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0128\tTop_Loss: 0.0203\tBottom_Loss: 0.0412\tLoss: 0.0744\t\n",
      "Subject: s15, n=04 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.281\tLabel_Loss: 1.3991\tTop_Loss: 1.4748\tBottom_Loss: 1.3113\tLoss: 4.1853\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.312\tLabel_Loss: 1.2859\tTop_Loss: 1.1389\tBottom_Loss: 1.1595\tLoss: 3.5843\t\n",
      "Subject: s18, n=07 | test_f1: 0.22222 |best_f1: 0.22222\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.562\tLabel_Loss: 1.2440\tTop_Loss: 1.0675\tBottom_Loss: 1.0562\tLoss: 3.3677\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.500\tLabel_Loss: 1.0980\tTop_Loss: 1.0346\tBottom_Loss: 1.2231\tLoss: 3.3557\t\n",
      "Subject: s18, n=07 | test_f1: 0.16667 |best_f1: 0.22222\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.562\tLabel_Loss: 0.9246\tTop_Loss: 0.8798\tBottom_Loss: 0.9565\tLoss: 2.7608\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.500\tLabel_Loss: 1.0524\tTop_Loss: 0.8347\tBottom_Loss: 0.8751\tLoss: 2.7622\t\n",
      "Subject: s18, n=07 | test_f1: 0.22222 |best_f1: 0.22222\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8801\tTop_Loss: 0.9549\tBottom_Loss: 0.7885\tLoss: 2.6235\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.531\tLabel_Loss: 0.9979\tTop_Loss: 1.1231\tBottom_Loss: 0.9335\tLoss: 3.0545\t\n",
      "Subject: s18, n=07 | test_f1: 0.16667 |best_f1: 0.22222\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8852\tTop_Loss: 0.7743\tBottom_Loss: 0.9426\tLoss: 2.6021\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.562\tLabel_Loss: 0.8778\tTop_Loss: 0.9181\tBottom_Loss: 0.9242\tLoss: 2.7201\t\n",
      "Subject: s18, n=07 | test_f1: 0.22222 |best_f1: 0.22222\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.344\tLabel_Loss: 1.0264\tTop_Loss: 0.9109\tBottom_Loss: 1.0268\tLoss: 2.9641\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8358\tTop_Loss: 0.9569\tBottom_Loss: 0.9919\tLoss: 2.7846\t\n",
      "Subject: s18, n=07 | test_f1: 0.22222 |best_f1: 0.22222\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8209\tTop_Loss: 0.7329\tBottom_Loss: 0.9499\tLoss: 2.5037\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8459\tTop_Loss: 0.8343\tBottom_Loss: 0.8641\tLoss: 2.5443\t\n",
      "Subject: s18, n=07 | test_f1: 0.22222 |best_f1: 0.22222\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.562\tLabel_Loss: 1.0481\tTop_Loss: 0.9325\tBottom_Loss: 0.9054\tLoss: 2.8860\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.656\tLabel_Loss: 0.8666\tTop_Loss: 0.9456\tBottom_Loss: 0.8926\tLoss: 2.7047\t\n",
      "Subject: s18, n=07 | test_f1: 0.3 |best_f1: 0.3\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8478\tTop_Loss: 0.8912\tBottom_Loss: 0.9872\tLoss: 2.7262\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8663\tTop_Loss: 0.9510\tBottom_Loss: 0.9840\tLoss: 2.8013\t\n",
      "Subject: s18, n=07 | test_f1: 0.70833 |best_f1: 0.70833\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6932\tTop_Loss: 0.8590\tBottom_Loss: 0.6403\tLoss: 2.1925\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.531\tLabel_Loss: 0.9738\tTop_Loss: 0.7999\tBottom_Loss: 0.9768\tLoss: 2.7505\t\n",
      "Subject: s18, n=07 | test_f1: 0.84444 |best_f1: 0.84444\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.469\tLabel_Loss: 0.9643\tTop_Loss: 0.8429\tBottom_Loss: 1.0825\tLoss: 2.8897\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8343\tTop_Loss: 0.8170\tBottom_Loss: 0.8743\tLoss: 2.5256\t\n",
      "Subject: s18, n=07 | test_f1: 0.41667 |best_f1: 0.84444\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7665\tTop_Loss: 0.7458\tBottom_Loss: 0.9636\tLoss: 2.4759\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7192\tTop_Loss: 0.8610\tBottom_Loss: 0.9176\tLoss: 2.4977\t\n",
      "Subject: s18, n=07 | test_f1: 0.51667 |best_f1: 0.84444\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5592\tTop_Loss: 0.7988\tBottom_Loss: 0.7412\tLoss: 2.0992\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.719\tLabel_Loss: 0.7664\tTop_Loss: 0.8794\tBottom_Loss: 0.8063\tLoss: 2.4521\t\n",
      "Subject: s18, n=07 | test_f1: 0.32381 |best_f1: 0.84444\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8427\tTop_Loss: 0.8362\tBottom_Loss: 0.9919\tLoss: 2.6708\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6199\tTop_Loss: 0.8071\tBottom_Loss: 0.7230\tLoss: 2.1500\t\n",
      "Subject: s18, n=07 | test_f1: 0.30159 |best_f1: 0.84444\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5304\tTop_Loss: 0.6122\tBottom_Loss: 0.6760\tLoss: 1.8186\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7396\tTop_Loss: 0.8434\tBottom_Loss: 0.7451\tLoss: 2.3281\t\n",
      "Subject: s18, n=07 | test_f1: 0.45714 |best_f1: 0.84444\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.656\tLabel_Loss: 0.5259\tTop_Loss: 0.5289\tBottom_Loss: 0.7936\tLoss: 1.8484\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.719\tLabel_Loss: 0.5103\tTop_Loss: 0.5758\tBottom_Loss: 0.7199\tLoss: 1.8061\t\n",
      "Subject: s18, n=07 | test_f1: 0.41667 |best_f1: 0.84444\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.719\tLabel_Loss: 0.7648\tTop_Loss: 0.8634\tBottom_Loss: 0.7748\tLoss: 2.4030\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7774\tTop_Loss: 0.7665\tBottom_Loss: 0.7400\tLoss: 2.2840\t\n",
      "Subject: s18, n=07 | test_f1: 0.51667 |best_f1: 0.84444\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6226\tTop_Loss: 0.7685\tBottom_Loss: 0.6749\tLoss: 2.0660\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5022\tTop_Loss: 0.6667\tBottom_Loss: 0.6525\tLoss: 1.8214\t\n",
      "Subject: s18, n=07 | test_f1: 0.41667 |best_f1: 0.84444\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4411\tTop_Loss: 0.5651\tBottom_Loss: 0.6649\tLoss: 1.6710\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5021\tTop_Loss: 0.5419\tBottom_Loss: 0.8482\tLoss: 1.8922\t\n",
      "Subject: s18, n=07 | test_f1: 0.41667 |best_f1: 0.84444\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5132\tTop_Loss: 0.5733\tBottom_Loss: 0.6768\tLoss: 1.7632\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4367\tTop_Loss: 0.8516\tBottom_Loss: 0.4462\tLoss: 1.7345\t\n",
      "Subject: s18, n=07 | test_f1: 0.30159 |best_f1: 0.84444\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4303\tTop_Loss: 0.5714\tBottom_Loss: 0.5880\tLoss: 1.5897\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3649\tTop_Loss: 0.4924\tBottom_Loss: 0.4628\tLoss: 1.3201\t\n",
      "Subject: s18, n=07 | test_f1: 0.51852 |best_f1: 0.84444\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6105\tTop_Loss: 0.7798\tBottom_Loss: 0.7896\tLoss: 2.1800\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4201\tTop_Loss: 0.6147\tBottom_Loss: 0.5436\tLoss: 1.5785\t\n",
      "Subject: s18, n=07 | test_f1: 0.30159 |best_f1: 0.84444\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4527\tTop_Loss: 0.5554\tBottom_Loss: 0.6134\tLoss: 1.6215\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4697\tTop_Loss: 0.5810\tBottom_Loss: 0.5154\tLoss: 1.5661\t\n",
      "Subject: s18, n=07 | test_f1: 0.70833 |best_f1: 0.84444\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3481\tTop_Loss: 0.5442\tBottom_Loss: 0.6124\tLoss: 1.5047\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.562\tLabel_Loss: 0.7889\tTop_Loss: 0.8748\tBottom_Loss: 0.9566\tLoss: 2.6202\t\n",
      "Subject: s18, n=07 | test_f1: 0.46296 |best_f1: 0.84444\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4095\tTop_Loss: 0.4747\tBottom_Loss: 0.5457\tLoss: 1.4299\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4047\tTop_Loss: 0.6236\tBottom_Loss: 0.4321\tLoss: 1.4603\t\n",
      "Subject: s18, n=07 | test_f1: 0.58333 |best_f1: 0.84444\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3997\tTop_Loss: 0.5072\tBottom_Loss: 0.6895\tLoss: 1.5964\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2304\tTop_Loss: 0.3213\tBottom_Loss: 0.4267\tLoss: 0.9784\t\n",
      "Subject: s18, n=07 | test_f1: 0.51852 |best_f1: 0.84444\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4157\tTop_Loss: 0.4443\tBottom_Loss: 0.5810\tLoss: 1.4409\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5552\tTop_Loss: 0.6719\tBottom_Loss: 0.7151\tLoss: 1.9422\t\n",
      "Subject: s18, n=07 | test_f1: 0.51667 |best_f1: 0.84444\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2420\tTop_Loss: 0.4195\tBottom_Loss: 0.4115\tLoss: 1.0730\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4364\tTop_Loss: 0.6623\tBottom_Loss: 0.5704\tLoss: 1.6690\t\n",
      "Subject: s18, n=07 | test_f1: 0.70833 |best_f1: 0.84444\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3408\tTop_Loss: 0.6041\tBottom_Loss: 0.6175\tLoss: 1.5624\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3503\tTop_Loss: 0.4510\tBottom_Loss: 0.4557\tLoss: 1.2570\t\n",
      "Subject: s18, n=07 | test_f1: 0.46296 |best_f1: 0.84444\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3690\tTop_Loss: 0.6317\tBottom_Loss: 0.3921\tLoss: 1.3928\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2705\tTop_Loss: 0.3922\tBottom_Loss: 0.4564\tLoss: 1.1192\t\n",
      "Subject: s18, n=07 | test_f1: 0.35714 |best_f1: 0.84444\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2622\tTop_Loss: 0.2827\tBottom_Loss: 0.3993\tLoss: 0.9442\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2320\tTop_Loss: 0.3510\tBottom_Loss: 0.4409\tLoss: 1.0238\t\n",
      "Subject: s18, n=07 | test_f1: 0.20635 |best_f1: 0.84444\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2791\tTop_Loss: 0.3826\tBottom_Loss: 0.4573\tLoss: 1.1189\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4037\tTop_Loss: 0.4409\tBottom_Loss: 0.3990\tLoss: 1.2435\t\n",
      "Subject: s18, n=07 | test_f1: 0.32381 |best_f1: 0.84444\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2990\tTop_Loss: 0.4452\tBottom_Loss: 0.4112\tLoss: 1.1554\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2579\tTop_Loss: 0.4092\tBottom_Loss: 0.3803\tLoss: 1.0474\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: s18, n=07 | test_f1: 0.3 |best_f1: 0.84444\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3228\tTop_Loss: 0.4199\tBottom_Loss: 0.4284\tLoss: 1.1710\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3621\tTop_Loss: 0.4628\tBottom_Loss: 0.5202\tLoss: 1.3451\t\n",
      "Subject: s18, n=07 | test_f1: 0.57143 |best_f1: 0.84444\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2206\tTop_Loss: 0.4320\tBottom_Loss: 0.3382\tLoss: 0.9908\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2778\tTop_Loss: 0.5257\tBottom_Loss: 0.4725\tLoss: 1.2760\t\n",
      "Subject: s18, n=07 | test_f1: 0.41667 |best_f1: 0.84444\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3613\tTop_Loss: 0.4875\tBottom_Loss: 0.5352\tLoss: 1.3840\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2541\tTop_Loss: 0.3525\tBottom_Loss: 0.4190\tLoss: 1.0255\t\n",
      "Subject: s18, n=07 | test_f1: 0.33333 |best_f1: 0.84444\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1672\tTop_Loss: 0.2333\tBottom_Loss: 0.3914\tLoss: 0.7919\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.844\tLabel_Loss: 0.2559\tTop_Loss: 0.4850\tBottom_Loss: 0.3836\tLoss: 1.1245\t\n",
      "Subject: s18, n=07 | test_f1: 0.3 |best_f1: 0.84444\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2036\tTop_Loss: 0.3063\tBottom_Loss: 0.4144\tLoss: 0.9243\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4408\tTop_Loss: 0.4962\tBottom_Loss: 0.4766\tLoss: 1.4137\t\n",
      "Subject: s18, n=07 | test_f1: 0.32381 |best_f1: 0.84444\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2070\tTop_Loss: 0.3720\tBottom_Loss: 0.3691\tLoss: 0.9480\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1364\tTop_Loss: 0.2677\tBottom_Loss: 0.3147\tLoss: 0.7188\t\n",
      "Subject: s18, n=07 | test_f1: 0.57143 |best_f1: 0.84444\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2068\tTop_Loss: 0.4242\tBottom_Loss: 0.3644\tLoss: 0.9954\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1396\tTop_Loss: 0.2543\tBottom_Loss: 0.2517\tLoss: 0.6456\t\n",
      "Subject: s18, n=07 | test_f1: 0.51667 |best_f1: 0.84444\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3006\tTop_Loss: 0.3457\tBottom_Loss: 0.3895\tLoss: 1.0359\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1733\tTop_Loss: 0.3759\tBottom_Loss: 0.2389\tLoss: 0.7881\t\n",
      "Subject: s18, n=07 | test_f1: 0.45714 |best_f1: 0.84444\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1329\tTop_Loss: 0.3765\tBottom_Loss: 0.1992\tLoss: 0.7086\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1732\tTop_Loss: 0.3382\tBottom_Loss: 0.1617\tLoss: 0.6732\t\n",
      "Subject: s18, n=07 | test_f1: 0.57143 |best_f1: 0.84444\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1042\tTop_Loss: 0.2631\tBottom_Loss: 0.2625\tLoss: 0.6298\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1755\tTop_Loss: 0.3499\tBottom_Loss: 0.2815\tLoss: 0.8068\t\n",
      "Subject: s18, n=07 | test_f1: 0.62963 |best_f1: 0.84444\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3217\tTop_Loss: 0.5404\tBottom_Loss: 0.3281\tLoss: 1.1901\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1160\tTop_Loss: 0.1757\tBottom_Loss: 0.1829\tLoss: 0.4746\t\n",
      "Subject: s18, n=07 | test_f1: 0.3 |best_f1: 0.84444\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1888\tTop_Loss: 0.2746\tBottom_Loss: 0.3166\tLoss: 0.7801\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0997\tTop_Loss: 0.2183\tBottom_Loss: 0.2429\tLoss: 0.5609\t\n",
      "Subject: s18, n=07 | test_f1: 0.51667 |best_f1: 0.84444\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1139\tTop_Loss: 0.2299\tBottom_Loss: 0.2657\tLoss: 0.6096\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1548\tTop_Loss: 0.3139\tBottom_Loss: 0.3045\tLoss: 0.7733\t\n",
      "Subject: s18, n=07 | test_f1: 0.62963 |best_f1: 0.84444\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0737\tTop_Loss: 0.1933\tBottom_Loss: 0.1846\tLoss: 0.4515\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1874\tTop_Loss: 0.2731\tBottom_Loss: 0.2625\tLoss: 0.7230\t\n",
      "Subject: s18, n=07 | test_f1: 0.51667 |best_f1: 0.84444\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1779\tTop_Loss: 0.2953\tBottom_Loss: 0.2416\tLoss: 0.7148\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2233\tTop_Loss: 0.2506\tBottom_Loss: 0.3003\tLoss: 0.7741\t\n",
      "Subject: s18, n=07 | test_f1: 0.57143 |best_f1: 0.84444\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1963\tTop_Loss: 0.3429\tBottom_Loss: 0.2483\tLoss: 0.7875\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1481\tTop_Loss: 0.2878\tBottom_Loss: 0.2289\tLoss: 0.6647\t\n",
      "Subject: s18, n=07 | test_f1: 0.53333 |best_f1: 0.84444\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2071\tTop_Loss: 0.2877\tBottom_Loss: 0.3123\tLoss: 0.8072\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1841\tTop_Loss: 0.2470\tBottom_Loss: 0.2623\tLoss: 0.6934\t\n",
      "Subject: s18, n=07 | test_f1: 0.38889 |best_f1: 0.84444\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1381\tTop_Loss: 0.1354\tBottom_Loss: 0.2333\tLoss: 0.5068\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0915\tTop_Loss: 0.2872\tBottom_Loss: 0.2603\tLoss: 0.6391\t\n",
      "Subject: s18, n=07 | test_f1: 0.38333 |best_f1: 0.84444\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1550\tTop_Loss: 0.3197\tBottom_Loss: 0.2446\tLoss: 0.7193\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2228\tTop_Loss: 0.2384\tBottom_Loss: 0.3798\tLoss: 0.8409\t\n",
      "Subject: s18, n=07 | test_f1: 0.4127 |best_f1: 0.84444\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1108\tTop_Loss: 0.1152\tBottom_Loss: 0.2301\tLoss: 0.4560\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1123\tTop_Loss: 0.3186\tBottom_Loss: 0.2335\tLoss: 0.6643\t\n",
      "Subject: s18, n=07 | test_f1: 0.4127 |best_f1: 0.84444\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0889\tTop_Loss: 0.1876\tBottom_Loss: 0.1710\tLoss: 0.4476\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2499\tTop_Loss: 0.3382\tBottom_Loss: 0.2769\tLoss: 0.8650\t\n",
      "Subject: s18, n=07 | test_f1: 0.45714 |best_f1: 0.84444\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0793\tTop_Loss: 0.2697\tBottom_Loss: 0.0947\tLoss: 0.4438\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0986\tTop_Loss: 0.1661\tBottom_Loss: 0.1250\tLoss: 0.3898\t\n",
      "Subject: s18, n=07 | test_f1: 0.32381 |best_f1: 0.84444\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1357\tTop_Loss: 0.1464\tBottom_Loss: 0.2669\tLoss: 0.5490\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1140\tTop_Loss: 0.2023\tBottom_Loss: 0.1566\tLoss: 0.4729\t\n",
      "Subject: s18, n=07 | test_f1: 0.4127 |best_f1: 0.84444\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0846\tTop_Loss: 0.2264\tBottom_Loss: 0.1941\tLoss: 0.5051\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1116\tTop_Loss: 0.2179\tBottom_Loss: 0.3199\tLoss: 0.6494\t\n",
      "Subject: s18, n=07 | test_f1: 0.32381 |best_f1: 0.84444\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0700\tTop_Loss: 0.1621\tBottom_Loss: 0.1717\tLoss: 0.4038\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1890\tTop_Loss: 0.1963\tBottom_Loss: 0.2260\tLoss: 0.6113\t\n",
      "Subject: s18, n=07 | test_f1: 0.35714 |best_f1: 0.84444\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0539\tTop_Loss: 0.1334\tBottom_Loss: 0.1924\tLoss: 0.3797\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0375\tTop_Loss: 0.1730\tBottom_Loss: 0.1171\tLoss: 0.3276\t\n",
      "Subject: s18, n=07 | test_f1: 0.51852 |best_f1: 0.84444\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0857\tTop_Loss: 0.1276\tBottom_Loss: 0.1433\tLoss: 0.3566\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1112\tTop_Loss: 0.3156\tBottom_Loss: 0.1955\tLoss: 0.6223\t\n",
      "Subject: s18, n=07 | test_f1: 0.41667 |best_f1: 0.84444\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1067\tTop_Loss: 0.1527\tBottom_Loss: 0.1974\tLoss: 0.4568\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0233\tTop_Loss: 0.0920\tBottom_Loss: 0.0677\tLoss: 0.1830\t\n",
      "Subject: s18, n=07 | test_f1: 0.51667 |best_f1: 0.84444\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0278\tTop_Loss: 0.1169\tBottom_Loss: 0.1066\tLoss: 0.2513\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 0.938\tLabel_Loss: 0.0777\tTop_Loss: 0.1625\tBottom_Loss: 0.1505\tLoss: 0.3907\t\n",
      "Subject: s18, n=07 | test_f1: 0.62963 |best_f1: 0.84444\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0710\tTop_Loss: 0.1919\tBottom_Loss: 0.1324\tLoss: 0.3953\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0582\tTop_Loss: 0.1532\tBottom_Loss: 0.1161\tLoss: 0.3275\t\n",
      "Subject: s18, n=07 | test_f1: 0.33333 |best_f1: 0.84444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0317\tTop_Loss: 0.1382\tBottom_Loss: 0.1060\tLoss: 0.2759\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0516\tTop_Loss: 0.0865\tBottom_Loss: 0.1198\tLoss: 0.2579\t\n",
      "Subject: s18, n=07 | test_f1: 0.41667 |best_f1: 0.84444\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1532\tTop_Loss: 0.3260\tBottom_Loss: 0.1715\tLoss: 0.6508\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0537\tTop_Loss: 0.2297\tBottom_Loss: 0.0907\tLoss: 0.3740\t\n",
      "Subject: s18, n=07 | test_f1: 0.4127 |best_f1: 0.84444\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0479\tTop_Loss: 0.1186\tBottom_Loss: 0.1280\tLoss: 0.2945\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1425\tTop_Loss: 0.2737\tBottom_Loss: 0.2914\tLoss: 0.7076\t\n",
      "Subject: s18, n=07 | test_f1: 0.41667 |best_f1: 0.84444\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1013\tTop_Loss: 0.3235\tBottom_Loss: 0.1430\tLoss: 0.5679\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0629\tTop_Loss: 0.1547\tBottom_Loss: 0.1184\tLoss: 0.3361\t\n",
      "Subject: s18, n=07 | test_f1: 0.22857 |best_f1: 0.84444\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0403\tTop_Loss: 0.0864\tBottom_Loss: 0.0910\tLoss: 0.2177\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0374\tTop_Loss: 0.0921\tBottom_Loss: 0.0762\tLoss: 0.2057\t\n",
      "Subject: s18, n=07 | test_f1: 0.35714 |best_f1: 0.84444\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1483\tTop_Loss: 0.1099\tBottom_Loss: 0.1483\tLoss: 0.4064\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0721\tTop_Loss: 0.1863\tBottom_Loss: 0.1631\tLoss: 0.4215\t\n",
      "Subject: s18, n=07 | test_f1: 0.41667 |best_f1: 0.84444\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0320\tTop_Loss: 0.0858\tBottom_Loss: 0.0846\tLoss: 0.2025\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0201\tTop_Loss: 0.0878\tBottom_Loss: 0.0906\tLoss: 0.1985\t\n",
      "Subject: s18, n=07 | test_f1: 0.38889 |best_f1: 0.84444\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0237\tTop_Loss: 0.1019\tBottom_Loss: 0.0934\tLoss: 0.2190\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0731\tTop_Loss: 0.1483\tBottom_Loss: 0.1416\tLoss: 0.3631\t\n",
      "Subject: s18, n=07 | test_f1: 0.33333 |best_f1: 0.84444\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0567\tTop_Loss: 0.1331\tBottom_Loss: 0.0938\tLoss: 0.2836\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0545\tTop_Loss: 0.0795\tBottom_Loss: 0.0542\tLoss: 0.1883\t\n",
      "Subject: s18, n=07 | test_f1: 0.33333 |best_f1: 0.84444\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0220\tTop_Loss: 0.0634\tBottom_Loss: 0.0703\tLoss: 0.1557\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0852\tTop_Loss: 0.1223\tBottom_Loss: 0.1718\tLoss: 0.3794\t\n",
      "Subject: s18, n=07 | test_f1: 0.41667 |best_f1: 0.84444\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0321\tTop_Loss: 0.0680\tBottom_Loss: 0.0625\tLoss: 0.1626\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0248\tTop_Loss: 0.0723\tBottom_Loss: 0.1005\tLoss: 0.1976\t\n",
      "Subject: s18, n=07 | test_f1: 0.30159 |best_f1: 0.84444\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0428\tTop_Loss: 0.1526\tBottom_Loss: 0.2005\tLoss: 0.3959\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0467\tTop_Loss: 0.0779\tBottom_Loss: 0.1050\tLoss: 0.2297\t\n",
      "Subject: s18, n=07 | test_f1: 0.38333 |best_f1: 0.84444\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 0.938\tLabel_Loss: 0.0810\tTop_Loss: 0.1443\tBottom_Loss: 0.0959\tLoss: 0.3212\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0399\tTop_Loss: 0.2072\tBottom_Loss: 0.0902\tLoss: 0.3374\t\n",
      "Subject: s18, n=07 | test_f1: 0.4127 |best_f1: 0.84444\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0414\tTop_Loss: 0.1186\tBottom_Loss: 0.1151\tLoss: 0.2751\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0258\tTop_Loss: 0.0486\tBottom_Loss: 0.0568\tLoss: 0.1312\t\n",
      "Subject: s18, n=07 | test_f1: 0.51852 |best_f1: 0.84444\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0461\tTop_Loss: 0.1158\tBottom_Loss: 0.0747\tLoss: 0.2366\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0165\tTop_Loss: 0.1024\tBottom_Loss: 0.0380\tLoss: 0.1569\t\n",
      "Subject: s18, n=07 | test_f1: 0.38889 |best_f1: 0.84444\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0146\tTop_Loss: 0.0661\tBottom_Loss: 0.0399\tLoss: 0.1206\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 0.938\tLabel_Loss: 0.0833\tTop_Loss: 0.1730\tBottom_Loss: 0.0866\tLoss: 0.3430\t\n",
      "Subject: s18, n=07 | test_f1: 0.51667 |best_f1: 0.84444\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0159\tTop_Loss: 0.1090\tBottom_Loss: 0.0380\tLoss: 0.1630\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0426\tTop_Loss: 0.1337\tBottom_Loss: 0.1127\tLoss: 0.2890\t\n",
      "Subject: s18, n=07 | test_f1: 0.38889 |best_f1: 0.84444\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0340\tTop_Loss: 0.0765\tBottom_Loss: 0.0602\tLoss: 0.1707\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0086\tTop_Loss: 0.0268\tBottom_Loss: 0.0231\tLoss: 0.0585\t\n",
      "Subject: s18, n=07 | test_f1: 0.62963 |best_f1: 0.84444\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0260\tTop_Loss: 0.0888\tBottom_Loss: 0.0550\tLoss: 0.1698\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0631\tTop_Loss: 0.0838\tBottom_Loss: 0.0657\tLoss: 0.2125\t\n",
      "Subject: s18, n=07 | test_f1: 0.35714 |best_f1: 0.84444\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0986\tTop_Loss: 0.1268\tBottom_Loss: 0.0824\tLoss: 0.3078\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0420\tTop_Loss: 0.0754\tBottom_Loss: 0.0942\tLoss: 0.2116\t\n",
      "Subject: s18, n=07 | test_f1: 0.51852 |best_f1: 0.84444\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1035\tTop_Loss: 0.0738\tBottom_Loss: 0.2730\tLoss: 0.4502\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0281\tTop_Loss: 0.0547\tBottom_Loss: 0.0592\tLoss: 0.1420\t\n",
      "Subject: s18, n=07 | test_f1: 0.51852 |best_f1: 0.84444\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0143\tTop_Loss: 0.0512\tBottom_Loss: 0.0573\tLoss: 0.1228\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0304\tTop_Loss: 0.0796\tBottom_Loss: 0.0656\tLoss: 0.1757\t\n",
      "Subject: s18, n=07 | test_f1: 0.57143 |best_f1: 0.84444\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0364\tTop_Loss: 0.0639\tBottom_Loss: 0.0603\tLoss: 0.1606\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0134\tTop_Loss: 0.0355\tBottom_Loss: 0.0298\tLoss: 0.0788\t\n",
      "Subject: s18, n=07 | test_f1: 0.4127 |best_f1: 0.84444\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0084\tTop_Loss: 0.0623\tBottom_Loss: 0.0401\tLoss: 0.1108\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0350\tTop_Loss: 0.0491\tBottom_Loss: 0.0927\tLoss: 0.1768\t\n",
      "Subject: s18, n=07 | test_f1: 0.41667 |best_f1: 0.84444\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0128\tTop_Loss: 0.1068\tBottom_Loss: 0.0322\tLoss: 0.1518\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0479\tTop_Loss: 0.1028\tBottom_Loss: 0.1002\tLoss: 0.2509\t\n",
      "Subject: s18, n=07 | test_f1: 0.53333 |best_f1: 0.84444\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0103\tTop_Loss: 0.0509\tBottom_Loss: 0.0478\tLoss: 0.1090\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0098\tTop_Loss: 0.0382\tBottom_Loss: 0.0137\tLoss: 0.0617\t\n",
      "Subject: s18, n=07 | test_f1: 0.41667 |best_f1: 0.84444\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0398\tTop_Loss: 0.0762\tBottom_Loss: 0.0324\tLoss: 0.1483\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0069\tTop_Loss: 0.0381\tBottom_Loss: 0.0834\tLoss: 0.1284\t\n",
      "Subject: s18, n=07 | test_f1: 0.32381 |best_f1: 0.84444\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0095\tTop_Loss: 0.0306\tBottom_Loss: 0.0333\tLoss: 0.0734\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0238\tTop_Loss: 0.0584\tBottom_Loss: 0.0569\tLoss: 0.1391\t\n",
      "Subject: s18, n=07 | test_f1: 0.32381 |best_f1: 0.84444\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0145\tTop_Loss: 0.0690\tBottom_Loss: 0.0268\tLoss: 0.1103\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0126\tTop_Loss: 0.0277\tBottom_Loss: 0.0321\tLoss: 0.0723\t\n",
      "Subject: s18, n=07 | test_f1: 0.62963 |best_f1: 0.84444\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0063\tTop_Loss: 0.0242\tBottom_Loss: 0.0295\tLoss: 0.0600\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0076\tTop_Loss: 0.0259\tBottom_Loss: 0.0207\tLoss: 0.0542\t\n",
      "Subject: s18, n=07 | test_f1: 0.45714 |best_f1: 0.84444\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0106\tTop_Loss: 0.0284\tBottom_Loss: 0.0177\tLoss: 0.0567\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0426\tTop_Loss: 0.0731\tBottom_Loss: 0.1070\tLoss: 0.2226\t\n",
      "Subject: s18, n=07 | test_f1: 0.30159 |best_f1: 0.84444\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0036\tTop_Loss: 0.0246\tBottom_Loss: 0.0332\tLoss: 0.0614\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0395\tTop_Loss: 0.1269\tBottom_Loss: 0.0663\tLoss: 0.2328\t\n",
      "Subject: s18, n=07 | test_f1: 0.4127 |best_f1: 0.84444\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0115\tTop_Loss: 0.0329\tBottom_Loss: 0.0142\tLoss: 0.0585\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0088\tTop_Loss: 0.0541\tBottom_Loss: 0.0138\tLoss: 0.0767\t\n",
      "Subject: s18, n=07 | test_f1: 0.38889 |best_f1: 0.84444\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0122\tTop_Loss: 0.0474\tBottom_Loss: 0.0434\tLoss: 0.1030\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0172\tTop_Loss: 0.0186\tBottom_Loss: 0.0373\tLoss: 0.0731\t\n",
      "Subject: s18, n=07 | test_f1: 0.53333 |best_f1: 0.84444\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0150\tTop_Loss: 0.0856\tBottom_Loss: 0.0190\tLoss: 0.1196\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0059\tTop_Loss: 0.0253\tBottom_Loss: 0.0406\tLoss: 0.0718\t\n",
      "Subject: s18, n=07 | test_f1: 0.62963 |best_f1: 0.84444\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0058\tTop_Loss: 0.0242\tBottom_Loss: 0.0288\tLoss: 0.0588\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0062\tTop_Loss: 0.0222\tBottom_Loss: 0.0199\tLoss: 0.0483\t\n",
      "Subject: s18, n=07 | test_f1: 0.22222 |best_f1: 0.84444\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0166\tTop_Loss: 0.0651\tBottom_Loss: 0.1174\tLoss: 0.1991\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0171\tTop_Loss: 0.0733\tBottom_Loss: 0.0231\tLoss: 0.1136\t\n",
      "Subject: s18, n=07 | test_f1: 0.51667 |best_f1: 0.84444\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.469\tLabel_Loss: 1.0341\tTop_Loss: 1.7604\tBottom_Loss: 1.8640\tLoss: 4.6585\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.594\tLabel_Loss: 1.0791\tTop_Loss: 1.3601\tBottom_Loss: 1.0797\tLoss: 3.5189\t\n",
      "Subject: s19, n=02 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.562\tLabel_Loss: 0.9471\tTop_Loss: 0.9862\tBottom_Loss: 0.8452\tLoss: 2.7784\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.438\tLabel_Loss: 1.1318\tTop_Loss: 1.2002\tBottom_Loss: 1.0668\tLoss: 3.3988\t\n",
      "Subject: s19, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.594\tLabel_Loss: 1.0645\tTop_Loss: 1.1565\tBottom_Loss: 1.0601\tLoss: 3.2811\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.594\tLabel_Loss: 1.0323\tTop_Loss: 0.9711\tBottom_Loss: 0.8764\tLoss: 2.8798\t\n",
      "Subject: s19, n=02 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.531\tLabel_Loss: 1.0211\tTop_Loss: 1.0174\tBottom_Loss: 0.9758\tLoss: 3.0144\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.656\tLabel_Loss: 0.9395\tTop_Loss: 0.7065\tBottom_Loss: 1.0354\tLoss: 2.6814\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.562\tLabel_Loss: 1.1663\tTop_Loss: 1.1514\tBottom_Loss: 1.0585\tLoss: 3.3762\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.594\tLabel_Loss: 0.9271\tTop_Loss: 0.9700\tBottom_Loss: 0.9796\tLoss: 2.8768\t\n",
      "Subject: s19, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8505\tTop_Loss: 1.0238\tBottom_Loss: 0.7428\tLoss: 2.6171\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.562\tLabel_Loss: 0.7977\tTop_Loss: 1.0567\tBottom_Loss: 0.8005\tLoss: 2.6548\t\n",
      "Subject: s19, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8076\tTop_Loss: 0.9083\tBottom_Loss: 0.9346\tLoss: 2.6506\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.500\tLabel_Loss: 0.9233\tTop_Loss: 0.8742\tBottom_Loss: 0.9201\tLoss: 2.7176\t\n",
      "Subject: s19, n=02 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6098\tTop_Loss: 0.5435\tBottom_Loss: 0.7040\tLoss: 1.8572\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8424\tTop_Loss: 0.9995\tBottom_Loss: 1.1091\tLoss: 2.9509\t\n",
      "Subject: s19, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.531\tLabel_Loss: 0.7884\tTop_Loss: 1.0378\tBottom_Loss: 0.8905\tLoss: 2.7167\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8467\tTop_Loss: 0.8460\tBottom_Loss: 0.8461\tLoss: 2.5388\t\n",
      "Subject: s19, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6790\tTop_Loss: 0.7663\tBottom_Loss: 0.7238\tLoss: 2.1691\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.781\tLabel_Loss: 0.6704\tTop_Loss: 0.7678\tBottom_Loss: 0.7667\tLoss: 2.2049\t\n",
      "Subject: s19, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.938\tLabel_Loss: 0.4582\tTop_Loss: 0.6115\tBottom_Loss: 0.8293\tLoss: 1.8990\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6656\tTop_Loss: 0.6984\tBottom_Loss: 0.8053\tLoss: 2.1693\t\n",
      "Subject: s19, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7222\tTop_Loss: 0.7283\tBottom_Loss: 0.7390\tLoss: 2.1896\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6471\tTop_Loss: 0.6489\tBottom_Loss: 0.8048\tLoss: 2.1008\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5122\tTop_Loss: 0.6262\tBottom_Loss: 0.6178\tLoss: 1.7562\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7440\tTop_Loss: 0.8824\tBottom_Loss: 0.7538\tLoss: 2.3803\t\n",
      "Subject: s19, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.781\tLabel_Loss: 0.6164\tTop_Loss: 0.6951\tBottom_Loss: 0.7671\tLoss: 2.0785\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.656\tLabel_Loss: 0.6593\tTop_Loss: 0.7273\tBottom_Loss: 0.7075\tLoss: 2.0940\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5372\tTop_Loss: 0.5250\tBottom_Loss: 0.6087\tLoss: 1.6709\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6035\tTop_Loss: 0.5660\tBottom_Loss: 0.7881\tLoss: 1.9576\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.531\tLabel_Loss: 0.7523\tTop_Loss: 0.8015\tBottom_Loss: 0.7263\tLoss: 2.2800\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.594\tLabel_Loss: 1.0366\tTop_Loss: 1.0051\tBottom_Loss: 1.0669\tLoss: 3.1086\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5143\tTop_Loss: 0.6885\tBottom_Loss: 0.6226\tLoss: 1.8253\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7199\tTop_Loss: 0.6882\tBottom_Loss: 0.8932\tLoss: 2.3013\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6490\tTop_Loss: 0.8218\tBottom_Loss: 0.6721\tLoss: 2.1430\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5520\tTop_Loss: 0.7272\tBottom_Loss: 0.5299\tLoss: 1.8091\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.844\tLabel_Loss: 0.5348\tTop_Loss: 0.6191\tBottom_Loss: 0.6979\tLoss: 1.8518\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4496\tTop_Loss: 0.4755\tBottom_Loss: 0.4634\tLoss: 1.3885\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7954\tTop_Loss: 0.7507\tBottom_Loss: 0.8341\tLoss: 2.3801\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3266\tTop_Loss: 0.4498\tBottom_Loss: 0.5180\tLoss: 1.2944\t\n",
      "Subject: s19, n=02 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3727\tTop_Loss: 0.4843\tBottom_Loss: 0.4009\tLoss: 1.2580\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3141\tTop_Loss: 0.4191\tBottom_Loss: 0.4506\tLoss: 1.1838\t\n",
      "Subject: s19, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3596\tTop_Loss: 0.4780\tBottom_Loss: 0.5131\tLoss: 1.3508\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.719\tLabel_Loss: 0.5313\tTop_Loss: 0.5230\tBottom_Loss: 0.6631\tLoss: 1.7175\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4254\tTop_Loss: 0.6184\tBottom_Loss: 0.5671\tLoss: 1.6109\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3542\tTop_Loss: 0.4593\tBottom_Loss: 0.6573\tLoss: 1.4708\t\n",
      "Subject: s19, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6018\tTop_Loss: 0.6963\tBottom_Loss: 0.6793\tLoss: 1.9775\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4397\tTop_Loss: 0.5560\tBottom_Loss: 0.5214\tLoss: 1.5171\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4663\tTop_Loss: 0.6169\tBottom_Loss: 0.6583\tLoss: 1.7414\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.938\tLabel_Loss: 0.3321\tTop_Loss: 0.5273\tBottom_Loss: 0.5773\tLoss: 1.4367\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4489\tTop_Loss: 0.5489\tBottom_Loss: 0.5620\tLoss: 1.5599\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4734\tTop_Loss: 0.5638\tBottom_Loss: 0.6252\tLoss: 1.6624\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2630\tTop_Loss: 0.4540\tBottom_Loss: 0.3949\tLoss: 1.1119\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1941\tTop_Loss: 0.4913\tBottom_Loss: 0.3601\tLoss: 1.0455\t\n",
      "Subject: s19, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3561\tTop_Loss: 0.4932\tBottom_Loss: 0.5008\tLoss: 1.3501\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4848\tTop_Loss: 0.5605\tBottom_Loss: 0.5810\tLoss: 1.6263\t\n",
      "Subject: s19, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2632\tTop_Loss: 0.3297\tBottom_Loss: 0.4562\tLoss: 1.0492\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3455\tTop_Loss: 0.3844\tBottom_Loss: 0.3523\tLoss: 1.0822\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3497\tTop_Loss: 0.6076\tBottom_Loss: 0.4253\tLoss: 1.3827\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.812\tLabel_Loss: 0.6502\tTop_Loss: 0.7050\tBottom_Loss: 0.8418\tLoss: 2.1971\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3618\tTop_Loss: 0.5787\tBottom_Loss: 0.4436\tLoss: 1.3842\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2829\tTop_Loss: 0.4379\tBottom_Loss: 0.3585\tLoss: 1.0793\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3310\tTop_Loss: 0.5773\tBottom_Loss: 0.5606\tLoss: 1.4688\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.781\tLabel_Loss: 0.3846\tTop_Loss: 0.4174\tBottom_Loss: 0.5107\tLoss: 1.3126\t\n",
      "Subject: s19, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2609\tTop_Loss: 0.3595\tBottom_Loss: 0.3748\tLoss: 0.9952\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2707\tTop_Loss: 0.4220\tBottom_Loss: 0.3052\tLoss: 0.9979\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2709\tTop_Loss: 0.3858\tBottom_Loss: 0.3103\tLoss: 0.9670\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3190\tTop_Loss: 0.4902\tBottom_Loss: 0.3808\tLoss: 1.1900\t\n",
      "Subject: s19, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2614\tTop_Loss: 0.3609\tBottom_Loss: 0.3026\tLoss: 0.9249\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2982\tTop_Loss: 0.4232\tBottom_Loss: 0.4526\tLoss: 1.1741\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2172\tTop_Loss: 0.5260\tBottom_Loss: 0.2912\tLoss: 1.0344\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3084\tTop_Loss: 0.5338\tBottom_Loss: 0.2708\tLoss: 1.1130\t\n",
      "Subject: s19, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2568\tTop_Loss: 0.3810\tBottom_Loss: 0.3305\tLoss: 0.9683\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2436\tTop_Loss: 0.2750\tBottom_Loss: 0.4389\tLoss: 0.9574\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2423\tTop_Loss: 0.3739\tBottom_Loss: 0.3680\tLoss: 0.9843\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1776\tTop_Loss: 0.4028\tBottom_Loss: 0.1831\tLoss: 0.7634\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1821\tTop_Loss: 0.3515\tBottom_Loss: 0.2333\tLoss: 0.7670\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1631\tTop_Loss: 0.2795\tBottom_Loss: 0.2996\tLoss: 0.7422\t\n",
      "Subject: s19, n=02 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1554\tTop_Loss: 0.3140\tBottom_Loss: 0.3470\tLoss: 0.8165\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1893\tTop_Loss: 0.4687\tBottom_Loss: 0.3301\tLoss: 0.9881\t\n",
      "Subject: s19, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3811\tTop_Loss: 0.4048\tBottom_Loss: 0.4060\tLoss: 1.1919\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.844\tLabel_Loss: 0.2979\tTop_Loss: 0.4730\tBottom_Loss: 0.2958\tLoss: 1.0667\t\n",
      "Subject: s19, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0976\tTop_Loss: 0.2377\tBottom_Loss: 0.1555\tLoss: 0.4908\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1957\tTop_Loss: 0.3044\tBottom_Loss: 0.2933\tLoss: 0.7933\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2149\tTop_Loss: 0.3618\tBottom_Loss: 0.3124\tLoss: 0.8890\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1468\tTop_Loss: 0.3834\tBottom_Loss: 0.3034\tLoss: 0.8337\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0761\tTop_Loss: 0.2577\tBottom_Loss: 0.2324\tLoss: 0.5662\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1721\tTop_Loss: 0.3810\tBottom_Loss: 0.2865\tLoss: 0.8396\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1254\tTop_Loss: 0.3011\tBottom_Loss: 0.3072\tLoss: 0.7337\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1853\tTop_Loss: 0.3208\tBottom_Loss: 0.2418\tLoss: 0.7479\t\n",
      "Subject: s19, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1213\tTop_Loss: 0.2290\tBottom_Loss: 0.2481\tLoss: 0.5984\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1410\tTop_Loss: 0.1642\tBottom_Loss: 0.2305\tLoss: 0.5356\t\n",
      "Subject: s19, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2025\tTop_Loss: 0.2290\tBottom_Loss: 0.3268\tLoss: 0.7584\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0999\tTop_Loss: 0.1822\tBottom_Loss: 0.1512\tLoss: 0.4334\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1079\tTop_Loss: 0.2282\tBottom_Loss: 0.2594\tLoss: 0.5956\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0917\tTop_Loss: 0.2819\tBottom_Loss: 0.1630\tLoss: 0.5367\t\n",
      "Subject: s19, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1085\tTop_Loss: 0.1876\tBottom_Loss: 0.1183\tLoss: 0.4144\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1601\tTop_Loss: 0.2546\tBottom_Loss: 0.2263\tLoss: 0.6410\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1175\tTop_Loss: 0.1969\tBottom_Loss: 0.1772\tLoss: 0.4917\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1420\tTop_Loss: 0.1474\tBottom_Loss: 0.2746\tLoss: 0.5640\t\n",
      "Subject: s19, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3149\tTop_Loss: 0.4027\tBottom_Loss: 0.3770\tLoss: 1.0946\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.844\tLabel_Loss: 0.2428\tTop_Loss: 0.2235\tBottom_Loss: 0.2856\tLoss: 0.7519\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0973\tTop_Loss: 0.1940\tBottom_Loss: 0.2640\tLoss: 0.5553\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0916\tTop_Loss: 0.1492\tBottom_Loss: 0.2015\tLoss: 0.4422\t\n",
      "Subject: s19, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1065\tTop_Loss: 0.2480\tBottom_Loss: 0.2423\tLoss: 0.5968\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1328\tTop_Loss: 0.2523\tBottom_Loss: 0.1974\tLoss: 0.5824\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1799\tTop_Loss: 0.4018\tBottom_Loss: 0.2099\tLoss: 0.7916\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1471\tTop_Loss: 0.2493\tBottom_Loss: 0.1745\tLoss: 0.5709\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0917\tTop_Loss: 0.2191\tBottom_Loss: 0.1983\tLoss: 0.5091\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1714\tTop_Loss: 0.3049\tBottom_Loss: 0.2194\tLoss: 0.6958\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.781\tLabel_Loss: 0.3850\tTop_Loss: 0.6327\tBottom_Loss: 0.6171\tLoss: 1.6348\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[55][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1354\tTop_Loss: 0.1405\tBottom_Loss: 0.2830\tLoss: 0.5590\t\n",
      "Subject: s19, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2133\tTop_Loss: 0.2191\tBottom_Loss: 0.2614\tLoss: 0.6938\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0319\tTop_Loss: 0.1505\tBottom_Loss: 0.1132\tLoss: 0.2956\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0969\tTop_Loss: 0.1914\tBottom_Loss: 0.2536\tLoss: 0.5419\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0906\tTop_Loss: 0.2388\tBottom_Loss: 0.1938\tLoss: 0.5231\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0664\tTop_Loss: 0.1725\tBottom_Loss: 0.1190\tLoss: 0.3579\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0388\tTop_Loss: 0.1117\tBottom_Loss: 0.0939\tLoss: 0.2444\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0290\tTop_Loss: 0.0655\tBottom_Loss: 0.1643\tLoss: 0.2588\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0689\tTop_Loss: 0.1623\tBottom_Loss: 0.1863\tLoss: 0.4176\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0708\tTop_Loss: 0.1483\tBottom_Loss: 0.1157\tLoss: 0.3347\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1734\tTop_Loss: 0.2587\tBottom_Loss: 0.2337\tLoss: 0.6658\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2116\tTop_Loss: 0.3395\tBottom_Loss: 0.2776\tLoss: 0.8287\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0342\tTop_Loss: 0.1310\tBottom_Loss: 0.1333\tLoss: 0.2985\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0701\tTop_Loss: 0.1760\tBottom_Loss: 0.0872\tLoss: 0.3333\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0445\tTop_Loss: 0.1073\tBottom_Loss: 0.0732\tLoss: 0.2250\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1185\tTop_Loss: 0.2125\tBottom_Loss: 0.1597\tLoss: 0.4907\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0800\tTop_Loss: 0.1489\tBottom_Loss: 0.1903\tLoss: 0.4193\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0462\tTop_Loss: 0.1243\tBottom_Loss: 0.1345\tLoss: 0.3049\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0701\tTop_Loss: 0.1178\tBottom_Loss: 0.1534\tLoss: 0.3413\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0275\tTop_Loss: 0.0918\tBottom_Loss: 0.0867\tLoss: 0.2060\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0550\tTop_Loss: 0.1179\tBottom_Loss: 0.1223\tLoss: 0.2952\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0914\tTop_Loss: 0.2143\tBottom_Loss: 0.1641\tLoss: 0.4698\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0493\tTop_Loss: 0.1159\tBottom_Loss: 0.1335\tLoss: 0.2986\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0503\tTop_Loss: 0.1015\tBottom_Loss: 0.1034\tLoss: 0.2552\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1102\tTop_Loss: 0.1936\tBottom_Loss: 0.1358\tLoss: 0.4395\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0499\tTop_Loss: 0.1506\tBottom_Loss: 0.2191\tLoss: 0.4195\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0477\tTop_Loss: 0.1211\tBottom_Loss: 0.1854\tLoss: 0.3542\t\n",
      "Subject: s19, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0445\tTop_Loss: 0.0964\tBottom_Loss: 0.0718\tLoss: 0.2127\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0280\tTop_Loss: 0.1136\tBottom_Loss: 0.0851\tLoss: 0.2267\t\n",
      "Subject: s19, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0398\tTop_Loss: 0.1254\tBottom_Loss: 0.0998\tLoss: 0.2651\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0392\tTop_Loss: 0.1286\tBottom_Loss: 0.1273\tLoss: 0.2950\t\n",
      "Subject: s19, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0954\tTop_Loss: 0.1710\tBottom_Loss: 0.1503\tLoss: 0.4167\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0400\tTop_Loss: 0.1392\tBottom_Loss: 0.0715\tLoss: 0.2507\t\n",
      "Subject: s19, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1276\tTop_Loss: 0.1334\tBottom_Loss: 0.2698\tLoss: 0.5308\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0435\tTop_Loss: 0.1026\tBottom_Loss: 0.0850\tLoss: 0.2311\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0763\tTop_Loss: 0.1227\tBottom_Loss: 0.1154\tLoss: 0.3143\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0740\tTop_Loss: 0.1360\tBottom_Loss: 0.2017\tLoss: 0.4118\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0589\tTop_Loss: 0.0728\tBottom_Loss: 0.0840\tLoss: 0.2157\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0197\tTop_Loss: 0.0495\tBottom_Loss: 0.0811\tLoss: 0.1503\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0145\tTop_Loss: 0.0905\tBottom_Loss: 0.0449\tLoss: 0.1498\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0238\tTop_Loss: 0.1011\tBottom_Loss: 0.0410\tLoss: 0.1658\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0566\tTop_Loss: 0.1418\tBottom_Loss: 0.1113\tLoss: 0.3098\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0502\tTop_Loss: 0.0925\tBottom_Loss: 0.0937\tLoss: 0.2364\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0586\tTop_Loss: 0.2121\tBottom_Loss: 0.1331\tLoss: 0.4038\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0127\tTop_Loss: 0.0551\tBottom_Loss: 0.0314\tLoss: 0.0992\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0174\tTop_Loss: 0.0771\tBottom_Loss: 0.0362\tLoss: 0.1307\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0100\tTop_Loss: 0.0586\tBottom_Loss: 0.0284\tLoss: 0.0970\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0199\tTop_Loss: 0.0671\tBottom_Loss: 0.0478\tLoss: 0.1348\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0185\tTop_Loss: 0.0620\tBottom_Loss: 0.0558\tLoss: 0.1362\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0145\tTop_Loss: 0.0529\tBottom_Loss: 0.0413\tLoss: 0.1088\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0258\tTop_Loss: 0.0467\tBottom_Loss: 0.0574\tLoss: 0.1298\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0125\tTop_Loss: 0.0326\tBottom_Loss: 0.0348\tLoss: 0.0798\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0268\tTop_Loss: 0.0527\tBottom_Loss: 0.0608\tLoss: 0.1402\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0155\tTop_Loss: 0.0744\tBottom_Loss: 0.0438\tLoss: 0.1337\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0306\tTop_Loss: 0.0497\tBottom_Loss: 0.0854\tLoss: 0.1657\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1104\tTop_Loss: 0.1781\tBottom_Loss: 0.1585\tLoss: 0.4471\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0338\tTop_Loss: 0.1229\tBottom_Loss: 0.0626\tLoss: 0.2192\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0158\tTop_Loss: 0.0594\tBottom_Loss: 0.0643\tLoss: 0.1396\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0536\tTop_Loss: 0.0798\tBottom_Loss: 0.0795\tLoss: 0.2128\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0341\tTop_Loss: 0.1048\tBottom_Loss: 0.0964\tLoss: 0.2353\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0490\tTop_Loss: 0.0714\tBottom_Loss: 0.1406\tLoss: 0.2610\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0676\tTop_Loss: 0.0757\tBottom_Loss: 0.0647\tLoss: 0.2079\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0196\tTop_Loss: 0.0776\tBottom_Loss: 0.0426\tLoss: 0.1398\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0259\tTop_Loss: 0.0778\tBottom_Loss: 0.0626\tLoss: 0.1663\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0252\tTop_Loss: 0.0420\tBottom_Loss: 0.0379\tLoss: 0.1052\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0359\tTop_Loss: 0.0808\tBottom_Loss: 0.0952\tLoss: 0.2118\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0220\tTop_Loss: 0.0648\tBottom_Loss: 0.0762\tLoss: 0.1630\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0063\tTop_Loss: 0.0230\tBottom_Loss: 0.0280\tLoss: 0.0572\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0182\tTop_Loss: 0.0575\tBottom_Loss: 0.0397\tLoss: 0.1154\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 0.938\tLabel_Loss: 0.0990\tTop_Loss: 0.2044\tBottom_Loss: 0.1348\tLoss: 0.4383\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0069\tTop_Loss: 0.0475\tBottom_Loss: 0.0223\tLoss: 0.0767\t\n",
      "Subject: s19, n=02 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0085\tTop_Loss: 0.0379\tBottom_Loss: 0.0367\tLoss: 0.0831\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0206\tTop_Loss: 0.0510\tBottom_Loss: 0.0317\tLoss: 0.1033\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0112\tTop_Loss: 0.0416\tBottom_Loss: 0.0223\tLoss: 0.0751\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0861\tTop_Loss: 0.1270\tBottom_Loss: 0.1193\tLoss: 0.3325\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0160\tTop_Loss: 0.0636\tBottom_Loss: 0.0236\tLoss: 0.1032\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0211\tTop_Loss: 0.0244\tBottom_Loss: 0.0544\tLoss: 0.1000\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0086\tTop_Loss: 0.0500\tBottom_Loss: 0.0321\tLoss: 0.0908\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0126\tTop_Loss: 0.0775\tBottom_Loss: 0.0331\tLoss: 0.1232\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0203\tTop_Loss: 0.0480\tBottom_Loss: 0.0370\tLoss: 0.1053\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0077\tTop_Loss: 0.0212\tBottom_Loss: 0.0170\tLoss: 0.0458\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0086\tTop_Loss: 0.0280\tBottom_Loss: 0.0533\tLoss: 0.0899\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0208\tTop_Loss: 0.0508\tBottom_Loss: 0.0849\tLoss: 0.1565\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0084\tTop_Loss: 0.0272\tBottom_Loss: 0.0255\tLoss: 0.0611\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0135\tTop_Loss: 0.0778\tBottom_Loss: 0.0788\tLoss: 0.1702\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0327\tTop_Loss: 0.0600\tBottom_Loss: 0.0347\tLoss: 0.1274\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0175\tTop_Loss: 0.0181\tBottom_Loss: 0.0779\tLoss: 0.1134\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0047\tTop_Loss: 0.0277\tBottom_Loss: 0.0282\tLoss: 0.0606\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0052\tTop_Loss: 0.0237\tBottom_Loss: 0.0204\tLoss: 0.0493\t\n",
      "Subject: s19, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.625\tLabel_Loss: 1.1345\tTop_Loss: 1.5499\tBottom_Loss: 1.1985\tLoss: 3.8830\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.469\tLabel_Loss: 1.2035\tTop_Loss: 1.2328\tBottom_Loss: 1.0887\tLoss: 3.5249\t\n",
      "Subject: s2, n=06 | test_f1: 0.11111 |best_f1: 0.11111\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.594\tLabel_Loss: 0.9394\tTop_Loss: 1.0962\tBottom_Loss: 1.0209\tLoss: 3.0565\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.594\tLabel_Loss: 0.9334\tTop_Loss: 0.7449\tBottom_Loss: 0.8661\tLoss: 2.5444\t\n",
      "Subject: s2, n=06 | test_f1: 0.16667 |best_f1: 0.16667\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.375\tLabel_Loss: 1.2448\tTop_Loss: 1.0088\tBottom_Loss: 1.0855\tLoss: 3.3391\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.531\tLabel_Loss: 0.8795\tTop_Loss: 1.0298\tBottom_Loss: 0.9994\tLoss: 2.9086\t\n",
      "Subject: s2, n=06 | test_f1: 0.27778 |best_f1: 0.27778\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.656\tLabel_Loss: 0.8256\tTop_Loss: 0.9226\tBottom_Loss: 0.9560\tLoss: 2.7041\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.625\tLabel_Loss: 0.9226\tTop_Loss: 0.8241\tBottom_Loss: 0.9269\tLoss: 2.6736\t\n",
      "Subject: s2, n=06 | test_f1: 0.11111 |best_f1: 0.27778\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.438\tLabel_Loss: 0.9674\tTop_Loss: 0.8761\tBottom_Loss: 0.8833\tLoss: 2.7268\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.500\tLabel_Loss: 1.0416\tTop_Loss: 0.9626\tBottom_Loss: 1.1084\tLoss: 3.1126\t\n",
      "Subject: s2, n=06 | test_f1: 0.0 |best_f1: 0.27778\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7825\tTop_Loss: 0.8790\tBottom_Loss: 0.8722\tLoss: 2.5336\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6484\tTop_Loss: 0.6794\tBottom_Loss: 0.8036\tLoss: 2.1314\t\n",
      "Subject: s2, n=06 | test_f1: 0.095238 |best_f1: 0.27778\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.594\tLabel_Loss: 0.9477\tTop_Loss: 0.8677\tBottom_Loss: 1.0656\tLoss: 2.8810\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.688\tLabel_Loss: 0.8302\tTop_Loss: 0.8538\tBottom_Loss: 0.9334\tLoss: 2.6174\t\n",
      "Subject: s2, n=06 | test_f1: 0.11111 |best_f1: 0.27778\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7847\tTop_Loss: 0.7533\tBottom_Loss: 0.7633\tLoss: 2.3013\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7506\tTop_Loss: 1.0086\tBottom_Loss: 0.7285\tLoss: 2.4878\t\n",
      "Subject: s2, n=06 | test_f1: 0.0 |best_f1: 0.27778\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5923\tTop_Loss: 0.6812\tBottom_Loss: 0.7690\tLoss: 2.0424\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.562\tLabel_Loss: 0.8624\tTop_Loss: 0.8554\tBottom_Loss: 0.8530\tLoss: 2.5709\t\n",
      "Subject: s2, n=06 | test_f1: 0.4127 |best_f1: 0.4127\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6846\tTop_Loss: 0.6992\tBottom_Loss: 0.6889\tLoss: 2.0728\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.781\tLabel_Loss: 0.6918\tTop_Loss: 0.6922\tBottom_Loss: 0.6897\tLoss: 2.0737\t\n",
      "Subject: s2, n=06 | test_f1: 0.11111 |best_f1: 0.4127\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7363\tTop_Loss: 0.5852\tBottom_Loss: 0.7328\tLoss: 2.0543\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.500\tLabel_Loss: 0.8171\tTop_Loss: 1.0503\tBottom_Loss: 0.8299\tLoss: 2.6974\t\n",
      "Subject: s2, n=06 | test_f1: 0.19048 |best_f1: 0.4127\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6926\tTop_Loss: 0.7375\tBottom_Loss: 0.9688\tLoss: 2.3989\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6974\tTop_Loss: 0.7721\tBottom_Loss: 0.6696\tLoss: 2.1392\t\n",
      "Subject: s2, n=06 | test_f1: 0.19048 |best_f1: 0.4127\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.656\tLabel_Loss: 0.6857\tTop_Loss: 0.7920\tBottom_Loss: 0.6696\tLoss: 2.1473\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5110\tTop_Loss: 0.5640\tBottom_Loss: 0.6588\tLoss: 1.7339\t\n",
      "Subject: s2, n=06 | test_f1: 0.52381 |best_f1: 0.52381\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4065\tTop_Loss: 0.5905\tBottom_Loss: 0.5447\tLoss: 1.5418\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6628\tTop_Loss: 0.7319\tBottom_Loss: 0.8380\tLoss: 2.2327\t\n",
      "Subject: s2, n=06 | test_f1: 0.47222 |best_f1: 0.52381\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4073\tTop_Loss: 0.4769\tBottom_Loss: 0.5950\tLoss: 1.4791\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7336\tTop_Loss: 0.9467\tBottom_Loss: 0.8344\tLoss: 2.5146\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.52381\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6382\tTop_Loss: 0.6261\tBottom_Loss: 0.7620\tLoss: 2.0262\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5627\tTop_Loss: 0.5407\tBottom_Loss: 0.6580\tLoss: 1.7614\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.52381\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6119\tTop_Loss: 0.8322\tBottom_Loss: 0.6233\tLoss: 2.0674\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4838\tTop_Loss: 0.6637\tBottom_Loss: 0.6314\tLoss: 1.7790\t\n",
      "Subject: s2, n=06 | test_f1: 0.52381 |best_f1: 0.52381\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.656\tLabel_Loss: 0.6508\tTop_Loss: 0.8405\tBottom_Loss: 0.9054\tLoss: 2.3968\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3858\tTop_Loss: 0.4822\tBottom_Loss: 0.5183\tLoss: 1.3862\t\n",
      "Subject: s2, n=06 | test_f1: 0.19048 |best_f1: 0.52381\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5938\tTop_Loss: 0.6814\tBottom_Loss: 0.7124\tLoss: 1.9877\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4470\tTop_Loss: 0.5644\tBottom_Loss: 0.6663\tLoss: 1.6777\t\n",
      "Subject: s2, n=06 | test_f1: 0.19048 |best_f1: 0.52381\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.812\tLabel_Loss: 0.6413\tTop_Loss: 0.7174\tBottom_Loss: 0.6116\tLoss: 1.9703\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.688\tLabel_Loss: 0.5595\tTop_Loss: 0.6499\tBottom_Loss: 0.5617\tLoss: 1.7711\t\n",
      "Subject: s2, n=06 | test_f1: 0.19048 |best_f1: 0.52381\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5751\tTop_Loss: 0.6437\tBottom_Loss: 0.4489\tLoss: 1.6677\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.938\tLabel_Loss: 0.3011\tTop_Loss: 0.5971\tBottom_Loss: 0.4399\tLoss: 1.3380\t\n",
      "Subject: s2, n=06 | test_f1: 0.19048 |best_f1: 0.52381\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3907\tTop_Loss: 0.5625\tBottom_Loss: 0.6623\tLoss: 1.6155\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.719\tLabel_Loss: 0.5456\tTop_Loss: 0.6232\tBottom_Loss: 0.5879\tLoss: 1.7567\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.52381\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4387\tTop_Loss: 0.5136\tBottom_Loss: 0.6653\tLoss: 1.6176\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3319\tTop_Loss: 0.5132\tBottom_Loss: 0.5636\tLoss: 1.4086\t\n",
      "Subject: s2, n=06 | test_f1: 0.19048 |best_f1: 0.52381\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3505\tTop_Loss: 0.4904\tBottom_Loss: 0.4690\tLoss: 1.3099\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4172\tTop_Loss: 0.6575\tBottom_Loss: 0.6753\tLoss: 1.7500\t\n",
      "Subject: s2, n=06 | test_f1: 0.19048 |best_f1: 0.52381\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.906\tLabel_Loss: 0.4188\tTop_Loss: 0.4940\tBottom_Loss: 0.3980\tLoss: 1.3108\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2988\tTop_Loss: 0.4513\tBottom_Loss: 0.3379\tLoss: 1.0880\t\n",
      "Subject: s2, n=06 | test_f1: 0.11111 |best_f1: 0.52381\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4285\tTop_Loss: 0.4852\tBottom_Loss: 0.5022\tLoss: 1.4159\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2660\tTop_Loss: 0.5321\tBottom_Loss: 0.3963\tLoss: 1.1944\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.52381\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4443\tTop_Loss: 0.4255\tBottom_Loss: 0.4446\tLoss: 1.3145\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3090\tTop_Loss: 0.4044\tBottom_Loss: 0.5095\tLoss: 1.2230\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.52381\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2973\tTop_Loss: 0.3586\tBottom_Loss: 0.4230\tLoss: 1.0789\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4151\tTop_Loss: 0.5837\tBottom_Loss: 0.4736\tLoss: 1.4724\t\n",
      "Subject: s2, n=06 | test_f1: 0.2963 |best_f1: 0.52381\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3409\tTop_Loss: 0.5787\tBottom_Loss: 0.4487\tLoss: 1.3682\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3408\tTop_Loss: 0.4787\tBottom_Loss: 0.3599\tLoss: 1.1793\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.52381\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2174\tTop_Loss: 0.3449\tBottom_Loss: 0.3972\tLoss: 0.9594\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2456\tTop_Loss: 0.3541\tBottom_Loss: 0.3633\tLoss: 0.9630\t\n",
      "Subject: s2, n=06 | test_f1: 0.19048 |best_f1: 0.52381\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1840\tTop_Loss: 0.3053\tBottom_Loss: 0.3485\tLoss: 0.8377\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2886\tTop_Loss: 0.3983\tBottom_Loss: 0.4531\tLoss: 1.1400\t\n",
      "Subject: s2, n=06 | test_f1: 0.19048 |best_f1: 0.52381\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3123\tTop_Loss: 0.3797\tBottom_Loss: 0.2575\tLoss: 0.9495\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2663\tTop_Loss: 0.4852\tBottom_Loss: 0.4550\tLoss: 1.2065\t\n",
      "Subject: s2, n=06 | test_f1: 0.19048 |best_f1: 0.52381\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3484\tTop_Loss: 0.4384\tBottom_Loss: 0.4457\tLoss: 1.2324\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2105\tTop_Loss: 0.3992\tBottom_Loss: 0.2077\tLoss: 0.8173\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.52381\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2080\tTop_Loss: 0.4589\tBottom_Loss: 0.2424\tLoss: 0.9093\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3376\tTop_Loss: 0.5594\tBottom_Loss: 0.5016\tLoss: 1.3986\t\n",
      "Subject: s2, n=06 | test_f1: 0.47222 |best_f1: 0.52381\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2838\tTop_Loss: 0.4764\tBottom_Loss: 0.4231\tLoss: 1.1833\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2851\tTop_Loss: 0.5224\tBottom_Loss: 0.3372\tLoss: 1.1447\t\n",
      "Subject: s2, n=06 | test_f1: 0.19048 |best_f1: 0.52381\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2611\tTop_Loss: 0.4529\tBottom_Loss: 0.3454\tLoss: 1.0594\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2412\tTop_Loss: 0.4388\tBottom_Loss: 0.2977\tLoss: 0.9778\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.52381\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2247\tTop_Loss: 0.4916\tBottom_Loss: 0.2401\tLoss: 0.9564\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3517\tTop_Loss: 0.5199\tBottom_Loss: 0.2953\tLoss: 1.1669\t\n",
      "Subject: s2, n=06 | test_f1: 0.58333 |best_f1: 0.58333\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2298\tTop_Loss: 0.5277\tBottom_Loss: 0.3086\tLoss: 1.0661\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.812\tLabel_Loss: 0.2890\tTop_Loss: 0.2890\tBottom_Loss: 0.3572\tLoss: 0.9352\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.58333\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1542\tTop_Loss: 0.2855\tBottom_Loss: 0.2542\tLoss: 0.6939\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2792\tTop_Loss: 0.5962\tBottom_Loss: 0.3421\tLoss: 1.2175\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.58333\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2026\tTop_Loss: 0.3176\tBottom_Loss: 0.3796\tLoss: 0.8999\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1529\tTop_Loss: 0.2519\tBottom_Loss: 0.3024\tLoss: 0.7072\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.58333\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2590\tTop_Loss: 0.4467\tBottom_Loss: 0.3195\tLoss: 1.0252\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1507\tTop_Loss: 0.2564\tBottom_Loss: 0.2150\tLoss: 0.6221\t\n",
      "Subject: s2, n=06 | test_f1: 0.19048 |best_f1: 0.58333\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0831\tTop_Loss: 0.2270\tBottom_Loss: 0.1633\tLoss: 0.4734\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1182\tTop_Loss: 0.1766\tBottom_Loss: 0.1986\tLoss: 0.4934\t\n",
      "Subject: s2, n=06 | test_f1: 0.19048 |best_f1: 0.58333\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1035\tTop_Loss: 0.3450\tBottom_Loss: 0.1578\tLoss: 0.6064\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0765\tTop_Loss: 0.1715\tBottom_Loss: 0.1453\tLoss: 0.3933\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.58333\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2656\tTop_Loss: 0.4566\tBottom_Loss: 0.4483\tLoss: 1.1705\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1502\tTop_Loss: 0.3855\tBottom_Loss: 0.1726\tLoss: 0.7083\t\n",
      "Subject: s2, n=06 | test_f1: 0.11111 |best_f1: 0.58333\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1580\tTop_Loss: 0.2361\tBottom_Loss: 0.2355\tLoss: 0.6297\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1325\tTop_Loss: 0.3464\tBottom_Loss: 0.1971\tLoss: 0.6760\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.58333\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0699\tTop_Loss: 0.2114\tBottom_Loss: 0.1382\tLoss: 0.4195\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.844\tLabel_Loss: 0.2217\tTop_Loss: 0.3575\tBottom_Loss: 0.1740\tLoss: 0.7532\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.58333\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1041\tTop_Loss: 0.2226\tBottom_Loss: 0.2203\tLoss: 0.5470\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1327\tTop_Loss: 0.2862\tBottom_Loss: 0.1479\tLoss: 0.5667\t\n",
      "Subject: s2, n=06 | test_f1: 0.19048 |best_f1: 0.58333\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0995\tTop_Loss: 0.2843\tBottom_Loss: 0.1277\tLoss: 0.5116\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1499\tTop_Loss: 0.3145\tBottom_Loss: 0.2223\tLoss: 0.6867\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.58333\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0939\tTop_Loss: 0.2716\tBottom_Loss: 0.1548\tLoss: 0.5203\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1277\tTop_Loss: 0.1993\tBottom_Loss: 0.2333\tLoss: 0.5603\t\n",
      "Subject: s2, n=06 | test_f1: 0.58333 |best_f1: 0.58333\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1427\tTop_Loss: 0.1996\tBottom_Loss: 0.1276\tLoss: 0.4699\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1267\tTop_Loss: 0.2326\tBottom_Loss: 0.2611\tLoss: 0.6204\t\n",
      "Subject: s2, n=06 | test_f1: 0.19048 |best_f1: 0.58333\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0910\tTop_Loss: 0.2865\tBottom_Loss: 0.1469\tLoss: 0.5244\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2759\tTop_Loss: 0.3916\tBottom_Loss: 0.2285\tLoss: 0.8960\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.58333\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0812\tTop_Loss: 0.3422\tBottom_Loss: 0.1488\tLoss: 0.5721\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1524\tTop_Loss: 0.2857\tBottom_Loss: 0.1574\tLoss: 0.5955\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.58333\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0865\tTop_Loss: 0.2019\tBottom_Loss: 0.2095\tLoss: 0.4978\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0847\tTop_Loss: 0.3082\tBottom_Loss: 0.1007\tLoss: 0.4936\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.58333\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2190\tTop_Loss: 0.2648\tBottom_Loss: 0.3474\tLoss: 0.8311\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 0.938\tLabel_Loss: 0.0993\tTop_Loss: 0.1031\tBottom_Loss: 0.2617\tLoss: 0.4640\t\n",
      "Subject: s2, n=06 | test_f1: 0.4127 |best_f1: 0.58333\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0915\tTop_Loss: 0.1419\tBottom_Loss: 0.1829\tLoss: 0.4163\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1473\tTop_Loss: 0.3663\tBottom_Loss: 0.1500\tLoss: 0.6636\t\n",
      "Subject: s2, n=06 | test_f1: 0.19048 |best_f1: 0.58333\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0618\tTop_Loss: 0.1679\tBottom_Loss: 0.1023\tLoss: 0.3320\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1301\tTop_Loss: 0.2082\tBottom_Loss: 0.1845\tLoss: 0.5228\t\n",
      "Subject: s2, n=06 | test_f1: 0.19048 |best_f1: 0.58333\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0871\tTop_Loss: 0.1430\tBottom_Loss: 0.1035\tLoss: 0.3336\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0424\tTop_Loss: 0.0736\tBottom_Loss: 0.1386\tLoss: 0.2546\t\n",
      "Subject: s2, n=06 | test_f1: 0.19048 |best_f1: 0.58333\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0253\tTop_Loss: 0.1324\tBottom_Loss: 0.0717\tLoss: 0.2293\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0591\tTop_Loss: 0.1847\tBottom_Loss: 0.1198\tLoss: 0.3637\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.58333\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0856\tTop_Loss: 0.2133\tBottom_Loss: 0.0938\tLoss: 0.3927\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0279\tTop_Loss: 0.1348\tBottom_Loss: 0.0728\tLoss: 0.2355\t\n",
      "Subject: s2, n=06 | test_f1: 0.19048 |best_f1: 0.58333\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0482\tTop_Loss: 0.1522\tBottom_Loss: 0.0969\tLoss: 0.2973\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1278\tTop_Loss: 0.2269\tBottom_Loss: 0.2034\tLoss: 0.5582\t\n",
      "Subject: s2, n=06 | test_f1: 0.19048 |best_f1: 0.58333\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0542\tTop_Loss: 0.1114\tBottom_Loss: 0.0862\tLoss: 0.2518\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0943\tTop_Loss: 0.1373\tBottom_Loss: 0.1642\tLoss: 0.3958\t\n",
      "Subject: s2, n=06 | test_f1: 0.58333 |best_f1: 0.58333\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0594\tTop_Loss: 0.1007\tBottom_Loss: 0.1388\tLoss: 0.2990\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0748\tTop_Loss: 0.0830\tBottom_Loss: 0.1422\tLoss: 0.3001\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.58333\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0419\tTop_Loss: 0.1189\tBottom_Loss: 0.1234\tLoss: 0.2842\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0429\tTop_Loss: 0.0705\tBottom_Loss: 0.1145\tLoss: 0.2279\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.58333\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0816\tTop_Loss: 0.2441\tBottom_Loss: 0.0828\tLoss: 0.4085\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0271\tTop_Loss: 0.0949\tBottom_Loss: 0.0807\tLoss: 0.2027\t\n",
      "Subject: s2, n=06 | test_f1: 0.19048 |best_f1: 0.58333\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0302\tTop_Loss: 0.1151\tBottom_Loss: 0.0813\tLoss: 0.2266\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0205\tTop_Loss: 0.1183\tBottom_Loss: 0.0633\tLoss: 0.2021\t\n",
      "Subject: s2, n=06 | test_f1: 0.19048 |best_f1: 0.58333\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1455\tTop_Loss: 0.1960\tBottom_Loss: 0.2647\tLoss: 0.6062\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0171\tTop_Loss: 0.0806\tBottom_Loss: 0.0531\tLoss: 0.1507\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.58333\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0256\tTop_Loss: 0.0929\tBottom_Loss: 0.0884\tLoss: 0.2069\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0334\tTop_Loss: 0.1284\tBottom_Loss: 0.0993\tLoss: 0.2611\t\n",
      "Subject: s2, n=06 | test_f1: 0.19048 |best_f1: 0.58333\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0756\tTop_Loss: 0.0804\tBottom_Loss: 0.1232\tLoss: 0.2793\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0281\tTop_Loss: 0.1257\tBottom_Loss: 0.0875\tLoss: 0.2413\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.58333\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0690\tTop_Loss: 0.1397\tBottom_Loss: 0.1919\tLoss: 0.4006\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0205\tTop_Loss: 0.0873\tBottom_Loss: 0.0823\tLoss: 0.1901\t\n",
      "Subject: s2, n=06 | test_f1: 0.19048 |best_f1: 0.58333\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0391\tTop_Loss: 0.1104\tBottom_Loss: 0.0574\tLoss: 0.2069\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0940\tTop_Loss: 0.1534\tBottom_Loss: 0.0702\tLoss: 0.3176\t\n",
      "Subject: s2, n=06 | test_f1: 0.19048 |best_f1: 0.58333\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0206\tTop_Loss: 0.0563\tBottom_Loss: 0.0586\tLoss: 0.1356\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0292\tTop_Loss: 0.1094\tBottom_Loss: 0.0613\tLoss: 0.1998\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.58333\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0713\tTop_Loss: 0.1207\tBottom_Loss: 0.1504\tLoss: 0.3423\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0446\tTop_Loss: 0.1063\tBottom_Loss: 0.0920\tLoss: 0.2429\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.58333\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0556\tTop_Loss: 0.1081\tBottom_Loss: 0.1140\tLoss: 0.2777\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 0.938\tLabel_Loss: 0.0998\tTop_Loss: 0.2321\tBottom_Loss: 0.1480\tLoss: 0.4799\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.58333\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0099\tTop_Loss: 0.0679\tBottom_Loss: 0.0265\tLoss: 0.1043\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0270\tTop_Loss: 0.1146\tBottom_Loss: 0.0440\tLoss: 0.1856\t\n",
      "Subject: s2, n=06 | test_f1: 0.19048 |best_f1: 0.58333\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0522\tTop_Loss: 0.0931\tBottom_Loss: 0.0612\tLoss: 0.2065\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1194\tTop_Loss: 0.2076\tBottom_Loss: 0.1107\tLoss: 0.4378\t\n",
      "Subject: s2, n=06 | test_f1: 0.19048 |best_f1: 0.58333\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0358\tTop_Loss: 0.1027\tBottom_Loss: 0.1007\tLoss: 0.2391\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0356\tTop_Loss: 0.0726\tBottom_Loss: 0.0679\tLoss: 0.1761\t\n",
      "Subject: s2, n=06 | test_f1: 0.4127 |best_f1: 0.58333\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0191\tTop_Loss: 0.0551\tBottom_Loss: 0.0671\tLoss: 0.1413\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0909\tTop_Loss: 0.2550\tBottom_Loss: 0.0288\tLoss: 0.3747\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.58333\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0156\tTop_Loss: 0.0468\tBottom_Loss: 0.0481\tLoss: 0.1105\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0095\tTop_Loss: 0.0369\tBottom_Loss: 0.0344\tLoss: 0.0809\t\n",
      "Subject: s2, n=06 | test_f1: 0.58333 |best_f1: 0.58333\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0088\tTop_Loss: 0.0302\tBottom_Loss: 0.0359\tLoss: 0.0749\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0060\tTop_Loss: 0.0318\tBottom_Loss: 0.0341\tLoss: 0.0719\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.58333\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0491\tTop_Loss: 0.0883\tBottom_Loss: 0.1034\tLoss: 0.2409\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0143\tTop_Loss: 0.0364\tBottom_Loss: 0.0548\tLoss: 0.1055\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.58333\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0104\tTop_Loss: 0.0372\tBottom_Loss: 0.0340\tLoss: 0.0816\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0826\tTop_Loss: 0.0442\tBottom_Loss: 0.1460\tLoss: 0.2728\t\n",
      "Subject: s2, n=06 | test_f1: 0.19048 |best_f1: 0.58333\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0938\tTop_Loss: 0.0954\tBottom_Loss: 0.1390\tLoss: 0.3282\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0216\tTop_Loss: 0.1106\tBottom_Loss: 0.1287\tLoss: 0.2609\t\n",
      "Subject: s2, n=06 | test_f1: 0.19048 |best_f1: 0.58333\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0070\tTop_Loss: 0.0394\tBottom_Loss: 0.0431\tLoss: 0.0894\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0350\tTop_Loss: 0.0831\tBottom_Loss: 0.0842\tLoss: 0.2022\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.58333\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0148\tTop_Loss: 0.1180\tBottom_Loss: 0.0350\tLoss: 0.1678\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0252\tTop_Loss: 0.0520\tBottom_Loss: 0.0556\tLoss: 0.1328\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.58333\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0715\tTop_Loss: 0.0915\tBottom_Loss: 0.2088\tLoss: 0.3717\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0131\tTop_Loss: 0.0597\tBottom_Loss: 0.0259\tLoss: 0.0987\t\n",
      "Subject: s2, n=06 | test_f1: 0.58333 |best_f1: 0.58333\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0169\tTop_Loss: 0.0525\tBottom_Loss: 0.0400\tLoss: 0.1094\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0785\tTop_Loss: 0.0576\tBottom_Loss: 0.1210\tLoss: 0.2571\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.58333\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0318\tTop_Loss: 0.0850\tBottom_Loss: 0.0845\tLoss: 0.2014\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0759\tTop_Loss: 0.0915\tBottom_Loss: 0.2102\tLoss: 0.3776\t\n",
      "Subject: s2, n=06 | test_f1: 0.19048 |best_f1: 0.58333\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0163\tTop_Loss: 0.0793\tBottom_Loss: 0.0469\tLoss: 0.1425\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0367\tTop_Loss: 0.0890\tBottom_Loss: 0.0684\tLoss: 0.1941\t\n",
      "Subject: s2, n=06 | test_f1: 0.19048 |best_f1: 0.58333\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0123\tTop_Loss: 0.0508\tBottom_Loss: 0.0394\tLoss: 0.1024\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0160\tTop_Loss: 0.0979\tBottom_Loss: 0.0213\tLoss: 0.1352\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.58333\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0075\tTop_Loss: 0.0226\tBottom_Loss: 0.0354\tLoss: 0.0655\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0281\tTop_Loss: 0.0779\tBottom_Loss: 0.0612\tLoss: 0.1672\t\n",
      "Subject: s2, n=06 | test_f1: 0.19048 |best_f1: 0.58333\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0138\tTop_Loss: 0.0616\tBottom_Loss: 0.0442\tLoss: 0.1196\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0067\tTop_Loss: 0.0173\tBottom_Loss: 0.0322\tLoss: 0.0562\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.58333\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0093\tTop_Loss: 0.0193\tBottom_Loss: 0.0305\tLoss: 0.0591\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0183\tTop_Loss: 0.0394\tBottom_Loss: 0.0358\tLoss: 0.0934\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.58333\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0067\tTop_Loss: 0.0159\tBottom_Loss: 0.0230\tLoss: 0.0456\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0319\tTop_Loss: 0.0647\tBottom_Loss: 0.0273\tLoss: 0.1239\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.58333\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0039\tTop_Loss: 0.0433\tBottom_Loss: 0.0299\tLoss: 0.0771\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0043\tTop_Loss: 0.0700\tBottom_Loss: 0.0224\tLoss: 0.0966\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.58333\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0132\tTop_Loss: 0.0239\tBottom_Loss: 0.0169\tLoss: 0.0540\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0362\tTop_Loss: 0.0417\tBottom_Loss: 0.0586\tLoss: 0.1365\t\n",
      "Subject: s2, n=06 | test_f1: 0.47222 |best_f1: 0.58333\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0182\tTop_Loss: 0.0363\tBottom_Loss: 0.0467\tLoss: 0.1012\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0244\tTop_Loss: 0.0909\tBottom_Loss: 0.0179\tLoss: 0.1331\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.58333\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0050\tTop_Loss: 0.0261\tBottom_Loss: 0.0331\tLoss: 0.0641\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0462\tTop_Loss: 0.0701\tBottom_Loss: 0.1102\tLoss: 0.2264\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.58333\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0043\tTop_Loss: 0.0201\tBottom_Loss: 0.0145\tLoss: 0.0389\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0096\tTop_Loss: 0.0393\tBottom_Loss: 0.0138\tLoss: 0.0628\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.58333\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0321\tTop_Loss: 0.0241\tBottom_Loss: 0.0580\tLoss: 0.1142\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0126\tTop_Loss: 0.0478\tBottom_Loss: 0.0224\tLoss: 0.0828\t\n",
      "Subject: s2, n=06 | test_f1: 0.25 |best_f1: 0.58333\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0132\tTop_Loss: 0.0278\tBottom_Loss: 0.0180\tLoss: 0.0589\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0104\tTop_Loss: 0.0257\tBottom_Loss: 0.0622\tLoss: 0.0984\t\n",
      "Subject: s2, n=06 | test_f1: 0.11111 |best_f1: 0.58333\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.281\tLabel_Loss: 1.7551\tTop_Loss: 2.4702\tBottom_Loss: 1.4515\tLoss: 5.6768\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.531\tLabel_Loss: 1.1232\tTop_Loss: 1.1745\tBottom_Loss: 1.2060\tLoss: 3.5037\t\n",
      "Subject: s20, n=22 | test_f1: 0.37778 |best_f1: 0.37778\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8784\tTop_Loss: 0.9565\tBottom_Loss: 1.0190\tLoss: 2.8539\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.562\tLabel_Loss: 0.9664\tTop_Loss: 1.0388\tBottom_Loss: 1.0564\tLoss: 3.0616\t\n",
      "Subject: s20, n=22 | test_f1: 0.37179 |best_f1: 0.37778\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.531\tLabel_Loss: 0.9490\tTop_Loss: 0.8218\tBottom_Loss: 0.7978\tLoss: 2.5686\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8552\tTop_Loss: 0.9701\tBottom_Loss: 0.8486\tLoss: 2.6739\t\n",
      "Subject: s20, n=22 | test_f1: 0.66846 |best_f1: 0.66846\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.562\tLabel_Loss: 1.0141\tTop_Loss: 0.9551\tBottom_Loss: 0.9650\tLoss: 2.9342\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.469\tLabel_Loss: 1.1581\tTop_Loss: 1.0646\tBottom_Loss: 1.0854\tLoss: 3.3081\t\n",
      "Subject: s20, n=22 | test_f1: 0.63997 |best_f1: 0.66846\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.656\tLabel_Loss: 0.9567\tTop_Loss: 0.7858\tBottom_Loss: 0.9947\tLoss: 2.7372\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7871\tTop_Loss: 0.8567\tBottom_Loss: 0.9027\tLoss: 2.5465\t\n",
      "Subject: s20, n=22 | test_f1: 0.29839 |best_f1: 0.66846\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.500\tLabel_Loss: 1.1622\tTop_Loss: 1.0708\tBottom_Loss: 1.1476\tLoss: 3.3807\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.656\tLabel_Loss: 0.8111\tTop_Loss: 0.7377\tBottom_Loss: 0.8212\tLoss: 2.3700\t\n",
      "Subject: s20, n=22 | test_f1: 0.50265 |best_f1: 0.66846\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.625\tLabel_Loss: 0.9057\tTop_Loss: 0.9655\tBottom_Loss: 0.8098\tLoss: 2.6809\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.562\tLabel_Loss: 0.8965\tTop_Loss: 0.8984\tBottom_Loss: 0.8991\tLoss: 2.6940\t\n",
      "Subject: s20, n=22 | test_f1: 0.41111 |best_f1: 0.66846\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.594\tLabel_Loss: 0.9333\tTop_Loss: 0.8560\tBottom_Loss: 1.0934\tLoss: 2.8826\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8046\tTop_Loss: 0.7972\tBottom_Loss: 0.9319\tLoss: 2.5336\t\n",
      "Subject: s20, n=22 | test_f1: 0.483 |best_f1: 0.66846\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.500\tLabel_Loss: 0.9426\tTop_Loss: 0.9736\tBottom_Loss: 0.8811\tLoss: 2.7973\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.656\tLabel_Loss: 0.6835\tTop_Loss: 0.8740\tBottom_Loss: 0.6939\tLoss: 2.2514\t\n",
      "Subject: s20, n=22 | test_f1: 0.60306 |best_f1: 0.66846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8397\tTop_Loss: 0.8699\tBottom_Loss: 1.0338\tLoss: 2.7434\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.781\tLabel_Loss: 0.6377\tTop_Loss: 0.6476\tBottom_Loss: 0.6412\tLoss: 1.9265\t\n",
      "Subject: s20, n=22 | test_f1: 0.4531 |best_f1: 0.66846\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7338\tTop_Loss: 0.7938\tBottom_Loss: 0.9798\tLoss: 2.5073\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7830\tTop_Loss: 0.8384\tBottom_Loss: 0.8508\tLoss: 2.4723\t\n",
      "Subject: s20, n=22 | test_f1: 0.48182 |best_f1: 0.66846\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5463\tTop_Loss: 0.7078\tBottom_Loss: 0.6800\tLoss: 1.9341\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.531\tLabel_Loss: 0.9141\tTop_Loss: 0.9932\tBottom_Loss: 1.0372\tLoss: 2.9445\t\n",
      "Subject: s20, n=22 | test_f1: 0.48846 |best_f1: 0.66846\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5691\tTop_Loss: 0.6948\tBottom_Loss: 0.6823\tLoss: 1.9462\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5791\tTop_Loss: 0.6178\tBottom_Loss: 0.6267\tLoss: 1.8237\t\n",
      "Subject: s20, n=22 | test_f1: 0.65556 |best_f1: 0.66846\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5154\tTop_Loss: 0.5292\tBottom_Loss: 0.6208\tLoss: 1.6654\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6910\tTop_Loss: 0.5749\tBottom_Loss: 0.6811\tLoss: 1.9470\t\n",
      "Subject: s20, n=22 | test_f1: 0.23333 |best_f1: 0.66846\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5806\tTop_Loss: 0.8404\tBottom_Loss: 0.6684\tLoss: 2.0895\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6515\tTop_Loss: 0.7331\tBottom_Loss: 0.6783\tLoss: 2.0629\t\n",
      "Subject: s20, n=22 | test_f1: 0.53896 |best_f1: 0.66846\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5794\tTop_Loss: 0.6683\tBottom_Loss: 0.6787\tLoss: 1.9264\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4381\tTop_Loss: 0.5555\tBottom_Loss: 0.7010\tLoss: 1.6946\t\n",
      "Subject: s20, n=22 | test_f1: 0.54921 |best_f1: 0.66846\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6117\tTop_Loss: 0.7091\tBottom_Loss: 0.6934\tLoss: 2.0142\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.906\tLabel_Loss: 0.4545\tTop_Loss: 0.4933\tBottom_Loss: 0.5794\tLoss: 1.5272\t\n",
      "Subject: s20, n=22 | test_f1: 0.60306 |best_f1: 0.66846\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5368\tTop_Loss: 0.6595\tBottom_Loss: 0.6218\tLoss: 1.8181\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5660\tTop_Loss: 0.7372\tBottom_Loss: 0.7561\tLoss: 2.0592\t\n",
      "Subject: s20, n=22 | test_f1: 0.50513 |best_f1: 0.66846\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5501\tTop_Loss: 0.6541\tBottom_Loss: 0.5606\tLoss: 1.7649\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5602\tTop_Loss: 0.6960\tBottom_Loss: 0.7080\tLoss: 1.9642\t\n",
      "Subject: s20, n=22 | test_f1: 0.48914 |best_f1: 0.66846\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4283\tTop_Loss: 0.4842\tBottom_Loss: 0.8575\tLoss: 1.7700\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3439\tTop_Loss: 0.5136\tBottom_Loss: 0.5156\tLoss: 1.3732\t\n",
      "Subject: s20, n=22 | test_f1: 0.36364 |best_f1: 0.66846\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4204\tTop_Loss: 0.6326\tBottom_Loss: 0.5433\tLoss: 1.5962\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5823\tTop_Loss: 0.7740\tBottom_Loss: 0.6376\tLoss: 1.9939\t\n",
      "Subject: s20, n=22 | test_f1: 0.49655 |best_f1: 0.66846\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7632\tTop_Loss: 0.8235\tBottom_Loss: 0.8251\tLoss: 2.4119\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4329\tTop_Loss: 0.5909\tBottom_Loss: 0.5084\tLoss: 1.5322\t\n",
      "Subject: s20, n=22 | test_f1: 0.68327 |best_f1: 0.68327\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.938\tLabel_Loss: 0.3169\tTop_Loss: 0.4353\tBottom_Loss: 0.4071\tLoss: 1.1593\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2986\tTop_Loss: 0.3748\tBottom_Loss: 0.5397\tLoss: 1.2130\t\n",
      "Subject: s20, n=22 | test_f1: 0.60045 |best_f1: 0.68327\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5350\tTop_Loss: 0.6131\tBottom_Loss: 0.5144\tLoss: 1.6626\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4228\tTop_Loss: 0.6405\tBottom_Loss: 0.7279\tLoss: 1.7912\t\n",
      "Subject: s20, n=22 | test_f1: 0.4881 |best_f1: 0.68327\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.906\tLabel_Loss: 0.4741\tTop_Loss: 0.5782\tBottom_Loss: 0.6198\tLoss: 1.6720\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4356\tTop_Loss: 0.5212\tBottom_Loss: 0.5653\tLoss: 1.5220\t\n",
      "Subject: s20, n=22 | test_f1: 0.36848 |best_f1: 0.68327\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3541\tTop_Loss: 0.4556\tBottom_Loss: 0.5248\tLoss: 1.3344\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5845\tTop_Loss: 0.7118\tBottom_Loss: 0.5382\tLoss: 1.8346\t\n",
      "Subject: s20, n=22 | test_f1: 0.4638 |best_f1: 0.68327\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2978\tTop_Loss: 0.3579\tBottom_Loss: 0.4010\tLoss: 1.0567\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.938\tLabel_Loss: 0.3059\tTop_Loss: 0.5811\tBottom_Loss: 0.3989\tLoss: 1.2859\t\n",
      "Subject: s20, n=22 | test_f1: 0.39594 |best_f1: 0.68327\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2962\tTop_Loss: 0.4665\tBottom_Loss: 0.6124\tLoss: 1.3751\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3596\tTop_Loss: 0.3972\tBottom_Loss: 0.4675\tLoss: 1.2244\t\n",
      "Subject: s20, n=22 | test_f1: 0.48846 |best_f1: 0.68327\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4689\tTop_Loss: 0.5779\tBottom_Loss: 0.4607\tLoss: 1.5076\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2289\tTop_Loss: 0.2792\tBottom_Loss: 0.3574\tLoss: 0.8656\t\n",
      "Subject: s20, n=22 | test_f1: 0.58621 |best_f1: 0.68327\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4093\tTop_Loss: 0.4378\tBottom_Loss: 0.4609\tLoss: 1.3080\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4467\tTop_Loss: 0.7651\tBottom_Loss: 0.3449\tLoss: 1.5567\t\n",
      "Subject: s20, n=22 | test_f1: 0.52707 |best_f1: 0.68327\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3810\tTop_Loss: 0.4588\tBottom_Loss: 0.4826\tLoss: 1.3223\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3070\tTop_Loss: 0.5192\tBottom_Loss: 0.5171\tLoss: 1.3433\t\n",
      "Subject: s20, n=22 | test_f1: 0.53016 |best_f1: 0.68327\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2468\tTop_Loss: 0.3737\tBottom_Loss: 0.5648\tLoss: 1.1852\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3047\tTop_Loss: 0.5158\tBottom_Loss: 0.3819\tLoss: 1.2025\t\n",
      "Subject: s20, n=22 | test_f1: 0.73457 |best_f1: 0.73457\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3222\tTop_Loss: 0.5220\tBottom_Loss: 0.2926\tLoss: 1.1368\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3509\tTop_Loss: 0.4751\tBottom_Loss: 0.6028\tLoss: 1.4287\t\n",
      "Subject: s20, n=22 | test_f1: 0.45767 |best_f1: 0.73457\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2265\tTop_Loss: 0.3752\tBottom_Loss: 0.3178\tLoss: 0.9194\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2663\tTop_Loss: 0.4085\tBottom_Loss: 0.4284\tLoss: 1.1032\t\n",
      "Subject: s20, n=22 | test_f1: 0.51492 |best_f1: 0.73457\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1836\tTop_Loss: 0.4581\tBottom_Loss: 0.3148\tLoss: 0.9565\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2936\tTop_Loss: 0.3876\tBottom_Loss: 0.4457\tLoss: 1.1270\t\n",
      "Subject: s20, n=22 | test_f1: 0.52707 |best_f1: 0.73457\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1819\tTop_Loss: 0.3298\tBottom_Loss: 0.2020\tLoss: 0.7138\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2005\tTop_Loss: 0.2825\tBottom_Loss: 0.3836\tLoss: 0.8667\t\n",
      "Subject: s20, n=22 | test_f1: 0.633 |best_f1: 0.73457\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1944\tTop_Loss: 0.3862\tBottom_Loss: 0.2067\tLoss: 0.7872\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1661\tTop_Loss: 0.3072\tBottom_Loss: 0.4332\tLoss: 0.9066\t\n",
      "Subject: s20, n=22 | test_f1: 0.56148 |best_f1: 0.73457\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1669\tTop_Loss: 0.2632\tBottom_Loss: 0.2646\tLoss: 0.6948\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1487\tTop_Loss: 0.3827\tBottom_Loss: 0.1866\tLoss: 0.7180\t\n",
      "Subject: s20, n=22 | test_f1: 0.55806 |best_f1: 0.73457\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1570\tTop_Loss: 0.3199\tBottom_Loss: 0.2241\tLoss: 0.7011\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4093\tTop_Loss: 0.5312\tBottom_Loss: 0.4264\tLoss: 1.3669\t\n",
      "Subject: s20, n=22 | test_f1: 0.53016 |best_f1: 0.73457\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1342\tTop_Loss: 0.2995\tBottom_Loss: 0.2719\tLoss: 0.7056\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2341\tTop_Loss: 0.5387\tBottom_Loss: 0.3651\tLoss: 1.1379\t\n",
      "Subject: s20, n=22 | test_f1: 0.42985 |best_f1: 0.73457\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2510\tTop_Loss: 0.3843\tBottom_Loss: 0.3139\tLoss: 0.9493\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0963\tTop_Loss: 0.2785\tBottom_Loss: 0.1366\tLoss: 0.5114\t\n",
      "Subject: s20, n=22 | test_f1: 0.57672 |best_f1: 0.73457\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1881\tTop_Loss: 0.3974\tBottom_Loss: 0.3443\tLoss: 0.9298\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1176\tTop_Loss: 0.2510\tBottom_Loss: 0.2466\tLoss: 0.6152\t\n",
      "Subject: s20, n=22 | test_f1: 0.52778 |best_f1: 0.73457\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1115\tTop_Loss: 0.2913\tBottom_Loss: 0.1916\tLoss: 0.5944\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1080\tTop_Loss: 0.2505\tBottom_Loss: 0.2331\tLoss: 0.5916\t\n",
      "Subject: s20, n=22 | test_f1: 0.43333 |best_f1: 0.73457\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1119\tTop_Loss: 0.2145\tBottom_Loss: 0.1603\tLoss: 0.4867\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1306\tTop_Loss: 0.2543\tBottom_Loss: 0.3120\tLoss: 0.6969\t\n",
      "Subject: s20, n=22 | test_f1: 0.56566 |best_f1: 0.73457\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1690\tTop_Loss: 0.2149\tBottom_Loss: 0.3088\tLoss: 0.6927\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1835\tTop_Loss: 0.2868\tBottom_Loss: 0.3656\tLoss: 0.8359\t\n",
      "Subject: s20, n=22 | test_f1: 0.4127 |best_f1: 0.73457\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1594\tTop_Loss: 0.3999\tBottom_Loss: 0.2675\tLoss: 0.8268\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1545\tTop_Loss: 0.2894\tBottom_Loss: 0.2214\tLoss: 0.6653\t\n",
      "Subject: s20, n=22 | test_f1: 0.6358 |best_f1: 0.73457\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1435\tTop_Loss: 0.3399\tBottom_Loss: 0.2410\tLoss: 0.7244\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3542\tTop_Loss: 0.4811\tBottom_Loss: 0.2589\tLoss: 1.0942\t\n",
      "Subject: s20, n=22 | test_f1: 0.71634 |best_f1: 0.73457\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1561\tTop_Loss: 0.3217\tBottom_Loss: 0.2147\tLoss: 0.6925\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0882\tTop_Loss: 0.1336\tBottom_Loss: 0.2964\tLoss: 0.5182\t\n",
      "Subject: s20, n=22 | test_f1: 0.50369 |best_f1: 0.73457\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1633\tTop_Loss: 0.2251\tBottom_Loss: 0.2081\tLoss: 0.5966\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0466\tTop_Loss: 0.1725\tBottom_Loss: 0.1279\tLoss: 0.3470\t\n",
      "Subject: s20, n=22 | test_f1: 0.53077 |best_f1: 0.73457\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0879\tTop_Loss: 0.1358\tBottom_Loss: 0.2328\tLoss: 0.4565\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1736\tTop_Loss: 0.2464\tBottom_Loss: 0.1903\tLoss: 0.6102\t\n",
      "Subject: s20, n=22 | test_f1: 0.72875 |best_f1: 0.73457\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1325\tTop_Loss: 0.2082\tBottom_Loss: 0.2864\tLoss: 0.6271\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0822\tTop_Loss: 0.1893\tBottom_Loss: 0.1594\tLoss: 0.4308\t\n",
      "Subject: s20, n=22 | test_f1: 0.53016 |best_f1: 0.73457\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0741\tTop_Loss: 0.1140\tBottom_Loss: 0.1742\tLoss: 0.3623\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0872\tTop_Loss: 0.1588\tBottom_Loss: 0.1989\tLoss: 0.4449\t\n",
      "Subject: s20, n=22 | test_f1: 0.50707 |best_f1: 0.73457\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1646\tTop_Loss: 0.2941\tBottom_Loss: 0.1932\tLoss: 0.6520\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0789\tTop_Loss: 0.2723\tBottom_Loss: 0.1321\tLoss: 0.4833\t\n",
      "Subject: s20, n=22 | test_f1: 0.53077 |best_f1: 0.73457\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0814\tTop_Loss: 0.2571\tBottom_Loss: 0.1650\tLoss: 0.5035\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1310\tTop_Loss: 0.2552\tBottom_Loss: 0.1630\tLoss: 0.5492\t\n",
      "Subject: s20, n=22 | test_f1: 0.61002 |best_f1: 0.73457\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1227\tTop_Loss: 0.2504\tBottom_Loss: 0.1522\tLoss: 0.5253\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0378\tTop_Loss: 0.1260\tBottom_Loss: 0.1214\tLoss: 0.2852\t\n",
      "Subject: s20, n=22 | test_f1: 0.46429 |best_f1: 0.73457\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0841\tTop_Loss: 0.2297\tBottom_Loss: 0.1682\tLoss: 0.4821\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0861\tTop_Loss: 0.1525\tBottom_Loss: 0.1611\tLoss: 0.3997\t\n",
      "Subject: s20, n=22 | test_f1: 0.64762 |best_f1: 0.73457\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0508\tTop_Loss: 0.1638\tBottom_Loss: 0.1064\tLoss: 0.3210\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1261\tTop_Loss: 0.2314\tBottom_Loss: 0.1746\tLoss: 0.5322\t\n",
      "Subject: s20, n=22 | test_f1: 0.5463 |best_f1: 0.73457\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0641\tTop_Loss: 0.1740\tBottom_Loss: 0.1764\tLoss: 0.4145\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0995\tTop_Loss: 0.2635\tBottom_Loss: 0.2110\tLoss: 0.5740\t\n",
      "Subject: s20, n=22 | test_f1: 0.53704 |best_f1: 0.73457\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1245\tTop_Loss: 0.3351\tBottom_Loss: 0.1615\tLoss: 0.6211\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0737\tTop_Loss: 0.1584\tBottom_Loss: 0.1133\tLoss: 0.3454\t\n",
      "Subject: s20, n=22 | test_f1: 0.50513 |best_f1: 0.73457\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1040\tTop_Loss: 0.2947\tBottom_Loss: 0.1352\tLoss: 0.5339\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0350\tTop_Loss: 0.1898\tBottom_Loss: 0.0381\tLoss: 0.2629\t\n",
      "Subject: s20, n=22 | test_f1: 0.55556 |best_f1: 0.73457\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1363\tTop_Loss: 0.1181\tBottom_Loss: 0.2956\tLoss: 0.5500\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0213\tTop_Loss: 0.0785\tBottom_Loss: 0.0819\tLoss: 0.1817\t\n",
      "Subject: s20, n=22 | test_f1: 0.44048 |best_f1: 0.73457\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1479\tTop_Loss: 0.2006\tBottom_Loss: 0.1679\tLoss: 0.5164\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0495\tTop_Loss: 0.1924\tBottom_Loss: 0.0980\tLoss: 0.3399\t\n",
      "Subject: s20, n=22 | test_f1: 0.53704 |best_f1: 0.73457\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0518\tTop_Loss: 0.1289\tBottom_Loss: 0.0930\tLoss: 0.2737\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1718\tTop_Loss: 0.1900\tBottom_Loss: 0.1702\tLoss: 0.5320\t\n",
      "Subject: s20, n=22 | test_f1: 0.54603 |best_f1: 0.73457\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0694\tTop_Loss: 0.1799\tBottom_Loss: 0.1053\tLoss: 0.3546\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1056\tTop_Loss: 0.1794\tBottom_Loss: 0.1867\tLoss: 0.4717\t\n",
      "Subject: s20, n=22 | test_f1: 0.53016 |best_f1: 0.73457\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0301\tTop_Loss: 0.1027\tBottom_Loss: 0.0607\tLoss: 0.1935\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0699\tTop_Loss: 0.1698\tBottom_Loss: 0.1457\tLoss: 0.3854\t\n",
      "Subject: s20, n=22 | test_f1: 0.3355 |best_f1: 0.73457\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 0.938\tLabel_Loss: 0.0796\tTop_Loss: 0.1602\tBottom_Loss: 0.0906\tLoss: 0.3304\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0997\tTop_Loss: 0.1339\tBottom_Loss: 0.1371\tLoss: 0.3707\t\n",
      "Subject: s20, n=22 | test_f1: 0.49306 |best_f1: 0.73457\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0672\tTop_Loss: 0.0752\tBottom_Loss: 0.1555\tLoss: 0.2978\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0785\tTop_Loss: 0.2463\tBottom_Loss: 0.0779\tLoss: 0.4026\t\n",
      "Subject: s20, n=22 | test_f1: 0.49444 |best_f1: 0.73457\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1323\tTop_Loss: 0.1849\tBottom_Loss: 0.1875\tLoss: 0.5047\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0612\tTop_Loss: 0.1670\tBottom_Loss: 0.0910\tLoss: 0.3192\t\n",
      "Subject: s20, n=22 | test_f1: 0.70833 |best_f1: 0.73457\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0643\tTop_Loss: 0.1679\tBottom_Loss: 0.2042\tLoss: 0.4365\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0185\tTop_Loss: 0.1274\tBottom_Loss: 0.0640\tLoss: 0.2099\t\n",
      "Subject: s20, n=22 | test_f1: 0.6358 |best_f1: 0.73457\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0949\tTop_Loss: 0.1972\tBottom_Loss: 0.0953\tLoss: 0.3873\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0207\tTop_Loss: 0.0640\tBottom_Loss: 0.0589\tLoss: 0.1436\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: s20, n=22 | test_f1: 0.64506 |best_f1: 0.73457\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0723\tTop_Loss: 0.1354\tBottom_Loss: 0.0857\tLoss: 0.2933\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0262\tTop_Loss: 0.0749\tBottom_Loss: 0.0651\tLoss: 0.1662\t\n",
      "Subject: s20, n=22 | test_f1: 0.63739 |best_f1: 0.73457\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0410\tTop_Loss: 0.1059\tBottom_Loss: 0.1580\tLoss: 0.3050\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0364\tTop_Loss: 0.0712\tBottom_Loss: 0.0946\tLoss: 0.2021\t\n",
      "Subject: s20, n=22 | test_f1: 0.5463 |best_f1: 0.73457\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0357\tTop_Loss: 0.1679\tBottom_Loss: 0.0485\tLoss: 0.2522\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0349\tTop_Loss: 0.0474\tBottom_Loss: 0.1027\tLoss: 0.1850\t\n",
      "Subject: s20, n=22 | test_f1: 0.65481 |best_f1: 0.73457\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0318\tTop_Loss: 0.0957\tBottom_Loss: 0.0528\tLoss: 0.1803\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0171\tTop_Loss: 0.1055\tBottom_Loss: 0.0681\tLoss: 0.1907\t\n",
      "Subject: s20, n=22 | test_f1: 0.72875 |best_f1: 0.73457\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1089\tTop_Loss: 0.1392\tBottom_Loss: 0.1086\tLoss: 0.3568\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0322\tTop_Loss: 0.1232\tBottom_Loss: 0.0460\tLoss: 0.2014\t\n",
      "Subject: s20, n=22 | test_f1: 0.55247 |best_f1: 0.73457\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0293\tTop_Loss: 0.1676\tBottom_Loss: 0.0793\tLoss: 0.2762\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0569\tTop_Loss: 0.1785\tBottom_Loss: 0.0977\tLoss: 0.3332\t\n",
      "Subject: s20, n=22 | test_f1: 0.72031 |best_f1: 0.73457\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0555\tTop_Loss: 0.1105\tBottom_Loss: 0.0864\tLoss: 0.2525\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0433\tTop_Loss: 0.0664\tBottom_Loss: 0.0436\tLoss: 0.1533\t\n",
      "Subject: s20, n=22 | test_f1: 0.52222 |best_f1: 0.73457\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0095\tTop_Loss: 0.0462\tBottom_Loss: 0.0313\tLoss: 0.0870\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0390\tTop_Loss: 0.1462\tBottom_Loss: 0.0803\tLoss: 0.2655\t\n",
      "Subject: s20, n=22 | test_f1: 0.57143 |best_f1: 0.73457\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0445\tTop_Loss: 0.1309\tBottom_Loss: 0.1444\tLoss: 0.3198\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0559\tTop_Loss: 0.2044\tBottom_Loss: 0.0325\tLoss: 0.2928\t\n",
      "Subject: s20, n=22 | test_f1: 0.52668 |best_f1: 0.73457\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0122\tTop_Loss: 0.0391\tBottom_Loss: 0.0487\tLoss: 0.1000\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0087\tTop_Loss: 0.0275\tBottom_Loss: 0.0290\tLoss: 0.0651\t\n",
      "Subject: s20, n=22 | test_f1: 0.56889 |best_f1: 0.73457\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0188\tTop_Loss: 0.0559\tBottom_Loss: 0.0633\tLoss: 0.1380\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0184\tTop_Loss: 0.0801\tBottom_Loss: 0.0373\tLoss: 0.1358\t\n",
      "Subject: s20, n=22 | test_f1: 0.53704 |best_f1: 0.73457\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0171\tTop_Loss: 0.1197\tBottom_Loss: 0.0454\tLoss: 0.1822\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0124\tTop_Loss: 0.0459\tBottom_Loss: 0.0428\tLoss: 0.1010\t\n",
      "Subject: s20, n=22 | test_f1: 0.59464 |best_f1: 0.73457\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0183\tTop_Loss: 0.0573\tBottom_Loss: 0.0446\tLoss: 0.1201\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0565\tTop_Loss: 0.1363\tBottom_Loss: 0.0625\tLoss: 0.2553\t\n",
      "Subject: s20, n=22 | test_f1: 0.67586 |best_f1: 0.73457\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0491\tTop_Loss: 0.0556\tBottom_Loss: 0.0370\tLoss: 0.1418\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0057\tTop_Loss: 0.0382\tBottom_Loss: 0.0160\tLoss: 0.0598\t\n",
      "Subject: s20, n=22 | test_f1: 0.54246 |best_f1: 0.73457\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0356\tTop_Loss: 0.0754\tBottom_Loss: 0.0828\tLoss: 0.1939\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0253\tTop_Loss: 0.0489\tBottom_Loss: 0.0371\tLoss: 0.1113\t\n",
      "Subject: s20, n=22 | test_f1: 0.65556 |best_f1: 0.73457\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0450\tTop_Loss: 0.1174\tBottom_Loss: 0.0312\tLoss: 0.1937\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0267\tTop_Loss: 0.0741\tBottom_Loss: 0.0530\tLoss: 0.1538\t\n",
      "Subject: s20, n=22 | test_f1: 0.44291 |best_f1: 0.73457\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0106\tTop_Loss: 0.0644\tBottom_Loss: 0.0545\tLoss: 0.1294\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0353\tTop_Loss: 0.0857\tBottom_Loss: 0.0953\tLoss: 0.2162\t\n",
      "Subject: s20, n=22 | test_f1: 0.67857 |best_f1: 0.73457\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0095\tTop_Loss: 0.0406\tBottom_Loss: 0.0752\tLoss: 0.1252\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0273\tTop_Loss: 0.1594\tBottom_Loss: 0.0230\tLoss: 0.2096\t\n",
      "Subject: s20, n=22 | test_f1: 0.62626 |best_f1: 0.73457\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0307\tTop_Loss: 0.0925\tBottom_Loss: 0.1190\tLoss: 0.2422\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0417\tTop_Loss: 0.0707\tBottom_Loss: 0.0529\tLoss: 0.1653\t\n",
      "Subject: s20, n=22 | test_f1: 0.57957 |best_f1: 0.73457\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0206\tTop_Loss: 0.0824\tBottom_Loss: 0.0306\tLoss: 0.1335\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0180\tTop_Loss: 0.0703\tBottom_Loss: 0.0534\tLoss: 0.1418\t\n",
      "Subject: s20, n=22 | test_f1: 0.52222 |best_f1: 0.73457\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0189\tTop_Loss: 0.0196\tBottom_Loss: 0.0296\tLoss: 0.0680\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0223\tTop_Loss: 0.0620\tBottom_Loss: 0.1007\tLoss: 0.1850\t\n",
      "Subject: s20, n=22 | test_f1: 0.6141 |best_f1: 0.73457\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0287\tTop_Loss: 0.0719\tBottom_Loss: 0.0454\tLoss: 0.1460\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0238\tTop_Loss: 0.0550\tBottom_Loss: 0.0633\tLoss: 0.1421\t\n",
      "Subject: s20, n=22 | test_f1: 0.64506 |best_f1: 0.73457\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0136\tTop_Loss: 0.0584\tBottom_Loss: 0.0312\tLoss: 0.1032\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0207\tTop_Loss: 0.1035\tBottom_Loss: 0.0443\tLoss: 0.1685\t\n",
      "Subject: s20, n=22 | test_f1: 0.67857 |best_f1: 0.73457\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0175\tTop_Loss: 0.1005\tBottom_Loss: 0.0394\tLoss: 0.1574\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0105\tTop_Loss: 0.0359\tBottom_Loss: 0.0240\tLoss: 0.0705\t\n",
      "Subject: s20, n=22 | test_f1: 0.55806 |best_f1: 0.73457\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0091\tTop_Loss: 0.0409\tBottom_Loss: 0.0580\tLoss: 0.1079\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0096\tTop_Loss: 0.0508\tBottom_Loss: 0.0224\tLoss: 0.0828\t\n",
      "Subject: s20, n=22 | test_f1: 0.58621 |best_f1: 0.73457\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0353\tTop_Loss: 0.0422\tBottom_Loss: 0.1455\tLoss: 0.2230\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0079\tTop_Loss: 0.0286\tBottom_Loss: 0.0163\tLoss: 0.0528\t\n",
      "Subject: s20, n=22 | test_f1: 0.51746 |best_f1: 0.73457\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0068\tTop_Loss: 0.0254\tBottom_Loss: 0.0146\tLoss: 0.0468\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0186\tTop_Loss: 0.0281\tBottom_Loss: 0.0344\tLoss: 0.0811\t\n",
      "Subject: s20, n=22 | test_f1: 0.62324 |best_f1: 0.73457\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0084\tTop_Loss: 0.1007\tBottom_Loss: 0.0129\tLoss: 0.1220\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0059\tTop_Loss: 0.0256\tBottom_Loss: 0.0395\tLoss: 0.0710\t\n",
      "Subject: s20, n=22 | test_f1: 0.55556 |best_f1: 0.73457\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0049\tTop_Loss: 0.0345\tBottom_Loss: 0.0109\tLoss: 0.0503\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0080\tTop_Loss: 0.0210\tBottom_Loss: 0.0192\tLoss: 0.0482\t\n",
      "Subject: s20, n=22 | test_f1: 0.56148 |best_f1: 0.73457\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0147\tTop_Loss: 0.0442\tBottom_Loss: 0.0360\tLoss: 0.0949\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0107\tTop_Loss: 0.0571\tBottom_Loss: 0.0458\tLoss: 0.1136\t\n",
      "Subject: s20, n=22 | test_f1: 0.53704 |best_f1: 0.73457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[0][1/13]   \tAcc: 0.188\tLabel_Loss: 1.9949\tTop_Loss: 1.3948\tBottom_Loss: 1.6230\tLoss: 5.0127\t\n",
      "Train:\tEpoch:[0][8/13]   \tAcc: 0.375\tLabel_Loss: 1.1802\tTop_Loss: 1.2377\tBottom_Loss: 1.1302\tLoss: 3.5481\t\n",
      "Subject: s3, n=39 | test_f1: 0.25304 |best_f1: 0.25304\n",
      "Train:\tEpoch:[1][1/13]   \tAcc: 0.625\tLabel_Loss: 0.8601\tTop_Loss: 0.9424\tBottom_Loss: 0.9135\tLoss: 2.7161\t\n",
      "Train:\tEpoch:[1][8/13]   \tAcc: 0.438\tLabel_Loss: 1.0883\tTop_Loss: 1.1448\tBottom_Loss: 1.0562\tLoss: 3.2893\t\n",
      "Subject: s3, n=39 | test_f1: 0.39064 |best_f1: 0.39064\n",
      "Train:\tEpoch:[2][1/13]   \tAcc: 0.688\tLabel_Loss: 0.7620\tTop_Loss: 0.7364\tBottom_Loss: 0.8013\tLoss: 2.2997\t\n",
      "Train:\tEpoch:[2][8/13]   \tAcc: 0.625\tLabel_Loss: 0.8321\tTop_Loss: 0.9372\tBottom_Loss: 0.9708\tLoss: 2.7401\t\n",
      "Subject: s3, n=39 | test_f1: 0.31203 |best_f1: 0.39064\n",
      "Train:\tEpoch:[3][1/13]   \tAcc: 0.656\tLabel_Loss: 0.9103\tTop_Loss: 0.9932\tBottom_Loss: 0.7955\tLoss: 2.6990\t\n",
      "Train:\tEpoch:[3][8/13]   \tAcc: 0.719\tLabel_Loss: 0.6793\tTop_Loss: 0.8334\tBottom_Loss: 0.8744\tLoss: 2.3871\t\n",
      "Subject: s3, n=39 | test_f1: 0.23392 |best_f1: 0.39064\n",
      "Train:\tEpoch:[4][1/13]   \tAcc: 0.594\tLabel_Loss: 0.8975\tTop_Loss: 0.8038\tBottom_Loss: 0.8816\tLoss: 2.5829\t\n",
      "Train:\tEpoch:[4][8/13]   \tAcc: 0.500\tLabel_Loss: 0.9683\tTop_Loss: 0.8723\tBottom_Loss: 1.0147\tLoss: 2.8553\t\n",
      "Subject: s3, n=39 | test_f1: 0.44534 |best_f1: 0.44534\n",
      "Train:\tEpoch:[5][1/13]   \tAcc: 0.719\tLabel_Loss: 0.8394\tTop_Loss: 0.8873\tBottom_Loss: 1.0473\tLoss: 2.7741\t\n",
      "Train:\tEpoch:[5][8/13]   \tAcc: 0.688\tLabel_Loss: 0.9692\tTop_Loss: 0.8181\tBottom_Loss: 0.9109\tLoss: 2.6982\t\n",
      "Subject: s3, n=39 | test_f1: 0.39376 |best_f1: 0.44534\n",
      "Train:\tEpoch:[6][1/13]   \tAcc: 0.625\tLabel_Loss: 0.7156\tTop_Loss: 0.6505\tBottom_Loss: 0.8848\tLoss: 2.2510\t\n",
      "Train:\tEpoch:[6][8/13]   \tAcc: 0.531\tLabel_Loss: 0.8926\tTop_Loss: 0.9654\tBottom_Loss: 0.9290\tLoss: 2.7869\t\n",
      "Subject: s3, n=39 | test_f1: 0.35 |best_f1: 0.44534\n",
      "Train:\tEpoch:[7][1/13]   \tAcc: 0.688\tLabel_Loss: 0.7982\tTop_Loss: 0.8585\tBottom_Loss: 0.8070\tLoss: 2.4637\t\n",
      "Train:\tEpoch:[7][8/13]   \tAcc: 0.562\tLabel_Loss: 0.9686\tTop_Loss: 0.9030\tBottom_Loss: 1.0551\tLoss: 2.9266\t\n",
      "Subject: s3, n=39 | test_f1: 0.52421 |best_f1: 0.52421\n",
      "Train:\tEpoch:[8][1/13]   \tAcc: 0.656\tLabel_Loss: 0.7428\tTop_Loss: 0.8088\tBottom_Loss: 0.8128\tLoss: 2.3645\t\n",
      "Train:\tEpoch:[8][8/13]   \tAcc: 0.719\tLabel_Loss: 0.6972\tTop_Loss: 0.9322\tBottom_Loss: 0.7355\tLoss: 2.3649\t\n",
      "Subject: s3, n=39 | test_f1: 0.30688 |best_f1: 0.52421\n",
      "Train:\tEpoch:[9][1/13]   \tAcc: 0.562\tLabel_Loss: 0.8511\tTop_Loss: 0.7291\tBottom_Loss: 0.9076\tLoss: 2.4878\t\n",
      "Train:\tEpoch:[9][8/13]   \tAcc: 0.656\tLabel_Loss: 0.6661\tTop_Loss: 0.7125\tBottom_Loss: 0.6894\tLoss: 2.0681\t\n",
      "Subject: s3, n=39 | test_f1: 0.48001 |best_f1: 0.52421\n",
      "Train:\tEpoch:[10][1/13]   \tAcc: 0.719\tLabel_Loss: 0.6161\tTop_Loss: 0.7631\tBottom_Loss: 0.5628\tLoss: 1.9420\t\n",
      "Train:\tEpoch:[10][8/13]   \tAcc: 0.594\tLabel_Loss: 0.8178\tTop_Loss: 0.9058\tBottom_Loss: 0.8196\tLoss: 2.5432\t\n",
      "Subject: s3, n=39 | test_f1: 0.41096 |best_f1: 0.52421\n",
      "Train:\tEpoch:[11][1/13]   \tAcc: 0.781\tLabel_Loss: 0.6799\tTop_Loss: 0.7524\tBottom_Loss: 0.8769\tLoss: 2.3092\t\n",
      "Train:\tEpoch:[11][8/13]   \tAcc: 0.750\tLabel_Loss: 0.6817\tTop_Loss: 0.8334\tBottom_Loss: 0.9228\tLoss: 2.4379\t\n",
      "Subject: s3, n=39 | test_f1: 0.60193 |best_f1: 0.60193\n",
      "Train:\tEpoch:[12][1/13]   \tAcc: 0.781\tLabel_Loss: 0.6247\tTop_Loss: 0.8095\tBottom_Loss: 0.8890\tLoss: 2.3232\t\n",
      "Train:\tEpoch:[12][8/13]   \tAcc: 0.719\tLabel_Loss: 0.6826\tTop_Loss: 0.7477\tBottom_Loss: 0.6668\tLoss: 2.0971\t\n",
      "Subject: s3, n=39 | test_f1: 0.50998 |best_f1: 0.60193\n",
      "Train:\tEpoch:[13][1/13]   \tAcc: 0.719\tLabel_Loss: 0.6474\tTop_Loss: 0.7809\tBottom_Loss: 0.6595\tLoss: 2.0878\t\n",
      "Train:\tEpoch:[13][8/13]   \tAcc: 0.688\tLabel_Loss: 0.6702\tTop_Loss: 0.7485\tBottom_Loss: 0.7981\tLoss: 2.2168\t\n",
      "Subject: s3, n=39 | test_f1: 0.4521 |best_f1: 0.60193\n",
      "Train:\tEpoch:[14][1/13]   \tAcc: 0.656\tLabel_Loss: 0.7025\tTop_Loss: 0.9498\tBottom_Loss: 0.8396\tLoss: 2.4919\t\n",
      "Train:\tEpoch:[14][8/13]   \tAcc: 0.844\tLabel_Loss: 0.5329\tTop_Loss: 0.5599\tBottom_Loss: 0.6360\tLoss: 1.7289\t\n",
      "Subject: s3, n=39 | test_f1: 0.42589 |best_f1: 0.60193\n",
      "Train:\tEpoch:[15][1/13]   \tAcc: 0.812\tLabel_Loss: 0.5662\tTop_Loss: 0.8004\tBottom_Loss: 0.7336\tLoss: 2.1001\t\n",
      "Train:\tEpoch:[15][8/13]   \tAcc: 0.750\tLabel_Loss: 0.6060\tTop_Loss: 0.5959\tBottom_Loss: 0.6815\tLoss: 1.8834\t\n",
      "Subject: s3, n=39 | test_f1: 0.31667 |best_f1: 0.60193\n",
      "Train:\tEpoch:[16][1/13]   \tAcc: 0.781\tLabel_Loss: 0.4276\tTop_Loss: 0.4637\tBottom_Loss: 0.5000\tLoss: 1.3913\t\n",
      "Train:\tEpoch:[16][8/13]   \tAcc: 0.750\tLabel_Loss: 0.5986\tTop_Loss: 0.5849\tBottom_Loss: 0.7335\tLoss: 1.9170\t\n",
      "Subject: s3, n=39 | test_f1: 0.49304 |best_f1: 0.60193\n",
      "Train:\tEpoch:[17][1/13]   \tAcc: 0.719\tLabel_Loss: 0.5753\tTop_Loss: 0.5872\tBottom_Loss: 0.6790\tLoss: 1.8416\t\n",
      "Train:\tEpoch:[17][8/13]   \tAcc: 0.594\tLabel_Loss: 0.8616\tTop_Loss: 0.8446\tBottom_Loss: 0.7462\tLoss: 2.4524\t\n",
      "Subject: s3, n=39 | test_f1: 0.42553 |best_f1: 0.60193\n",
      "Train:\tEpoch:[18][1/13]   \tAcc: 0.844\tLabel_Loss: 0.3980\tTop_Loss: 0.5346\tBottom_Loss: 0.5201\tLoss: 1.4526\t\n",
      "Train:\tEpoch:[18][8/13]   \tAcc: 0.688\tLabel_Loss: 0.6017\tTop_Loss: 0.7230\tBottom_Loss: 0.8214\tLoss: 2.1461\t\n",
      "Subject: s3, n=39 | test_f1: 0.43756 |best_f1: 0.60193\n",
      "Train:\tEpoch:[19][1/13]   \tAcc: 0.844\tLabel_Loss: 0.4986\tTop_Loss: 0.5148\tBottom_Loss: 0.7458\tLoss: 1.7593\t\n",
      "Train:\tEpoch:[19][8/13]   \tAcc: 0.844\tLabel_Loss: 0.5025\tTop_Loss: 0.5159\tBottom_Loss: 0.8081\tLoss: 1.8266\t\n",
      "Subject: s3, n=39 | test_f1: 0.39541 |best_f1: 0.60193\n",
      "Train:\tEpoch:[20][1/13]   \tAcc: 0.781\tLabel_Loss: 0.5655\tTop_Loss: 0.7384\tBottom_Loss: 0.6621\tLoss: 1.9660\t\n",
      "Train:\tEpoch:[20][8/13]   \tAcc: 0.750\tLabel_Loss: 0.6097\tTop_Loss: 0.6945\tBottom_Loss: 0.5849\tLoss: 1.8891\t\n",
      "Subject: s3, n=39 | test_f1: 0.44179 |best_f1: 0.60193\n",
      "Train:\tEpoch:[21][1/13]   \tAcc: 0.844\tLabel_Loss: 0.4301\tTop_Loss: 0.5324\tBottom_Loss: 0.5512\tLoss: 1.5136\t\n",
      "Train:\tEpoch:[21][8/13]   \tAcc: 0.812\tLabel_Loss: 0.5943\tTop_Loss: 0.6755\tBottom_Loss: 0.6878\tLoss: 1.9577\t\n",
      "Subject: s3, n=39 | test_f1: 0.43757 |best_f1: 0.60193\n",
      "Train:\tEpoch:[22][1/13]   \tAcc: 0.812\tLabel_Loss: 0.4567\tTop_Loss: 0.4781\tBottom_Loss: 0.6157\tLoss: 1.5505\t\n",
      "Train:\tEpoch:[22][8/13]   \tAcc: 0.812\tLabel_Loss: 0.4318\tTop_Loss: 0.4825\tBottom_Loss: 0.6432\tLoss: 1.5576\t\n",
      "Subject: s3, n=39 | test_f1: 0.58211 |best_f1: 0.60193\n",
      "Train:\tEpoch:[23][1/13]   \tAcc: 0.781\tLabel_Loss: 0.4441\tTop_Loss: 0.6802\tBottom_Loss: 0.6339\tLoss: 1.7582\t\n",
      "Train:\tEpoch:[23][8/13]   \tAcc: 0.750\tLabel_Loss: 0.4129\tTop_Loss: 0.6042\tBottom_Loss: 0.6026\tLoss: 1.6196\t\n",
      "Subject: s3, n=39 | test_f1: 0.51296 |best_f1: 0.60193\n",
      "Train:\tEpoch:[24][1/13]   \tAcc: 0.781\tLabel_Loss: 0.4282\tTop_Loss: 0.4230\tBottom_Loss: 0.5848\tLoss: 1.4360\t\n",
      "Train:\tEpoch:[24][8/13]   \tAcc: 0.844\tLabel_Loss: 0.4438\tTop_Loss: 0.6302\tBottom_Loss: 0.5996\tLoss: 1.6736\t\n",
      "Subject: s3, n=39 | test_f1: 0.45178 |best_f1: 0.60193\n",
      "Train:\tEpoch:[25][1/13]   \tAcc: 0.875\tLabel_Loss: 0.3509\tTop_Loss: 0.4755\tBottom_Loss: 0.4608\tLoss: 1.2872\t\n",
      "Train:\tEpoch:[25][8/13]   \tAcc: 0.875\tLabel_Loss: 0.3755\tTop_Loss: 0.5001\tBottom_Loss: 0.6312\tLoss: 1.5068\t\n",
      "Subject: s3, n=39 | test_f1: 0.44048 |best_f1: 0.60193\n",
      "Train:\tEpoch:[26][1/13]   \tAcc: 0.906\tLabel_Loss: 0.3439\tTop_Loss: 0.4756\tBottom_Loss: 0.4113\tLoss: 1.2308\t\n",
      "Train:\tEpoch:[26][8/13]   \tAcc: 0.969\tLabel_Loss: 0.2859\tTop_Loss: 0.3258\tBottom_Loss: 0.5442\tLoss: 1.1559\t\n",
      "Subject: s3, n=39 | test_f1: 0.39463 |best_f1: 0.60193\n",
      "Train:\tEpoch:[27][1/13]   \tAcc: 0.969\tLabel_Loss: 0.2308\tTop_Loss: 0.3249\tBottom_Loss: 0.4613\tLoss: 1.0170\t\n",
      "Train:\tEpoch:[27][8/13]   \tAcc: 0.719\tLabel_Loss: 0.4730\tTop_Loss: 0.4519\tBottom_Loss: 0.7370\tLoss: 1.6619\t\n",
      "Subject: s3, n=39 | test_f1: 0.48108 |best_f1: 0.60193\n",
      "Train:\tEpoch:[28][1/13]   \tAcc: 0.969\tLabel_Loss: 0.2039\tTop_Loss: 0.2903\tBottom_Loss: 0.4849\tLoss: 0.9791\t\n",
      "Train:\tEpoch:[28][8/13]   \tAcc: 0.812\tLabel_Loss: 0.3797\tTop_Loss: 0.5127\tBottom_Loss: 0.4289\tLoss: 1.3213\t\n",
      "Subject: s3, n=39 | test_f1: 0.5093 |best_f1: 0.60193\n",
      "Train:\tEpoch:[29][1/13]   \tAcc: 0.875\tLabel_Loss: 0.3311\tTop_Loss: 0.4281\tBottom_Loss: 0.5181\tLoss: 1.2773\t\n",
      "Train:\tEpoch:[29][8/13]   \tAcc: 0.969\tLabel_Loss: 0.2366\tTop_Loss: 0.3308\tBottom_Loss: 0.4685\tLoss: 1.0358\t\n",
      "Subject: s3, n=39 | test_f1: 0.3725 |best_f1: 0.60193\n",
      "Train:\tEpoch:[30][1/13]   \tAcc: 0.969\tLabel_Loss: 0.1929\tTop_Loss: 0.3446\tBottom_Loss: 0.3414\tLoss: 0.8789\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[30][8/13]   \tAcc: 0.969\tLabel_Loss: 0.1438\tTop_Loss: 0.2475\tBottom_Loss: 0.2726\tLoss: 0.6639\t\n",
      "Subject: s3, n=39 | test_f1: 0.39848 |best_f1: 0.60193\n",
      "Train:\tEpoch:[31][1/13]   \tAcc: 0.969\tLabel_Loss: 0.2038\tTop_Loss: 0.3002\tBottom_Loss: 0.3452\tLoss: 0.8493\t\n",
      "Train:\tEpoch:[31][8/13]   \tAcc: 0.781\tLabel_Loss: 0.4519\tTop_Loss: 0.4025\tBottom_Loss: 0.5725\tLoss: 1.4269\t\n",
      "Subject: s3, n=39 | test_f1: 0.52137 |best_f1: 0.60193\n",
      "Train:\tEpoch:[32][1/13]   \tAcc: 1.000\tLabel_Loss: 0.1763\tTop_Loss: 0.3212\tBottom_Loss: 0.4432\tLoss: 0.9407\t\n",
      "Train:\tEpoch:[32][8/13]   \tAcc: 0.938\tLabel_Loss: 0.2687\tTop_Loss: 0.3254\tBottom_Loss: 0.5328\tLoss: 1.1269\t\n",
      "Subject: s3, n=39 | test_f1: 0.41953 |best_f1: 0.60193\n",
      "Train:\tEpoch:[33][1/13]   \tAcc: 0.906\tLabel_Loss: 0.3052\tTop_Loss: 0.3617\tBottom_Loss: 0.3831\tLoss: 1.0499\t\n",
      "Train:\tEpoch:[33][8/13]   \tAcc: 0.875\tLabel_Loss: 0.3299\tTop_Loss: 0.4563\tBottom_Loss: 0.5578\tLoss: 1.3439\t\n",
      "Subject: s3, n=39 | test_f1: 0.23623 |best_f1: 0.60193\n",
      "Train:\tEpoch:[34][1/13]   \tAcc: 0.969\tLabel_Loss: 0.1452\tTop_Loss: 0.1901\tBottom_Loss: 0.2989\tLoss: 0.6342\t\n",
      "Train:\tEpoch:[34][8/13]   \tAcc: 0.875\tLabel_Loss: 0.2803\tTop_Loss: 0.3845\tBottom_Loss: 0.3582\tLoss: 1.0230\t\n",
      "Subject: s3, n=39 | test_f1: 0.48655 |best_f1: 0.60193\n",
      "Train:\tEpoch:[35][1/13]   \tAcc: 0.906\tLabel_Loss: 0.2364\tTop_Loss: 0.2478\tBottom_Loss: 0.4378\tLoss: 0.9219\t\n",
      "Train:\tEpoch:[35][8/13]   \tAcc: 0.938\tLabel_Loss: 0.2914\tTop_Loss: 0.3398\tBottom_Loss: 0.4136\tLoss: 1.0448\t\n",
      "Subject: s3, n=39 | test_f1: 0.32729 |best_f1: 0.60193\n",
      "Train:\tEpoch:[36][1/13]   \tAcc: 0.938\tLabel_Loss: 0.2898\tTop_Loss: 0.3886\tBottom_Loss: 0.4302\tLoss: 1.1087\t\n",
      "Train:\tEpoch:[36][8/13]   \tAcc: 0.906\tLabel_Loss: 0.2371\tTop_Loss: 0.3188\tBottom_Loss: 0.5346\tLoss: 1.0905\t\n",
      "Subject: s3, n=39 | test_f1: 0.3254 |best_f1: 0.60193\n",
      "Train:\tEpoch:[37][1/13]   \tAcc: 0.938\tLabel_Loss: 0.2234\tTop_Loss: 0.3621\tBottom_Loss: 0.4354\tLoss: 1.0208\t\n",
      "Train:\tEpoch:[37][8/13]   \tAcc: 0.875\tLabel_Loss: 0.2075\tTop_Loss: 0.2968\tBottom_Loss: 0.3795\tLoss: 0.8837\t\n",
      "Subject: s3, n=39 | test_f1: 0.49436 |best_f1: 0.60193\n",
      "Train:\tEpoch:[38][1/13]   \tAcc: 0.875\tLabel_Loss: 0.3114\tTop_Loss: 0.3636\tBottom_Loss: 0.4337\tLoss: 1.1088\t\n",
      "Train:\tEpoch:[38][8/13]   \tAcc: 0.906\tLabel_Loss: 0.2322\tTop_Loss: 0.4425\tBottom_Loss: 0.5469\tLoss: 1.2216\t\n",
      "Subject: s3, n=39 | test_f1: 0.49304 |best_f1: 0.60193\n",
      "Train:\tEpoch:[39][1/13]   \tAcc: 0.875\tLabel_Loss: 0.3120\tTop_Loss: 0.5400\tBottom_Loss: 0.5942\tLoss: 1.4462\t\n",
      "Train:\tEpoch:[39][8/13]   \tAcc: 0.875\tLabel_Loss: 0.3361\tTop_Loss: 0.3710\tBottom_Loss: 0.4692\tLoss: 1.1763\t\n",
      "Subject: s3, n=39 | test_f1: 0.48416 |best_f1: 0.60193\n",
      "Train:\tEpoch:[40][1/13]   \tAcc: 0.938\tLabel_Loss: 0.2310\tTop_Loss: 0.3353\tBottom_Loss: 0.2263\tLoss: 0.7927\t\n",
      "Train:\tEpoch:[40][8/13]   \tAcc: 0.969\tLabel_Loss: 0.1638\tTop_Loss: 0.2447\tBottom_Loss: 0.3162\tLoss: 0.7248\t\n",
      "Subject: s3, n=39 | test_f1: 0.57166 |best_f1: 0.60193\n",
      "Train:\tEpoch:[41][1/13]   \tAcc: 0.969\tLabel_Loss: 0.1804\tTop_Loss: 0.2498\tBottom_Loss: 0.3559\tLoss: 0.7860\t\n",
      "Train:\tEpoch:[41][8/13]   \tAcc: 0.969\tLabel_Loss: 0.1899\tTop_Loss: 0.2792\tBottom_Loss: 0.2481\tLoss: 0.7172\t\n",
      "Subject: s3, n=39 | test_f1: 0.34335 |best_f1: 0.60193\n",
      "Train:\tEpoch:[42][1/13]   \tAcc: 0.938\tLabel_Loss: 0.2311\tTop_Loss: 0.2341\tBottom_Loss: 0.3651\tLoss: 0.8303\t\n",
      "Train:\tEpoch:[42][8/13]   \tAcc: 0.969\tLabel_Loss: 0.1379\tTop_Loss: 0.2032\tBottom_Loss: 0.2036\tLoss: 0.5447\t\n",
      "Subject: s3, n=39 | test_f1: 0.49902 |best_f1: 0.60193\n",
      "Train:\tEpoch:[43][1/13]   \tAcc: 0.906\tLabel_Loss: 0.1639\tTop_Loss: 0.1648\tBottom_Loss: 0.2912\tLoss: 0.6198\t\n",
      "Train:\tEpoch:[43][8/13]   \tAcc: 0.938\tLabel_Loss: 0.1232\tTop_Loss: 0.2239\tBottom_Loss: 0.2015\tLoss: 0.5485\t\n",
      "Subject: s3, n=39 | test_f1: 0.4127 |best_f1: 0.60193\n",
      "Train:\tEpoch:[44][1/13]   \tAcc: 0.875\tLabel_Loss: 0.3119\tTop_Loss: 0.3403\tBottom_Loss: 0.2788\tLoss: 0.9310\t\n",
      "Train:\tEpoch:[44][8/13]   \tAcc: 0.938\tLabel_Loss: 0.1296\tTop_Loss: 0.1358\tBottom_Loss: 0.3260\tLoss: 0.5914\t\n",
      "Subject: s3, n=39 | test_f1: 0.42605 |best_f1: 0.60193\n",
      "Train:\tEpoch:[45][1/13]   \tAcc: 0.938\tLabel_Loss: 0.1417\tTop_Loss: 0.2276\tBottom_Loss: 0.2306\tLoss: 0.5999\t\n",
      "Train:\tEpoch:[45][8/13]   \tAcc: 0.938\tLabel_Loss: 0.1814\tTop_Loss: 0.2941\tBottom_Loss: 0.2712\tLoss: 0.7467\t\n",
      "Subject: s3, n=39 | test_f1: 0.42914 |best_f1: 0.60193\n",
      "Train:\tEpoch:[46][1/13]   \tAcc: 0.938\tLabel_Loss: 0.1659\tTop_Loss: 0.2903\tBottom_Loss: 0.2267\tLoss: 0.6829\t\n",
      "Train:\tEpoch:[46][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0770\tTop_Loss: 0.1616\tBottom_Loss: 0.1444\tLoss: 0.3830\t\n",
      "Subject: s3, n=39 | test_f1: 0.37749 |best_f1: 0.60193\n",
      "Train:\tEpoch:[47][1/13]   \tAcc: 0.969\tLabel_Loss: 0.1527\tTop_Loss: 0.2567\tBottom_Loss: 0.2030\tLoss: 0.6124\t\n",
      "Train:\tEpoch:[47][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0936\tTop_Loss: 0.3027\tBottom_Loss: 0.1529\tLoss: 0.5492\t\n",
      "Subject: s3, n=39 | test_f1: 0.40171 |best_f1: 0.60193\n",
      "Train:\tEpoch:[48][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0630\tTop_Loss: 0.1061\tBottom_Loss: 0.1780\tLoss: 0.3472\t\n",
      "Train:\tEpoch:[48][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0965\tTop_Loss: 0.1562\tBottom_Loss: 0.1664\tLoss: 0.4192\t\n",
      "Subject: s3, n=39 | test_f1: 0.52222 |best_f1: 0.60193\n",
      "Train:\tEpoch:[49][1/13]   \tAcc: 1.000\tLabel_Loss: 0.1042\tTop_Loss: 0.2039\tBottom_Loss: 0.2227\tLoss: 0.5309\t\n",
      "Train:\tEpoch:[49][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0917\tTop_Loss: 0.1978\tBottom_Loss: 0.2031\tLoss: 0.4926\t\n",
      "Subject: s3, n=39 | test_f1: 0.44678 |best_f1: 0.60193\n",
      "Train:\tEpoch:[50][1/13]   \tAcc: 0.938\tLabel_Loss: 0.2324\tTop_Loss: 0.2819\tBottom_Loss: 0.3859\tLoss: 0.9003\t\n",
      "Train:\tEpoch:[50][8/13]   \tAcc: 0.969\tLabel_Loss: 0.0919\tTop_Loss: 0.2045\tBottom_Loss: 0.1236\tLoss: 0.4200\t\n",
      "Subject: s3, n=39 | test_f1: 0.43531 |best_f1: 0.60193\n",
      "Train:\tEpoch:[51][1/13]   \tAcc: 0.906\tLabel_Loss: 0.1739\tTop_Loss: 0.2269\tBottom_Loss: 0.2648\tLoss: 0.6655\t\n",
      "Train:\tEpoch:[51][8/13]   \tAcc: 0.969\tLabel_Loss: 0.1326\tTop_Loss: 0.1540\tBottom_Loss: 0.1808\tLoss: 0.4674\t\n",
      "Subject: s3, n=39 | test_f1: 0.46732 |best_f1: 0.60193\n",
      "Train:\tEpoch:[52][1/13]   \tAcc: 0.938\tLabel_Loss: 0.1105\tTop_Loss: 0.1626\tBottom_Loss: 0.2739\tLoss: 0.5469\t\n",
      "Train:\tEpoch:[52][8/13]   \tAcc: 0.938\tLabel_Loss: 0.1651\tTop_Loss: 0.2758\tBottom_Loss: 0.1921\tLoss: 0.6330\t\n",
      "Subject: s3, n=39 | test_f1: 0.43642 |best_f1: 0.60193\n",
      "Train:\tEpoch:[53][1/13]   \tAcc: 0.906\tLabel_Loss: 0.1680\tTop_Loss: 0.3060\tBottom_Loss: 0.1466\tLoss: 0.6205\t\n",
      "Train:\tEpoch:[53][8/13]   \tAcc: 0.875\tLabel_Loss: 0.2304\tTop_Loss: 0.2327\tBottom_Loss: 0.3583\tLoss: 0.8214\t\n",
      "Subject: s3, n=39 | test_f1: 0.4512 |best_f1: 0.60193\n",
      "Train:\tEpoch:[54][1/13]   \tAcc: 0.938\tLabel_Loss: 0.1123\tTop_Loss: 0.1623\tBottom_Loss: 0.2847\tLoss: 0.5594\t\n",
      "Train:\tEpoch:[54][8/13]   \tAcc: 0.938\tLabel_Loss: 0.1606\tTop_Loss: 0.2662\tBottom_Loss: 0.3145\tLoss: 0.7414\t\n",
      "Subject: s3, n=39 | test_f1: 0.32194 |best_f1: 0.60193\n",
      "Train:\tEpoch:[55][1/13]   \tAcc: 0.969\tLabel_Loss: 0.1111\tTop_Loss: 0.1881\tBottom_Loss: 0.1782\tLoss: 0.4774\t\n",
      "Train:\tEpoch:[55][8/13]   \tAcc: 0.938\tLabel_Loss: 0.1574\tTop_Loss: 0.3995\tBottom_Loss: 0.2409\tLoss: 0.7978\t\n",
      "Subject: s3, n=39 | test_f1: 0.52525 |best_f1: 0.60193\n",
      "Train:\tEpoch:[56][1/13]   \tAcc: 0.969\tLabel_Loss: 0.1208\tTop_Loss: 0.2209\tBottom_Loss: 0.2195\tLoss: 0.5613\t\n",
      "Train:\tEpoch:[56][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0540\tTop_Loss: 0.1330\tBottom_Loss: 0.1190\tLoss: 0.3059\t\n",
      "Subject: s3, n=39 | test_f1: 0.4377 |best_f1: 0.60193\n",
      "Train:\tEpoch:[57][1/13]   \tAcc: 0.969\tLabel_Loss: 0.1672\tTop_Loss: 0.2351\tBottom_Loss: 0.2325\tLoss: 0.6347\t\n",
      "Train:\tEpoch:[57][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0665\tTop_Loss: 0.0993\tBottom_Loss: 0.1722\tLoss: 0.3381\t\n",
      "Subject: s3, n=39 | test_f1: 0.48602 |best_f1: 0.60193\n",
      "Train:\tEpoch:[58][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0222\tTop_Loss: 0.0596\tBottom_Loss: 0.0831\tLoss: 0.1649\t\n",
      "Train:\tEpoch:[58][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0615\tTop_Loss: 0.2059\tBottom_Loss: 0.1142\tLoss: 0.3816\t\n",
      "Subject: s3, n=39 | test_f1: 0.45317 |best_f1: 0.60193\n",
      "Train:\tEpoch:[59][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0387\tTop_Loss: 0.0751\tBottom_Loss: 0.1267\tLoss: 0.2405\t\n",
      "Train:\tEpoch:[59][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0691\tTop_Loss: 0.1808\tBottom_Loss: 0.0863\tLoss: 0.3362\t\n",
      "Subject: s3, n=39 | test_f1: 0.47536 |best_f1: 0.60193\n",
      "Train:\tEpoch:[60][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0280\tTop_Loss: 0.0789\tBottom_Loss: 0.1546\tLoss: 0.2615\t\n",
      "Train:\tEpoch:[60][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0519\tTop_Loss: 0.1263\tBottom_Loss: 0.1844\tLoss: 0.3626\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: s3, n=39 | test_f1: 0.46324 |best_f1: 0.60193\n",
      "Train:\tEpoch:[61][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0641\tTop_Loss: 0.2326\tBottom_Loss: 0.0903\tLoss: 0.3870\t\n",
      "Train:\tEpoch:[61][8/13]   \tAcc: 0.969\tLabel_Loss: 0.1032\tTop_Loss: 0.2154\tBottom_Loss: 0.1794\tLoss: 0.4980\t\n",
      "Subject: s3, n=39 | test_f1: 0.42626 |best_f1: 0.60193\n",
      "Train:\tEpoch:[62][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0321\tTop_Loss: 0.0924\tBottom_Loss: 0.1099\tLoss: 0.2344\t\n",
      "Train:\tEpoch:[62][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0195\tTop_Loss: 0.0416\tBottom_Loss: 0.1120\tLoss: 0.1730\t\n",
      "Subject: s3, n=39 | test_f1: 0.45294 |best_f1: 0.60193\n",
      "Train:\tEpoch:[63][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0404\tTop_Loss: 0.0820\tBottom_Loss: 0.0976\tLoss: 0.2199\t\n",
      "Train:\tEpoch:[63][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0609\tTop_Loss: 0.2146\tBottom_Loss: 0.0866\tLoss: 0.3620\t\n",
      "Subject: s3, n=39 | test_f1: 0.43565 |best_f1: 0.60193\n",
      "Train:\tEpoch:[64][1/13]   \tAcc: 0.969\tLabel_Loss: 0.0554\tTop_Loss: 0.1410\tBottom_Loss: 0.1099\tLoss: 0.3062\t\n",
      "Train:\tEpoch:[64][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0225\tTop_Loss: 0.0743\tBottom_Loss: 0.0729\tLoss: 0.1697\t\n",
      "Subject: s3, n=39 | test_f1: 0.41288 |best_f1: 0.60193\n",
      "Train:\tEpoch:[65][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0599\tTop_Loss: 0.0897\tBottom_Loss: 0.1321\tLoss: 0.2817\t\n",
      "Train:\tEpoch:[65][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0502\tTop_Loss: 0.1358\tBottom_Loss: 0.1034\tLoss: 0.2894\t\n",
      "Subject: s3, n=39 | test_f1: 0.4766 |best_f1: 0.60193\n",
      "Train:\tEpoch:[66][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0218\tTop_Loss: 0.0719\tBottom_Loss: 0.0520\tLoss: 0.1457\t\n",
      "Train:\tEpoch:[66][8/13]   \tAcc: 0.969\tLabel_Loss: 0.0742\tTop_Loss: 0.0972\tBottom_Loss: 0.0980\tLoss: 0.2693\t\n",
      "Subject: s3, n=39 | test_f1: 0.41134 |best_f1: 0.60193\n",
      "Train:\tEpoch:[67][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0572\tTop_Loss: 0.0859\tBottom_Loss: 0.1835\tLoss: 0.3266\t\n",
      "Train:\tEpoch:[67][8/13]   \tAcc: 0.969\tLabel_Loss: 0.0942\tTop_Loss: 0.1563\tBottom_Loss: 0.1496\tLoss: 0.4001\t\n",
      "Subject: s3, n=39 | test_f1: 0.45094 |best_f1: 0.60193\n",
      "Train:\tEpoch:[68][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0312\tTop_Loss: 0.0931\tBottom_Loss: 0.1248\tLoss: 0.2491\t\n",
      "Train:\tEpoch:[68][8/13]   \tAcc: 0.969\tLabel_Loss: 0.0437\tTop_Loss: 0.0802\tBottom_Loss: 0.1414\tLoss: 0.2652\t\n",
      "Subject: s3, n=39 | test_f1: 0.58187 |best_f1: 0.60193\n",
      "Train:\tEpoch:[69][1/13]   \tAcc: 0.969\tLabel_Loss: 0.0469\tTop_Loss: 0.0508\tBottom_Loss: 0.0654\tLoss: 0.1631\t\n",
      "Train:\tEpoch:[69][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0475\tTop_Loss: 0.0805\tBottom_Loss: 0.1509\tLoss: 0.2788\t\n",
      "Subject: s3, n=39 | test_f1: 0.43628 |best_f1: 0.60193\n",
      "Train:\tEpoch:[70][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0330\tTop_Loss: 0.1053\tBottom_Loss: 0.0799\tLoss: 0.2182\t\n",
      "Train:\tEpoch:[70][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0499\tTop_Loss: 0.1139\tBottom_Loss: 0.0765\tLoss: 0.2403\t\n",
      "Subject: s3, n=39 | test_f1: 0.45178 |best_f1: 0.60193\n",
      "Train:\tEpoch:[71][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0325\tTop_Loss: 0.0441\tBottom_Loss: 0.0690\tLoss: 0.1456\t\n",
      "Train:\tEpoch:[71][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0422\tTop_Loss: 0.1040\tBottom_Loss: 0.0752\tLoss: 0.2214\t\n",
      "Subject: s3, n=39 | test_f1: 0.51868 |best_f1: 0.60193\n",
      "Train:\tEpoch:[72][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0287\tTop_Loss: 0.0812\tBottom_Loss: 0.1417\tLoss: 0.2516\t\n",
      "Train:\tEpoch:[72][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0154\tTop_Loss: 0.0629\tBottom_Loss: 0.0577\tLoss: 0.1360\t\n",
      "Subject: s3, n=39 | test_f1: 0.45014 |best_f1: 0.60193\n",
      "Train:\tEpoch:[73][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0103\tTop_Loss: 0.0393\tBottom_Loss: 0.0357\tLoss: 0.0853\t\n",
      "Train:\tEpoch:[73][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0485\tTop_Loss: 0.0946\tBottom_Loss: 0.1011\tLoss: 0.2442\t\n",
      "Subject: s3, n=39 | test_f1: 0.46012 |best_f1: 0.60193\n",
      "Train:\tEpoch:[74][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0171\tTop_Loss: 0.0444\tBottom_Loss: 0.0454\tLoss: 0.1069\t\n",
      "Train:\tEpoch:[74][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0181\tTop_Loss: 0.0949\tBottom_Loss: 0.0487\tLoss: 0.1617\t\n",
      "Subject: s3, n=39 | test_f1: 0.47483 |best_f1: 0.60193\n",
      "Train:\tEpoch:[75][1/13]   \tAcc: 0.969\tLabel_Loss: 0.1252\tTop_Loss: 0.2100\tBottom_Loss: 0.1442\tLoss: 0.4794\t\n",
      "Train:\tEpoch:[75][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0208\tTop_Loss: 0.0526\tBottom_Loss: 0.0523\tLoss: 0.1258\t\n",
      "Subject: s3, n=39 | test_f1: 0.56575 |best_f1: 0.60193\n",
      "Train:\tEpoch:[76][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0175\tTop_Loss: 0.0656\tBottom_Loss: 0.0373\tLoss: 0.1204\t\n",
      "Train:\tEpoch:[76][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0142\tTop_Loss: 0.0885\tBottom_Loss: 0.0431\tLoss: 0.1458\t\n",
      "Subject: s3, n=39 | test_f1: 0.3957 |best_f1: 0.60193\n",
      "Train:\tEpoch:[77][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0384\tTop_Loss: 0.1004\tBottom_Loss: 0.0443\tLoss: 0.1830\t\n",
      "Train:\tEpoch:[77][8/13]   \tAcc: 0.969\tLabel_Loss: 0.0701\tTop_Loss: 0.1467\tBottom_Loss: 0.1105\tLoss: 0.3273\t\n",
      "Subject: s3, n=39 | test_f1: 0.49448 |best_f1: 0.60193\n",
      "Train:\tEpoch:[78][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0308\tTop_Loss: 0.0746\tBottom_Loss: 0.0432\tLoss: 0.1486\t\n",
      "Train:\tEpoch:[78][8/13]   \tAcc: 0.969\tLabel_Loss: 0.0940\tTop_Loss: 0.1000\tBottom_Loss: 0.2770\tLoss: 0.4710\t\n",
      "Subject: s3, n=39 | test_f1: 0.3062 |best_f1: 0.60193\n",
      "Train:\tEpoch:[79][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0724\tTop_Loss: 0.1769\tBottom_Loss: 0.1973\tLoss: 0.4466\t\n",
      "Train:\tEpoch:[79][8/13]   \tAcc: 0.969\tLabel_Loss: 0.0464\tTop_Loss: 0.1227\tBottom_Loss: 0.0575\tLoss: 0.2266\t\n",
      "Subject: s3, n=39 | test_f1: 0.50786 |best_f1: 0.60193\n",
      "Train:\tEpoch:[80][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0112\tTop_Loss: 0.0145\tBottom_Loss: 0.0374\tLoss: 0.0631\t\n",
      "Train:\tEpoch:[80][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0179\tTop_Loss: 0.0395\tBottom_Loss: 0.0665\tLoss: 0.1240\t\n",
      "Subject: s3, n=39 | test_f1: 0.49631 |best_f1: 0.60193\n",
      "Train:\tEpoch:[81][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0210\tTop_Loss: 0.0413\tBottom_Loss: 0.0585\tLoss: 0.1208\t\n",
      "Train:\tEpoch:[81][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0419\tTop_Loss: 0.0854\tBottom_Loss: 0.1229\tLoss: 0.2502\t\n",
      "Subject: s3, n=39 | test_f1: 0.47896 |best_f1: 0.60193\n",
      "Train:\tEpoch:[82][1/13]   \tAcc: 0.969\tLabel_Loss: 0.1208\tTop_Loss: 0.1877\tBottom_Loss: 0.0981\tLoss: 0.4066\t\n",
      "Train:\tEpoch:[82][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0472\tTop_Loss: 0.0881\tBottom_Loss: 0.0925\tLoss: 0.2277\t\n",
      "Subject: s3, n=39 | test_f1: 0.49411 |best_f1: 0.60193\n",
      "Train:\tEpoch:[83][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0251\tTop_Loss: 0.0669\tBottom_Loss: 0.0781\tLoss: 0.1701\t\n",
      "Train:\tEpoch:[83][8/13]   \tAcc: 0.969\tLabel_Loss: 0.0733\tTop_Loss: 0.1289\tBottom_Loss: 0.0277\tLoss: 0.2299\t\n",
      "Subject: s3, n=39 | test_f1: 0.39405 |best_f1: 0.60193\n",
      "Train:\tEpoch:[84][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0157\tTop_Loss: 0.0194\tBottom_Loss: 0.0462\tLoss: 0.0813\t\n",
      "Train:\tEpoch:[84][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0130\tTop_Loss: 0.0333\tBottom_Loss: 0.0321\tLoss: 0.0784\t\n",
      "Subject: s3, n=39 | test_f1: 0.40238 |best_f1: 0.60193\n",
      "Train:\tEpoch:[85][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0096\tTop_Loss: 0.0118\tBottom_Loss: 0.0424\tLoss: 0.0639\t\n",
      "Train:\tEpoch:[85][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0228\tTop_Loss: 0.0434\tBottom_Loss: 0.0951\tLoss: 0.1613\t\n",
      "Subject: s3, n=39 | test_f1: 0.41488 |best_f1: 0.60193\n",
      "Train:\tEpoch:[86][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0331\tTop_Loss: 0.0748\tBottom_Loss: 0.1603\tLoss: 0.2683\t\n",
      "Train:\tEpoch:[86][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0127\tTop_Loss: 0.0323\tBottom_Loss: 0.0505\tLoss: 0.0955\t\n",
      "Subject: s3, n=39 | test_f1: 0.46208 |best_f1: 0.60193\n",
      "Train:\tEpoch:[87][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0191\tTop_Loss: 0.0182\tBottom_Loss: 0.0474\tLoss: 0.0847\t\n",
      "Train:\tEpoch:[87][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0134\tTop_Loss: 0.0207\tBottom_Loss: 0.0921\tLoss: 0.1263\t\n",
      "Subject: s3, n=39 | test_f1: 0.43508 |best_f1: 0.60193\n",
      "Train:\tEpoch:[88][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0182\tTop_Loss: 0.0404\tBottom_Loss: 0.0786\tLoss: 0.1372\t\n",
      "Train:\tEpoch:[88][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0373\tTop_Loss: 0.0734\tBottom_Loss: 0.1258\tLoss: 0.2365\t\n",
      "Subject: s3, n=39 | test_f1: 0.53341 |best_f1: 0.60193\n",
      "Train:\tEpoch:[89][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0237\tTop_Loss: 0.0229\tBottom_Loss: 0.0608\tLoss: 0.1074\t\n",
      "Train:\tEpoch:[89][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0098\tTop_Loss: 0.0283\tBottom_Loss: 0.0263\tLoss: 0.0643\t\n",
      "Subject: s3, n=39 | test_f1: 0.40212 |best_f1: 0.60193\n",
      "Train:\tEpoch:[90][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0114\tTop_Loss: 0.0382\tBottom_Loss: 0.0254\tLoss: 0.0750\t\n",
      "Train:\tEpoch:[90][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0189\tTop_Loss: 0.0460\tBottom_Loss: 0.0538\tLoss: 0.1187\t\n",
      "Subject: s3, n=39 | test_f1: 0.47816 |best_f1: 0.60193\n",
      "Train:\tEpoch:[91][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0112\tTop_Loss: 0.0337\tBottom_Loss: 0.0337\tLoss: 0.0786\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[91][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0180\tTop_Loss: 0.0335\tBottom_Loss: 0.0525\tLoss: 0.1040\t\n",
      "Subject: s3, n=39 | test_f1: 0.39683 |best_f1: 0.60193\n",
      "Train:\tEpoch:[92][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0102\tTop_Loss: 0.0162\tBottom_Loss: 0.0369\tLoss: 0.0633\t\n",
      "Train:\tEpoch:[92][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0249\tTop_Loss: 0.0599\tBottom_Loss: 0.0616\tLoss: 0.1465\t\n",
      "Subject: s3, n=39 | test_f1: 0.45238 |best_f1: 0.60193\n",
      "Train:\tEpoch:[93][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0111\tTop_Loss: 0.0198\tBottom_Loss: 0.0411\tLoss: 0.0720\t\n",
      "Train:\tEpoch:[93][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0063\tTop_Loss: 0.0157\tBottom_Loss: 0.0361\tLoss: 0.0581\t\n",
      "Subject: s3, n=39 | test_f1: 0.43816 |best_f1: 0.60193\n",
      "Train:\tEpoch:[94][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0225\tTop_Loss: 0.0310\tBottom_Loss: 0.0373\tLoss: 0.0908\t\n",
      "Train:\tEpoch:[94][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0104\tTop_Loss: 0.0262\tBottom_Loss: 0.0216\tLoss: 0.0582\t\n",
      "Subject: s3, n=39 | test_f1: 0.57334 |best_f1: 0.60193\n",
      "Train:\tEpoch:[95][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0248\tTop_Loss: 0.1086\tBottom_Loss: 0.0427\tLoss: 0.1761\t\n",
      "Train:\tEpoch:[95][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0108\tTop_Loss: 0.0164\tBottom_Loss: 0.0394\tLoss: 0.0667\t\n",
      "Subject: s3, n=39 | test_f1: 0.44444 |best_f1: 0.60193\n",
      "Train:\tEpoch:[96][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0097\tTop_Loss: 0.0280\tBottom_Loss: 0.0335\tLoss: 0.0711\t\n",
      "Train:\tEpoch:[96][8/13]   \tAcc: 0.969\tLabel_Loss: 0.0351\tTop_Loss: 0.0504\tBottom_Loss: 0.0307\tLoss: 0.1162\t\n",
      "Subject: s3, n=39 | test_f1: 0.52824 |best_f1: 0.60193\n",
      "Train:\tEpoch:[97][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0141\tTop_Loss: 0.0544\tBottom_Loss: 0.0311\tLoss: 0.0995\t\n",
      "Train:\tEpoch:[97][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0064\tTop_Loss: 0.0148\tBottom_Loss: 0.0191\tLoss: 0.0403\t\n",
      "Subject: s3, n=39 | test_f1: 0.33893 |best_f1: 0.60193\n",
      "Train:\tEpoch:[98][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0068\tTop_Loss: 0.0150\tBottom_Loss: 0.0231\tLoss: 0.0449\t\n",
      "Train:\tEpoch:[98][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0140\tTop_Loss: 0.1045\tBottom_Loss: 0.0166\tLoss: 0.1350\t\n",
      "Subject: s3, n=39 | test_f1: 0.43565 |best_f1: 0.60193\n",
      "Train:\tEpoch:[99][1/13]   \tAcc: 1.000\tLabel_Loss: 0.0069\tTop_Loss: 0.0270\tBottom_Loss: 0.0310\tLoss: 0.0649\t\n",
      "Train:\tEpoch:[99][8/13]   \tAcc: 1.000\tLabel_Loss: 0.0110\tTop_Loss: 0.0210\tBottom_Loss: 0.0216\tLoss: 0.0537\t\n",
      "Subject: s3, n=39 | test_f1: 0.44361 |best_f1: 0.60193\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.094\tLabel_Loss: 1.5592\tTop_Loss: 1.7578\tBottom_Loss: 2.3640\tLoss: 5.6810\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.562\tLabel_Loss: 0.9370\tTop_Loss: 0.9122\tBottom_Loss: 1.0983\tLoss: 2.9475\t\n",
      "Subject: s4, n=19 | test_f1: 0.38847 |best_f1: 0.38847\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.406\tLabel_Loss: 1.3278\tTop_Loss: 1.1685\tBottom_Loss: 1.0807\tLoss: 3.5770\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.531\tLabel_Loss: 1.3182\tTop_Loss: 1.1583\tBottom_Loss: 1.0624\tLoss: 3.5389\t\n",
      "Subject: s4, n=19 | test_f1: 0.17172 |best_f1: 0.38847\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.531\tLabel_Loss: 0.9469\tTop_Loss: 0.9618\tBottom_Loss: 0.9641\tLoss: 2.8728\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.594\tLabel_Loss: 0.9984\tTop_Loss: 1.0567\tBottom_Loss: 1.1635\tLoss: 3.2186\t\n",
      "Subject: s4, n=19 | test_f1: 0.22826 |best_f1: 0.38847\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.812\tLabel_Loss: 0.7589\tTop_Loss: 0.7343\tBottom_Loss: 0.6873\tLoss: 2.1805\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.500\tLabel_Loss: 0.9869\tTop_Loss: 1.0377\tBottom_Loss: 1.1352\tLoss: 3.1598\t\n",
      "Subject: s4, n=19 | test_f1: 0.25725 |best_f1: 0.38847\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.719\tLabel_Loss: 0.8796\tTop_Loss: 0.8842\tBottom_Loss: 0.8172\tLoss: 2.5810\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.625\tLabel_Loss: 0.9890\tTop_Loss: 0.8900\tBottom_Loss: 0.9189\tLoss: 2.7979\t\n",
      "Subject: s4, n=19 | test_f1: 0.19964 |best_f1: 0.38847\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.531\tLabel_Loss: 0.8271\tTop_Loss: 0.8411\tBottom_Loss: 0.9982\tLoss: 2.6664\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8402\tTop_Loss: 0.8746\tBottom_Loss: 0.9172\tLoss: 2.6320\t\n",
      "Subject: s4, n=19 | test_f1: 0.33174 |best_f1: 0.38847\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.531\tLabel_Loss: 0.9232\tTop_Loss: 0.9962\tBottom_Loss: 0.8877\tLoss: 2.8071\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.531\tLabel_Loss: 1.0400\tTop_Loss: 1.0586\tBottom_Loss: 0.7925\tLoss: 2.8911\t\n",
      "Subject: s4, n=19 | test_f1: 0.24621 |best_f1: 0.38847\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7754\tTop_Loss: 0.9380\tBottom_Loss: 0.9643\tLoss: 2.6777\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7426\tTop_Loss: 0.7708\tBottom_Loss: 0.8421\tLoss: 2.3556\t\n",
      "Subject: s4, n=19 | test_f1: 0.19145 |best_f1: 0.38847\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6043\tTop_Loss: 0.7291\tBottom_Loss: 0.8195\tLoss: 2.1530\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7441\tTop_Loss: 0.8155\tBottom_Loss: 0.7653\tLoss: 2.3249\t\n",
      "Subject: s4, n=19 | test_f1: 0.10526 |best_f1: 0.38847\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7406\tTop_Loss: 0.8439\tBottom_Loss: 0.7936\tLoss: 2.3781\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7571\tTop_Loss: 0.7102\tBottom_Loss: 0.8897\tLoss: 2.3570\t\n",
      "Subject: s4, n=19 | test_f1: 0.28148 |best_f1: 0.38847\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.531\tLabel_Loss: 0.8096\tTop_Loss: 0.7410\tBottom_Loss: 0.8919\tLoss: 2.4425\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6341\tTop_Loss: 0.7319\tBottom_Loss: 0.7647\tLoss: 2.1307\t\n",
      "Subject: s4, n=19 | test_f1: 0.33333 |best_f1: 0.38847\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4911\tTop_Loss: 0.5044\tBottom_Loss: 0.5605\tLoss: 1.5560\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5259\tTop_Loss: 0.5407\tBottom_Loss: 0.6726\tLoss: 1.7392\t\n",
      "Subject: s4, n=19 | test_f1: 0.27619 |best_f1: 0.38847\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.719\tLabel_Loss: 0.7025\tTop_Loss: 0.7589\tBottom_Loss: 0.7187\tLoss: 2.1801\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6571\tTop_Loss: 0.6985\tBottom_Loss: 0.7581\tLoss: 2.1137\t\n",
      "Subject: s4, n=19 | test_f1: 0.2605 |best_f1: 0.38847\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.688\tLabel_Loss: 0.5777\tTop_Loss: 0.5555\tBottom_Loss: 0.5959\tLoss: 1.7291\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.719\tLabel_Loss: 0.5661\tTop_Loss: 0.6479\tBottom_Loss: 0.8050\tLoss: 2.0189\t\n",
      "Subject: s4, n=19 | test_f1: 0.21289 |best_f1: 0.38847\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6178\tTop_Loss: 0.5963\tBottom_Loss: 0.5369\tLoss: 1.7510\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.844\tLabel_Loss: 0.5139\tTop_Loss: 0.7554\tBottom_Loss: 0.6990\tLoss: 1.9684\t\n",
      "Subject: s4, n=19 | test_f1: 0.15556 |best_f1: 0.38847\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.688\tLabel_Loss: 0.8173\tTop_Loss: 0.9162\tBottom_Loss: 0.8402\tLoss: 2.5738\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7218\tTop_Loss: 0.8524\tBottom_Loss: 0.8682\tLoss: 2.4424\t\n",
      "Subject: s4, n=19 | test_f1: 0.28042 |best_f1: 0.38847\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6627\tTop_Loss: 0.8925\tBottom_Loss: 0.7082\tLoss: 2.2634\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.656\tLabel_Loss: 0.5732\tTop_Loss: 0.6238\tBottom_Loss: 0.7064\tLoss: 1.9034\t\n",
      "Subject: s4, n=19 | test_f1: 0.41141 |best_f1: 0.41141\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.625\tLabel_Loss: 0.6342\tTop_Loss: 0.6692\tBottom_Loss: 0.6426\tLoss: 1.9460\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.656\tLabel_Loss: 0.6920\tTop_Loss: 0.6472\tBottom_Loss: 0.8215\tLoss: 2.1608\t\n",
      "Subject: s4, n=19 | test_f1: 0.46667 |best_f1: 0.46667\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3836\tTop_Loss: 0.4809\tBottom_Loss: 0.4612\tLoss: 1.3257\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3619\tTop_Loss: 0.6621\tBottom_Loss: 0.5038\tLoss: 1.5278\t\n",
      "Subject: s4, n=19 | test_f1: 0.43326 |best_f1: 0.46667\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.781\tLabel_Loss: 0.6812\tTop_Loss: 0.6829\tBottom_Loss: 0.5932\tLoss: 1.9573\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3943\tTop_Loss: 0.5627\tBottom_Loss: 0.5496\tLoss: 1.5065\t\n",
      "Subject: s4, n=19 | test_f1: 0.38198 |best_f1: 0.46667\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7088\tTop_Loss: 0.8122\tBottom_Loss: 0.9131\tLoss: 2.4341\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3810\tTop_Loss: 0.6332\tBottom_Loss: 0.6525\tLoss: 1.6667\t\n",
      "Subject: s4, n=19 | test_f1: 0.26068 |best_f1: 0.46667\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3979\tTop_Loss: 0.4492\tBottom_Loss: 0.6370\tLoss: 1.4841\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.906\tLabel_Loss: 0.4213\tTop_Loss: 0.4751\tBottom_Loss: 0.5094\tLoss: 1.4058\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: s4, n=19 | test_f1: 0.51682 |best_f1: 0.51682\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5069\tTop_Loss: 0.5825\tBottom_Loss: 0.6498\tLoss: 1.7392\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3600\tTop_Loss: 0.6048\tBottom_Loss: 0.4992\tLoss: 1.4640\t\n",
      "Subject: s4, n=19 | test_f1: 0.51429 |best_f1: 0.51682\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5568\tTop_Loss: 0.6809\tBottom_Loss: 0.4038\tLoss: 1.6415\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4966\tTop_Loss: 0.6102\tBottom_Loss: 0.5376\tLoss: 1.6444\t\n",
      "Subject: s4, n=19 | test_f1: 0.41905 |best_f1: 0.51682\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2917\tTop_Loss: 0.3779\tBottom_Loss: 0.4596\tLoss: 1.1293\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.844\tLabel_Loss: 0.2984\tTop_Loss: 0.3420\tBottom_Loss: 0.5162\tLoss: 1.1565\t\n",
      "Subject: s4, n=19 | test_f1: 0.27937 |best_f1: 0.51682\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2908\tTop_Loss: 0.5132\tBottom_Loss: 0.5072\tLoss: 1.3112\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4512\tTop_Loss: 0.3864\tBottom_Loss: 0.6596\tLoss: 1.4972\t\n",
      "Subject: s4, n=19 | test_f1: 0.4692 |best_f1: 0.51682\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3220\tTop_Loss: 0.4035\tBottom_Loss: 0.5001\tLoss: 1.2257\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3498\tTop_Loss: 0.4995\tBottom_Loss: 0.5144\tLoss: 1.3637\t\n",
      "Subject: s4, n=19 | test_f1: 0.39829 |best_f1: 0.51682\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4105\tTop_Loss: 0.4503\tBottom_Loss: 0.6744\tLoss: 1.5352\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.938\tLabel_Loss: 0.3368\tTop_Loss: 0.4441\tBottom_Loss: 0.5506\tLoss: 1.3315\t\n",
      "Subject: s4, n=19 | test_f1: 0.46496 |best_f1: 0.51682\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.719\tLabel_Loss: 0.4508\tTop_Loss: 0.5438\tBottom_Loss: 0.4849\tLoss: 1.4795\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3524\tTop_Loss: 0.4308\tBottom_Loss: 0.3713\tLoss: 1.1545\t\n",
      "Subject: s4, n=19 | test_f1: 0.28034 |best_f1: 0.51682\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3348\tTop_Loss: 0.4884\tBottom_Loss: 0.5201\tLoss: 1.3432\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2889\tTop_Loss: 0.4123\tBottom_Loss: 0.4182\tLoss: 1.1193\t\n",
      "Subject: s4, n=19 | test_f1: 0.29394 |best_f1: 0.51682\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3066\tTop_Loss: 0.5033\tBottom_Loss: 0.4139\tLoss: 1.2238\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4106\tTop_Loss: 0.4015\tBottom_Loss: 0.3968\tLoss: 1.2089\t\n",
      "Subject: s4, n=19 | test_f1: 0.30603 |best_f1: 0.51682\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2506\tTop_Loss: 0.3747\tBottom_Loss: 0.5227\tLoss: 1.1480\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2122\tTop_Loss: 0.3378\tBottom_Loss: 0.4836\tLoss: 1.0336\t\n",
      "Subject: s4, n=19 | test_f1: 0.4 |best_f1: 0.51682\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2755\tTop_Loss: 0.2854\tBottom_Loss: 0.4404\tLoss: 1.0013\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3708\tTop_Loss: 0.3567\tBottom_Loss: 0.7409\tLoss: 1.4684\t\n",
      "Subject: s4, n=19 | test_f1: 0.2381 |best_f1: 0.51682\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2838\tTop_Loss: 0.4801\tBottom_Loss: 0.2957\tLoss: 1.0596\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2015\tTop_Loss: 0.3473\tBottom_Loss: 0.3787\tLoss: 0.9275\t\n",
      "Subject: s4, n=19 | test_f1: 0.27619 |best_f1: 0.51682\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2334\tTop_Loss: 0.3492\tBottom_Loss: 0.3961\tLoss: 0.9788\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2094\tTop_Loss: 0.2970\tBottom_Loss: 0.2816\tLoss: 0.7880\t\n",
      "Subject: s4, n=19 | test_f1: 0.46553 |best_f1: 0.51682\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1518\tTop_Loss: 0.3225\tBottom_Loss: 0.3918\tLoss: 0.8661\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1631\tTop_Loss: 0.2829\tBottom_Loss: 0.3482\tLoss: 0.7942\t\n",
      "Subject: s4, n=19 | test_f1: 0.34444 |best_f1: 0.51682\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3180\tTop_Loss: 0.3800\tBottom_Loss: 0.4694\tLoss: 1.1674\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0916\tTop_Loss: 0.2264\tBottom_Loss: 0.3407\tLoss: 0.6586\t\n",
      "Subject: s4, n=19 | test_f1: 0.51429 |best_f1: 0.51682\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1997\tTop_Loss: 0.2858\tBottom_Loss: 0.2494\tLoss: 0.7349\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2975\tTop_Loss: 0.3504\tBottom_Loss: 0.4784\tLoss: 1.1263\t\n",
      "Subject: s4, n=19 | test_f1: 0.36752 |best_f1: 0.51682\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1686\tTop_Loss: 0.3010\tBottom_Loss: 0.3629\tLoss: 0.8326\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2911\tTop_Loss: 0.4343\tBottom_Loss: 0.2267\tLoss: 0.9521\t\n",
      "Subject: s4, n=19 | test_f1: 0.46667 |best_f1: 0.51682\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1675\tTop_Loss: 0.2744\tBottom_Loss: 0.3556\tLoss: 0.7975\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2883\tTop_Loss: 0.3835\tBottom_Loss: 0.2998\tLoss: 0.9716\t\n",
      "Subject: s4, n=19 | test_f1: 0.46667 |best_f1: 0.51682\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3068\tTop_Loss: 0.3981\tBottom_Loss: 0.4267\tLoss: 1.1316\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1001\tTop_Loss: 0.2855\tBottom_Loss: 0.2512\tLoss: 0.6368\t\n",
      "Subject: s4, n=19 | test_f1: 0.41425 |best_f1: 0.51682\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2422\tTop_Loss: 0.3700\tBottom_Loss: 0.2416\tLoss: 0.8538\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1845\tTop_Loss: 0.3193\tBottom_Loss: 0.1786\tLoss: 0.6824\t\n",
      "Subject: s4, n=19 | test_f1: 0.37908 |best_f1: 0.51682\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1451\tTop_Loss: 0.2978\tBottom_Loss: 0.3596\tLoss: 0.8025\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1373\tTop_Loss: 0.2253\tBottom_Loss: 0.1991\tLoss: 0.5617\t\n",
      "Subject: s4, n=19 | test_f1: 0.39459 |best_f1: 0.51682\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1092\tTop_Loss: 0.1807\tBottom_Loss: 0.1748\tLoss: 0.4647\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1290\tTop_Loss: 0.2731\tBottom_Loss: 0.3512\tLoss: 0.7534\t\n",
      "Subject: s4, n=19 | test_f1: 0.20147 |best_f1: 0.51682\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2162\tTop_Loss: 0.3485\tBottom_Loss: 0.2960\tLoss: 0.8607\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1159\tTop_Loss: 0.1973\tBottom_Loss: 0.2232\tLoss: 0.5364\t\n",
      "Subject: s4, n=19 | test_f1: 0.44048 |best_f1: 0.51682\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1255\tTop_Loss: 0.3451\tBottom_Loss: 0.2156\tLoss: 0.6863\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1301\tTop_Loss: 0.1961\tBottom_Loss: 0.2246\tLoss: 0.5508\t\n",
      "Subject: s4, n=19 | test_f1: 0.34205 |best_f1: 0.51682\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1051\tTop_Loss: 0.2159\tBottom_Loss: 0.1816\tLoss: 0.5026\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0597\tTop_Loss: 0.1352\tBottom_Loss: 0.2722\tLoss: 0.4671\t\n",
      "Subject: s4, n=19 | test_f1: 0.30278 |best_f1: 0.51682\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2616\tTop_Loss: 0.2889\tBottom_Loss: 0.4822\tLoss: 1.0327\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1133\tTop_Loss: 0.2230\tBottom_Loss: 0.2063\tLoss: 0.5426\t\n",
      "Subject: s4, n=19 | test_f1: 0.22222 |best_f1: 0.51682\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1008\tTop_Loss: 0.1859\tBottom_Loss: 0.1767\tLoss: 0.4635\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0730\tTop_Loss: 0.1803\tBottom_Loss: 0.2855\tLoss: 0.5388\t\n",
      "Subject: s4, n=19 | test_f1: 0.29394 |best_f1: 0.51682\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0854\tTop_Loss: 0.1421\tBottom_Loss: 0.1458\tLoss: 0.3733\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0400\tTop_Loss: 0.1911\tBottom_Loss: 0.1086\tLoss: 0.3396\t\n",
      "Subject: s4, n=19 | test_f1: 0.30265 |best_f1: 0.51682\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0342\tTop_Loss: 0.1044\tBottom_Loss: 0.1041\tLoss: 0.2426\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1718\tTop_Loss: 0.3510\tBottom_Loss: 0.1842\tLoss: 0.7070\t\n",
      "Subject: s4, n=19 | test_f1: 0.37302 |best_f1: 0.51682\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1250\tTop_Loss: 0.2835\tBottom_Loss: 0.1417\tLoss: 0.5502\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1422\tTop_Loss: 0.1703\tBottom_Loss: 0.2001\tLoss: 0.5126\t\n",
      "Subject: s4, n=19 | test_f1: 0.35238 |best_f1: 0.51682\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0717\tTop_Loss: 0.1201\tBottom_Loss: 0.2058\tLoss: 0.3976\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[52][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0572\tTop_Loss: 0.1662\tBottom_Loss: 0.2228\tLoss: 0.4463\t\n",
      "Subject: s4, n=19 | test_f1: 0.36742 |best_f1: 0.51682\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1138\tTop_Loss: 0.1431\tBottom_Loss: 0.2316\tLoss: 0.4885\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1049\tTop_Loss: 0.1686\tBottom_Loss: 0.1450\tLoss: 0.4185\t\n",
      "Subject: s4, n=19 | test_f1: 0.35365 |best_f1: 0.51682\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0530\tTop_Loss: 0.1632\tBottom_Loss: 0.1348\tLoss: 0.3511\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0520\tTop_Loss: 0.1636\tBottom_Loss: 0.1468\tLoss: 0.3624\t\n",
      "Subject: s4, n=19 | test_f1: 0.24949 |best_f1: 0.51682\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0249\tTop_Loss: 0.0667\tBottom_Loss: 0.1270\tLoss: 0.2186\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1043\tTop_Loss: 0.1789\tBottom_Loss: 0.2308\tLoss: 0.5139\t\n",
      "Subject: s4, n=19 | test_f1: 0.35292 |best_f1: 0.51682\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0229\tTop_Loss: 0.1040\tBottom_Loss: 0.0941\tLoss: 0.2211\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0609\tTop_Loss: 0.0735\tBottom_Loss: 0.1191\tLoss: 0.2535\t\n",
      "Subject: s4, n=19 | test_f1: 0.51033 |best_f1: 0.51682\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2257\tTop_Loss: 0.3711\tBottom_Loss: 0.1968\tLoss: 0.7936\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1334\tTop_Loss: 0.1998\tBottom_Loss: 0.1732\tLoss: 0.5063\t\n",
      "Subject: s4, n=19 | test_f1: 0.31901 |best_f1: 0.51682\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0557\tTop_Loss: 0.1480\tBottom_Loss: 0.0992\tLoss: 0.3029\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1492\tTop_Loss: 0.1882\tBottom_Loss: 0.1006\tLoss: 0.4380\t\n",
      "Subject: s4, n=19 | test_f1: 0.22857 |best_f1: 0.51682\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0473\tTop_Loss: 0.1338\tBottom_Loss: 0.1127\tLoss: 0.2938\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0433\tTop_Loss: 0.1343\tBottom_Loss: 0.1220\tLoss: 0.2996\t\n",
      "Subject: s4, n=19 | test_f1: 0.3449 |best_f1: 0.51682\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1864\tTop_Loss: 0.2896\tBottom_Loss: 0.2297\tLoss: 0.7056\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0448\tTop_Loss: 0.1441\tBottom_Loss: 0.1144\tLoss: 0.3034\t\n",
      "Subject: s4, n=19 | test_f1: 0.35238 |best_f1: 0.51682\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0237\tTop_Loss: 0.0591\tBottom_Loss: 0.1414\tLoss: 0.2242\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0510\tTop_Loss: 0.1167\tBottom_Loss: 0.0759\tLoss: 0.2436\t\n",
      "Subject: s4, n=19 | test_f1: 0.28788 |best_f1: 0.51682\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0676\tTop_Loss: 0.0970\tBottom_Loss: 0.1701\tLoss: 0.3347\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0347\tTop_Loss: 0.1371\tBottom_Loss: 0.1036\tLoss: 0.2754\t\n",
      "Subject: s4, n=19 | test_f1: 0.26797 |best_f1: 0.51682\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0099\tTop_Loss: 0.0379\tBottom_Loss: 0.0516\tLoss: 0.0993\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0331\tTop_Loss: 0.1320\tBottom_Loss: 0.0932\tLoss: 0.2583\t\n",
      "Subject: s4, n=19 | test_f1: 0.50833 |best_f1: 0.51682\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0767\tTop_Loss: 0.1605\tBottom_Loss: 0.0929\tLoss: 0.3301\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0543\tTop_Loss: 0.1418\tBottom_Loss: 0.1255\tLoss: 0.3215\t\n",
      "Subject: s4, n=19 | test_f1: 0.41792 |best_f1: 0.51682\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0384\tTop_Loss: 0.0691\tBottom_Loss: 0.0698\tLoss: 0.1773\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0324\tTop_Loss: 0.0733\tBottom_Loss: 0.1090\tLoss: 0.2147\t\n",
      "Subject: s4, n=19 | test_f1: 0.41792 |best_f1: 0.51682\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0694\tTop_Loss: 0.1688\tBottom_Loss: 0.1188\tLoss: 0.3571\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0219\tTop_Loss: 0.0699\tBottom_Loss: 0.0718\tLoss: 0.1636\t\n",
      "Subject: s4, n=19 | test_f1: 0.30952 |best_f1: 0.51682\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0789\tTop_Loss: 0.1319\tBottom_Loss: 0.0830\tLoss: 0.2938\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0744\tTop_Loss: 0.1006\tBottom_Loss: 0.1784\tLoss: 0.3533\t\n",
      "Subject: s4, n=19 | test_f1: 0.39788 |best_f1: 0.51682\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0352\tTop_Loss: 0.1251\tBottom_Loss: 0.1235\tLoss: 0.2838\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0900\tTop_Loss: 0.2478\tBottom_Loss: 0.1391\tLoss: 0.4769\t\n",
      "Subject: s4, n=19 | test_f1: 0.41905 |best_f1: 0.51682\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0399\tTop_Loss: 0.1387\tBottom_Loss: 0.0966\tLoss: 0.2751\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0151\tTop_Loss: 0.0801\tBottom_Loss: 0.0561\tLoss: 0.1514\t\n",
      "Subject: s4, n=19 | test_f1: 0.36663 |best_f1: 0.51682\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 0.906\tLabel_Loss: 0.0987\tTop_Loss: 0.0978\tBottom_Loss: 0.1489\tLoss: 0.3454\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0294\tTop_Loss: 0.0946\tBottom_Loss: 0.0542\tLoss: 0.1782\t\n",
      "Subject: s4, n=19 | test_f1: 0.34949 |best_f1: 0.51682\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0179\tTop_Loss: 0.0577\tBottom_Loss: 0.1299\tLoss: 0.2055\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0935\tTop_Loss: 0.1712\tBottom_Loss: 0.1574\tLoss: 0.4221\t\n",
      "Subject: s4, n=19 | test_f1: 0.30265 |best_f1: 0.51682\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0183\tTop_Loss: 0.0851\tBottom_Loss: 0.0514\tLoss: 0.1547\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0160\tTop_Loss: 0.0447\tBottom_Loss: 0.0520\tLoss: 0.1127\t\n",
      "Subject: s4, n=19 | test_f1: 0.36508 |best_f1: 0.51682\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1041\tTop_Loss: 0.3079\tBottom_Loss: 0.2761\tLoss: 0.6881\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0281\tTop_Loss: 0.1071\tBottom_Loss: 0.0737\tLoss: 0.2088\t\n",
      "Subject: s4, n=19 | test_f1: 0.34949 |best_f1: 0.51682\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0559\tTop_Loss: 0.1341\tBottom_Loss: 0.0616\tLoss: 0.2516\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0161\tTop_Loss: 0.0295\tBottom_Loss: 0.0560\tLoss: 0.1015\t\n",
      "Subject: s4, n=19 | test_f1: 0.35238 |best_f1: 0.51682\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0419\tTop_Loss: 0.0657\tBottom_Loss: 0.0573\tLoss: 0.1650\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0227\tTop_Loss: 0.0569\tBottom_Loss: 0.0507\tLoss: 0.1303\t\n",
      "Subject: s4, n=19 | test_f1: 0.30505 |best_f1: 0.51682\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0609\tTop_Loss: 0.0857\tBottom_Loss: 0.1654\tLoss: 0.3120\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 0.938\tLabel_Loss: 0.0574\tTop_Loss: 0.0902\tBottom_Loss: 0.1129\tLoss: 0.2605\t\n",
      "Subject: s4, n=19 | test_f1: 0.36663 |best_f1: 0.51682\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0258\tTop_Loss: 0.0362\tBottom_Loss: 0.0743\tLoss: 0.1364\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1072\tTop_Loss: 0.1125\tBottom_Loss: 0.0999\tLoss: 0.3197\t\n",
      "Subject: s4, n=19 | test_f1: 0.41792 |best_f1: 0.51682\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0459\tTop_Loss: 0.0738\tBottom_Loss: 0.0481\tLoss: 0.1679\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0415\tTop_Loss: 0.0587\tBottom_Loss: 0.0700\tLoss: 0.1703\t\n",
      "Subject: s4, n=19 | test_f1: 0.2359 |best_f1: 0.51682\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0400\tTop_Loss: 0.1080\tBottom_Loss: 0.0637\tLoss: 0.2117\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0107\tTop_Loss: 0.0308\tBottom_Loss: 0.0162\tLoss: 0.0577\t\n",
      "Subject: s4, n=19 | test_f1: 0.32121 |best_f1: 0.51682\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0076\tTop_Loss: 0.0523\tBottom_Loss: 0.0294\tLoss: 0.0892\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0402\tTop_Loss: 0.0683\tBottom_Loss: 0.0593\tLoss: 0.1678\t\n",
      "Subject: s4, n=19 | test_f1: 0.31197 |best_f1: 0.51682\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0504\tTop_Loss: 0.0389\tBottom_Loss: 0.0828\tLoss: 0.1722\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0134\tTop_Loss: 0.0678\tBottom_Loss: 0.0349\tLoss: 0.1161\t\n",
      "Subject: s4, n=19 | test_f1: 0.46553 |best_f1: 0.51682\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0159\tTop_Loss: 0.0452\tBottom_Loss: 0.0304\tLoss: 0.0914\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0470\tTop_Loss: 0.1138\tBottom_Loss: 0.0693\tLoss: 0.2300\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: s4, n=19 | test_f1: 0.34524 |best_f1: 0.51682\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0279\tTop_Loss: 0.0633\tBottom_Loss: 0.0430\tLoss: 0.1341\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0170\tTop_Loss: 0.0754\tBottom_Loss: 0.0488\tLoss: 0.1413\t\n",
      "Subject: s4, n=19 | test_f1: 0.24722 |best_f1: 0.51682\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0160\tTop_Loss: 0.0643\tBottom_Loss: 0.0353\tLoss: 0.1156\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0129\tTop_Loss: 0.0439\tBottom_Loss: 0.0425\tLoss: 0.0994\t\n",
      "Subject: s4, n=19 | test_f1: 0.34205 |best_f1: 0.51682\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0161\tTop_Loss: 0.0751\tBottom_Loss: 0.0651\tLoss: 0.1564\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0129\tTop_Loss: 0.0256\tBottom_Loss: 0.0569\tLoss: 0.0954\t\n",
      "Subject: s4, n=19 | test_f1: 0.46553 |best_f1: 0.51682\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0424\tTop_Loss: 0.0960\tBottom_Loss: 0.0297\tLoss: 0.1681\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0124\tTop_Loss: 0.0411\tBottom_Loss: 0.0903\tLoss: 0.1438\t\n",
      "Subject: s4, n=19 | test_f1: 0.42626 |best_f1: 0.51682\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0052\tTop_Loss: 0.0198\tBottom_Loss: 0.0228\tLoss: 0.0478\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0119\tTop_Loss: 0.0197\tBottom_Loss: 0.0258\tLoss: 0.0574\t\n",
      "Subject: s4, n=19 | test_f1: 0.26068 |best_f1: 0.51682\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0132\tTop_Loss: 0.0729\tBottom_Loss: 0.0683\tLoss: 0.1544\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0074\tTop_Loss: 0.0696\tBottom_Loss: 0.0161\tLoss: 0.0930\t\n",
      "Subject: s4, n=19 | test_f1: 0.46553 |best_f1: 0.51682\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0114\tTop_Loss: 0.0153\tBottom_Loss: 0.0407\tLoss: 0.0674\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0065\tTop_Loss: 0.0279\tBottom_Loss: 0.0239\tLoss: 0.0583\t\n",
      "Subject: s4, n=19 | test_f1: 0.30505 |best_f1: 0.51682\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0099\tTop_Loss: 0.0282\tBottom_Loss: 0.0317\tLoss: 0.0698\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0384\tTop_Loss: 0.1093\tBottom_Loss: 0.0607\tLoss: 0.2084\t\n",
      "Subject: s4, n=19 | test_f1: 0.5164 |best_f1: 0.51682\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0329\tTop_Loss: 0.0763\tBottom_Loss: 0.0866\tLoss: 0.1959\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0041\tTop_Loss: 0.0238\tBottom_Loss: 0.0270\tLoss: 0.0549\t\n",
      "Subject: s4, n=19 | test_f1: 0.30603 |best_f1: 0.51682\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0060\tTop_Loss: 0.0304\tBottom_Loss: 0.0219\tLoss: 0.0583\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0153\tTop_Loss: 0.0630\tBottom_Loss: 0.0492\tLoss: 0.1275\t\n",
      "Subject: s4, n=19 | test_f1: 0.29394 |best_f1: 0.51682\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0063\tTop_Loss: 0.0602\tBottom_Loss: 0.0179\tLoss: 0.0845\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0077\tTop_Loss: 0.0226\tBottom_Loss: 0.0233\tLoss: 0.0536\t\n",
      "Subject: s4, n=19 | test_f1: 0.35365 |best_f1: 0.51682\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0039\tTop_Loss: 0.0336\tBottom_Loss: 0.0164\tLoss: 0.0539\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0233\tTop_Loss: 0.0469\tBottom_Loss: 0.0525\tLoss: 0.1227\t\n",
      "Subject: s4, n=19 | test_f1: 0.41792 |best_f1: 0.51682\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0034\tTop_Loss: 0.0218\tBottom_Loss: 0.0184\tLoss: 0.0436\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0160\tTop_Loss: 0.0315\tBottom_Loss: 0.0785\tLoss: 0.1260\t\n",
      "Subject: s4, n=19 | test_f1: 0.34949 |best_f1: 0.51682\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 0.938\tLabel_Loss: 0.0770\tTop_Loss: 0.0570\tBottom_Loss: 0.1494\tLoss: 0.2835\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0072\tTop_Loss: 0.0175\tBottom_Loss: 0.0197\tLoss: 0.0444\t\n",
      "Subject: s4, n=19 | test_f1: 0.31197 |best_f1: 0.51682\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0069\tTop_Loss: 0.0223\tBottom_Loss: 0.0273\tLoss: 0.0565\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0108\tTop_Loss: 0.0809\tBottom_Loss: 0.0377\tLoss: 0.1295\t\n",
      "Subject: s4, n=19 | test_f1: 0.28788 |best_f1: 0.51682\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0031\tTop_Loss: 0.0129\tBottom_Loss: 0.0185\tLoss: 0.0345\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0121\tTop_Loss: 0.0138\tBottom_Loss: 0.0472\tLoss: 0.0730\t\n",
      "Subject: s4, n=19 | test_f1: 0.27778 |best_f1: 0.51682\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0053\tTop_Loss: 0.0290\tBottom_Loss: 0.0165\tLoss: 0.0508\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0108\tTop_Loss: 0.0515\tBottom_Loss: 0.0185\tLoss: 0.0808\t\n",
      "Subject: s4, n=19 | test_f1: 0.31197 |best_f1: 0.51682\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.438\tLabel_Loss: 1.2071\tTop_Loss: 1.5018\tBottom_Loss: 1.1736\tLoss: 3.8825\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.500\tLabel_Loss: 1.0052\tTop_Loss: 1.0890\tBottom_Loss: 1.3129\tLoss: 3.4071\t\n",
      "Subject: s5, n=02 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.594\tLabel_Loss: 0.7680\tTop_Loss: 0.8584\tBottom_Loss: 1.0623\tLoss: 2.6887\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.531\tLabel_Loss: 1.0824\tTop_Loss: 0.8678\tBottom_Loss: 0.9096\tLoss: 2.8598\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.344\tLabel_Loss: 1.0576\tTop_Loss: 1.0559\tBottom_Loss: 1.0754\tLoss: 3.1888\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.781\tLabel_Loss: 0.7399\tTop_Loss: 0.8655\tBottom_Loss: 0.8639\tLoss: 2.4693\t\n",
      "Subject: s5, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7932\tTop_Loss: 0.6810\tBottom_Loss: 0.7756\tLoss: 2.2498\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.438\tLabel_Loss: 0.9468\tTop_Loss: 0.8831\tBottom_Loss: 0.9919\tLoss: 2.8218\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.594\tLabel_Loss: 0.9027\tTop_Loss: 1.0497\tBottom_Loss: 0.9280\tLoss: 2.8804\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.781\tLabel_Loss: 0.7149\tTop_Loss: 0.8685\tBottom_Loss: 0.7227\tLoss: 2.3061\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8425\tTop_Loss: 0.8707\tBottom_Loss: 1.0570\tLoss: 2.7703\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.438\tLabel_Loss: 1.2046\tTop_Loss: 1.0326\tBottom_Loss: 1.1414\tLoss: 3.3786\t\n",
      "Subject: s5, n=02 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.625\tLabel_Loss: 0.9141\tTop_Loss: 0.9066\tBottom_Loss: 1.0337\tLoss: 2.8544\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8186\tTop_Loss: 0.9228\tBottom_Loss: 0.9790\tLoss: 2.7204\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.500\tLabel_Loss: 1.0511\tTop_Loss: 0.9411\tBottom_Loss: 0.8380\tLoss: 2.8303\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.750\tLabel_Loss: 0.7005\tTop_Loss: 0.8427\tBottom_Loss: 0.8016\tLoss: 2.3447\t\n",
      "Subject: s5, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8935\tTop_Loss: 0.9482\tBottom_Loss: 1.1491\tLoss: 2.9908\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6691\tTop_Loss: 0.9887\tBottom_Loss: 0.7717\tLoss: 2.4295\t\n",
      "Subject: s5, n=02 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.469\tLabel_Loss: 0.8132\tTop_Loss: 1.0009\tBottom_Loss: 0.9554\tLoss: 2.7695\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5502\tTop_Loss: 0.6430\tBottom_Loss: 0.6670\tLoss: 1.8602\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6179\tTop_Loss: 0.8242\tBottom_Loss: 0.7321\tLoss: 2.1742\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7648\tTop_Loss: 0.7219\tBottom_Loss: 0.7219\tLoss: 2.2087\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6254\tTop_Loss: 0.6994\tBottom_Loss: 0.7116\tLoss: 2.0364\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.562\tLabel_Loss: 0.9237\tTop_Loss: 0.9688\tBottom_Loss: 0.8313\tLoss: 2.7238\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.719\tLabel_Loss: 0.7074\tTop_Loss: 0.7598\tBottom_Loss: 0.8634\tLoss: 2.3306\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.688\tLabel_Loss: 0.8012\tTop_Loss: 0.7475\tBottom_Loss: 0.8243\tLoss: 2.3730\t\n",
      "Subject: s5, n=02 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7524\tTop_Loss: 0.7545\tBottom_Loss: 0.8651\tLoss: 2.3720\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6273\tTop_Loss: 0.6936\tBottom_Loss: 0.7814\tLoss: 2.1023\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6425\tTop_Loss: 0.6967\tBottom_Loss: 0.7650\tLoss: 2.1042\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.625\tLabel_Loss: 0.6056\tTop_Loss: 0.7836\tBottom_Loss: 0.8725\tLoss: 2.2616\t\n",
      "Subject: s5, n=02 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6263\tTop_Loss: 0.5202\tBottom_Loss: 0.5740\tLoss: 1.7205\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5888\tTop_Loss: 0.6311\tBottom_Loss: 0.6744\tLoss: 1.8943\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5927\tTop_Loss: 0.6275\tBottom_Loss: 0.7285\tLoss: 1.9487\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3224\tTop_Loss: 0.4565\tBottom_Loss: 0.5710\tLoss: 1.3499\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5032\tTop_Loss: 0.5480\tBottom_Loss: 0.5606\tLoss: 1.6119\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5150\tTop_Loss: 0.7318\tBottom_Loss: 0.7765\tLoss: 2.0233\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5596\tTop_Loss: 0.5362\tBottom_Loss: 0.7748\tLoss: 1.8706\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.688\tLabel_Loss: 0.5877\tTop_Loss: 0.7377\tBottom_Loss: 0.7815\tLoss: 2.1069\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4689\tTop_Loss: 0.6593\tBottom_Loss: 0.6662\tLoss: 1.7944\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6029\tTop_Loss: 0.6542\tBottom_Loss: 0.7335\tLoss: 1.9906\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6372\tTop_Loss: 0.6737\tBottom_Loss: 0.5778\tLoss: 1.8886\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.719\tLabel_Loss: 0.5281\tTop_Loss: 0.4938\tBottom_Loss: 0.5188\tLoss: 1.5408\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4304\tTop_Loss: 0.6020\tBottom_Loss: 0.4453\tLoss: 1.4777\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3571\tTop_Loss: 0.4388\tBottom_Loss: 0.5060\tLoss: 1.3020\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.812\tLabel_Loss: 0.3855\tTop_Loss: 0.4901\tBottom_Loss: 0.6170\tLoss: 1.4926\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6359\tTop_Loss: 0.7567\tBottom_Loss: 0.7349\tLoss: 2.1275\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4415\tTop_Loss: 0.5002\tBottom_Loss: 0.5221\tLoss: 1.4638\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.719\tLabel_Loss: 0.5066\tTop_Loss: 0.5986\tBottom_Loss: 0.5383\tLoss: 1.6435\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3943\tTop_Loss: 0.4827\tBottom_Loss: 0.5252\tLoss: 1.4023\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4037\tTop_Loss: 0.4833\tBottom_Loss: 0.5846\tLoss: 1.4716\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4364\tTop_Loss: 0.4701\tBottom_Loss: 0.6481\tLoss: 1.5546\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3533\tTop_Loss: 0.4197\tBottom_Loss: 0.4505\tLoss: 1.2235\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5084\tTop_Loss: 0.7226\tBottom_Loss: 0.4489\tLoss: 1.6798\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5422\tTop_Loss: 0.5987\tBottom_Loss: 0.5950\tLoss: 1.7358\t\n",
      "Subject: s5, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2712\tTop_Loss: 0.3309\tBottom_Loss: 0.4063\tLoss: 1.0084\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3734\tTop_Loss: 0.4087\tBottom_Loss: 0.5354\tLoss: 1.3175\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2740\tTop_Loss: 0.4507\tBottom_Loss: 0.4596\tLoss: 1.1843\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2715\tTop_Loss: 0.4271\tBottom_Loss: 0.3432\tLoss: 1.0419\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5268\tTop_Loss: 0.6833\tBottom_Loss: 0.5389\tLoss: 1.7490\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2755\tTop_Loss: 0.4377\tBottom_Loss: 0.3870\tLoss: 1.1002\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4052\tTop_Loss: 0.4861\tBottom_Loss: 0.5929\tLoss: 1.4841\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2139\tTop_Loss: 0.3360\tBottom_Loss: 0.3073\tLoss: 0.8572\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2428\tTop_Loss: 0.3427\tBottom_Loss: 0.3485\tLoss: 0.9340\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2964\tTop_Loss: 0.4500\tBottom_Loss: 0.2941\tLoss: 1.0405\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4169\tTop_Loss: 0.5463\tBottom_Loss: 0.4911\tLoss: 1.4543\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3573\tTop_Loss: 0.4596\tBottom_Loss: 0.4395\tLoss: 1.2563\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3111\tTop_Loss: 0.3525\tBottom_Loss: 0.3230\tLoss: 0.9865\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3411\tTop_Loss: 0.3576\tBottom_Loss: 0.4709\tLoss: 1.1696\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2819\tTop_Loss: 0.4264\tBottom_Loss: 0.3352\tLoss: 1.0436\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3093\tTop_Loss: 0.6716\tBottom_Loss: 0.4803\tLoss: 1.4612\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2525\tTop_Loss: 0.4199\tBottom_Loss: 0.4911\tLoss: 1.1635\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1586\tTop_Loss: 0.3007\tBottom_Loss: 0.2441\tLoss: 0.7034\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2791\tTop_Loss: 0.3952\tBottom_Loss: 0.3877\tLoss: 1.0620\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1731\tTop_Loss: 0.3041\tBottom_Loss: 0.2239\tLoss: 0.7012\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.938\tLabel_Loss: 0.3476\tTop_Loss: 0.4011\tBottom_Loss: 0.3612\tLoss: 1.1100\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1904\tTop_Loss: 0.2862\tBottom_Loss: 0.2139\tLoss: 0.6906\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2381\tTop_Loss: 0.4774\tBottom_Loss: 0.3651\tLoss: 1.0806\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3649\tTop_Loss: 0.5108\tBottom_Loss: 0.5048\tLoss: 1.3805\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2063\tTop_Loss: 0.3934\tBottom_Loss: 0.3625\tLoss: 0.9622\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1997\tTop_Loss: 0.3446\tBottom_Loss: 0.3275\tLoss: 0.8718\t\n",
      "Subject: s5, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2805\tTop_Loss: 0.4125\tBottom_Loss: 0.3837\tLoss: 1.0767\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1730\tTop_Loss: 0.3579\tBottom_Loss: 0.2186\tLoss: 0.7495\t\n",
      "Subject: s5, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1576\tTop_Loss: 0.2263\tBottom_Loss: 0.2968\tLoss: 0.6807\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2459\tTop_Loss: 0.4145\tBottom_Loss: 0.2956\tLoss: 0.9560\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2773\tTop_Loss: 0.3352\tBottom_Loss: 0.2656\tLoss: 0.8782\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1913\tTop_Loss: 0.2329\tBottom_Loss: 0.3558\tLoss: 0.7800\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1550\tTop_Loss: 0.3414\tBottom_Loss: 0.4277\tLoss: 0.9241\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2520\tTop_Loss: 0.3034\tBottom_Loss: 0.3939\tLoss: 0.9493\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1691\tTop_Loss: 0.2532\tBottom_Loss: 0.2172\tLoss: 0.6395\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1534\tTop_Loss: 0.3228\tBottom_Loss: 0.2190\tLoss: 0.6952\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1032\tTop_Loss: 0.1635\tBottom_Loss: 0.1775\tLoss: 0.4442\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1236\tTop_Loss: 0.2980\tBottom_Loss: 0.1951\tLoss: 0.6167\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1030\tTop_Loss: 0.1965\tBottom_Loss: 0.2179\tLoss: 0.5175\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.938\tLabel_Loss: 0.0945\tTop_Loss: 0.1771\tBottom_Loss: 0.1376\tLoss: 0.4092\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0668\tTop_Loss: 0.1163\tBottom_Loss: 0.2412\tLoss: 0.4243\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0925\tTop_Loss: 0.1785\tBottom_Loss: 0.2718\tLoss: 0.5428\t\n",
      "Subject: s5, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1238\tTop_Loss: 0.2202\tBottom_Loss: 0.1947\tLoss: 0.5388\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0885\tTop_Loss: 0.1336\tBottom_Loss: 0.2366\tLoss: 0.4587\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0641\tTop_Loss: 0.1094\tBottom_Loss: 0.1377\tLoss: 0.3112\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0758\tTop_Loss: 0.1990\tBottom_Loss: 0.1111\tLoss: 0.3859\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1382\tTop_Loss: 0.2406\tBottom_Loss: 0.2492\tLoss: 0.6281\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2249\tTop_Loss: 0.3001\tBottom_Loss: 0.2372\tLoss: 0.7623\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0777\tTop_Loss: 0.1431\tBottom_Loss: 0.1476\tLoss: 0.3684\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1342\tTop_Loss: 0.2621\tBottom_Loss: 0.2541\tLoss: 0.6504\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1216\tTop_Loss: 0.1910\tBottom_Loss: 0.2678\tLoss: 0.5804\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0750\tTop_Loss: 0.1600\tBottom_Loss: 0.0999\tLoss: 0.3349\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1164\tTop_Loss: 0.1879\tBottom_Loss: 0.1176\tLoss: 0.4219\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1298\tTop_Loss: 0.2323\tBottom_Loss: 0.2588\tLoss: 0.6209\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1423\tTop_Loss: 0.2860\tBottom_Loss: 0.1694\tLoss: 0.5977\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2009\tTop_Loss: 0.2357\tBottom_Loss: 0.2612\tLoss: 0.6978\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1433\tTop_Loss: 0.2306\tBottom_Loss: 0.2408\tLoss: 0.6147\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0940\tTop_Loss: 0.1948\tBottom_Loss: 0.2588\tLoss: 0.5476\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0850\tTop_Loss: 0.1832\tBottom_Loss: 0.1321\tLoss: 0.4003\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0912\tTop_Loss: 0.1316\tBottom_Loss: 0.1512\tLoss: 0.3740\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0250\tTop_Loss: 0.0882\tBottom_Loss: 0.0896\tLoss: 0.2027\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0390\tTop_Loss: 0.1731\tBottom_Loss: 0.0848\tLoss: 0.2970\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0848\tTop_Loss: 0.1061\tBottom_Loss: 0.1657\tLoss: 0.3566\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0335\tTop_Loss: 0.1106\tBottom_Loss: 0.0663\tLoss: 0.2104\t\n",
      "Subject: s5, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1308\tTop_Loss: 0.2662\tBottom_Loss: 0.2968\tLoss: 0.6938\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0488\tTop_Loss: 0.0889\tBottom_Loss: 0.1194\tLoss: 0.2571\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0750\tTop_Loss: 0.1706\tBottom_Loss: 0.1404\tLoss: 0.3860\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0658\tTop_Loss: 0.1444\tBottom_Loss: 0.1012\tLoss: 0.3114\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0715\tTop_Loss: 0.1186\tBottom_Loss: 0.2131\tLoss: 0.4032\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0381\tTop_Loss: 0.0736\tBottom_Loss: 0.1061\tLoss: 0.2179\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1207\tTop_Loss: 0.1729\tBottom_Loss: 0.1389\tLoss: 0.4325\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0363\tTop_Loss: 0.1168\tBottom_Loss: 0.1290\tLoss: 0.2821\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0708\tTop_Loss: 0.1468\tBottom_Loss: 0.1652\tLoss: 0.3829\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0377\tTop_Loss: 0.1654\tBottom_Loss: 0.1359\tLoss: 0.3391\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0410\tTop_Loss: 0.1103\tBottom_Loss: 0.0638\tLoss: 0.2151\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0520\tTop_Loss: 0.1537\tBottom_Loss: 0.0791\tLoss: 0.2848\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0805\tTop_Loss: 0.0783\tBottom_Loss: 0.2681\tLoss: 0.4269\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0258\tTop_Loss: 0.1065\tBottom_Loss: 0.0558\tLoss: 0.1881\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0607\tTop_Loss: 0.1469\tBottom_Loss: 0.1029\tLoss: 0.3105\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0333\tTop_Loss: 0.1638\tBottom_Loss: 0.0613\tLoss: 0.2584\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0203\tTop_Loss: 0.0729\tBottom_Loss: 0.0691\tLoss: 0.1623\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0407\tTop_Loss: 0.0935\tBottom_Loss: 0.1704\tLoss: 0.3046\t\n",
      "Subject: s5, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0404\tTop_Loss: 0.1144\tBottom_Loss: 0.1223\tLoss: 0.2771\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0713\tTop_Loss: 0.1416\tBottom_Loss: 0.0689\tLoss: 0.2817\t\n",
      "Subject: s5, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0100\tTop_Loss: 0.0417\tBottom_Loss: 0.0378\tLoss: 0.0896\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0322\tTop_Loss: 0.0582\tBottom_Loss: 0.0967\tLoss: 0.1871\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1499\tTop_Loss: 0.2043\tBottom_Loss: 0.1504\tLoss: 0.5045\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0178\tTop_Loss: 0.0639\tBottom_Loss: 0.0315\tLoss: 0.1132\t\n",
      "Subject: s5, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0390\tTop_Loss: 0.1207\tBottom_Loss: 0.0583\tLoss: 0.2180\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0221\tTop_Loss: 0.0687\tBottom_Loss: 0.0469\tLoss: 0.1376\t\n",
      "Subject: s5, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0512\tTop_Loss: 0.1039\tBottom_Loss: 0.0759\tLoss: 0.2310\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0170\tTop_Loss: 0.0402\tBottom_Loss: 0.0579\tLoss: 0.1151\t\n",
      "Subject: s5, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0347\tTop_Loss: 0.0519\tBottom_Loss: 0.0975\tLoss: 0.1841\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0391\tTop_Loss: 0.0886\tBottom_Loss: 0.0718\tLoss: 0.1994\t\n",
      "Subject: s5, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0290\tTop_Loss: 0.0494\tBottom_Loss: 0.0948\tLoss: 0.1733\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0482\tTop_Loss: 0.1210\tBottom_Loss: 0.1229\tLoss: 0.2921\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0388\tTop_Loss: 0.1152\tBottom_Loss: 0.0585\tLoss: 0.2125\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0168\tTop_Loss: 0.0571\tBottom_Loss: 0.0417\tLoss: 0.1156\t\n",
      "Subject: s5, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0763\tTop_Loss: 0.0848\tBottom_Loss: 0.1207\tLoss: 0.2819\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0293\tTop_Loss: 0.0709\tBottom_Loss: 0.0517\tLoss: 0.1520\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0147\tTop_Loss: 0.0325\tBottom_Loss: 0.0810\tLoss: 0.1282\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0133\tTop_Loss: 0.0439\tBottom_Loss: 0.0392\tLoss: 0.0964\t\n",
      "Subject: s5, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0124\tTop_Loss: 0.0378\tBottom_Loss: 0.0225\tLoss: 0.0727\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0452\tTop_Loss: 0.0870\tBottom_Loss: 0.0817\tLoss: 0.2138\t\n",
      "Subject: s5, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0651\tTop_Loss: 0.1553\tBottom_Loss: 0.0816\tLoss: 0.3020\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 0.938\tLabel_Loss: 0.0722\tTop_Loss: 0.0439\tBottom_Loss: 0.1385\tLoss: 0.2547\t\n",
      "Subject: s5, n=02 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0239\tTop_Loss: 0.0966\tBottom_Loss: 0.0498\tLoss: 0.1702\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0150\tTop_Loss: 0.0379\tBottom_Loss: 0.0570\tLoss: 0.1099\t\n",
      "Subject: s5, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0354\tTop_Loss: 0.1165\tBottom_Loss: 0.0578\tLoss: 0.2097\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0144\tTop_Loss: 0.0416\tBottom_Loss: 0.0420\tLoss: 0.0980\t\n",
      "Subject: s5, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0390\tTop_Loss: 0.1117\tBottom_Loss: 0.0688\tLoss: 0.2195\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0144\tTop_Loss: 0.0537\tBottom_Loss: 0.0434\tLoss: 0.1115\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0242\tTop_Loss: 0.0628\tBottom_Loss: 0.0731\tLoss: 0.1601\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0540\tTop_Loss: 0.0895\tBottom_Loss: 0.0997\tLoss: 0.2432\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0142\tTop_Loss: 0.0606\tBottom_Loss: 0.0343\tLoss: 0.1091\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0815\tTop_Loss: 0.2114\tBottom_Loss: 0.0981\tLoss: 0.3910\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0261\tTop_Loss: 0.0829\tBottom_Loss: 0.0436\tLoss: 0.1525\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0101\tTop_Loss: 0.0318\tBottom_Loss: 0.0236\tLoss: 0.0654\t\n",
      "Subject: s5, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0578\tTop_Loss: 0.1000\tBottom_Loss: 0.0769\tLoss: 0.2346\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0088\tTop_Loss: 0.0559\tBottom_Loss: 0.0221\tLoss: 0.0868\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0138\tTop_Loss: 0.0647\tBottom_Loss: 0.0583\tLoss: 0.1368\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0151\tTop_Loss: 0.0261\tBottom_Loss: 0.0405\tLoss: 0.0817\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0060\tTop_Loss: 0.0258\tBottom_Loss: 0.0225\tLoss: 0.0543\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0107\tTop_Loss: 0.0419\tBottom_Loss: 0.0413\tLoss: 0.0939\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0473\tTop_Loss: 0.0894\tBottom_Loss: 0.1524\tLoss: 0.2892\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0127\tTop_Loss: 0.0312\tBottom_Loss: 0.1292\tLoss: 0.1731\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0056\tTop_Loss: 0.0260\tBottom_Loss: 0.0132\tLoss: 0.0448\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0100\tTop_Loss: 0.0296\tBottom_Loss: 0.0336\tLoss: 0.0732\t\n",
      "Subject: s5, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0087\tTop_Loss: 0.0555\tBottom_Loss: 0.0157\tLoss: 0.0799\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0458\tTop_Loss: 0.0747\tBottom_Loss: 0.0894\tLoss: 0.2099\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0346\tTop_Loss: 0.0471\tBottom_Loss: 0.0541\tLoss: 0.1358\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0308\tTop_Loss: 0.0699\tBottom_Loss: 0.0306\tLoss: 0.1312\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0230\tTop_Loss: 0.0379\tBottom_Loss: 0.0286\tLoss: 0.0894\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0520\tTop_Loss: 0.0962\tBottom_Loss: 0.0692\tLoss: 0.2175\t\n",
      "Subject: s5, n=02 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0245\tTop_Loss: 0.0254\tBottom_Loss: 0.1349\tLoss: 0.1848\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0063\tTop_Loss: 0.0206\tBottom_Loss: 0.0216\tLoss: 0.0484\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0075\tTop_Loss: 0.0169\tBottom_Loss: 0.0276\tLoss: 0.0520\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0329\tTop_Loss: 0.0423\tBottom_Loss: 0.0604\tLoss: 0.1357\t\n",
      "Subject: s5, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0081\tTop_Loss: 0.0196\tBottom_Loss: 0.0155\tLoss: 0.0431\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0197\tTop_Loss: 0.0583\tBottom_Loss: 0.0607\tLoss: 0.1387\t\n",
      "Subject: s5, n=02 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0097\tTop_Loss: 0.0317\tBottom_Loss: 0.0271\tLoss: 0.0684\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0200\tTop_Loss: 0.0658\tBottom_Loss: 0.0216\tLoss: 0.1074\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0040\tTop_Loss: 0.0135\tBottom_Loss: 0.0099\tLoss: 0.0274\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0133\tTop_Loss: 0.0284\tBottom_Loss: 0.0667\tLoss: 0.1085\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0152\tTop_Loss: 0.0264\tBottom_Loss: 0.0278\tLoss: 0.0694\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0130\tTop_Loss: 0.0922\tBottom_Loss: 0.0152\tLoss: 0.1204\t\n",
      "Subject: s5, n=02 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.406\tLabel_Loss: 1.4445\tTop_Loss: 1.3273\tBottom_Loss: 1.5602\tLoss: 4.3320\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.531\tLabel_Loss: 1.0247\tTop_Loss: 0.7712\tBottom_Loss: 1.0551\tLoss: 2.8511\t\n",
      "Subject: s6, n=04 | test_f1: 0.16667 |best_f1: 0.16667\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.500\tLabel_Loss: 1.1203\tTop_Loss: 1.0359\tBottom_Loss: 1.0705\tLoss: 3.2268\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.531\tLabel_Loss: 1.2260\tTop_Loss: 1.0713\tBottom_Loss: 1.1011\tLoss: 3.3983\t\n",
      "Subject: s6, n=04 | test_f1: 0.73333 |best_f1: 0.73333\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.562\tLabel_Loss: 0.9189\tTop_Loss: 0.9935\tBottom_Loss: 0.8630\tLoss: 2.7753\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.625\tLabel_Loss: 0.9206\tTop_Loss: 0.8658\tBottom_Loss: 0.8549\tLoss: 2.6413\t\n",
      "Subject: s6, n=04 | test_f1: 0.38889 |best_f1: 0.73333\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.625\tLabel_Loss: 0.8015\tTop_Loss: 0.8981\tBottom_Loss: 1.0355\tLoss: 2.7351\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.531\tLabel_Loss: 0.9950\tTop_Loss: 1.0523\tBottom_Loss: 1.1773\tLoss: 3.2246\t\n",
      "Subject: s6, n=04 | test_f1: 0.33333 |best_f1: 0.73333\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8840\tTop_Loss: 1.0457\tBottom_Loss: 0.8939\tLoss: 2.8236\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.500\tLabel_Loss: 0.9668\tTop_Loss: 0.9047\tBottom_Loss: 1.0132\tLoss: 2.8846\t\n",
      "Subject: s6, n=04 | test_f1: 0.13333 |best_f1: 0.73333\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.531\tLabel_Loss: 0.9040\tTop_Loss: 0.7402\tBottom_Loss: 0.6925\tLoss: 2.3367\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.594\tLabel_Loss: 1.0265\tTop_Loss: 1.0141\tBottom_Loss: 1.1434\tLoss: 3.1840\t\n",
      "Subject: s6, n=04 | test_f1: 0.0 |best_f1: 0.73333\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8594\tTop_Loss: 0.8288\tBottom_Loss: 0.8744\tLoss: 2.5627\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.531\tLabel_Loss: 0.8592\tTop_Loss: 1.0401\tBottom_Loss: 0.9377\tLoss: 2.8370\t\n",
      "Subject: s6, n=04 | test_f1: 0.38889 |best_f1: 0.73333\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.656\tLabel_Loss: 0.8655\tTop_Loss: 0.9264\tBottom_Loss: 0.7816\tLoss: 2.5735\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.562\tLabel_Loss: 0.8187\tTop_Loss: 0.8248\tBottom_Loss: 0.8279\tLoss: 2.4713\t\n",
      "Subject: s6, n=04 | test_f1: 0.33333 |best_f1: 0.73333\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.594\tLabel_Loss: 0.9910\tTop_Loss: 0.9081\tBottom_Loss: 1.0661\tLoss: 2.9652\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8197\tTop_Loss: 0.9743\tBottom_Loss: 0.6581\tLoss: 2.4520\t\n",
      "Subject: s6, n=04 | test_f1: 0.33333 |best_f1: 0.73333\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4913\tTop_Loss: 0.6441\tBottom_Loss: 0.6886\tLoss: 1.8239\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6082\tTop_Loss: 0.7566\tBottom_Loss: 0.7365\tLoss: 2.1013\t\n",
      "Subject: s6, n=04 | test_f1: 0.73333 |best_f1: 0.73333\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.562\tLabel_Loss: 0.7404\tTop_Loss: 0.9828\tBottom_Loss: 0.9081\tLoss: 2.6313\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7913\tTop_Loss: 0.7887\tBottom_Loss: 0.7249\tLoss: 2.3048\t\n",
      "Subject: s6, n=04 | test_f1: 0.55556 |best_f1: 0.73333\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.656\tLabel_Loss: 0.7967\tTop_Loss: 0.7484\tBottom_Loss: 0.8017\tLoss: 2.3468\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7251\tTop_Loss: 0.6290\tBottom_Loss: 0.7482\tLoss: 2.1023\t\n",
      "Subject: s6, n=04 | test_f1: 0.73333 |best_f1: 0.73333\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.594\tLabel_Loss: 0.9439\tTop_Loss: 0.9400\tBottom_Loss: 0.9256\tLoss: 2.8095\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.625\tLabel_Loss: 0.8157\tTop_Loss: 0.7368\tBottom_Loss: 0.9381\tLoss: 2.4905\t\n",
      "Subject: s6, n=04 | test_f1: 0.13333 |best_f1: 0.73333\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.625\tLabel_Loss: 0.6762\tTop_Loss: 0.7106\tBottom_Loss: 0.5731\tLoss: 1.9599\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5982\tTop_Loss: 0.7473\tBottom_Loss: 0.7441\tLoss: 2.0896\t\n",
      "Subject: s6, n=04 | test_f1: 0.13333 |best_f1: 0.73333\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5182\tTop_Loss: 0.6917\tBottom_Loss: 0.7124\tLoss: 1.9222\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6160\tTop_Loss: 0.5405\tBottom_Loss: 0.6133\tLoss: 1.7698\t\n",
      "Subject: s6, n=04 | test_f1: 0.55556 |best_f1: 0.73333\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4592\tTop_Loss: 0.6224\tBottom_Loss: 0.6241\tLoss: 1.7057\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6283\tTop_Loss: 0.8687\tBottom_Loss: 0.5744\tLoss: 2.0714\t\n",
      "Subject: s6, n=04 | test_f1: 0.13333 |best_f1: 0.73333\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7427\tTop_Loss: 0.6617\tBottom_Loss: 0.8135\tLoss: 2.2178\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6823\tTop_Loss: 0.8973\tBottom_Loss: 0.6031\tLoss: 2.1827\t\n",
      "Subject: s6, n=04 | test_f1: 0.73333 |best_f1: 0.73333\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5542\tTop_Loss: 0.6029\tBottom_Loss: 0.6026\tLoss: 1.7597\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5779\tTop_Loss: 0.6348\tBottom_Loss: 0.6488\tLoss: 1.8614\t\n",
      "Subject: s6, n=04 | test_f1: 0.13333 |best_f1: 0.73333\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3877\tTop_Loss: 0.5107\tBottom_Loss: 0.5654\tLoss: 1.4637\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6631\tTop_Loss: 0.7978\tBottom_Loss: 0.7317\tLoss: 2.1926\t\n",
      "Subject: s6, n=04 | test_f1: 0.55556 |best_f1: 0.73333\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4624\tTop_Loss: 0.4816\tBottom_Loss: 0.6727\tLoss: 1.6167\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7057\tTop_Loss: 0.9560\tBottom_Loss: 0.7612\tLoss: 2.4230\t\n",
      "Subject: s6, n=04 | test_f1: 0.16667 |best_f1: 0.73333\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4564\tTop_Loss: 0.5162\tBottom_Loss: 0.5627\tLoss: 1.5354\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4116\tTop_Loss: 0.6426\tBottom_Loss: 0.5904\tLoss: 1.6446\t\n",
      "Subject: s6, n=04 | test_f1: 0.0 |best_f1: 0.73333\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3621\tTop_Loss: 0.4365\tBottom_Loss: 0.5835\tLoss: 1.3821\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5909\tTop_Loss: 0.6292\tBottom_Loss: 0.6098\tLoss: 1.8300\t\n",
      "Subject: s6, n=04 | test_f1: 0.5 |best_f1: 0.73333\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.781\tLabel_Loss: 0.3843\tTop_Loss: 0.5372\tBottom_Loss: 0.4313\tLoss: 1.3529\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.938\tLabel_Loss: 0.3000\tTop_Loss: 0.3327\tBottom_Loss: 0.5930\tLoss: 1.2257\t\n",
      "Subject: s6, n=04 | test_f1: 0.73333 |best_f1: 0.73333\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3312\tTop_Loss: 0.4805\tBottom_Loss: 0.5285\tLoss: 1.3402\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5408\tTop_Loss: 0.6428\tBottom_Loss: 0.6170\tLoss: 1.8006\t\n",
      "Subject: s6, n=04 | test_f1: 0.55556 |best_f1: 0.73333\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4369\tTop_Loss: 0.5795\tBottom_Loss: 0.5710\tLoss: 1.5874\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2759\tTop_Loss: 0.4040\tBottom_Loss: 0.4199\tLoss: 1.0998\t\n",
      "Subject: s6, n=04 | test_f1: 0.55556 |best_f1: 0.73333\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.688\tLabel_Loss: 0.5854\tTop_Loss: 0.7027\tBottom_Loss: 0.5813\tLoss: 1.8694\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3793\tTop_Loss: 0.6717\tBottom_Loss: 0.5073\tLoss: 1.5583\t\n",
      "Subject: s6, n=04 | test_f1: 0.73333 |best_f1: 0.73333\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2737\tTop_Loss: 0.3908\tBottom_Loss: 0.3389\tLoss: 1.0034\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2425\tTop_Loss: 0.3307\tBottom_Loss: 0.4997\tLoss: 1.0729\t\n",
      "Subject: s6, n=04 | test_f1: 0.44444 |best_f1: 0.73333\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2332\tTop_Loss: 0.3681\tBottom_Loss: 0.4790\tLoss: 1.0804\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.938\tLabel_Loss: 0.3134\tTop_Loss: 0.3721\tBottom_Loss: 0.3790\tLoss: 1.0645\t\n",
      "Subject: s6, n=04 | test_f1: 0.13333 |best_f1: 0.73333\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2698\tTop_Loss: 0.3713\tBottom_Loss: 0.4682\tLoss: 1.1093\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4114\tTop_Loss: 0.6726\tBottom_Loss: 0.5009\tLoss: 1.5850\t\n",
      "Subject: s6, n=04 | test_f1: 0.22222 |best_f1: 0.73333\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4219\tTop_Loss: 0.6293\tBottom_Loss: 0.4363\tLoss: 1.4874\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4151\tTop_Loss: 0.4947\tBottom_Loss: 0.4989\tLoss: 1.4087\t\n",
      "Subject: s6, n=04 | test_f1: 0.73333 |best_f1: 0.73333\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3365\tTop_Loss: 0.5052\tBottom_Loss: 0.4757\tLoss: 1.3174\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2352\tTop_Loss: 0.4764\tBottom_Loss: 0.4199\tLoss: 1.1316\t\n",
      "Subject: s6, n=04 | test_f1: 0.33333 |best_f1: 0.73333\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.781\tLabel_Loss: 0.4904\tTop_Loss: 0.6516\tBottom_Loss: 0.5639\tLoss: 1.7058\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3623\tTop_Loss: 0.3614\tBottom_Loss: 0.4870\tLoss: 1.2107\t\n",
      "Subject: s6, n=04 | test_f1: 0.55556 |best_f1: 0.73333\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3206\tTop_Loss: 0.5094\tBottom_Loss: 0.3237\tLoss: 1.1537\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3210\tTop_Loss: 0.5375\tBottom_Loss: 0.3741\tLoss: 1.2327\t\n",
      "Subject: s6, n=04 | test_f1: 0.38889 |best_f1: 0.73333\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2336\tTop_Loss: 0.3070\tBottom_Loss: 0.4116\tLoss: 0.9522\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2473\tTop_Loss: 0.4575\tBottom_Loss: 0.3080\tLoss: 1.0128\t\n",
      "Subject: s6, n=04 | test_f1: 0.38889 |best_f1: 0.73333\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1805\tTop_Loss: 0.3119\tBottom_Loss: 0.4343\tLoss: 0.9267\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2646\tTop_Loss: 0.5388\tBottom_Loss: 0.3115\tLoss: 1.1149\t\n",
      "Subject: s6, n=04 | test_f1: 0.73333 |best_f1: 0.73333\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3855\tTop_Loss: 0.5398\tBottom_Loss: 0.4275\tLoss: 1.3528\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1373\tTop_Loss: 0.2727\tBottom_Loss: 0.2637\tLoss: 0.6737\t\n",
      "Subject: s6, n=04 | test_f1: 0.38889 |best_f1: 0.73333\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3338\tTop_Loss: 0.5040\tBottom_Loss: 0.3961\tLoss: 1.2340\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2170\tTop_Loss: 0.4106\tBottom_Loss: 0.1814\tLoss: 0.8090\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: s6, n=04 | test_f1: 0.55556 |best_f1: 0.73333\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5215\tTop_Loss: 0.6045\tBottom_Loss: 0.5497\tLoss: 1.6758\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1549\tTop_Loss: 0.3802\tBottom_Loss: 0.2400\tLoss: 0.7752\t\n",
      "Subject: s6, n=04 | test_f1: 0.26667 |best_f1: 0.73333\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1526\tTop_Loss: 0.3185\tBottom_Loss: 0.2049\tLoss: 0.6760\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1921\tTop_Loss: 0.3261\tBottom_Loss: 0.2421\tLoss: 0.7603\t\n",
      "Subject: s6, n=04 | test_f1: 0.73333 |best_f1: 0.73333\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1637\tTop_Loss: 0.2546\tBottom_Loss: 0.2794\tLoss: 0.6976\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2381\tTop_Loss: 0.4152\tBottom_Loss: 0.3452\tLoss: 0.9985\t\n",
      "Subject: s6, n=04 | test_f1: 0.73333 |best_f1: 0.73333\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1212\tTop_Loss: 0.1971\tBottom_Loss: 0.1629\tLoss: 0.4812\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2386\tTop_Loss: 0.3465\tBottom_Loss: 0.2689\tLoss: 0.8540\t\n",
      "Subject: s6, n=04 | test_f1: 0.73333 |best_f1: 0.73333\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1460\tTop_Loss: 0.2887\tBottom_Loss: 0.2474\tLoss: 0.6820\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1065\tTop_Loss: 0.1979\tBottom_Loss: 0.1757\tLoss: 0.4802\t\n",
      "Subject: s6, n=04 | test_f1: 0.73333 |best_f1: 0.73333\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1374\tTop_Loss: 0.3846\tBottom_Loss: 0.2184\tLoss: 0.7405\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1227\tTop_Loss: 0.2758\tBottom_Loss: 0.2451\tLoss: 0.6437\t\n",
      "Subject: s6, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2085\tTop_Loss: 0.2789\tBottom_Loss: 0.3503\tLoss: 0.8377\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1818\tTop_Loss: 0.4566\tBottom_Loss: 0.3000\tLoss: 0.9384\t\n",
      "Subject: s6, n=04 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2279\tTop_Loss: 0.3551\tBottom_Loss: 0.3944\tLoss: 0.9774\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2287\tTop_Loss: 0.4600\tBottom_Loss: 0.3183\tLoss: 1.0069\t\n",
      "Subject: s6, n=04 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1291\tTop_Loss: 0.2630\tBottom_Loss: 0.1916\tLoss: 0.5836\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1961\tTop_Loss: 0.2627\tBottom_Loss: 0.2392\tLoss: 0.6980\t\n",
      "Subject: s6, n=04 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1441\tTop_Loss: 0.2309\tBottom_Loss: 0.3187\tLoss: 0.6937\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1461\tTop_Loss: 0.3273\tBottom_Loss: 0.2500\tLoss: 0.7234\t\n",
      "Subject: s6, n=04 | test_f1: 0.38889 |best_f1: 1.0\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1962\tTop_Loss: 0.3017\tBottom_Loss: 0.2894\tLoss: 0.7873\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1157\tTop_Loss: 0.2414\tBottom_Loss: 0.1803\tLoss: 0.5374\t\n",
      "Subject: s6, n=04 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1496\tTop_Loss: 0.1712\tBottom_Loss: 0.1957\tLoss: 0.5165\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1269\tTop_Loss: 0.1594\tBottom_Loss: 0.1514\tLoss: 0.4377\t\n",
      "Subject: s6, n=04 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0695\tTop_Loss: 0.1650\tBottom_Loss: 0.1727\tLoss: 0.4072\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1068\tTop_Loss: 0.2095\tBottom_Loss: 0.1698\tLoss: 0.4860\t\n",
      "Subject: s6, n=04 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0739\tTop_Loss: 0.1328\tBottom_Loss: 0.1689\tLoss: 0.3757\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0469\tTop_Loss: 0.1308\tBottom_Loss: 0.0992\tLoss: 0.2770\t\n",
      "Subject: s6, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1384\tTop_Loss: 0.2545\tBottom_Loss: 0.2356\tLoss: 0.6284\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0777\tTop_Loss: 0.2145\tBottom_Loss: 0.1581\tLoss: 0.4502\t\n",
      "Subject: s6, n=04 | test_f1: 0.73333 |best_f1: 1.0\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1457\tTop_Loss: 0.1849\tBottom_Loss: 0.1920\tLoss: 0.5226\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0906\tTop_Loss: 0.2588\tBottom_Loss: 0.1071\tLoss: 0.4566\t\n",
      "Subject: s6, n=04 | test_f1: 0.13333 |best_f1: 1.0\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1164\tTop_Loss: 0.2618\tBottom_Loss: 0.2054\tLoss: 0.5836\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0578\tTop_Loss: 0.2968\tBottom_Loss: 0.1091\tLoss: 0.4638\t\n",
      "Subject: s6, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1151\tTop_Loss: 0.2323\tBottom_Loss: 0.1394\tLoss: 0.4868\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1512\tTop_Loss: 0.3030\tBottom_Loss: 0.2308\tLoss: 0.6851\t\n",
      "Subject: s6, n=04 | test_f1: 0.38889 |best_f1: 1.0\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1423\tTop_Loss: 0.2082\tBottom_Loss: 0.2403\tLoss: 0.5908\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0963\tTop_Loss: 0.2317\tBottom_Loss: 0.1421\tLoss: 0.4701\t\n",
      "Subject: s6, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0972\tTop_Loss: 0.2566\tBottom_Loss: 0.1438\tLoss: 0.4976\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0715\tTop_Loss: 0.1166\tBottom_Loss: 0.2132\tLoss: 0.4014\t\n",
      "Subject: s6, n=04 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1165\tTop_Loss: 0.1887\tBottom_Loss: 0.2191\tLoss: 0.5243\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1780\tTop_Loss: 0.1795\tBottom_Loss: 0.2325\tLoss: 0.5900\t\n",
      "Subject: s6, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0604\tTop_Loss: 0.1099\tBottom_Loss: 0.1066\tLoss: 0.2768\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0497\tTop_Loss: 0.1972\tBottom_Loss: 0.1257\tLoss: 0.3725\t\n",
      "Subject: s6, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0537\tTop_Loss: 0.2240\tBottom_Loss: 0.1559\tLoss: 0.4336\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0549\tTop_Loss: 0.0994\tBottom_Loss: 0.1532\tLoss: 0.3075\t\n",
      "Subject: s6, n=04 | test_f1: 0.38889 |best_f1: 1.0\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0435\tTop_Loss: 0.1302\tBottom_Loss: 0.0569\tLoss: 0.2306\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0437\tTop_Loss: 0.1518\tBottom_Loss: 0.0823\tLoss: 0.2777\t\n",
      "Subject: s6, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0329\tTop_Loss: 0.1158\tBottom_Loss: 0.0985\tLoss: 0.2472\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0579\tTop_Loss: 0.1381\tBottom_Loss: 0.2110\tLoss: 0.4069\t\n",
      "Subject: s6, n=04 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0396\tTop_Loss: 0.1156\tBottom_Loss: 0.1217\tLoss: 0.2769\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0301\tTop_Loss: 0.0845\tBottom_Loss: 0.1230\tLoss: 0.2376\t\n",
      "Subject: s6, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0421\tTop_Loss: 0.1260\tBottom_Loss: 0.1286\tLoss: 0.2967\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1631\tTop_Loss: 0.2176\tBottom_Loss: 0.2815\tLoss: 0.6622\t\n",
      "Subject: s6, n=04 | test_f1: 0.38889 |best_f1: 1.0\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0867\tTop_Loss: 0.1810\tBottom_Loss: 0.0761\tLoss: 0.3438\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0402\tTop_Loss: 0.1393\tBottom_Loss: 0.0900\tLoss: 0.2695\t\n",
      "Subject: s6, n=04 | test_f1: 0.38889 |best_f1: 1.0\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1551\tTop_Loss: 0.1591\tBottom_Loss: 0.3144\tLoss: 0.6286\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0468\tTop_Loss: 0.1209\tBottom_Loss: 0.1919\tLoss: 0.3596\t\n",
      "Subject: s6, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0364\tTop_Loss: 0.1226\tBottom_Loss: 0.0929\tLoss: 0.2519\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0660\tTop_Loss: 0.1136\tBottom_Loss: 0.1092\tLoss: 0.2888\t\n",
      "Subject: s6, n=04 | test_f1: 0.38889 |best_f1: 1.0\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0295\tTop_Loss: 0.1205\tBottom_Loss: 0.0532\tLoss: 0.2032\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0757\tTop_Loss: 0.1642\tBottom_Loss: 0.1592\tLoss: 0.3992\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: s6, n=04 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1018\tTop_Loss: 0.1472\tBottom_Loss: 0.2093\tLoss: 0.4583\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0282\tTop_Loss: 0.1032\tBottom_Loss: 0.0383\tLoss: 0.1698\t\n",
      "Subject: s6, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0246\tTop_Loss: 0.0607\tBottom_Loss: 0.0711\tLoss: 0.1564\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0140\tTop_Loss: 0.0653\tBottom_Loss: 0.0592\tLoss: 0.1385\t\n",
      "Subject: s6, n=04 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0201\tTop_Loss: 0.0904\tBottom_Loss: 0.0479\tLoss: 0.1584\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0159\tTop_Loss: 0.0426\tBottom_Loss: 0.0848\tLoss: 0.1433\t\n",
      "Subject: s6, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0199\tTop_Loss: 0.0924\tBottom_Loss: 0.0471\tLoss: 0.1593\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0484\tTop_Loss: 0.1282\tBottom_Loss: 0.0820\tLoss: 0.2586\t\n",
      "Subject: s6, n=04 | test_f1: 0.44444 |best_f1: 1.0\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0409\tTop_Loss: 0.1066\tBottom_Loss: 0.0999\tLoss: 0.2474\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0503\tTop_Loss: 0.1921\tBottom_Loss: 0.0821\tLoss: 0.3245\t\n",
      "Subject: s6, n=04 | test_f1: 0.38889 |best_f1: 1.0\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0429\tTop_Loss: 0.0931\tBottom_Loss: 0.0946\tLoss: 0.2306\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0195\tTop_Loss: 0.0554\tBottom_Loss: 0.0329\tLoss: 0.1078\t\n",
      "Subject: s6, n=04 | test_f1: 0.73333 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0557\tTop_Loss: 0.1498\tBottom_Loss: 0.1129\tLoss: 0.3184\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0177\tTop_Loss: 0.0686\tBottom_Loss: 0.0521\tLoss: 0.1384\t\n",
      "Subject: s6, n=04 | test_f1: 0.38889 |best_f1: 1.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1455\tTop_Loss: 0.1226\tBottom_Loss: 0.1934\tLoss: 0.4615\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0652\tTop_Loss: 0.1496\tBottom_Loss: 0.1284\tLoss: 0.3432\t\n",
      "Subject: s6, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0965\tTop_Loss: 0.1629\tBottom_Loss: 0.1178\tLoss: 0.3772\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0614\tTop_Loss: 0.0669\tBottom_Loss: 0.1095\tLoss: 0.2378\t\n",
      "Subject: s6, n=04 | test_f1: 0.38889 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0343\tTop_Loss: 0.0788\tBottom_Loss: 0.0814\tLoss: 0.1945\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0250\tTop_Loss: 0.1284\tBottom_Loss: 0.0498\tLoss: 0.2032\t\n",
      "Subject: s6, n=04 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0119\tTop_Loss: 0.0375\tBottom_Loss: 0.0429\tLoss: 0.0922\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0128\tTop_Loss: 0.0525\tBottom_Loss: 0.0666\tLoss: 0.1319\t\n",
      "Subject: s6, n=04 | test_f1: 0.13333 |best_f1: 1.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0382\tTop_Loss: 0.1076\tBottom_Loss: 0.0943\tLoss: 0.2402\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0159\tTop_Loss: 0.0350\tBottom_Loss: 0.0763\tLoss: 0.1272\t\n",
      "Subject: s6, n=04 | test_f1: 0.73333 |best_f1: 1.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0337\tTop_Loss: 0.0918\tBottom_Loss: 0.1269\tLoss: 0.2524\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0106\tTop_Loss: 0.0357\tBottom_Loss: 0.0472\tLoss: 0.0935\t\n",
      "Subject: s6, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0243\tTop_Loss: 0.1360\tBottom_Loss: 0.0332\tLoss: 0.1934\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0390\tTop_Loss: 0.0551\tBottom_Loss: 0.0955\tLoss: 0.1897\t\n",
      "Subject: s6, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0270\tTop_Loss: 0.0487\tBottom_Loss: 0.0306\tLoss: 0.1063\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0239\tTop_Loss: 0.0371\tBottom_Loss: 0.0613\tLoss: 0.1223\t\n",
      "Subject: s6, n=04 | test_f1: 0.38889 |best_f1: 1.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0535\tTop_Loss: 0.0667\tBottom_Loss: 0.2014\tLoss: 0.3216\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0148\tTop_Loss: 0.0747\tBottom_Loss: 0.0423\tLoss: 0.1318\t\n",
      "Subject: s6, n=04 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0108\tTop_Loss: 0.0540\tBottom_Loss: 0.0501\tLoss: 0.1149\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0089\tTop_Loss: 0.0175\tBottom_Loss: 0.0370\tLoss: 0.0634\t\n",
      "Subject: s6, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0227\tTop_Loss: 0.1324\tBottom_Loss: 0.0699\tLoss: 0.2251\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0114\tTop_Loss: 0.0416\tBottom_Loss: 0.0324\tLoss: 0.0854\t\n",
      "Subject: s6, n=04 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0111\tTop_Loss: 0.0193\tBottom_Loss: 0.0414\tLoss: 0.0718\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0146\tTop_Loss: 0.0290\tBottom_Loss: 0.0312\tLoss: 0.0748\t\n",
      "Subject: s6, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0134\tTop_Loss: 0.0295\tBottom_Loss: 0.0651\tLoss: 0.1079\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0084\tTop_Loss: 0.0190\tBottom_Loss: 0.0394\tLoss: 0.0668\t\n",
      "Subject: s6, n=04 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0085\tTop_Loss: 0.0179\tBottom_Loss: 0.0315\tLoss: 0.0579\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0271\tTop_Loss: 0.0568\tBottom_Loss: 0.0520\tLoss: 0.1359\t\n",
      "Subject: s6, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0330\tTop_Loss: 0.0546\tBottom_Loss: 0.0560\tLoss: 0.1436\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0095\tTop_Loss: 0.0199\tBottom_Loss: 0.0216\tLoss: 0.0510\t\n",
      "Subject: s6, n=04 | test_f1: 0.38889 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0079\tTop_Loss: 0.0226\tBottom_Loss: 0.0175\tLoss: 0.0479\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0109\tTop_Loss: 0.0351\tBottom_Loss: 0.0443\tLoss: 0.0903\t\n",
      "Subject: s6, n=04 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0034\tTop_Loss: 0.0210\tBottom_Loss: 0.0155\tLoss: 0.0400\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0057\tTop_Loss: 0.0216\tBottom_Loss: 0.0168\tLoss: 0.0441\t\n",
      "Subject: s6, n=04 | test_f1: 0.38889 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0175\tTop_Loss: 0.0527\tBottom_Loss: 0.0227\tLoss: 0.0929\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0071\tTop_Loss: 0.0372\tBottom_Loss: 0.0213\tLoss: 0.0656\t\n",
      "Subject: s6, n=04 | test_f1: 0.38889 |best_f1: 1.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0043\tTop_Loss: 0.0185\tBottom_Loss: 0.0187\tLoss: 0.0415\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0106\tTop_Loss: 0.0394\tBottom_Loss: 0.0448\tLoss: 0.0947\t\n",
      "Subject: s6, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0144\tTop_Loss: 0.0291\tBottom_Loss: 0.0493\tLoss: 0.0928\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0046\tTop_Loss: 0.0370\tBottom_Loss: 0.0194\tLoss: 0.0609\t\n",
      "Subject: s6, n=04 | test_f1: 0.73333 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0081\tTop_Loss: 0.0473\tBottom_Loss: 0.0231\tLoss: 0.0786\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0404\tTop_Loss: 0.0752\tBottom_Loss: 0.0382\tLoss: 0.1538\t\n",
      "Subject: s6, n=04 | test_f1: 0.73333 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0202\tTop_Loss: 0.0671\tBottom_Loss: 0.0276\tLoss: 0.1149\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0093\tTop_Loss: 0.0368\tBottom_Loss: 0.0137\tLoss: 0.0598\t\n",
      "Subject: s6, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0052\tTop_Loss: 0.0237\tBottom_Loss: 0.0116\tLoss: 0.0405\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0091\tTop_Loss: 0.0498\tBottom_Loss: 0.0207\tLoss: 0.0796\t\n",
      "Subject: s6, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0057\tTop_Loss: 0.0228\tBottom_Loss: 0.0290\tLoss: 0.0575\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0114\tTop_Loss: 0.0430\tBottom_Loss: 0.0417\tLoss: 0.0961\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: s6, n=04 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0063\tTop_Loss: 0.0373\tBottom_Loss: 0.0236\tLoss: 0.0672\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0074\tTop_Loss: 0.0176\tBottom_Loss: 0.0549\tLoss: 0.0798\t\n",
      "Subject: s6, n=04 | test_f1: 0.55556 |best_f1: 1.0\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.438\tLabel_Loss: 1.0804\tTop_Loss: 2.1606\tBottom_Loss: 2.2411\tLoss: 5.4821\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.531\tLabel_Loss: 1.2304\tTop_Loss: 1.0639\tBottom_Loss: 1.2216\tLoss: 3.5159\t\n",
      "Subject: s8, n=13 | test_f1: 0.17677 |best_f1: 0.17677\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.406\tLabel_Loss: 1.1438\tTop_Loss: 1.2057\tBottom_Loss: 1.0751\tLoss: 3.4245\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.500\tLabel_Loss: 1.0706\tTop_Loss: 1.0395\tBottom_Loss: 1.0599\tLoss: 3.1701\t\n",
      "Subject: s8, n=13 | test_f1: 0.17778 |best_f1: 0.17778\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.344\tLabel_Loss: 1.0536\tTop_Loss: 1.1063\tBottom_Loss: 0.9475\tLoss: 3.1075\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.562\tLabel_Loss: 0.9382\tTop_Loss: 0.8369\tBottom_Loss: 0.8965\tLoss: 2.6717\t\n",
      "Subject: s8, n=13 | test_f1: 0.22222 |best_f1: 0.22222\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.812\tLabel_Loss: 0.7612\tTop_Loss: 0.6394\tBottom_Loss: 0.8709\tLoss: 2.2715\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.594\tLabel_Loss: 0.9003\tTop_Loss: 1.0399\tBottom_Loss: 0.9542\tLoss: 2.8945\t\n",
      "Subject: s8, n=13 | test_f1: 0.31746 |best_f1: 0.31746\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.500\tLabel_Loss: 0.9764\tTop_Loss: 0.9779\tBottom_Loss: 1.0741\tLoss: 3.0285\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.594\tLabel_Loss: 0.7905\tTop_Loss: 0.8995\tBottom_Loss: 0.8069\tLoss: 2.4969\t\n",
      "Subject: s8, n=13 | test_f1: 0.43333 |best_f1: 0.43333\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.562\tLabel_Loss: 0.9501\tTop_Loss: 1.0468\tBottom_Loss: 1.0269\tLoss: 3.0237\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.562\tLabel_Loss: 0.8477\tTop_Loss: 0.9222\tBottom_Loss: 0.9785\tLoss: 2.7484\t\n",
      "Subject: s8, n=13 | test_f1: 0.21053 |best_f1: 0.43333\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.562\tLabel_Loss: 0.7802\tTop_Loss: 0.8309\tBottom_Loss: 0.8994\tLoss: 2.5106\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.438\tLabel_Loss: 1.0052\tTop_Loss: 1.0071\tBottom_Loss: 0.9369\tLoss: 2.9492\t\n",
      "Subject: s8, n=13 | test_f1: 0.23333 |best_f1: 0.43333\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.594\tLabel_Loss: 0.7723\tTop_Loss: 0.9559\tBottom_Loss: 0.9648\tLoss: 2.6929\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.781\tLabel_Loss: 0.6278\tTop_Loss: 0.8783\tBottom_Loss: 0.7642\tLoss: 2.2703\t\n",
      "Subject: s8, n=13 | test_f1: 0.21053 |best_f1: 0.43333\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6911\tTop_Loss: 0.8038\tBottom_Loss: 0.7616\tLoss: 2.2564\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6944\tTop_Loss: 0.7577\tBottom_Loss: 0.7061\tLoss: 2.1583\t\n",
      "Subject: s8, n=13 | test_f1: 0.22222 |best_f1: 0.43333\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8732\tTop_Loss: 0.9324\tBottom_Loss: 0.8849\tLoss: 2.6905\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7093\tTop_Loss: 0.8092\tBottom_Loss: 0.7971\tLoss: 2.3155\t\n",
      "Subject: s8, n=13 | test_f1: 0.33333 |best_f1: 0.43333\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.625\tLabel_Loss: 0.7903\tTop_Loss: 0.8974\tBottom_Loss: 0.6322\tLoss: 2.3199\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7863\tTop_Loss: 0.7410\tBottom_Loss: 0.7690\tLoss: 2.2962\t\n",
      "Subject: s8, n=13 | test_f1: 0.30303 |best_f1: 0.43333\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.500\tLabel_Loss: 0.8957\tTop_Loss: 1.0648\tBottom_Loss: 0.8511\tLoss: 2.8116\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7765\tTop_Loss: 0.9132\tBottom_Loss: 0.7250\tLoss: 2.4147\t\n",
      "Subject: s8, n=13 | test_f1: 0.35385 |best_f1: 0.43333\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5232\tTop_Loss: 0.5692\tBottom_Loss: 0.5544\tLoss: 1.6468\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5862\tTop_Loss: 0.8330\tBottom_Loss: 0.7653\tLoss: 2.1845\t\n",
      "Subject: s8, n=13 | test_f1: 0.16667 |best_f1: 0.43333\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5892\tTop_Loss: 0.7347\tBottom_Loss: 0.5740\tLoss: 1.8979\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6370\tTop_Loss: 0.8237\tBottom_Loss: 0.5455\tLoss: 2.0062\t\n",
      "Subject: s8, n=13 | test_f1: 0.27506 |best_f1: 0.43333\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.594\tLabel_Loss: 0.6909\tTop_Loss: 0.6451\tBottom_Loss: 0.7702\tLoss: 2.1061\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.688\tLabel_Loss: 0.7203\tTop_Loss: 0.8332\tBottom_Loss: 0.7241\tLoss: 2.2776\t\n",
      "Subject: s8, n=13 | test_f1: 0.16667 |best_f1: 0.43333\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.938\tLabel_Loss: 0.4229\tTop_Loss: 0.6476\tBottom_Loss: 0.6623\tLoss: 1.7328\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.875\tLabel_Loss: 0.4220\tTop_Loss: 0.5919\tBottom_Loss: 0.4805\tLoss: 1.4944\t\n",
      "Subject: s8, n=13 | test_f1: 0.10256 |best_f1: 0.43333\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.750\tLabel_Loss: 0.6827\tTop_Loss: 0.5363\tBottom_Loss: 0.7131\tLoss: 1.9320\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6098\tTop_Loss: 0.6899\tBottom_Loss: 0.8302\tLoss: 2.1300\t\n",
      "Subject: s8, n=13 | test_f1: 0.34343 |best_f1: 0.43333\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.844\tLabel_Loss: 0.5074\tTop_Loss: 0.8291\tBottom_Loss: 0.5960\tLoss: 1.9325\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6759\tTop_Loss: 0.8294\tBottom_Loss: 0.7656\tLoss: 2.2709\t\n",
      "Subject: s8, n=13 | test_f1: 0.41667 |best_f1: 0.43333\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5037\tTop_Loss: 0.7257\tBottom_Loss: 0.5549\tLoss: 1.7843\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5504\tTop_Loss: 0.6259\tBottom_Loss: 0.6259\tLoss: 1.8021\t\n",
      "Subject: s8, n=13 | test_f1: 0.11111 |best_f1: 0.43333\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.812\tLabel_Loss: 0.5161\tTop_Loss: 0.5472\tBottom_Loss: 0.5671\tLoss: 1.6304\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.781\tLabel_Loss: 0.3838\tTop_Loss: 0.5365\tBottom_Loss: 0.5569\tLoss: 1.4772\t\n",
      "Subject: s8, n=13 | test_f1: 0.4127 |best_f1: 0.43333\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5125\tTop_Loss: 0.7261\tBottom_Loss: 0.5253\tLoss: 1.7639\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.781\tLabel_Loss: 0.4457\tTop_Loss: 0.5763\tBottom_Loss: 0.5845\tLoss: 1.6065\t\n",
      "Subject: s8, n=13 | test_f1: 0.26111 |best_f1: 0.43333\n",
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4355\tTop_Loss: 0.6675\tBottom_Loss: 0.5727\tLoss: 1.6758\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.750\tLabel_Loss: 0.4601\tTop_Loss: 0.6440\tBottom_Loss: 0.5626\tLoss: 1.6667\t\n",
      "Subject: s8, n=13 | test_f1: 0.30199 |best_f1: 0.43333\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4379\tTop_Loss: 0.5490\tBottom_Loss: 0.5341\tLoss: 1.5210\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.938\tLabel_Loss: 0.3239\tTop_Loss: 0.4559\tBottom_Loss: 0.4624\tLoss: 1.2422\t\n",
      "Subject: s8, n=13 | test_f1: 0.2359 |best_f1: 0.43333\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3762\tTop_Loss: 0.4357\tBottom_Loss: 0.4979\tLoss: 1.3098\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2887\tTop_Loss: 0.4739\tBottom_Loss: 0.3941\tLoss: 1.1567\t\n",
      "Subject: s8, n=13 | test_f1: 0.16667 |best_f1: 0.43333\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4397\tTop_Loss: 0.6134\tBottom_Loss: 0.5086\tLoss: 1.5616\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3981\tTop_Loss: 0.6580\tBottom_Loss: 0.3628\tLoss: 1.4189\t\n",
      "Subject: s8, n=13 | test_f1: 0.16239 |best_f1: 0.43333\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2756\tTop_Loss: 0.4774\tBottom_Loss: 0.3836\tLoss: 1.1365\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2629\tTop_Loss: 0.5377\tBottom_Loss: 0.3701\tLoss: 1.1707\t\n",
      "Subject: s8, n=13 | test_f1: 0.2381 |best_f1: 0.43333\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2668\tTop_Loss: 0.4067\tBottom_Loss: 0.3123\tLoss: 0.9858\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.906\tLabel_Loss: 0.4262\tTop_Loss: 0.6214\tBottom_Loss: 0.4609\tLoss: 1.5085\t\n",
      "Subject: s8, n=13 | test_f1: 0.15079 |best_f1: 0.43333\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2996\tTop_Loss: 0.4412\tBottom_Loss: 0.2944\tLoss: 1.0351\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3753\tTop_Loss: 0.5209\tBottom_Loss: 0.3995\tLoss: 1.2956\t\n",
      "Subject: s8, n=13 | test_f1: 0.20952 |best_f1: 0.43333\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4765\tTop_Loss: 0.6301\tBottom_Loss: 0.5342\tLoss: 1.6409\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.781\tLabel_Loss: 0.5064\tTop_Loss: 0.5235\tBottom_Loss: 0.7284\tLoss: 1.7583\t\n",
      "Subject: s8, n=13 | test_f1: 0.15686 |best_f1: 0.43333\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3310\tTop_Loss: 0.4080\tBottom_Loss: 0.4298\tLoss: 1.1689\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3522\tTop_Loss: 0.4538\tBottom_Loss: 0.5288\tLoss: 1.3348\t\n",
      "Subject: s8, n=13 | test_f1: 0.44048 |best_f1: 0.44048\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3023\tTop_Loss: 0.3456\tBottom_Loss: 0.4305\tLoss: 1.0784\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2810\tTop_Loss: 0.3366\tBottom_Loss: 0.3345\tLoss: 0.9521\t\n",
      "Subject: s8, n=13 | test_f1: 0.17778 |best_f1: 0.44048\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1729\tTop_Loss: 0.3596\tBottom_Loss: 0.2664\tLoss: 0.7989\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2009\tTop_Loss: 0.3612\tBottom_Loss: 0.3778\tLoss: 0.9399\t\n",
      "Subject: s8, n=13 | test_f1: 0.1859 |best_f1: 0.44048\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2187\tTop_Loss: 0.5985\tBottom_Loss: 0.3484\tLoss: 1.1656\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2041\tTop_Loss: 0.4244\tBottom_Loss: 0.3281\tLoss: 0.9566\t\n",
      "Subject: s8, n=13 | test_f1: 0.1859 |best_f1: 0.44048\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2145\tTop_Loss: 0.5363\tBottom_Loss: 0.2606\tLoss: 1.0114\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2527\tTop_Loss: 0.4445\tBottom_Loss: 0.4098\tLoss: 1.1070\t\n",
      "Subject: s8, n=13 | test_f1: 0.30159 |best_f1: 0.44048\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2795\tTop_Loss: 0.4134\tBottom_Loss: 0.3420\tLoss: 1.0350\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.969\tLabel_Loss: 0.2660\tTop_Loss: 0.3608\tBottom_Loss: 0.3530\tLoss: 0.9798\t\n",
      "Subject: s8, n=13 | test_f1: 0.13889 |best_f1: 0.44048\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2814\tTop_Loss: 0.4351\tBottom_Loss: 0.3940\tLoss: 1.1106\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2762\tTop_Loss: 0.4490\tBottom_Loss: 0.4951\tLoss: 1.2203\t\n",
      "Subject: s8, n=13 | test_f1: 0.17857 |best_f1: 0.44048\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1366\tTop_Loss: 0.2772\tBottom_Loss: 0.1951\tLoss: 0.6090\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2387\tTop_Loss: 0.4857\tBottom_Loss: 0.2960\tLoss: 1.0204\t\n",
      "Subject: s8, n=13 | test_f1: 0.34432 |best_f1: 0.44048\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1748\tTop_Loss: 0.3407\tBottom_Loss: 0.2695\tLoss: 0.7850\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3030\tTop_Loss: 0.3379\tBottom_Loss: 0.4659\tLoss: 1.1068\t\n",
      "Subject: s8, n=13 | test_f1: 0.095238 |best_f1: 0.44048\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1914\tTop_Loss: 0.3363\tBottom_Loss: 0.3082\tLoss: 0.8359\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3779\tTop_Loss: 0.3779\tBottom_Loss: 0.3846\tLoss: 1.1403\t\n",
      "Subject: s8, n=13 | test_f1: 0.375 |best_f1: 0.44048\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1117\tTop_Loss: 0.2816\tBottom_Loss: 0.2424\tLoss: 0.6358\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1300\tTop_Loss: 0.3729\tBottom_Loss: 0.1963\tLoss: 0.6993\t\n",
      "Subject: s8, n=13 | test_f1: 0.12222 |best_f1: 0.44048\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.875\tLabel_Loss: 0.1987\tTop_Loss: 0.3176\tBottom_Loss: 0.3079\tLoss: 0.8242\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2578\tTop_Loss: 0.3333\tBottom_Loss: 0.2957\tLoss: 0.8868\t\n",
      "Subject: s8, n=13 | test_f1: 0.25397 |best_f1: 0.44048\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 1.000\tLabel_Loss: 0.1741\tTop_Loss: 0.3780\tBottom_Loss: 0.2664\tLoss: 0.8185\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1776\tTop_Loss: 0.3485\tBottom_Loss: 0.3115\tLoss: 0.8375\t\n",
      "Subject: s8, n=13 | test_f1: 0.4127 |best_f1: 0.44048\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1444\tTop_Loss: 0.3901\tBottom_Loss: 0.1145\tLoss: 0.6490\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1607\tTop_Loss: 0.3153\tBottom_Loss: 0.2451\tLoss: 0.7210\t\n",
      "Subject: s8, n=13 | test_f1: 0.25 |best_f1: 0.44048\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1181\tTop_Loss: 0.1830\tBottom_Loss: 0.2128\tLoss: 0.5139\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1766\tTop_Loss: 0.3927\tBottom_Loss: 0.2421\tLoss: 0.8114\t\n",
      "Subject: s8, n=13 | test_f1: 0.28718 |best_f1: 0.44048\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2156\tTop_Loss: 0.3779\tBottom_Loss: 0.2218\tLoss: 0.8153\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0980\tTop_Loss: 0.1708\tBottom_Loss: 0.1836\tLoss: 0.4524\t\n",
      "Subject: s8, n=13 | test_f1: 0.20741 |best_f1: 0.44048\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2512\tTop_Loss: 0.5275\tBottom_Loss: 0.2056\tLoss: 0.9843\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1299\tTop_Loss: 0.2978\tBottom_Loss: 0.2401\tLoss: 0.6678\t\n",
      "Subject: s8, n=13 | test_f1: 0.0 |best_f1: 0.44048\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2012\tTop_Loss: 0.3053\tBottom_Loss: 0.2372\tLoss: 0.7437\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.875\tLabel_Loss: 0.3104\tTop_Loss: 0.5642\tBottom_Loss: 0.3316\tLoss: 1.2063\t\n",
      "Subject: s8, n=13 | test_f1: 0.22857 |best_f1: 0.44048\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1108\tTop_Loss: 0.2539\tBottom_Loss: 0.1783\tLoss: 0.5430\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1564\tTop_Loss: 0.3505\tBottom_Loss: 0.3049\tLoss: 0.8118\t\n",
      "Subject: s8, n=13 | test_f1: 0.28889 |best_f1: 0.44048\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0851\tTop_Loss: 0.1456\tBottom_Loss: 0.1351\tLoss: 0.3658\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1481\tTop_Loss: 0.2327\tBottom_Loss: 0.2500\tLoss: 0.6308\t\n",
      "Subject: s8, n=13 | test_f1: 0.19444 |best_f1: 0.44048\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0640\tTop_Loss: 0.2237\tBottom_Loss: 0.1489\tLoss: 0.4366\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0882\tTop_Loss: 0.2097\tBottom_Loss: 0.2619\tLoss: 0.5599\t\n",
      "Subject: s8, n=13 | test_f1: 0.26111 |best_f1: 0.44048\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0614\tTop_Loss: 0.2261\tBottom_Loss: 0.1076\tLoss: 0.3952\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1746\tTop_Loss: 0.4402\tBottom_Loss: 0.2167\tLoss: 0.8315\t\n",
      "Subject: s8, n=13 | test_f1: 0.1619 |best_f1: 0.44048\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0512\tTop_Loss: 0.1331\tBottom_Loss: 0.0824\tLoss: 0.2666\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1076\tTop_Loss: 0.2470\tBottom_Loss: 0.2253\tLoss: 0.5798\t\n",
      "Subject: s8, n=13 | test_f1: 0.28889 |best_f1: 0.44048\n",
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1143\tTop_Loss: 0.2137\tBottom_Loss: 0.2346\tLoss: 0.5626\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0558\tTop_Loss: 0.2852\tBottom_Loss: 0.1515\tLoss: 0.4925\t\n",
      "Subject: s8, n=13 | test_f1: 0.33862 |best_f1: 0.44048\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0367\tTop_Loss: 0.2563\tBottom_Loss: 0.0506\tLoss: 0.3437\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1178\tTop_Loss: 0.1606\tBottom_Loss: 0.1509\tLoss: 0.4293\t\n",
      "Subject: s8, n=13 | test_f1: 0.44048 |best_f1: 0.44048\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0739\tTop_Loss: 0.2268\tBottom_Loss: 0.1027\tLoss: 0.4034\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0678\tTop_Loss: 0.1386\tBottom_Loss: 0.1521\tLoss: 0.3585\t\n",
      "Subject: s8, n=13 | test_f1: 0.30199 |best_f1: 0.44048\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0746\tTop_Loss: 0.2055\tBottom_Loss: 0.1446\tLoss: 0.4247\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0442\tTop_Loss: 0.1908\tBottom_Loss: 0.1041\tLoss: 0.3391\t\n",
      "Subject: s8, n=13 | test_f1: 0.14815 |best_f1: 0.44048\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1027\tTop_Loss: 0.1995\tBottom_Loss: 0.1374\tLoss: 0.4396\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0770\tTop_Loss: 0.1427\tBottom_Loss: 0.1597\tLoss: 0.3794\t\n",
      "Subject: s8, n=13 | test_f1: 0.13333 |best_f1: 0.44048\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0717\tTop_Loss: 0.2216\tBottom_Loss: 0.0759\tLoss: 0.3692\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0825\tTop_Loss: 0.2063\tBottom_Loss: 0.1116\tLoss: 0.4004\t\n",
      "Subject: s8, n=13 | test_f1: 0.27302 |best_f1: 0.44048\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0484\tTop_Loss: 0.1759\tBottom_Loss: 0.0815\tLoss: 0.3058\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0631\tTop_Loss: 0.1496\tBottom_Loss: 0.0930\tLoss: 0.3057\t\n",
      "Subject: s8, n=13 | test_f1: 0.1859 |best_f1: 0.44048\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1041\tTop_Loss: 0.2622\tBottom_Loss: 0.0855\tLoss: 0.4518\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0866\tTop_Loss: 0.1058\tBottom_Loss: 0.1286\tLoss: 0.3210\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: s8, n=13 | test_f1: 0.16667 |best_f1: 0.44048\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0621\tTop_Loss: 0.1965\tBottom_Loss: 0.0584\tLoss: 0.3170\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1786\tTop_Loss: 0.1393\tBottom_Loss: 0.2154\tLoss: 0.5333\t\n",
      "Subject: s8, n=13 | test_f1: 0.2381 |best_f1: 0.44048\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0725\tTop_Loss: 0.1655\tBottom_Loss: 0.0981\tLoss: 0.3362\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0767\tTop_Loss: 0.1275\tBottom_Loss: 0.0890\tLoss: 0.2932\t\n",
      "Subject: s8, n=13 | test_f1: 0.12963 |best_f1: 0.44048\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1030\tTop_Loss: 0.2270\tBottom_Loss: 0.1435\tLoss: 0.4735\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0617\tTop_Loss: 0.1760\tBottom_Loss: 0.1121\tLoss: 0.3497\t\n",
      "Subject: s8, n=13 | test_f1: 0.28889 |best_f1: 0.44048\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0450\tTop_Loss: 0.1100\tBottom_Loss: 0.0545\tLoss: 0.2094\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0441\tTop_Loss: 0.1993\tBottom_Loss: 0.1114\tLoss: 0.3548\t\n",
      "Subject: s8, n=13 | test_f1: 0.22619 |best_f1: 0.44048\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0792\tTop_Loss: 0.1543\tBottom_Loss: 0.1127\tLoss: 0.3462\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0296\tTop_Loss: 0.1324\tBottom_Loss: 0.0601\tLoss: 0.2220\t\n",
      "Subject: s8, n=13 | test_f1: 0.25397 |best_f1: 0.44048\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1337\tTop_Loss: 0.3031\tBottom_Loss: 0.1598\tLoss: 0.5967\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0470\tTop_Loss: 0.1458\tBottom_Loss: 0.0972\tLoss: 0.2899\t\n",
      "Subject: s8, n=13 | test_f1: 0.21667 |best_f1: 0.44048\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1124\tTop_Loss: 0.1344\tBottom_Loss: 0.2674\tLoss: 0.5141\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0523\tTop_Loss: 0.1314\tBottom_Loss: 0.0830\tLoss: 0.2667\t\n",
      "Subject: s8, n=13 | test_f1: 0.31944 |best_f1: 0.44048\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0320\tTop_Loss: 0.0858\tBottom_Loss: 0.1464\tLoss: 0.2642\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0427\tTop_Loss: 0.1448\tBottom_Loss: 0.1133\tLoss: 0.3007\t\n",
      "Subject: s8, n=13 | test_f1: 0.1978 |best_f1: 0.44048\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0482\tTop_Loss: 0.1752\tBottom_Loss: 0.0894\tLoss: 0.3128\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0355\tTop_Loss: 0.1209\tBottom_Loss: 0.0631\tLoss: 0.2194\t\n",
      "Subject: s8, n=13 | test_f1: 0.055556 |best_f1: 0.44048\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0463\tTop_Loss: 0.0951\tBottom_Loss: 0.0985\tLoss: 0.2399\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0318\tTop_Loss: 0.0794\tBottom_Loss: 0.0767\tLoss: 0.1879\t\n",
      "Subject: s8, n=13 | test_f1: 0.32051 |best_f1: 0.44048\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1463\tTop_Loss: 0.1792\tBottom_Loss: 0.1523\tLoss: 0.4778\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0165\tTop_Loss: 0.0811\tBottom_Loss: 0.0506\tLoss: 0.1482\t\n",
      "Subject: s8, n=13 | test_f1: 0.19048 |best_f1: 0.44048\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0665\tTop_Loss: 0.1655\tBottom_Loss: 0.0984\tLoss: 0.3304\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0689\tTop_Loss: 0.1393\tBottom_Loss: 0.1845\tLoss: 0.3927\t\n",
      "Subject: s8, n=13 | test_f1: 0.2619 |best_f1: 0.44048\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0126\tTop_Loss: 0.0599\tBottom_Loss: 0.0396\tLoss: 0.1121\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0118\tTop_Loss: 0.0480\tBottom_Loss: 0.0325\tLoss: 0.0923\t\n",
      "Subject: s8, n=13 | test_f1: 0.31944 |best_f1: 0.44048\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0285\tTop_Loss: 0.0707\tBottom_Loss: 0.0868\tLoss: 0.1859\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0216\tTop_Loss: 0.0837\tBottom_Loss: 0.0408\tLoss: 0.1461\t\n",
      "Subject: s8, n=13 | test_f1: 0.19048 |best_f1: 0.44048\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0385\tTop_Loss: 0.0968\tBottom_Loss: 0.0511\tLoss: 0.1864\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0632\tTop_Loss: 0.1252\tBottom_Loss: 0.0465\tLoss: 0.2349\t\n",
      "Subject: s8, n=13 | test_f1: 0.1978 |best_f1: 0.44048\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0586\tTop_Loss: 0.2031\tBottom_Loss: 0.1072\tLoss: 0.3690\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0238\tTop_Loss: 0.0451\tBottom_Loss: 0.0703\tLoss: 0.1391\t\n",
      "Subject: s8, n=13 | test_f1: 0.17172 |best_f1: 0.44048\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0116\tTop_Loss: 0.0634\tBottom_Loss: 0.0659\tLoss: 0.1409\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0371\tTop_Loss: 0.1314\tBottom_Loss: 0.0829\tLoss: 0.2514\t\n",
      "Subject: s8, n=13 | test_f1: 0.24908 |best_f1: 0.44048\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0604\tTop_Loss: 0.1000\tBottom_Loss: 0.0506\tLoss: 0.2109\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0194\tTop_Loss: 0.0478\tBottom_Loss: 0.0748\tLoss: 0.1420\t\n",
      "Subject: s8, n=13 | test_f1: 0.27778 |best_f1: 0.44048\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0870\tTop_Loss: 0.1409\tBottom_Loss: 0.1028\tLoss: 0.3307\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0155\tTop_Loss: 0.0614\tBottom_Loss: 0.0330\tLoss: 0.1098\t\n",
      "Subject: s8, n=13 | test_f1: 0.20635 |best_f1: 0.44048\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0271\tTop_Loss: 0.0691\tBottom_Loss: 0.0443\tLoss: 0.1404\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0185\tTop_Loss: 0.0566\tBottom_Loss: 0.0361\tLoss: 0.1113\t\n",
      "Subject: s8, n=13 | test_f1: 0.14286 |best_f1: 0.44048\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0067\tTop_Loss: 0.0253\tBottom_Loss: 0.0202\tLoss: 0.0522\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0115\tTop_Loss: 0.0354\tBottom_Loss: 0.0371\tLoss: 0.0840\t\n",
      "Subject: s8, n=13 | test_f1: 0.25108 |best_f1: 0.44048\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0096\tTop_Loss: 0.0596\tBottom_Loss: 0.0277\tLoss: 0.0968\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0189\tTop_Loss: 0.0427\tBottom_Loss: 0.0614\tLoss: 0.1230\t\n",
      "Subject: s8, n=13 | test_f1: 0.28889 |best_f1: 0.44048\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0324\tTop_Loss: 0.0796\tBottom_Loss: 0.0564\tLoss: 0.1684\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0150\tTop_Loss: 0.0372\tBottom_Loss: 0.0264\tLoss: 0.0786\t\n",
      "Subject: s8, n=13 | test_f1: 0.32051 |best_f1: 0.44048\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0408\tTop_Loss: 0.1241\tBottom_Loss: 0.0423\tLoss: 0.2072\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0082\tTop_Loss: 0.0500\tBottom_Loss: 0.0298\tLoss: 0.0880\t\n",
      "Subject: s8, n=13 | test_f1: 0.32051 |best_f1: 0.44048\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0123\tTop_Loss: 0.1311\tBottom_Loss: 0.0222\tLoss: 0.1656\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0067\tTop_Loss: 0.0335\tBottom_Loss: 0.0101\tLoss: 0.0502\t\n",
      "Subject: s8, n=13 | test_f1: 0.13333 |best_f1: 0.44048\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0253\tTop_Loss: 0.0318\tBottom_Loss: 0.1237\tLoss: 0.1809\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0478\tTop_Loss: 0.1233\tBottom_Loss: 0.0608\tLoss: 0.2318\t\n",
      "Subject: s8, n=13 | test_f1: 0.20833 |best_f1: 0.44048\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0067\tTop_Loss: 0.0340\tBottom_Loss: 0.0170\tLoss: 0.0577\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0302\tTop_Loss: 0.0696\tBottom_Loss: 0.0321\tLoss: 0.1319\t\n",
      "Subject: s8, n=13 | test_f1: 0.20635 |best_f1: 0.44048\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0168\tTop_Loss: 0.0541\tBottom_Loss: 0.0858\tLoss: 0.1567\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0179\tTop_Loss: 0.0482\tBottom_Loss: 0.0327\tLoss: 0.0988\t\n",
      "Subject: s8, n=13 | test_f1: 0.25397 |best_f1: 0.44048\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0147\tTop_Loss: 0.0469\tBottom_Loss: 0.0424\tLoss: 0.1040\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0128\tTop_Loss: 0.0334\tBottom_Loss: 0.0269\tLoss: 0.0732\t\n",
      "Subject: s8, n=13 | test_f1: 0.2381 |best_f1: 0.44048\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0174\tTop_Loss: 0.0290\tBottom_Loss: 0.0438\tLoss: 0.0901\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0079\tTop_Loss: 0.0740\tBottom_Loss: 0.0121\tLoss: 0.0940\t\n",
      "Subject: s8, n=13 | test_f1: 0.10256 |best_f1: 0.44048\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0147\tTop_Loss: 0.0252\tBottom_Loss: 0.0179\tLoss: 0.0578\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0057\tTop_Loss: 0.0304\tBottom_Loss: 0.0144\tLoss: 0.0504\t\n",
      "Subject: s8, n=13 | test_f1: 0.30952 |best_f1: 0.44048\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0458\tTop_Loss: 0.0702\tBottom_Loss: 0.0461\tLoss: 0.1620\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 0.938\tLabel_Loss: 0.0822\tTop_Loss: 0.1203\tBottom_Loss: 0.0854\tLoss: 0.2879\t\n",
      "Subject: s8, n=13 | test_f1: 0.38889 |best_f1: 0.44048\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0083\tTop_Loss: 0.0619\tBottom_Loss: 0.0162\tLoss: 0.0864\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0099\tTop_Loss: 0.0364\tBottom_Loss: 0.0219\tLoss: 0.0682\t\n",
      "Subject: s8, n=13 | test_f1: 0.25071 |best_f1: 0.44048\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0079\tTop_Loss: 0.0245\tBottom_Loss: 0.0148\tLoss: 0.0472\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0070\tTop_Loss: 0.0839\tBottom_Loss: 0.0122\tLoss: 0.1032\t\n",
      "Subject: s8, n=13 | test_f1: 0.4127 |best_f1: 0.44048\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0120\tTop_Loss: 0.0877\tBottom_Loss: 0.0288\tLoss: 0.1284\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0122\tTop_Loss: 0.0983\tBottom_Loss: 0.0228\tLoss: 0.1334\t\n",
      "Subject: s8, n=13 | test_f1: 0.4127 |best_f1: 0.44048\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0045\tTop_Loss: 0.0207\tBottom_Loss: 0.0115\tLoss: 0.0367\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0049\tTop_Loss: 0.0291\tBottom_Loss: 0.0094\tLoss: 0.0435\t\n",
      "Subject: s8, n=13 | test_f1: 0.30719 |best_f1: 0.44048\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0164\tTop_Loss: 0.1089\tBottom_Loss: 0.0222\tLoss: 0.1474\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0042\tTop_Loss: 0.0230\tBottom_Loss: 0.0305\tLoss: 0.0576\t\n",
      "Subject: s8, n=13 | test_f1: 0.44444 |best_f1: 0.44444\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0057\tTop_Loss: 0.0254\tBottom_Loss: 0.0202\tLoss: 0.0513\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0059\tTop_Loss: 0.0142\tBottom_Loss: 0.0145\tLoss: 0.0345\t\n",
      "Subject: s8, n=13 | test_f1: 0.088889 |best_f1: 0.44444\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0022\tTop_Loss: 0.0165\tBottom_Loss: 0.0114\tLoss: 0.0301\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0099\tTop_Loss: 0.0223\tBottom_Loss: 0.0623\tLoss: 0.0945\t\n",
      "Subject: s8, n=13 | test_f1: 0.29101 |best_f1: 0.44444\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0037\tTop_Loss: 0.0125\tBottom_Loss: 0.0144\tLoss: 0.0307\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0054\tTop_Loss: 0.0318\tBottom_Loss: 0.0081\tLoss: 0.0453\t\n",
      "Subject: s8, n=13 | test_f1: 0.24908 |best_f1: 0.44444\n",
      "Train:\tEpoch:[0][1/14]   \tAcc: 0.406\tLabel_Loss: 1.3778\tTop_Loss: 1.1967\tBottom_Loss: 0.9669\tLoss: 3.5414\t\n",
      "Train:\tEpoch:[0][8/14]   \tAcc: 0.562\tLabel_Loss: 1.0700\tTop_Loss: 1.1543\tBottom_Loss: 1.2947\tLoss: 3.5189\t\n",
      "Subject: s9, n=04 | test_f1: 0.0 |best_f1: 0.0\n",
      "Train:\tEpoch:[1][1/14]   \tAcc: 0.500\tLabel_Loss: 1.0564\tTop_Loss: 1.0105\tBottom_Loss: 1.0252\tLoss: 3.0921\t\n",
      "Train:\tEpoch:[1][8/14]   \tAcc: 0.562\tLabel_Loss: 0.9670\tTop_Loss: 1.0009\tBottom_Loss: 0.9202\tLoss: 2.8881\t\n",
      "Subject: s9, n=04 | test_f1: 0.16667 |best_f1: 0.16667\n",
      "Train:\tEpoch:[2][1/14]   \tAcc: 0.500\tLabel_Loss: 0.9012\tTop_Loss: 0.9752\tBottom_Loss: 0.8925\tLoss: 2.7689\t\n",
      "Train:\tEpoch:[2][8/14]   \tAcc: 0.531\tLabel_Loss: 1.1071\tTop_Loss: 1.0228\tBottom_Loss: 0.9653\tLoss: 3.0952\t\n",
      "Subject: s9, n=04 | test_f1: 0.0 |best_f1: 0.16667\n",
      "Train:\tEpoch:[3][1/14]   \tAcc: 0.719\tLabel_Loss: 0.7154\tTop_Loss: 0.9792\tBottom_Loss: 0.9138\tLoss: 2.6084\t\n",
      "Train:\tEpoch:[3][8/14]   \tAcc: 0.500\tLabel_Loss: 1.0498\tTop_Loss: 1.2099\tBottom_Loss: 1.1490\tLoss: 3.4087\t\n",
      "Subject: s9, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[4][1/14]   \tAcc: 0.594\tLabel_Loss: 0.8978\tTop_Loss: 1.0550\tBottom_Loss: 0.8873\tLoss: 2.8401\t\n",
      "Train:\tEpoch:[4][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7146\tTop_Loss: 0.8737\tBottom_Loss: 0.8711\tLoss: 2.4594\t\n",
      "Subject: s9, n=04 | test_f1: 0.16667 |best_f1: 0.33333\n",
      "Train:\tEpoch:[5][1/14]   \tAcc: 0.438\tLabel_Loss: 1.1338\tTop_Loss: 0.9176\tBottom_Loss: 1.1052\tLoss: 3.1567\t\n",
      "Train:\tEpoch:[5][8/14]   \tAcc: 0.438\tLabel_Loss: 1.1466\tTop_Loss: 1.1418\tBottom_Loss: 0.9941\tLoss: 3.2825\t\n",
      "Subject: s9, n=04 | test_f1: 0.16667 |best_f1: 0.33333\n",
      "Train:\tEpoch:[6][1/14]   \tAcc: 0.688\tLabel_Loss: 0.7717\tTop_Loss: 0.7971\tBottom_Loss: 0.8838\tLoss: 2.4526\t\n",
      "Train:\tEpoch:[6][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8017\tTop_Loss: 0.9676\tBottom_Loss: 1.1860\tLoss: 2.9554\t\n",
      "Subject: s9, n=04 | test_f1: 0.16667 |best_f1: 0.33333\n",
      "Train:\tEpoch:[7][1/14]   \tAcc: 0.750\tLabel_Loss: 0.7599\tTop_Loss: 0.6962\tBottom_Loss: 0.9879\tLoss: 2.4440\t\n",
      "Train:\tEpoch:[7][8/14]   \tAcc: 0.719\tLabel_Loss: 0.6271\tTop_Loss: 0.8245\tBottom_Loss: 0.7052\tLoss: 2.1568\t\n",
      "Subject: s9, n=04 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[8][1/14]   \tAcc: 0.719\tLabel_Loss: 0.6071\tTop_Loss: 0.6328\tBottom_Loss: 0.7062\tLoss: 1.9461\t\n",
      "Train:\tEpoch:[8][8/14]   \tAcc: 0.594\tLabel_Loss: 0.7664\tTop_Loss: 0.8474\tBottom_Loss: 0.7752\tLoss: 2.3890\t\n",
      "Subject: s9, n=04 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[9][1/14]   \tAcc: 0.594\tLabel_Loss: 0.7850\tTop_Loss: 1.2068\tBottom_Loss: 0.6953\tLoss: 2.6871\t\n",
      "Train:\tEpoch:[9][8/14]   \tAcc: 0.594\tLabel_Loss: 0.8724\tTop_Loss: 0.9238\tBottom_Loss: 0.9248\tLoss: 2.7210\t\n",
      "Subject: s9, n=04 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[10][1/14]   \tAcc: 0.625\tLabel_Loss: 0.6295\tTop_Loss: 0.5699\tBottom_Loss: 0.8659\tLoss: 2.0653\t\n",
      "Train:\tEpoch:[10][8/14]   \tAcc: 0.656\tLabel_Loss: 0.6810\tTop_Loss: 1.0784\tBottom_Loss: 0.9070\tLoss: 2.6664\t\n",
      "Subject: s9, n=04 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[11][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5418\tTop_Loss: 0.7089\tBottom_Loss: 0.6129\tLoss: 1.8637\t\n",
      "Train:\tEpoch:[11][8/14]   \tAcc: 0.656\tLabel_Loss: 0.6647\tTop_Loss: 0.8065\tBottom_Loss: 0.6358\tLoss: 2.1070\t\n",
      "Subject: s9, n=04 | test_f1: 0.33333 |best_f1: 0.33333\n",
      "Train:\tEpoch:[12][1/14]   \tAcc: 0.656\tLabel_Loss: 0.6308\tTop_Loss: 0.6673\tBottom_Loss: 0.7142\tLoss: 2.0123\t\n",
      "Train:\tEpoch:[12][8/14]   \tAcc: 0.750\tLabel_Loss: 0.7041\tTop_Loss: 0.6713\tBottom_Loss: 0.8299\tLoss: 2.2053\t\n",
      "Subject: s9, n=04 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[13][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6198\tTop_Loss: 0.7368\tBottom_Loss: 0.8419\tLoss: 2.1985\t\n",
      "Train:\tEpoch:[13][8/14]   \tAcc: 0.812\tLabel_Loss: 0.5955\tTop_Loss: 0.7398\tBottom_Loss: 0.7356\tLoss: 2.0709\t\n",
      "Subject: s9, n=04 | test_f1: 0.0 |best_f1: 0.33333\n",
      "Train:\tEpoch:[14][1/14]   \tAcc: 0.719\tLabel_Loss: 0.5875\tTop_Loss: 0.7132\tBottom_Loss: 0.8366\tLoss: 2.1373\t\n",
      "Train:\tEpoch:[14][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5511\tTop_Loss: 0.6899\tBottom_Loss: 0.5960\tLoss: 1.8370\t\n",
      "Subject: s9, n=04 | test_f1: 0.22222 |best_f1: 0.33333\n",
      "Train:\tEpoch:[15][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4433\tTop_Loss: 0.5850\tBottom_Loss: 0.5663\tLoss: 1.5946\t\n",
      "Train:\tEpoch:[15][8/14]   \tAcc: 0.750\tLabel_Loss: 0.5729\tTop_Loss: 0.7620\tBottom_Loss: 0.5803\tLoss: 1.9152\t\n",
      "Subject: s9, n=04 | test_f1: 0.38889 |best_f1: 0.38889\n",
      "Train:\tEpoch:[16][1/14]   \tAcc: 0.750\tLabel_Loss: 0.5468\tTop_Loss: 0.6831\tBottom_Loss: 0.5659\tLoss: 1.7958\t\n",
      "Train:\tEpoch:[16][8/14]   \tAcc: 0.750\tLabel_Loss: 0.6763\tTop_Loss: 0.7316\tBottom_Loss: 0.6920\tLoss: 2.0999\t\n",
      "Subject: s9, n=04 | test_f1: 0.22222 |best_f1: 0.38889\n",
      "Train:\tEpoch:[17][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2959\tTop_Loss: 0.3319\tBottom_Loss: 0.4606\tLoss: 1.0885\t\n",
      "Train:\tEpoch:[17][8/14]   \tAcc: 0.688\tLabel_Loss: 0.6688\tTop_Loss: 0.6803\tBottom_Loss: 0.7056\tLoss: 2.0547\t\n",
      "Subject: s9, n=04 | test_f1: 0.0 |best_f1: 0.38889\n",
      "Train:\tEpoch:[18][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3503\tTop_Loss: 0.4217\tBottom_Loss: 0.6094\tLoss: 1.3814\t\n",
      "Train:\tEpoch:[18][8/14]   \tAcc: 0.656\tLabel_Loss: 0.7786\tTop_Loss: 0.8221\tBottom_Loss: 0.7648\tLoss: 2.3655\t\n",
      "Subject: s9, n=04 | test_f1: 0.0 |best_f1: 0.38889\n",
      "Train:\tEpoch:[19][1/14]   \tAcc: 0.812\tLabel_Loss: 0.4795\tTop_Loss: 0.6632\tBottom_Loss: 0.6951\tLoss: 1.8378\t\n",
      "Train:\tEpoch:[19][8/14]   \tAcc: 0.844\tLabel_Loss: 0.3769\tTop_Loss: 0.4786\tBottom_Loss: 0.5554\tLoss: 1.4109\t\n",
      "Subject: s9, n=04 | test_f1: 0.16667 |best_f1: 0.38889\n",
      "Train:\tEpoch:[20][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3617\tTop_Loss: 0.5757\tBottom_Loss: 0.4641\tLoss: 1.4014\t\n",
      "Train:\tEpoch:[20][8/14]   \tAcc: 0.844\tLabel_Loss: 0.4312\tTop_Loss: 0.4709\tBottom_Loss: 0.4894\tLoss: 1.3915\t\n",
      "Subject: s9, n=04 | test_f1: 0.16667 |best_f1: 0.38889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[21][1/14]   \tAcc: 0.844\tLabel_Loss: 0.4007\tTop_Loss: 0.6850\tBottom_Loss: 0.4838\tLoss: 1.5695\t\n",
      "Train:\tEpoch:[21][8/14]   \tAcc: 0.625\tLabel_Loss: 0.7446\tTop_Loss: 0.9709\tBottom_Loss: 0.8896\tLoss: 2.6051\t\n",
      "Subject: s9, n=04 | test_f1: 0.0 |best_f1: 0.38889\n",
      "Train:\tEpoch:[22][1/14]   \tAcc: 0.844\tLabel_Loss: 0.5123\tTop_Loss: 0.5910\tBottom_Loss: 0.5523\tLoss: 1.6556\t\n",
      "Train:\tEpoch:[22][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4846\tTop_Loss: 0.7365\tBottom_Loss: 0.5918\tLoss: 1.8129\t\n",
      "Subject: s9, n=04 | test_f1: 0.0 |best_f1: 0.38889\n",
      "Train:\tEpoch:[23][1/14]   \tAcc: 0.781\tLabel_Loss: 0.5798\tTop_Loss: 0.6648\tBottom_Loss: 0.6072\tLoss: 1.8517\t\n",
      "Train:\tEpoch:[23][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2922\tTop_Loss: 0.5515\tBottom_Loss: 0.3552\tLoss: 1.1989\t\n",
      "Subject: s9, n=04 | test_f1: 0.0 |best_f1: 0.38889\n",
      "Train:\tEpoch:[24][1/14]   \tAcc: 0.688\tLabel_Loss: 0.6245\tTop_Loss: 0.6579\tBottom_Loss: 0.5103\tLoss: 1.7926\t\n",
      "Train:\tEpoch:[24][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2977\tTop_Loss: 0.3716\tBottom_Loss: 0.5452\tLoss: 1.2146\t\n",
      "Subject: s9, n=04 | test_f1: 0.5 |best_f1: 0.5\n",
      "Train:\tEpoch:[25][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2953\tTop_Loss: 0.3936\tBottom_Loss: 0.3374\tLoss: 1.0262\t\n",
      "Train:\tEpoch:[25][8/14]   \tAcc: 0.812\tLabel_Loss: 0.4744\tTop_Loss: 0.6194\tBottom_Loss: 0.5992\tLoss: 1.6930\t\n",
      "Subject: s9, n=04 | test_f1: 0.22222 |best_f1: 0.5\n",
      "Train:\tEpoch:[26][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3843\tTop_Loss: 0.4433\tBottom_Loss: 0.5756\tLoss: 1.4032\t\n",
      "Train:\tEpoch:[26][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3561\tTop_Loss: 0.4323\tBottom_Loss: 0.4377\tLoss: 1.2260\t\n",
      "Subject: s9, n=04 | test_f1: 0.5 |best_f1: 0.5\n",
      "Train:\tEpoch:[27][1/14]   \tAcc: 0.781\tLabel_Loss: 0.3754\tTop_Loss: 0.3975\tBottom_Loss: 0.6562\tLoss: 1.4292\t\n",
      "Train:\tEpoch:[27][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2999\tTop_Loss: 0.4753\tBottom_Loss: 0.5575\tLoss: 1.3327\t\n",
      "Subject: s9, n=04 | test_f1: 0.16667 |best_f1: 0.5\n",
      "Train:\tEpoch:[28][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2650\tTop_Loss: 0.4397\tBottom_Loss: 0.3641\tLoss: 1.0688\t\n",
      "Train:\tEpoch:[28][8/14]   \tAcc: 0.938\tLabel_Loss: 0.3070\tTop_Loss: 0.5081\tBottom_Loss: 0.4526\tLoss: 1.2677\t\n",
      "Subject: s9, n=04 | test_f1: 0.0 |best_f1: 0.5\n",
      "Train:\tEpoch:[29][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3215\tTop_Loss: 0.4102\tBottom_Loss: 0.5869\tLoss: 1.3186\t\n",
      "Train:\tEpoch:[29][8/14]   \tAcc: 0.812\tLabel_Loss: 0.3697\tTop_Loss: 0.6239\tBottom_Loss: 0.4109\tLoss: 1.4045\t\n",
      "Subject: s9, n=04 | test_f1: 0.5 |best_f1: 0.5\n",
      "Train:\tEpoch:[30][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3195\tTop_Loss: 0.5312\tBottom_Loss: 0.4652\tLoss: 1.3159\t\n",
      "Train:\tEpoch:[30][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3453\tTop_Loss: 0.5180\tBottom_Loss: 0.4955\tLoss: 1.3588\t\n",
      "Subject: s9, n=04 | test_f1: 0.33333 |best_f1: 0.5\n",
      "Train:\tEpoch:[31][1/14]   \tAcc: 0.844\tLabel_Loss: 0.3385\tTop_Loss: 0.4482\tBottom_Loss: 0.4929\tLoss: 1.2796\t\n",
      "Train:\tEpoch:[31][8/14]   \tAcc: 0.906\tLabel_Loss: 0.3169\tTop_Loss: 0.4280\tBottom_Loss: 0.3635\tLoss: 1.1084\t\n",
      "Subject: s9, n=04 | test_f1: 0.22222 |best_f1: 0.5\n",
      "Train:\tEpoch:[32][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3094\tTop_Loss: 0.5307\tBottom_Loss: 0.5212\tLoss: 1.3613\t\n",
      "Train:\tEpoch:[32][8/14]   \tAcc: 1.000\tLabel_Loss: 0.1546\tTop_Loss: 0.3497\tBottom_Loss: 0.2651\tLoss: 0.7693\t\n",
      "Subject: s9, n=04 | test_f1: 0.0 |best_f1: 0.5\n",
      "Train:\tEpoch:[33][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2857\tTop_Loss: 0.5574\tBottom_Loss: 0.4009\tLoss: 1.2439\t\n",
      "Train:\tEpoch:[33][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2655\tTop_Loss: 0.6080\tBottom_Loss: 0.3906\tLoss: 1.2641\t\n",
      "Subject: s9, n=04 | test_f1: 0.0 |best_f1: 0.5\n",
      "Train:\tEpoch:[34][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3428\tTop_Loss: 0.4901\tBottom_Loss: 0.3961\tLoss: 1.2290\t\n",
      "Train:\tEpoch:[34][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2948\tTop_Loss: 0.3685\tBottom_Loss: 0.4354\tLoss: 1.0987\t\n",
      "Subject: s9, n=04 | test_f1: 0.38889 |best_f1: 0.5\n",
      "Train:\tEpoch:[35][1/14]   \tAcc: 0.938\tLabel_Loss: 0.2760\tTop_Loss: 0.4603\tBottom_Loss: 0.2669\tLoss: 1.0033\t\n",
      "Train:\tEpoch:[35][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2946\tTop_Loss: 0.2986\tBottom_Loss: 0.3950\tLoss: 0.9882\t\n",
      "Subject: s9, n=04 | test_f1: 0.0 |best_f1: 0.5\n",
      "Train:\tEpoch:[36][1/14]   \tAcc: 0.875\tLabel_Loss: 0.4434\tTop_Loss: 0.6120\tBottom_Loss: 0.4628\tLoss: 1.5182\t\n",
      "Train:\tEpoch:[36][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2461\tTop_Loss: 0.3887\tBottom_Loss: 0.4692\tLoss: 1.1041\t\n",
      "Subject: s9, n=04 | test_f1: 0.0 |best_f1: 0.5\n",
      "Train:\tEpoch:[37][1/14]   \tAcc: 0.906\tLabel_Loss: 0.1771\tTop_Loss: 0.2958\tBottom_Loss: 0.2926\tLoss: 0.7655\t\n",
      "Train:\tEpoch:[37][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2013\tTop_Loss: 0.4834\tBottom_Loss: 0.2760\tLoss: 0.9607\t\n",
      "Subject: s9, n=04 | test_f1: 0.0 |best_f1: 0.5\n",
      "Train:\tEpoch:[38][1/14]   \tAcc: 0.906\tLabel_Loss: 0.3105\tTop_Loss: 0.6241\tBottom_Loss: 0.4712\tLoss: 1.4058\t\n",
      "Train:\tEpoch:[38][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1794\tTop_Loss: 0.3260\tBottom_Loss: 0.2598\tLoss: 0.7652\t\n",
      "Subject: s9, n=04 | test_f1: 0.16667 |best_f1: 0.5\n",
      "Train:\tEpoch:[39][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2031\tTop_Loss: 0.3551\tBottom_Loss: 0.3030\tLoss: 0.8613\t\n",
      "Train:\tEpoch:[39][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1601\tTop_Loss: 0.3416\tBottom_Loss: 0.1951\tLoss: 0.6967\t\n",
      "Subject: s9, n=04 | test_f1: 0.26667 |best_f1: 0.5\n",
      "Train:\tEpoch:[40][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1561\tTop_Loss: 0.2096\tBottom_Loss: 0.3739\tLoss: 0.7396\t\n",
      "Train:\tEpoch:[40][8/14]   \tAcc: 0.906\tLabel_Loss: 0.1856\tTop_Loss: 0.2022\tBottom_Loss: 0.2076\tLoss: 0.5954\t\n",
      "Subject: s9, n=04 | test_f1: 0.33333 |best_f1: 0.5\n",
      "Train:\tEpoch:[41][1/14]   \tAcc: 0.875\tLabel_Loss: 0.3402\tTop_Loss: 0.4121\tBottom_Loss: 0.4618\tLoss: 1.2142\t\n",
      "Train:\tEpoch:[41][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2054\tTop_Loss: 0.4519\tBottom_Loss: 0.2852\tLoss: 0.9425\t\n",
      "Subject: s9, n=04 | test_f1: 0.16667 |best_f1: 0.5\n",
      "Train:\tEpoch:[42][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1459\tTop_Loss: 0.2440\tBottom_Loss: 0.1994\tLoss: 0.5894\t\n",
      "Train:\tEpoch:[42][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2798\tTop_Loss: 0.4241\tBottom_Loss: 0.4045\tLoss: 1.1084\t\n",
      "Subject: s9, n=04 | test_f1: 0.16667 |best_f1: 0.5\n",
      "Train:\tEpoch:[43][1/14]   \tAcc: 0.906\tLabel_Loss: 0.2088\tTop_Loss: 0.3770\tBottom_Loss: 0.3301\tLoss: 0.9159\t\n",
      "Train:\tEpoch:[43][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0892\tTop_Loss: 0.2661\tBottom_Loss: 0.1943\tLoss: 0.5496\t\n",
      "Subject: s9, n=04 | test_f1: 0.38889 |best_f1: 0.5\n",
      "Train:\tEpoch:[44][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0776\tTop_Loss: 0.1632\tBottom_Loss: 0.1990\tLoss: 0.4398\t\n",
      "Train:\tEpoch:[44][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1372\tTop_Loss: 0.2140\tBottom_Loss: 0.2555\tLoss: 0.6067\t\n",
      "Subject: s9, n=04 | test_f1: 0.16667 |best_f1: 0.5\n",
      "Train:\tEpoch:[45][1/14]   \tAcc: 0.875\tLabel_Loss: 0.2490\tTop_Loss: 0.4297\tBottom_Loss: 0.2460\tLoss: 0.9247\t\n",
      "Train:\tEpoch:[45][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2602\tTop_Loss: 0.3669\tBottom_Loss: 0.3231\tLoss: 0.9501\t\n",
      "Subject: s9, n=04 | test_f1: 0.22222 |best_f1: 0.5\n",
      "Train:\tEpoch:[46][1/14]   \tAcc: 0.969\tLabel_Loss: 0.2044\tTop_Loss: 0.3432\tBottom_Loss: 0.3370\tLoss: 0.8846\t\n",
      "Train:\tEpoch:[46][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1479\tTop_Loss: 0.3783\tBottom_Loss: 0.1898\tLoss: 0.7161\t\n",
      "Subject: s9, n=04 | test_f1: 0.16667 |best_f1: 0.5\n",
      "Train:\tEpoch:[47][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1903\tTop_Loss: 0.3199\tBottom_Loss: 0.2796\tLoss: 0.7898\t\n",
      "Train:\tEpoch:[47][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0884\tTop_Loss: 0.2137\tBottom_Loss: 0.2197\tLoss: 0.5218\t\n",
      "Subject: s9, n=04 | test_f1: 0.0 |best_f1: 0.5\n",
      "Train:\tEpoch:[48][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1327\tTop_Loss: 0.2775\tBottom_Loss: 0.1493\tLoss: 0.5594\t\n",
      "Train:\tEpoch:[48][8/14]   \tAcc: 0.875\tLabel_Loss: 0.2754\tTop_Loss: 0.3937\tBottom_Loss: 0.4120\tLoss: 1.0811\t\n",
      "Subject: s9, n=04 | test_f1: 0.0 |best_f1: 0.5\n",
      "Train:\tEpoch:[49][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0529\tTop_Loss: 0.1781\tBottom_Loss: 0.1263\tLoss: 0.3573\t\n",
      "Train:\tEpoch:[49][8/14]   \tAcc: 0.906\tLabel_Loss: 0.2213\tTop_Loss: 0.2981\tBottom_Loss: 0.2517\tLoss: 0.7712\t\n",
      "Subject: s9, n=04 | test_f1: 0.16667 |best_f1: 0.5\n",
      "Train:\tEpoch:[50][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0611\tTop_Loss: 0.2397\tBottom_Loss: 0.1330\tLoss: 0.4338\t\n",
      "Train:\tEpoch:[50][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0694\tTop_Loss: 0.2131\tBottom_Loss: 0.2023\tLoss: 0.4848\t\n",
      "Subject: s9, n=04 | test_f1: 0.0 |best_f1: 0.5\n",
      "Train:\tEpoch:[51][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1484\tTop_Loss: 0.2206\tBottom_Loss: 0.2110\tLoss: 0.5801\t\n",
      "Train:\tEpoch:[51][8/14]   \tAcc: 0.938\tLabel_Loss: 0.2083\tTop_Loss: 0.3258\tBottom_Loss: 0.1988\tLoss: 0.7329\t\n",
      "Subject: s9, n=04 | test_f1: 0.33333 |best_f1: 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\tEpoch:[52][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0927\tTop_Loss: 0.2854\tBottom_Loss: 0.2325\tLoss: 0.6105\t\n",
      "Train:\tEpoch:[52][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1095\tTop_Loss: 0.2966\tBottom_Loss: 0.1010\tLoss: 0.5070\t\n",
      "Subject: s9, n=04 | test_f1: 0.16667 |best_f1: 0.5\n",
      "Train:\tEpoch:[53][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1293\tTop_Loss: 0.2398\tBottom_Loss: 0.1347\tLoss: 0.5038\t\n",
      "Train:\tEpoch:[53][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1857\tTop_Loss: 0.2316\tBottom_Loss: 0.2357\tLoss: 0.6530\t\n",
      "Subject: s9, n=04 | test_f1: 0.22222 |best_f1: 0.5\n",
      "Train:\tEpoch:[54][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0969\tTop_Loss: 0.1552\tBottom_Loss: 0.1585\tLoss: 0.4105\t\n",
      "Train:\tEpoch:[54][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0599\tTop_Loss: 0.1864\tBottom_Loss: 0.1141\tLoss: 0.3604\t\n",
      "Subject: s9, n=04 | test_f1: 0.16667 |best_f1: 0.5\n",
      "Train:\tEpoch:[55][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0651\tTop_Loss: 0.2442\tBottom_Loss: 0.0793\tLoss: 0.3885\t\n",
      "Train:\tEpoch:[55][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0884\tTop_Loss: 0.2250\tBottom_Loss: 0.1292\tLoss: 0.4426\t\n",
      "Subject: s9, n=04 | test_f1: 0.16667 |best_f1: 0.5\n",
      "Train:\tEpoch:[56][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0451\tTop_Loss: 0.1593\tBottom_Loss: 0.1231\tLoss: 0.3275\t\n",
      "Train:\tEpoch:[56][8/14]   \tAcc: 0.938\tLabel_Loss: 0.1718\tTop_Loss: 0.2626\tBottom_Loss: 0.2978\tLoss: 0.7322\t\n",
      "Subject: s9, n=04 | test_f1: 0.38889 |best_f1: 0.5\n",
      "Train:\tEpoch:[57][1/14]   \tAcc: 0.938\tLabel_Loss: 0.1184\tTop_Loss: 0.1492\tBottom_Loss: 0.1852\tLoss: 0.4527\t\n",
      "Train:\tEpoch:[57][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0538\tTop_Loss: 0.2106\tBottom_Loss: 0.1583\tLoss: 0.4227\t\n",
      "Subject: s9, n=04 | test_f1: 0.38889 |best_f1: 0.5\n",
      "Train:\tEpoch:[58][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1010\tTop_Loss: 0.1877\tBottom_Loss: 0.1671\tLoss: 0.4558\t\n",
      "Train:\tEpoch:[58][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0692\tTop_Loss: 0.2086\tBottom_Loss: 0.1738\tLoss: 0.4516\t\n",
      "Subject: s9, n=04 | test_f1: 0.26667 |best_f1: 0.5\n",
      "Train:\tEpoch:[59][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1039\tTop_Loss: 0.2259\tBottom_Loss: 0.1980\tLoss: 0.5279\t\n",
      "Train:\tEpoch:[59][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0337\tTop_Loss: 0.1531\tBottom_Loss: 0.0835\tLoss: 0.2703\t\n",
      "Subject: s9, n=04 | test_f1: 0.16667 |best_f1: 0.5\n",
      "Train:\tEpoch:[60][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0586\tTop_Loss: 0.2264\tBottom_Loss: 0.1323\tLoss: 0.4173\t\n",
      "Train:\tEpoch:[60][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0874\tTop_Loss: 0.2417\tBottom_Loss: 0.0976\tLoss: 0.4267\t\n",
      "Subject: s9, n=04 | test_f1: 0.16667 |best_f1: 0.5\n",
      "Train:\tEpoch:[61][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0837\tTop_Loss: 0.2057\tBottom_Loss: 0.1319\tLoss: 0.4213\t\n",
      "Train:\tEpoch:[61][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0908\tTop_Loss: 0.2652\tBottom_Loss: 0.1192\tLoss: 0.4752\t\n",
      "Subject: s9, n=04 | test_f1: 0.0 |best_f1: 0.5\n",
      "Train:\tEpoch:[62][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0815\tTop_Loss: 0.1826\tBottom_Loss: 0.0913\tLoss: 0.3554\t\n",
      "Train:\tEpoch:[62][8/14]   \tAcc: 0.969\tLabel_Loss: 0.0719\tTop_Loss: 0.1502\tBottom_Loss: 0.1185\tLoss: 0.3407\t\n",
      "Subject: s9, n=04 | test_f1: 0.16667 |best_f1: 0.5\n",
      "Train:\tEpoch:[63][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0794\tTop_Loss: 0.1768\tBottom_Loss: 0.1734\tLoss: 0.4296\t\n",
      "Train:\tEpoch:[63][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0640\tTop_Loss: 0.1327\tBottom_Loss: 0.0827\tLoss: 0.2794\t\n",
      "Subject: s9, n=04 | test_f1: 0.16667 |best_f1: 0.5\n",
      "Train:\tEpoch:[64][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0318\tTop_Loss: 0.0544\tBottom_Loss: 0.1060\tLoss: 0.1922\t\n",
      "Train:\tEpoch:[64][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0701\tTop_Loss: 0.1685\tBottom_Loss: 0.1662\tLoss: 0.4048\t\n",
      "Subject: s9, n=04 | test_f1: 0.16667 |best_f1: 0.5\n",
      "Train:\tEpoch:[65][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0671\tTop_Loss: 0.1873\tBottom_Loss: 0.0542\tLoss: 0.3086\t\n",
      "Train:\tEpoch:[65][8/14]   \tAcc: 0.969\tLabel_Loss: 0.1387\tTop_Loss: 0.3276\tBottom_Loss: 0.1725\tLoss: 0.6388\t\n",
      "Subject: s9, n=04 | test_f1: 0.6 |best_f1: 0.6\n",
      "Train:\tEpoch:[66][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0617\tTop_Loss: 0.1978\tBottom_Loss: 0.1387\tLoss: 0.3982\t\n",
      "Train:\tEpoch:[66][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0751\tTop_Loss: 0.1966\tBottom_Loss: 0.1031\tLoss: 0.3747\t\n",
      "Subject: s9, n=04 | test_f1: 0.38889 |best_f1: 0.6\n",
      "Train:\tEpoch:[67][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0564\tTop_Loss: 0.1113\tBottom_Loss: 0.1015\tLoss: 0.2692\t\n",
      "Train:\tEpoch:[67][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0289\tTop_Loss: 0.0781\tBottom_Loss: 0.1040\tLoss: 0.2111\t\n",
      "Subject: s9, n=04 | test_f1: 0.16667 |best_f1: 0.6\n",
      "Train:\tEpoch:[68][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0404\tTop_Loss: 0.0772\tBottom_Loss: 0.0681\tLoss: 0.1858\t\n",
      "Train:\tEpoch:[68][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0483\tTop_Loss: 0.1398\tBottom_Loss: 0.0537\tLoss: 0.2418\t\n",
      "Subject: s9, n=04 | test_f1: 0.16667 |best_f1: 0.6\n",
      "Train:\tEpoch:[69][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0814\tTop_Loss: 0.2010\tBottom_Loss: 0.1419\tLoss: 0.4244\t\n",
      "Train:\tEpoch:[69][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0509\tTop_Loss: 0.1765\tBottom_Loss: 0.0680\tLoss: 0.2955\t\n",
      "Subject: s9, n=04 | test_f1: 0.0 |best_f1: 0.6\n",
      "Train:\tEpoch:[70][1/14]   \tAcc: 0.969\tLabel_Loss: 0.1075\tTop_Loss: 0.1697\tBottom_Loss: 0.2074\tLoss: 0.4845\t\n",
      "Train:\tEpoch:[70][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0460\tTop_Loss: 0.2779\tBottom_Loss: 0.0739\tLoss: 0.3978\t\n",
      "Subject: s9, n=04 | test_f1: 0.38889 |best_f1: 0.6\n",
      "Train:\tEpoch:[71][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0329\tTop_Loss: 0.0853\tBottom_Loss: 0.0820\tLoss: 0.2002\t\n",
      "Train:\tEpoch:[71][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0257\tTop_Loss: 0.0872\tBottom_Loss: 0.0636\tLoss: 0.1765\t\n",
      "Subject: s9, n=04 | test_f1: 0.0 |best_f1: 0.6\n",
      "Train:\tEpoch:[72][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0431\tTop_Loss: 0.0899\tBottom_Loss: 0.0774\tLoss: 0.2103\t\n",
      "Train:\tEpoch:[72][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0209\tTop_Loss: 0.1327\tBottom_Loss: 0.0354\tLoss: 0.1890\t\n",
      "Subject: s9, n=04 | test_f1: 0.6 |best_f1: 0.6\n",
      "Train:\tEpoch:[73][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0223\tTop_Loss: 0.0947\tBottom_Loss: 0.0591\tLoss: 0.1762\t\n",
      "Train:\tEpoch:[73][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0397\tTop_Loss: 0.1024\tBottom_Loss: 0.1416\tLoss: 0.2837\t\n",
      "Subject: s9, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[74][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0508\tTop_Loss: 0.1433\tBottom_Loss: 0.0848\tLoss: 0.2789\t\n",
      "Train:\tEpoch:[74][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0517\tTop_Loss: 0.1346\tBottom_Loss: 0.0934\tLoss: 0.2797\t\n",
      "Subject: s9, n=04 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[75][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0254\tTop_Loss: 0.2311\tBottom_Loss: 0.0362\tLoss: 0.2928\t\n",
      "Train:\tEpoch:[75][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0356\tTop_Loss: 0.2151\tBottom_Loss: 0.0862\tLoss: 0.3369\t\n",
      "Subject: s9, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[76][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0290\tTop_Loss: 0.0991\tBottom_Loss: 0.0683\tLoss: 0.1965\t\n",
      "Train:\tEpoch:[76][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0099\tTop_Loss: 0.0351\tBottom_Loss: 0.0541\tLoss: 0.0990\t\n",
      "Subject: s9, n=04 | test_f1: 0.22222 |best_f1: 1.0\n",
      "Train:\tEpoch:[77][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0121\tTop_Loss: 0.0466\tBottom_Loss: 0.0416\tLoss: 0.1003\t\n",
      "Train:\tEpoch:[77][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0104\tTop_Loss: 0.0517\tBottom_Loss: 0.0426\tLoss: 0.1047\t\n",
      "Subject: s9, n=04 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[78][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0405\tTop_Loss: 0.0817\tBottom_Loss: 0.0962\tLoss: 0.2184\t\n",
      "Train:\tEpoch:[78][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0148\tTop_Loss: 0.0665\tBottom_Loss: 0.0298\tLoss: 0.1111\t\n",
      "Subject: s9, n=04 | test_f1: 0.6 |best_f1: 1.0\n",
      "Train:\tEpoch:[79][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0156\tTop_Loss: 0.0529\tBottom_Loss: 0.0421\tLoss: 0.1106\t\n",
      "Train:\tEpoch:[79][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0084\tTop_Loss: 0.0365\tBottom_Loss: 0.0249\tLoss: 0.0698\t\n",
      "Subject: s9, n=04 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[80][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0634\tTop_Loss: 0.0841\tBottom_Loss: 0.0988\tLoss: 0.2463\t\n",
      "Train:\tEpoch:[80][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0328\tTop_Loss: 0.1096\tBottom_Loss: 0.0922\tLoss: 0.2346\t\n",
      "Subject: s9, n=04 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[81][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0412\tTop_Loss: 0.0889\tBottom_Loss: 0.0710\tLoss: 0.2012\t\n",
      "Train:\tEpoch:[81][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0210\tTop_Loss: 0.0726\tBottom_Loss: 0.0800\tLoss: 0.1736\t\n",
      "Subject: s9, n=04 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[82][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0195\tTop_Loss: 0.0626\tBottom_Loss: 0.0655\tLoss: 0.1476\t\n",
      "Train:\tEpoch:[82][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0367\tTop_Loss: 0.1001\tBottom_Loss: 0.0843\tLoss: 0.2211\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: s9, n=04 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[83][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0197\tTop_Loss: 0.0999\tBottom_Loss: 0.0415\tLoss: 0.1611\t\n",
      "Train:\tEpoch:[83][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0138\tTop_Loss: 0.0680\tBottom_Loss: 0.0319\tLoss: 0.1137\t\n",
      "Subject: s9, n=04 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[84][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0208\tTop_Loss: 0.0488\tBottom_Loss: 0.0243\tLoss: 0.0939\t\n",
      "Train:\tEpoch:[84][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0133\tTop_Loss: 0.0579\tBottom_Loss: 0.0419\tLoss: 0.1131\t\n",
      "Subject: s9, n=04 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[85][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0507\tTop_Loss: 0.1018\tBottom_Loss: 0.0898\tLoss: 0.2422\t\n",
      "Train:\tEpoch:[85][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0190\tTop_Loss: 0.0450\tBottom_Loss: 0.0454\tLoss: 0.1094\t\n",
      "Subject: s9, n=04 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[86][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0322\tTop_Loss: 0.1690\tBottom_Loss: 0.0623\tLoss: 0.2634\t\n",
      "Train:\tEpoch:[86][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0150\tTop_Loss: 0.0463\tBottom_Loss: 0.0427\tLoss: 0.1040\t\n",
      "Subject: s9, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[87][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0141\tTop_Loss: 0.0525\tBottom_Loss: 0.0314\tLoss: 0.0980\t\n",
      "Train:\tEpoch:[87][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0355\tTop_Loss: 0.1046\tBottom_Loss: 0.0543\tLoss: 0.1944\t\n",
      "Subject: s9, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[88][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0419\tTop_Loss: 0.1352\tBottom_Loss: 0.0582\tLoss: 0.2353\t\n",
      "Train:\tEpoch:[88][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0155\tTop_Loss: 0.0569\tBottom_Loss: 0.0343\tLoss: 0.1067\t\n",
      "Subject: s9, n=04 | test_f1: 0.5 |best_f1: 1.0\n",
      "Train:\tEpoch:[89][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0468\tTop_Loss: 0.0478\tBottom_Loss: 0.0329\tLoss: 0.1274\t\n",
      "Train:\tEpoch:[89][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0283\tTop_Loss: 0.0490\tBottom_Loss: 0.0383\tLoss: 0.1156\t\n",
      "Subject: s9, n=04 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[90][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0248\tTop_Loss: 0.0695\tBottom_Loss: 0.0711\tLoss: 0.1654\t\n",
      "Train:\tEpoch:[90][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0485\tTop_Loss: 0.1319\tBottom_Loss: 0.0485\tLoss: 0.2289\t\n",
      "Subject: s9, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[91][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0048\tTop_Loss: 0.0251\tBottom_Loss: 0.0254\tLoss: 0.0553\t\n",
      "Train:\tEpoch:[91][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0178\tTop_Loss: 0.0641\tBottom_Loss: 0.0286\tLoss: 0.1105\t\n",
      "Subject: s9, n=04 | test_f1: 0.38889 |best_f1: 1.0\n",
      "Train:\tEpoch:[92][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0484\tTop_Loss: 0.0272\tBottom_Loss: 0.0985\tLoss: 0.1741\t\n",
      "Train:\tEpoch:[92][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0099\tTop_Loss: 0.0293\tBottom_Loss: 0.0234\tLoss: 0.0627\t\n",
      "Subject: s9, n=04 | test_f1: 0.16667 |best_f1: 1.0\n",
      "Train:\tEpoch:[93][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0058\tTop_Loss: 0.0270\tBottom_Loss: 0.0285\tLoss: 0.0613\t\n",
      "Train:\tEpoch:[93][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0158\tTop_Loss: 0.0221\tBottom_Loss: 0.0604\tLoss: 0.0983\t\n",
      "Subject: s9, n=04 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[94][1/14]   \tAcc: 0.969\tLabel_Loss: 0.0592\tTop_Loss: 0.1316\tBottom_Loss: 0.0746\tLoss: 0.2654\t\n",
      "Train:\tEpoch:[94][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0067\tTop_Loss: 0.0507\tBottom_Loss: 0.0203\tLoss: 0.0777\t\n",
      "Subject: s9, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Train:\tEpoch:[95][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0145\tTop_Loss: 0.0448\tBottom_Loss: 0.0264\tLoss: 0.0857\t\n",
      "Train:\tEpoch:[95][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0157\tTop_Loss: 0.0340\tBottom_Loss: 0.0501\tLoss: 0.0998\t\n",
      "Subject: s9, n=04 | test_f1: 1.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[96][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0086\tTop_Loss: 0.0652\tBottom_Loss: 0.0248\tLoss: 0.0986\t\n",
      "Train:\tEpoch:[96][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0066\tTop_Loss: 0.0626\tBottom_Loss: 0.0178\tLoss: 0.0870\t\n",
      "Subject: s9, n=04 | test_f1: 0.26667 |best_f1: 1.0\n",
      "Train:\tEpoch:[97][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0097\tTop_Loss: 0.0452\tBottom_Loss: 0.0365\tLoss: 0.0914\t\n",
      "Train:\tEpoch:[97][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0086\tTop_Loss: 0.0341\tBottom_Loss: 0.0312\tLoss: 0.0740\t\n",
      "Subject: s9, n=04 | test_f1: 0.0 |best_f1: 1.0\n",
      "Train:\tEpoch:[98][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0105\tTop_Loss: 0.0288\tBottom_Loss: 0.0282\tLoss: 0.0675\t\n",
      "Train:\tEpoch:[98][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0115\tTop_Loss: 0.0430\tBottom_Loss: 0.0250\tLoss: 0.0796\t\n",
      "Subject: s9, n=04 | test_f1: 0.73333 |best_f1: 1.0\n",
      "Train:\tEpoch:[99][1/14]   \tAcc: 1.000\tLabel_Loss: 0.0077\tTop_Loss: 0.0241\tBottom_Loss: 0.0170\tLoss: 0.0489\t\n",
      "Train:\tEpoch:[99][8/14]   \tAcc: 1.000\tLabel_Loss: 0.0066\tTop_Loss: 0.0189\tBottom_Loss: 0.0244\tLoss: 0.0498\t\n",
      "Subject: s9, n=04 | test_f1: 0.33333 |best_f1: 1.0\n",
      "Total f1: 0.5098451709853463, SMIC: 0.47025448477263243, CASME2: 0.5572626347082869, SAMM: 0.38079531662740057\n"
     ]
    }
   ],
   "source": [
    "LOSO(flows, df, epochs=100, lr=0.01, weight_decay=0.000001,\n",
    "     dropout=0.5, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EMR with bug and no adversarial loss\n",
    "Total f1: 0.7618467522303171, SMIC: 0.7267611376522267, CASME2: 0.8386900914664003, SAMM: 0.6452826682770474\n",
    "EMR without bug and no adversarial loss\n",
    "Total f1: 0.5098451709853463, SMIC: 0.47025448477263243, CASME2: 0.5572626347082869, SAMM: 0.38079531662740057"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, model, criterion, optimizer, epoch, print_freq=7):\n",
    "\n",
    "    model['resnet'].train()\n",
    "    model['fc_top'].train()\n",
    "    model['fc_bottom'].train()\n",
    "    model['classifier'].train()\n",
    "    model['classifier_top'].train()\n",
    "    model['classifier_bottom'].train()\n",
    "\n",
    "    correct = 0\n",
    "\n",
    "    for i, sample in enumerate(train_dataloader):\n",
    "        input, label = sample['image'].to(device), sample['label'].to(device)\n",
    "\n",
    "        output_resnet_top, output_resnet_bottom = model['resnet'](input)\n",
    "\n",
    "        output_fc_top = model['fc_top'](output_resnet_top)\n",
    "        output_fc_bottom = model['fc_bottom'](output_resnet_bottom)\n",
    "\n",
    "        features = torch.cat((output_fc_top, output_fc_bottom), 1)\n",
    "\n",
    "        output = model['classifier'](features)\n",
    "        output_top = model['classifier_top'](output_fc_top)\n",
    "        output_bottom = model['classifier_bottom'](output_fc_bottom)\n",
    "\n",
    "        loss_label = criterion(output, label)\n",
    "        loss_top = criterion(output_top, label)\n",
    "        loss_bottom = criterion(output_bottom, label)\n",
    "\n",
    "        loss = loss_label + loss_top + loss_bottom\n",
    "\n",
    "        _, preds = torch.max(output, dim=1)\n",
    "\n",
    "        correct = float((label.int() == preds.int()).sum())\n",
    "        accuracy = correct / len(label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        Clip_Norm = 1\n",
    "        nn.utils.clip_grad_norm_(\n",
    "            model['resnet'].parameters(), Clip_Norm, norm_type=2)\n",
    "        nn.utils.clip_grad_norm_(\n",
    "            model['fc_top'].parameters(), Clip_Norm, norm_type=2)\n",
    "        nn.utils.clip_grad_norm_(\n",
    "            model['fc_bottom'].parameters(), Clip_Norm, norm_type=2)\n",
    "        nn.utils.clip_grad_norm_(\n",
    "            model['classifier'].parameters(), Clip_Norm, norm_type=2)\n",
    "        nn.utils.clip_grad_norm_(\n",
    "            model['classifier_top'].parameters(), Clip_Norm, norm_type=2)\n",
    "        nn.utils.clip_grad_norm_(\n",
    "            model['classifier_bottom'].parameters(), Clip_Norm, norm_type=2)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Train:\\t'\n",
    "                  'Epoch:[{0}][{1}/{2}]   \\t'\n",
    "                  'Acc: {acc:.3f}\\t'\n",
    "                  'Label_Loss: {l_loss:.4f}\\t'\n",
    "                  'Top_Loss: {t_loss:.4f}\\t'\n",
    "                  'Bottom_Loss: {b_loss:.4f}\\t'\n",
    "                  'Loss: {loss:.4f}\\t'.format(\n",
    "                      epoch, i + 1, len(train_dataloader), acc=accuracy,\n",
    "                      l_loss=loss_label, t_loss=loss_top, b_loss=loss_bottom, loss=loss))\n",
    "            \n",
    "            \n",
    "def validate(validate_dataloader, model, criterion, epoch):\n",
    "\n",
    "    model['resnet'].eval()\n",
    "    model['fc_top'].eval()\n",
    "    model['fc_bottom'].eval()\n",
    "    model['classifier'].eval()\n",
    "    model['classifier_top'].eval()\n",
    "    model['classifier_bottom'].eval()\n",
    "\n",
    "    losses = 0\n",
    "    correctes = 0\n",
    "    preds_return = torch.LongTensor([])\n",
    "    target_return = torch.LongTensor([])\n",
    "\n",
    "    sample_file = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sample in validate_dataloader:\n",
    "            input, target = sample['image'].to(device), sample['label'].to(device)\n",
    "\n",
    "            output_resnet_top, output_resnet_bottom = model['resnet'](input)\n",
    "            output_fc_top = model['fc_top'](output_resnet_top)\n",
    "            output_fc_bottom = model['fc_bottom'](output_resnet_bottom)\n",
    "\n",
    "            output_model = torch.cat((output_fc_top, output_fc_bottom), 1)\n",
    "\n",
    "            output = model['classifier'](output_model)\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            _, preds = torch.max(output, dim=1)\n",
    "\n",
    "            preds_return = torch.cat((preds_return, preds.cpu()), 0)\n",
    "            target_return = torch.cat((target_return, target.cpu()), 0)\n",
    "\n",
    "            losses += loss\n",
    "\n",
    "    return preds_return, target_return, losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LOSO(features, df, epochs=200, lr=0.01, batch_size=128, dropout=0.5, weight_decay=0.001,\n",
    "         verbose=True):\n",
    "    outputs_list = []\n",
    "    #groupby reorders elements, now the labels are in same order as outputs\n",
    "    df_groupby = pd.concat([i[1] for i in df.groupby(\"subject\")])\n",
    "    dataset_groupby = df_groupby[\"dataset\"]\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    labels = le.fit_transform(df[\"emotion\"])\n",
    "    labels_groupby = le.transform(df_groupby[\"emotion\"])\n",
    "\n",
    "    #loop over each subject\n",
    "    for group in df.groupby(\"subject\"):\n",
    "        subject = group[0]\n",
    "        #split data to train and test based on the subject index\n",
    "        train_index = df[df[\"subject\"] != subject].index\n",
    "        X_train = features[train_index, :]\n",
    "        y_train = labels[train_index]\n",
    "        \n",
    "        test_index = df[df[\"subject\"] == subject].index\n",
    "        X_test = features[test_index, :]\n",
    "        y_test = labels[test_index]\n",
    "\n",
    "        #create pytorch dataloaders from the split\n",
    "        megc_dataset_train = MEData(X_train, y_train, transform)\n",
    "        train_loader = torch.utils.data.DataLoader(megc_dataset_train,\n",
    "                                                             batch_size=batch_size, shuffle=True,\n",
    "                                                             num_workers=0)\n",
    "\n",
    "        megc_dataset_test = MEData(X_test, y_test, transform)\n",
    "        test_loader = torch.utils.data.DataLoader(megc_dataset_test,\n",
    "                                                         batch_size=100, shuffle=False,\n",
    "                                                         num_workers=0)\n",
    "\n",
    "        \n",
    "        model = Flow_Part_npic()\n",
    "        model['resnet'] = model['resnet'].to(device)\n",
    "        model['fc_top'] = model['fc_top'].to(device)\n",
    "        model['fc_bottom'] = model['fc_bottom'].to(device)\n",
    "        model['fc_top'] = model['fc_top'].apply(weight_init)\n",
    "        model['fc_bottom'] = model['fc_bottom'].apply(weight_init)\n",
    "\n",
    "        model['classifier'] = model['classifier'].to(device)\n",
    "        model['classifier_top'] = model['classifier_top'].to(device)\n",
    "        model['classifier_bottom'] = model['classifier_bottom'].to(device)\n",
    "\n",
    "        model['classifier'] = model['classifier'].apply(weight_init)\n",
    "        model['classifier_top'] = model['classifier_top'].apply(weight_init)\n",
    "        model['classifier_bottom'] = model['classifier_bottom'].apply(\n",
    "            weight_init)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam([\n",
    "            {'params': model['resnet'].parameters(), 'lr':0.00001},\n",
    "            {'params': model['fc_top'].parameters(), 'lr':LEARNING_RATE},\n",
    "            {'params': model['fc_bottom'].parameters(), 'lr':LEARNING_RATE},\n",
    "            {'params': model['classifier'].parameters(), 'lr':LEARNING_RATE},\n",
    "            {'params': model['classifier_top'].parameters(),\n",
    "             'lr':LEARNING_RATE},\n",
    "            {'params': model['classifier_bottom'].parameters(),\n",
    "             'lr':LEARNING_RATE},\n",
    "        ], weight_decay=weight_decay)\n",
    "        \n",
    "        \n",
    "        Epoch_F1_score = 0\n",
    "        for epoch in range(epochs):\n",
    "            if epoch % 10 == 0 and epoch != 0:\n",
    "                if optimizer.param_groups[2]['lr'] > 0.00001:\n",
    "                    optimizer.param_groups[1]['lr'] = optimizer.param_groups[1]['lr'] * 0.5\n",
    "                    optimizer.param_groups[2]['lr'] = optimizer.param_groups[2]['lr'] * 0.5\n",
    "                    optimizer.param_groups[3]['lr'] = optimizer.param_groups[3]['lr'] * 0.5\n",
    "                    optimizer.param_groups[4]['lr'] = optimizer.param_groups[4]['lr'] * 0.5\n",
    "                    optimizer.param_groups[5]['lr'] = optimizer.param_groups[5]['lr'] * 0.5\n",
    "                    \n",
    "            train(train_loader, model, criterion, optimizer, epoch)\n",
    "            preds, target, loss = validate(test_loader, model, criterion, epoch)\n",
    "            \n",
    "            preds = preds.cpu().detach().data.numpy()\n",
    "            test_f1 = f1_score(preds, target.cpu().data.numpy(), average=\"macro\")\n",
    "            \n",
    "            \n",
    "            if test_f1 >= Epoch_F1_score:\n",
    "                Epoch_F1_score = test_f1\n",
    "                best_preds = preds\n",
    "            #Print statistics\n",
    "            if verbose:\n",
    "                print(\"Subject: {}, n={} | test_f1: {:.5} |best_f1: {:.5}\".format(\n",
    "                    subject, str(target.shape[0]).zfill(2), test_f1, Epoch_F1_score))\n",
    "        outputs_list.append(preds)\n",
    "            \n",
    "    outputs = np.concatenate(outputs_list)\n",
    "    f1_total = f1_score(labels_groupby, outputs, average=\"macro\")\n",
    "    idx = dataset_groupby == \"smic\"\n",
    "    f1_smic = f1_score(labels_groupby[idx], outputs[idx], average=\"macro\")\n",
    "    idx = dataset_groupby == \"casme2\"\n",
    "    f1_casme2 = f1_score(labels_groupby[idx], outputs[idx], average=\"macro\")\n",
    "    idx = dataset_groupby == \"samm\"\n",
    "    f1_samm = f1_score(labels_groupby[idx], outputs[idx], average=\"macro\")\n",
    "    print(\"Total f1: {}, SMIC: {}, CASME2: {}, SAMM: {}\".format(f1_total, f1_smic, f1_casme2, f1_samm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import meb\n",
    "from meb import utils\n",
    "from meb import datasets\n",
    "from meb import core\n",
    "from meb import models\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only validate casme2\n",
    "class IValidator(core.CrossDatasetValidator):\n",
    "    def __init__(self, config: \"Config\"):\n",
    "        super().__init__(config)\n",
    "        \n",
    "    def validate_n_times(\n",
    "        self, df: pd.DataFrame, input_data, n_times: int = 5\n",
    "    ) -> None:\n",
    "        self.verbose = False\n",
    "        self.disable_tqdm = True\n",
    "        au_results = []\n",
    "        dataset_results = []\n",
    "        casme2_idx = df[\"dataset\"] == \"casme2\"\n",
    "        for n in tqdm(range(n_times)):\n",
    "            outputs_list = self.validate(df, input_data, seed_n=n + 45)\n",
    "            au_result, dataset_result = self.printer.results_to_list(outputs_list, df[casme2_idx])\n",
    "            au_results.append(au_result)\n",
    "            dataset_results.append(dataset_result)\n",
    "\n",
    "        aus = [i for i in self.cf.action_units]\n",
    "        dataset_names = df[\"dataset\"].unique().tolist()\n",
    "        aus.append(\"Average\")\n",
    "        dataset_names.append(\"Average\")\n",
    "        au_results = np.array(au_results)\n",
    "        dataset_results = np.array(dataset_results)\n",
    "        for i in range(len(self.cf.evaluation_fn)):\n",
    "            if len(self.cf.evaluation_fn) > 1:\n",
    "                print(self.printer.metric_name(self.cf.evaluation_fn[i]))\n",
    "            au_result = self.printer.list_to_latex(list(au_results[:, i].mean(axis=0)))\n",
    "            dataset_result = self.printer.list_to_latex(\n",
    "                list(dataset_results[:, i].mean(axis=0))\n",
    "            )\n",
    "            print(\"AUS:\", aus)\n",
    "            print(au_result)\n",
    "            print(\"\\nDatasets: \", dataset_names)\n",
    "            print(dataset_result)\n",
    "    \n",
    "    def validate(self, df: pd.DataFrame, input_data: np.ndarray, seed_n: int = 1):\n",
    "        utils.set_random_seeds(seed_n)\n",
    "        dataset_names = df[\"dataset\"].unique()\n",
    "        # Create a boolean array with the AUs\n",
    "        labels = np.array(df[self.cf.action_units])\n",
    "        outputs_list = []\n",
    "        for dataset_name in dataset_names:\n",
    "            if dataset_name != \"casme2\":\n",
    "                continue\n",
    "            train_metrics, test_metrics, outputs_test = self.validate_split(\n",
    "                df, input_data, labels, dataset_name\n",
    "            )\n",
    "            outputs_list.append(outputs_test)\n",
    "            if self.verbose:\n",
    "                self.printer.print_train_test_evaluation(\n",
    "                    train_metrics, test_metrics, dataset_name, outputs_test.shape[0]\n",
    "                )\n",
    "\n",
    "        # Calculate total f1-scores\n",
    "        predictions = torch.cat(outputs_list)\n",
    "        idx = df[\"dataset\"] == \"casme2\"\n",
    "        metrics = self.evaluation_fn(labels[idx], predictions)\n",
    "        if self.verbose:\n",
    "            self.printer.print_test_validation(metrics)\n",
    "        return outputs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Off-ApexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = datasets.CrossDataset(resize=28, optical_flow=True)\n",
    "df = c.data_frame\n",
    "data = c.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(core.Config):\n",
    "    device = torch.device(\"cuda:1\")\n",
    "    optimizer = partial(optim.Adam, lr=1e-4, weight_decay=1e-3)\n",
    "    batch_size = 128\n",
    "    epochs = 3000\n",
    "    evaluation_fn = [\n",
    "        partial(utils.MultiLabelF1Score, average=\"macro\"),\n",
    "        partial(utils.MultiLabelF1Score, average=\"binary\")\n",
    "    ]\n",
    "    model = partial(meb.models.OffApexNet, num_classes=len(core.Config.action_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['casme2', 'casme']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 20%|████████▍                                 | 1/5 [15:11<1:00:47, 911.85s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 40%|█████████████████▌                          | 2/5 [30:23<45:34, 911.59s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 60%|██████████████████████████▍                 | 3/5 [45:28<30:17, 908.91s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 80%|█████████████████████████████████▌        | 4/5 [1:00:31<15:06, 906.49s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "100%|██████████████████████████████████████████| 5/5 [1:15:37<00:00, 907.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "84.5 & 82.2 & 93.7 & 49.8 & 48.7 & 45.9 & 57.5 & 48.4 & 58.3 & 56.8 & 64.9 & 68.8 & 63.3\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'Average']\n",
      "63.3 & 63.3\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "73.1 & 68.2 & 93.9 & 0.0 & 0.0 & 0.0 & 23.7 & 0.0 & 23.2 & 21.2 & 32.5 & 41.6 & 31.5\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'Average']\n",
      "31.5 & 31.5\n",
      "['casme2', 'casme', 'samm']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 5/5 [1:12:33<00:00, 870.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "86.3 & 84.5 & 93.4 & 49.8 & 48.7 & 55.4 & 64.9 & 48.2 & 68.8 & 57.4 & 68.8 & 73.5 & 66.6\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'Average']\n",
      "66.6 & 66.6\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "75.4 & 72.1 & 93.4 & 0.0 & 0.0 & 18.3 & 35.3 & 0.0 & 44.4 & 21.0 & 40.0 & 50.5 & 37.5\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'Average']\n",
      "37.5 & 37.5\n",
      "['casme2', 'casme', 'samm', 'mmew']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 5/5 [1:18:17<00:00, 939.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "89.7 & 82.4 & 95.2 & 48.5 & 59.8 & 57.7 & 62.5 & 50.9 & 73.6 & 66.3 & 67.1 & 76.1 & 69.1\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'mmew', 'Average']\n",
      "69.1 & 69.1\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "81.7 & 68.6 & 95.2 & 0.0 & 22.1 & 23.2 & 30.9 & 5.6 & 52.7 & 37.7 & 36.6 & 55.5 & 42.5\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'mmew', 'Average']\n",
      "42.5 & 42.5\n",
      "['casme2', 'casme', 'samm', 'mmew', 'fourd']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 5/5 [1:27:31<00:00, 1050.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "91.0 & 84.0 & 95.5 & 49.5 & 60.7 & 69.3 & 64.4 & 52.4 & 74.4 & 60.1 & 70.7 & 75.5 & 70.6\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'fourd', 'mmew', 'Average']\n",
      "70.6 & 70.6\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "83.9 & 71.3 & 95.6 & 0.0 & 24.4 & 46.8 & 32.4 & 8.2 & 55.6 & 25.3 & 43.7 & 54.2 & 45.1\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'fourd', 'mmew', 'Average']\n",
      "45.1 & 45.1\n",
      "['casme2', 'casme', 'samm', 'mmew', 'fourd', 'casme3a']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 5/5 [1:37:20<00:00, 1168.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "92.5 & 85.3 & 94.7 & 49.7 & 56.4 & 65.7 & 54.3 & 56.6 & 70.8 & 75.0 & 65.3 & 72.4 & 69.9\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'fourd', 'mmew', 'casme3a', 'Average']\n",
      "69.9 & 69.9\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "86.5 & 73.5 & 94.7 & 0.0 & 15.4 & 38.1 & 11.7 & 16.4 & 47.2 & 55.2 & 33.3 & 48.4 & 43.4\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'fourd', 'mmew', 'casme3a', 'Average']\n",
      "43.4 & 43.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# [:, :2] to remove optical strain as it is not used in OffApexNet\n",
    "use_datasets = [\"casme2\"]\n",
    "for dataset in [\"casme\", \"samm\", \"mmew\", \"fourd\", \"casme3a\"]:\n",
    "    use_datasets.append(dataset)\n",
    "    idx = df[\"dataset\"].isin(use_datasets)\n",
    "    print(use_datasets)\n",
    "    IValidator(Config).validate_n_times(df[idx].reset_index(), data[idx, :2], n_times=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSSNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = datasets.CrossDataset(resize=64, optical_flow=True)\n",
    "df = c.data_frame\n",
    "data = c.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(core.Config):\n",
    "    device = torch.device(\"cuda:1\")\n",
    "    evaluation_fn = [\n",
    "        partial(utils.MultiLabelF1Score, average=\"macro\"),\n",
    "        partial(utils.MultiLabelF1Score, average=\"binary\")\n",
    "    ]\n",
    "    batch_size = 128\n",
    "    epochs = 200\n",
    "    model = partial(meb.models.SSSNet, num_classes=len(core.Config.action_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['casme2', 'casme']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 20%|█████████                                    | 1/5 [01:25<05:42, 85.52s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 40%|██████████████████                           | 2/5 [02:47<04:10, 83.36s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 60%|███████████████████████████                  | 3/5 [04:10<02:46, 83.30s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 80%|████████████████████████████████████         | 4/5 [05:33<01:23, 83.20s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "100%|█████████████████████████████████████████████| 5/5 [06:54<00:00, 82.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "90.7 & 79.2 & 94.2 & 49.8 & 48.7 & 45.9 & 55.8 & 48.4 & 56.3 & 64.0 & 71.0 & 76.5 & 65.1\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'Average']\n",
      "65.1 & 65.1\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "83.7 & 62.9 & 94.3 & 0.0 & 0.0 & 0.0 & 14.4 & 0.0 & 19.2 & 36.1 & 44.4 & 56.3 & 34.3\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'Average']\n",
      "34.3 & 34.3\n",
      "['casme2', 'casme', 'samm']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 5/5 [06:42<00:00, 80.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "95.5 & 84.7 & 94.4 & 49.8 & 48.7 & 63.5 & 63.8 & 48.2 & 71.3 & 68.9 & 70.3 & 77.9 & 69.7\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'Average']\n",
      "69.7 & 69.7\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "91.9 & 72.5 & 94.3 & 0.0 & 0.0 & 34.0 & 30.1 & 0.0 & 48.4 & 43.0 & 42.9 & 58.9 & 43.0\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'Average']\n",
      "43.0 & 43.0\n",
      "['casme2', 'casme', 'samm', 'mmew']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 5/5 [07:39<00:00, 91.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "93.7 & 82.8 & 96.2 & 48.1 & 52.9 & 68.0 & 56.3 & 51.0 & 69.1 & 67.3 & 61.2 & 80.3 & 68.9\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'mmew', 'Average']\n",
      "68.9 & 68.9\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "88.8 & 69.4 & 96.3 & 0.0 & 8.4 & 43.8 & 15.3 & 5.8 & 44.6 & 39.6 & 25.2 & 63.4 & 41.7\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'mmew', 'Average']\n",
      "41.7 & 41.7\n",
      "['casme2', 'casme', 'samm', 'mmew', 'fourd']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 5/5 [07:52<00:00, 94.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "93.1 & 84.2 & 96.5 & 49.8 & 63.8 & 72.6 & 54.0 & 53.4 & 75.6 & 66.8 & 69.6 & 79.7 & 71.6\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'fourd', 'mmew', 'Average']\n",
      "71.6 & 71.6\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "87.8 & 71.9 & 96.4 & 0.0 & 30.2 & 54.0 & 10.7 & 10.3 & 57.2 & 38.4 & 41.5 & 62.3 & 46.7\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'fourd', 'mmew', 'Average']\n",
      "46.7 & 46.7\n",
      "['casme2', 'casme', 'samm', 'mmew', 'fourd', 'casme3a']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 5/5 [09:23<00:00, 112.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "91.2 & 84.5 & 95.1 & 49.8 & 60.0 & 73.0 & 55.2 & 53.9 & 74.6 & 78.8 & 57.6 & 79.4 & 71.1\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'fourd', 'mmew', 'casme3a', 'Average']\n",
      "71.1 & 71.1\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "84.4 & 72.3 & 95.0 & 0.0 & 22.5 & 52.3 & 13.0 & 11.0 & 54.3 & 61.9 & 18.0 & 61.7 & 45.5\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'fourd', 'mmew', 'casme3a', 'Average']\n",
      "45.5 & 45.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "use_datasets = [\"casme2\"]\n",
    "for dataset in [\"casme\", \"samm\", \"mmew\", \"fourd\", \"casme3a\"]:\n",
    "    use_datasets.append(dataset)\n",
    "    idx = df[\"dataset\"].isin(use_datasets)\n",
    "    print(use_datasets)\n",
    "    IValidator(Config).validate_n_times(df[idx].reset_index(), data[idx], n_times=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = datasets.CrossDataset(resize=112, optical_flow=True)\n",
    "df = c.data_frame\n",
    "data = c.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(core.Config):\n",
    "    epochs = 50\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    optimizer = partial(optim.Adam, lr=1e-4, weight_decay=1e-3)\n",
    "    num_workers = 0\n",
    "    evaluation_fn = [\n",
    "        partial(utils.MultiLabelF1Score, average=\"macro\"),\n",
    "        partial(utils.MultiLabelF1Score, average=\"binary\"),\n",
    "    ]\n",
    "    model = partial(timm.models.resnet10t, num_classes=len(core.Config.action_units), pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['casme2', 'casme']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/10 [00:00<?, ?it/s]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 10%|████▍                                       | 1/10 [00:11<01:39, 11.08s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 20%|████████▊                                   | 2/10 [00:22<01:28, 11.01s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 30%|█████████████▏                              | 3/10 [00:33<01:17, 11.06s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 40%|█████████████████▌                          | 4/10 [00:44<01:06, 11.02s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 50%|██████████████████████                      | 5/10 [00:54<00:54, 10.94s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 60%|██████████████████████████▍                 | 6/10 [01:05<00:43, 10.89s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 70%|██████████████████████████████▊             | 7/10 [01:16<00:32, 10.84s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 80%|███████████████████████████████████▏        | 8/10 [01:27<00:21, 10.85s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 90%|███████████████████████████████████████▌    | 9/10 [01:38<00:10, 10.90s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "100%|███████████████████████████████████████████| 10/10 [01:49<00:00, 10.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "60.9 & 61.1 & 78.4 & 49.8 & 48.7 & 45.9 & 48.7 & 48.4 & 46.3 & 50.8 & 48.4 & 47.4 & 52.9\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'Average']\n",
      "52.9 & 52.9\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "26.9 & 26.6 & 74.5 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 7.6 & 0.0 & 0.0 & 11.3\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'Average']\n",
      "11.3 & 11.3\n",
      "['casme2', 'casme', 'samm']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [03:15<00:00, 19.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "76.4 & 80.6 & 86.8 & 49.8 & 48.7 & 47.4 & 53.5 & 48.4 & 51.9 & 53.8 & 48.4 & 52.0 & 58.1\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'Average']\n",
      "58.1 & 58.1\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "56.2 & 65.1 & 85.2 & 0.0 & 0.0 & 3.0 & 9.5 & 0.0 & 11.4 & 13.6 & 0.0 & 8.9 & 21.1\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'Average']\n",
      "21.1 & 21.1\n",
      "['casme2', 'casme', 'samm', 'mmew']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [06:13<00:00, 37.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "93.6 & 82.2 & 92.2 & 49.7 & 48.7 & 59.8 & 53.5 & 50.1 & 53.2 & 58.4 & 48.4 & 67.4 & 63.1\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'mmew', 'Average']\n",
      "63.1 & 63.1\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "88.6 & 68.1 & 91.7 & 0.0 & 0.0 & 27.3 & 9.8 & 3.5 & 13.4 & 23.4 & 0.0 & 38.9 & 30.4\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'mmew', 'Average']\n",
      "30.4 & 30.4\n",
      "['casme2', 'casme', 'samm', 'mmew', 'fourd']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [08:26<00:00, 50.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "91.7 & 81.7 & 94.7 & 49.8 & 62.4 & 70.8 & 50.7 & 50.1 & 66.7 & 58.0 & 49.0 & 62.4 & 65.7\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'fourd', 'mmew', 'Average']\n",
      "65.7 & 65.7\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "85.4 & 67.2 & 94.7 & 0.0 & 27.3 & 51.4 & 4.1 & 3.5 & 41.5 & 21.7 & 1.2 & 29.2 & 35.6\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'fourd', 'mmew', 'Average']\n",
      "35.6 & 35.6\n",
      "['casme2', 'casme', 'samm', 'mmew', 'fourd', 'casme3a']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [16:13<00:00, 97.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "91.5 & 83.8 & 94.5 & 49.6 & 55.8 & 71.5 & 52.0 & 54.4 & 70.4 & 72.3 & 48.4 & 71.2 & 67.9\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'fourd', 'mmew', 'casme3a', 'Average']\n",
      "67.9 & 67.9\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "85.0 & 71.0 & 94.4 & 0.0 & 14.0 & 49.4 & 6.6 & 11.9 & 46.2 & 50.6 & 0.0 & 45.9 & 39.6\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'fourd', 'mmew', 'casme3a', 'Average']\n",
      "39.6 & 39.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "use_datasets = [\"casme2\"]\n",
    "for dataset in [\"casme\", \"samm\", \"mmew\", \"fourd\", \"casme3a\"]:\n",
    "    use_datasets.append(dataset)\n",
    "    idx = df[\"dataset\"].isin(use_datasets)\n",
    "    print(use_datasets)\n",
    "    IValidator(Config).validate_n_times(df[idx].reset_index(), data[idx], n_times=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(core.Config):\n",
    "    epochs = 50\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    optimizer = partial(optim.Adam, lr=1e-4, weight_decay=1e-3)\n",
    "    num_workers = 0\n",
    "    evaluation_fn = [\n",
    "        partial(utils.MultiLabelF1Score, average=\"macro\"),\n",
    "        partial(utils.MultiLabelF1Score, average=\"binary\"),\n",
    "    ]\n",
    "    model = partial(timm.models.resnet18, num_classes=len(core.Config.action_units), pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['casme2', 'casme']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 20%|█████████                                    | 1/5 [00:32<02:10, 32.68s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 40%|██████████████████                           | 2/5 [01:01<01:30, 30.13s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 60%|███████████████████████████                  | 3/5 [01:29<00:58, 29.34s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 80%|████████████████████████████████████         | 4/5 [01:57<00:28, 28.96s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "100%|█████████████████████████████████████████████| 5/5 [02:26<00:00, 29.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "59.3 & 54.7 & 86.4 & 49.8 & 48.7 & 45.9 & 48.7 & 48.4 & 46.4 & 47.2 & 48.4 & 48.2 & 52.7\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'Average']\n",
      "52.7 & 52.7\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "23.5 & 13.9 & 86.4 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.5 & 10.4\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'Average']\n",
      "10.4 & 10.4\n",
      "['casme2', 'casme', 'samm']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 5/5 [04:14<00:00, 50.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "67.4 & 84.6 & 92.1 & 49.8 & 48.7 & 50.1 & 48.6 & 48.4 & 51.9 & 53.9 & 49.6 & 60.7 & 58.8\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'Average']\n",
      "58.8 & 58.8\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "39.1 & 72.3 & 91.8 & 0.0 & 0.0 & 8.4 & 0.0 & 0.0 & 11.2 & 13.9 & 2.4 & 26.0 & 22.1\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'Average']\n",
      "22.1 & 22.1\n",
      "['casme2', 'casme', 'samm', 'mmew']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 5/5 [07:53<00:00, 94.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "87.6 & 81.9 & 94.2 & 49.7 & 48.7 & 57.0 & 48.6 & 52.9 & 57.6 & 67.7 & 51.8 & 68.7 & 63.9\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'mmew', 'Average']\n",
      "63.9 & 63.9\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "77.5 & 67.5 & 94.2 & 0.0 & 0.0 & 22.4 & 0.0 & 9.0 & 21.9 & 42.8 & 6.8 & 41.5 & 32.0\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'mmew', 'Average']\n",
      "32.0 & 32.0\n",
      "['casme2', 'casme', 'samm', 'mmew', 'fourd']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 5/5 [10:58<00:00, 131.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "92.2 & 82.3 & 94.8 & 49.8 & 64.9 & 69.3 & 52.6 & 49.5 & 68.4 & 57.5 & 59.7 & 68.6 & 67.5\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'fourd', 'mmew', 'Average']\n",
      "67.5 & 67.5\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "86.1 & 68.8 & 94.8 & 0.0 & 32.6 & 47.3 & 8.4 & 2.2 & 45.2 & 21.5 & 22.2 & 41.0 & 39.2\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'fourd', 'mmew', 'Average']\n",
      "39.2 & 39.2\n",
      "['casme2', 'casme', 'samm', 'mmew', 'fourd', 'casme3a']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 5/5 [21:13<00:00, 254.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "91.6 & 85.7 & 95.2 & 49.7 & 54.5 & 69.0 & 49.3 & 54.2 & 75.2 & 77.4 & 56.5 & 80.0 & 69.9\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'fourd', 'mmew', 'casme3a', 'Average']\n",
      "69.9 & 69.9\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "85.2 & 74.3 & 95.1 & 0.0 & 11.4 & 44.6 & 1.7 & 11.5 & 55.1 & 59.4 & 15.9 & 63.0 & 43.1\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'fourd', 'mmew', 'casme3a', 'Average']\n",
      "43.1 & 43.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "use_datasets = [\"casme2\"]\n",
    "for dataset in [\"casme\", \"samm\", \"mmew\", \"fourd\", \"casme3a\"]:\n",
    "    use_datasets.append(dataset)\n",
    "    idx = df[\"dataset\"].isin(use_datasets)\n",
    "    print(use_datasets)\n",
    "    IValidator(Config).validate_n_times(df[idx].reset_index(), data[idx], n_times=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(core.Config):\n",
    "    epochs = 50\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    optimizer = partial(optim.Adam, lr=1e-4, weight_decay=1e-3)\n",
    "    num_workers = 0\n",
    "    evaluation_fn = [\n",
    "        partial(utils.MultiLabelF1Score, average=\"macro\"),\n",
    "        partial(utils.MultiLabelF1Score, average=\"binary\"),\n",
    "    ]\n",
    "    model = partial(timm.models.resnet34, num_classes=len(core.Config.action_units), pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['casme2', 'casme']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 20%|█████████                                    | 1/5 [00:25<01:43, 25.89s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 40%|██████████████████                           | 2/5 [00:51<01:17, 25.83s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 60%|███████████████████████████                  | 3/5 [01:19<00:53, 26.66s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 80%|████████████████████████████████████         | 4/5 [01:46<00:27, 27.06s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "100%|█████████████████████████████████████████████| 5/5 [02:14<00:00, 27.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "67.9 & 62.9 & 78.9 & 49.8 & 48.7 & 45.9 & 49.2 & 48.4 & 46.4 & 51.0 & 48.3 & 50.1 & 54.0\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'Average']\n",
      "54.0 & 54.0\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "42.5 & 33.3 & 76.2 & 0.0 & 0.0 & 0.0 & 1.6 & 0.0 & 0.0 & 7.7 & 0.0 & 5.4 & 13.9\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'Average']\n",
      "13.9 & 13.9\n",
      "['casme2', 'casme', 'samm']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 5/5 [04:01<00:00, 48.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "71.4 & 69.4 & 87.0 & 49.7 & 48.7 & 51.6 & 50.1 & 48.4 & 55.5 & 58.3 & 49.4 & 67.6 & 58.9\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'Average']\n",
      "58.9 & 58.9\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "47.6 & 44.8 & 86.4 & 0.0 & 0.0 & 11.7 & 2.9 & 0.0 & 18.2 & 23.1 & 2.1 & 39.7 & 23.0\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'Average']\n",
      "23.0 & 23.0\n",
      "['casme2', 'casme', 'samm', 'mmew']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 5/5 [07:34<00:00, 90.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "87.0 & 80.0 & 93.0 & 49.7 & 48.7 & 60.1 & 53.2 & 51.7 & 62.5 & 63.4 & 51.8 & 70.3 & 64.3\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'mmew', 'Average']\n",
      "64.3 & 64.3\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "76.5 & 64.0 & 92.8 & 0.0 & 0.0 & 28.9 & 9.9 & 6.7 & 31.8 & 33.7 & 6.7 & 44.8 & 33.0\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'mmew', 'Average']\n",
      "33.0 & 33.0\n",
      "['casme2', 'casme', 'samm', 'mmew', 'fourd']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 5/5 [10:37<00:00, 127.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "93.0 & 83.7 & 94.8 & 49.7 & 56.3 & 68.4 & 49.4 & 52.0 & 70.9 & 54.1 & 57.8 & 67.9 & 66.5\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'fourd', 'mmew', 'Average']\n",
      "66.5 & 66.5\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "87.6 & 70.8 & 94.8 & 0.0 & 15.4 & 45.5 & 2.0 & 7.1 & 50.1 & 14.7 & 18.4 & 39.7 & 37.2\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'fourd', 'mmew', 'Average']\n",
      "37.2 & 37.2\n",
      "['casme2', 'casme', 'samm', 'mmew', 'fourd', 'casme3a']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 5/5 [23:27<00:00, 281.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "93.5 & 85.3 & 94.2 & 49.7 & 52.7 & 70.0 & 50.8 & 53.9 & 67.9 & 76.9 & 56.6 & 79.2 & 69.2\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'fourd', 'mmew', 'casme3a', 'Average']\n",
      "69.2 & 69.2\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "88.5 & 73.6 & 94.1 & 0.0 & 8.0 & 46.6 & 4.7 & 11.2 & 41.4 & 58.9 & 16.3 & 61.6 & 42.1\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'fourd', 'mmew', 'casme3a', 'Average']\n",
      "42.1 & 42.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "use_datasets = [\"casme2\"]\n",
    "for dataset in [\"casme\", \"samm\", \"mmew\", \"fourd\", \"casme3a\"]:\n",
    "    use_datasets.append(dataset)\n",
    "    idx = df[\"dataset\"].isin(use_datasets)\n",
    "    print(use_datasets)\n",
    "    IValidator(Config).validate_n_times(df[idx].reset_index(), data[idx], n_times=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(core.Config):\n",
    "    epochs = 50\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    optimizer = partial(optim.Adam, lr=1e-4, weight_decay=1e-3)\n",
    "    num_workers = 0\n",
    "    evaluation_fn = [\n",
    "        partial(utils.MultiLabelF1Score, average=\"macro\"),\n",
    "        partial(utils.MultiLabelF1Score, average=\"binary\"),\n",
    "    ]\n",
    "    model = partial(timm.models.resnet50, num_classes=len(core.Config.action_units), pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['casme2', 'casme']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/10 [00:00<?, ?it/s]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 10%|████▍                                       | 1/10 [01:16<11:31, 76.82s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 20%|████████▊                                   | 2/10 [02:33<10:15, 76.91s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 30%|█████████████▏                              | 3/10 [03:49<08:56, 76.57s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 40%|█████████████████▌                          | 4/10 [05:06<07:40, 76.68s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 50%|██████████████████████                      | 5/10 [06:23<06:22, 76.58s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 60%|██████████████████████████▍                 | 6/10 [07:40<05:06, 76.71s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 70%|██████████████████████████████▊             | 7/10 [08:57<03:50, 76.75s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 80%|███████████████████████████████████▏        | 8/10 [10:12<02:32, 76.50s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 90%|███████████████████████████████████████▌    | 9/10 [11:29<01:16, 76.58s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "100%|███████████████████████████████████████████| 10/10 [12:45<00:00, 76.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "47.3 & 47.8 & 36.5 & 49.8 & 48.7 & 45.9 & 48.7 & 48.4 & 46.4 & 47.2 & 48.4 & 47.4 & 46.9\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'Average']\n",
      "46.9 & 46.9\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "0.0 & 0.0 & 6.7 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.6\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'Average']\n",
      "0.6 & 0.6\n",
      "['casme2', 'casme', 'samm']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [22:12<00:00, 133.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "47.3 & 47.8 & 47.4 & 49.8 & 48.7 & 45.9 & 48.7 & 48.4 & 46.4 & 47.2 & 48.4 & 47.4 & 47.8\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'Average']\n",
      "47.8 & 47.8\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "0.0 & 0.0 & 24.8 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 2.1\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'Average']\n",
      "2.1 & 2.1\n",
      "['casme2', 'casme', 'samm', 'mmew']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [32:03<00:00, 192.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "50.8 & 55.5 & 74.9 & 49.8 & 48.7 & 49.3 & 48.7 & 48.4 & 46.4 & 47.2 & 48.4 & 47.4 & 51.3\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'mmew', 'Average']\n",
      "51.3 & 51.3\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "6.7 & 15.4 & 69.2 & 0.0 & 0.0 & 6.6 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 8.2\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'mmew', 'Average']\n",
      "8.2 & 8.2\n",
      "['casme2', 'casme', 'samm', 'mmew', 'fourd']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [45:01<00:00, 270.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "88.3 & 79.8 & 91.1 & 49.8 & 48.7 & 59.3 & 48.7 & 48.4 & 62.5 & 47.2 & 48.4 & 47.4 & 60.0\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'fourd', 'mmew', 'Average']\n",
      "60.0 & 60.0\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "78.9 & 63.7 & 90.5 & 0.0 & 0.0 & 29.0 & 0.0 & 0.0 & 31.7 & 0.0 & 0.0 & 0.0 & 24.5\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'fourd', 'mmew', 'Average']\n",
      "24.5 & 24.5\n",
      "['casme2', 'casme', 'samm', 'mmew', 'fourd', 'casme3a']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 10/10 [1:01:38<00:00, 369.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "91.5 & 80.1 & 94.7 & 49.6 & 48.7 & 61.2 & 50.0 & 48.4 & 62.2 & 64.9 & 48.4 & 51.9 & 62.6\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'fourd', 'mmew', 'casme3a', 'Average']\n",
      "62.6 & 62.6\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "84.9 & 64.3 & 94.6 & 0.0 & 0.0 & 30.1 & 2.7 & 0.0 & 30.4 & 36.7 & 0.0 & 8.8 & 29.4\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'fourd', 'mmew', 'casme3a', 'Average']\n",
      "29.4 & 29.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "use_datasets = [\"casme2\"]\n",
    "for dataset in [\"casme\", \"samm\", \"mmew\", \"fourd\", \"casme3a\"]:\n",
    "    use_datasets.append(dataset)\n",
    "    idx = df[\"dataset\"].isin(use_datasets)\n",
    "    print(use_datasets)\n",
    "    IValidator(Config).validate_n_times(df[idx].reset_index(), data[idx], n_times=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(core.Config):\n",
    "    epochs = 50\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    optimizer = partial(optim.Adam, lr=1e-4, weight_decay=1e-3)\n",
    "    num_workers = 0\n",
    "    evaluation_fn = [\n",
    "        partial(utils.MultiLabelF1Score, average=\"macro\"),\n",
    "        partial(utils.MultiLabelF1Score, average=\"binary\"),\n",
    "    ]\n",
    "    model = partial(timm.models.resnet101, num_classes=len(core.Config.action_units), pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['casme2', 'casme']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 20%|████████▊                                   | 1/5 [01:44<06:58, 104.57s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 40%|█████████████████▌                          | 2/5 [03:29<05:13, 104.61s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 60%|██████████████████████████▍                 | 3/5 [05:13<03:28, 104.46s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 80%|███████████████████████████████████▏        | 4/5 [06:57<01:44, 104.25s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "100%|████████████████████████████████████████████| 5/5 [08:42<00:00, 104.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "47.3 & 47.5 & 33.6 & 49.8 & 48.7 & 45.9 & 48.7 & 48.4 & 46.4 & 47.1 & 48.4 & 49.0 & 46.7\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'Average']\n",
      "46.7 & 46.7\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "0.0 & 0.0 & 1.5 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 3.0 & 0.4\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'Average']\n",
      "0.4 & 0.4\n",
      "['casme2', 'casme', 'samm']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 5/5 [14:55<00:00, 179.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "47.3 & 47.7 & 34.4 & 49.8 & 48.7 & 45.8 & 48.7 & 48.4 & 46.4 & 47.2 & 48.4 & 47.4 & 46.7\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'Average']\n",
      "46.7 & 46.7\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "0.0 & 0.0 & 2.9 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.2\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'Average']\n",
      "0.2 & 0.2\n",
      "['casme2', 'casme', 'samm', 'mmew']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 5/5 [30:46<00:00, 369.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "50.4 & 55.0 & 73.6 & 49.7 & 48.7 & 46.4 & 48.7 & 48.4 & 46.4 & 47.6 & 48.4 & 48.2 & 51.0\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'mmew', 'Average']\n",
      "51.0 & 51.0\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "6.3 & 15.1 & 67.9 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 1.1 & 0.0 & 1.5 & 7.7\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'mmew', 'Average']\n",
      "7.7 & 7.7\n",
      "['casme2', 'casme', 'samm', 'mmew', 'fourd']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 5/5 [29:49<00:00, 357.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "76.0 & 75.1 & 86.2 & 49.8 & 48.7 & 57.5 & 48.7 & 48.4 & 54.2 & 47.2 & 52.0 & 51.4 & 57.9\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'fourd', 'mmew', 'Average']\n",
      "57.9 & 57.9\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "56.0 & 54.2 & 85.1 & 0.0 & 0.0 & 29.3 & 0.0 & 0.0 & 15.8 & 0.0 & 7.9 & 8.3 & 21.4\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'fourd', 'mmew', 'Average']\n",
      "21.4 & 21.4\n",
      "['casme2', 'casme', 'samm', 'mmew', 'fourd', 'casme3a']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 5/5 [57:14<00:00, 686.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "89.2 & 80.4 & 91.5 & 49.6 & 48.7 & 53.8 & 48.7 & 48.2 & 58.4 & 64.6 & 50.5 & 54.2 & 61.5\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'fourd', 'mmew', 'casme3a', 'Average']\n",
      "61.5 & 61.5\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "80.9 & 65.0 & 91.1 & 0.0 & 0.0 & 16.6 & 0.0 & 0.0 & 23.7 & 36.1 & 4.4 & 13.6 & 27.6\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'fourd', 'mmew', 'casme3a', 'Average']\n",
      "27.6 & 27.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "use_datasets = [\"casme2\"]\n",
    "for dataset in [\"casme\", \"samm\", \"mmew\", \"fourd\", \"casme3a\"]:\n",
    "    use_datasets.append(dataset)\n",
    "    idx = df[\"dataset\"].isin(use_datasets)\n",
    "    print(use_datasets)\n",
    "    IValidator(Config).validate_n_times(df[idx].reset_index(), data[idx], n_times=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resnet 2+1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|███████████████████████████| 189/189 [00:29<00:00,  6.32it/s]\n",
      "Loading data: 100%|███████████████████████████| 256/256 [02:15<00:00,  1.88it/s]\n",
      "Loading data: 100%|███████████████████████████| 159/159 [01:51<00:00,  1.43it/s]\n",
      "Loading data: 100%|███████████████████████████| 267/267 [00:43<00:00,  6.14it/s]\n",
      "Loading data: 100%|███████████████████████████| 300/300 [01:15<00:00,  3.97it/s]\n",
      "Loading data: 100%|███████████████████████████| 860/860 [03:42<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning:             The number of frames does not correspond for the sample             spNO.170_k\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.171_e\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.171_e2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.171_f\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.171_f2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.171_h2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.171_h3\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.171_h4\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.171_h5\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.171_l\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.172_f\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.172_k\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.172_k3\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.174_e\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.202_m\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.202_m2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.206_d\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.206_e2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.206_e3\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.206_g3\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.206_l\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.206_m\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.207_a\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.207_a2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.207_b\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.207_c4\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.207_c5\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.207_c6\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.207_d\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.207_e\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.207_h2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.207_h3\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.207_i\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.207_j2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.207_l\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.207_l2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.207_l3\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.208_c\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.208_c6\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.209_m\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.210_b2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.210_b3\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.210_c2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.210_c3\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.210_d\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.210_d2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.210_d3\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.210_e\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.210_f\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.210_f2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.210_h\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.210_h2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.210_i2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.210_k\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.210_k2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.212_b\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.212_f\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.212_i\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.212_i2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.212_j\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.212_j2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.213_k\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.214_c\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.214_j\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_a3\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_b5\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_d\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_d2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_d3\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_d4\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_d5\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_d6\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_d7\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_e2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_f3\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_f4\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_h\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_i\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_j\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_j3\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_j4\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_k2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_l\n",
      "Warning: The offset does not correspond for the sample            spNO.214_c\n"
     ]
    }
   ],
   "source": [
    "c = datasets.CrossDataset(resize=112, color=True, preload=True)\n",
    "df = c.data_frame\n",
    "data = c.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "#interpolate samples with less than 8 frames\n",
    "n_frames = 8\n",
    "for i, video in enumerate(data):\n",
    "    if video.shape[0] < n_frames:\n",
    "        new_shape = (n_frames,) + video.shape[1:-1]\n",
    "        video = torch.tensor(video).permute(3, 0, 1, 2).unsqueeze(0).float()\n",
    "        new_video = F.interpolate(video, size=new_shape, mode=\"trilinear\")\n",
    "        data[i] = new_video.squeeze(0).permute(1, 2, 3, 0).byte().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that returns the model as it needs to be modified\n",
    "def r2plus1d(num_classes: int):\n",
    "    model = torchvision.models.video.r2plus1d_18(weights=torchvision.models.video.R2Plus1D_18_Weights.DEFAULT)\n",
    "    model.fc = nn.Linear(in_features=512, out_features=num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(core.Config):\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    epochs = 100\n",
    "    batch_size = 16\n",
    "    optimizer = partial(optim.Adam, lr=1e-4, weight_decay=1e-3)\n",
    "    evaluation_fn = [\n",
    "        partial(utils.MultiLabelF1Score, average=\"macro\"),\n",
    "        partial(utils.MultiLabelF1Score, average=\"binary\")\n",
    "    ]\n",
    "    train_transform = {\n",
    "        \"spatial\": None,\n",
    "        \"temporal\": datasets.UniformTemporalSubsample(8),\n",
    "    }\n",
    "    test_transform = {\n",
    "        \"spatial\": None,\n",
    "        \"temporal\": datasets.UniformTemporalSubsample(8),\n",
    "    }\n",
    "    model = partial(r2plus1d, num_classes=len(core.Config.action_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['casme2', 'casme']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 20%|████████▏                                | 1/5 [20:26<1:21:47, 1227.00s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 40%|████████████████▍                        | 2/5 [41:01<1:01:34, 1231.46s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 60%|████████████████████████▌                | 3/5 [1:01:34<41:04, 1232.24s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      " 80%|████████████████████████████████▊        | 4/5 [1:22:08<20:32, 1232.65s/it]/home/tvaranka/anaconda3/envs/python3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "100%|█████████████████████████████████████████| 5/5 [1:42:40<00:00, 1232.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "49.0 & 47.6 & 71.7 & 49.8 & 48.7 & 45.9 & 50.1 & 48.4 & 47.5 & 49.7 & 55.7 & 48.7 & 51.1\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'Average']\n",
      "51.1 & 51.1\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "4.6 & 0.0 & 67.6 & 0.0 & 0.0 & 0.0 & 2.9 & 0.0 & 2.2 & 5.3 & 15.6 & 2.6 & 8.4\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'Average']\n",
      "8.4 & 8.4\n",
      "['casme2', 'casme', 'samm']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 5/5 [3:05:23<00:00, 2224.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "48.2 & 47.9 & 70.7 & 49.6 & 48.7 & 47.0 & 49.9 & 48.3 & 46.9 & 50.0 & 49.1 & 50.2 & 50.6\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'Average']\n",
      "50.6 & 50.6\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "2.5 & 1.1 & 68.7 & 0.0 & 0.0 & 3.3 & 2.5 & 0.0 & 1.1 & 7.1 & 1.7 & 6.2 & 7.8\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'Average']\n",
      "7.8 & 7.8\n",
      "['casme2', 'casme', 'samm', 'mmew']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 5/5 [5:41:10<00:00, 4094.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "64.8 & 61.9 & 84.7 & 49.6 & 48.7 & 51.5 & 48.6 & 50.4 & 51.2 & 54.8 & 54.1 & 56.8 & 56.4\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'mmew', 'Average']\n",
      "56.4 & 56.4\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "35.0 & 28.0 & 83.4 & 0.0 & 0.0 & 11.2 & 0.0 & 4.0 & 10.3 & 15.2 & 11.3 & 19.0 & 18.1\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'mmew', 'Average']\n",
      "18.1 & 18.1\n",
      "['casme2', 'casme', 'samm', 'mmew', 'fourd']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 5/5 [7:59:26<00:00, 5753.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "86.5 & 77.5 & 87.8 & 49.7 & 48.7 & 49.0 & 49.7 & 48.4 & 51.9 & 59.5 & 53.7 & 58.1 & 60.0\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'fourd', 'mmew', 'Average']\n",
      "60.0 & 60.0\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "75.4 & 58.5 & 86.9 & 0.0 & 0.0 & 6.3 & 2.2 & 0.0 & 10.8 & 24.5 & 10.4 & 21.2 & 24.7\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'fourd', 'mmew', 'Average']\n",
      "24.7 & 24.7\n",
      "['casme2', 'casme', 'samm', 'mmew', 'fourd', 'casme3a']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 5/5 [15:23:04<00:00, 11076.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "91.2 & 76.6 & 90.6 & 49.7 & 48.7 & 59.8 & 48.4 & 52.5 & 57.6 & 66.6 & 62.9 & 74.1 & 64.9\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'fourd', 'mmew', 'casme3a', 'Average']\n",
      "64.9 & 64.9\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "84.1 & 56.6 & 90.2 & 0.0 & 0.0 & 26.9 & 0.0 & 8.4 & 22.0 & 38.4 & 28.6 & 51.6 & 33.9\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'fourd', 'mmew', 'casme3a', 'Average']\n",
      "33.9 & 33.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "use_datasets = [\"casme2\"]\n",
    "for dataset in [\"casme\", \"samm\", \"mmew\", \"fourd\", \"casme3a\"]:\n",
    "    use_datasets.append(dataset)\n",
    "    idx = df[\"dataset\"].isin(use_datasets)\n",
    "    print(use_datasets)\n",
    "    IValidator(Config).validate_n_times(df[idx].reset_index(), data[idx], n_times=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3d67583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import meb\n",
    "from meb import utils\n",
    "from meb import datasets\n",
    "from meb import core\n",
    "from meb import models\n",
    "\n",
    "from functools import partial\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import jit, njit\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35edf853",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning:             The number of frames does not correspond for the sample             spNO.170_k\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.171_e\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.171_e2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.171_f\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.171_f2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.171_h2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.171_h3\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.171_h4\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.171_h5\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.171_l\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.172_f\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.172_k\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.172_k3\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.174_e\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.202_m\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.202_m2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.206_d\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.206_e2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.206_e3\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.206_g3\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.206_l\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.206_m\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.207_a\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.207_a2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.207_b\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.207_c4\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.207_c5\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.207_c6\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.207_d\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.207_e\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.207_h2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.207_h3\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.207_i\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.207_j2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.207_l\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.207_l2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.207_l3\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.208_c\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.208_c6\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.209_m\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.210_b2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.210_b3\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.210_c2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.210_c3\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.210_d\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.210_d2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.210_d3\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.210_e\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.210_f\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.210_f2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.210_h\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.210_h2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.210_i2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.210_k\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.210_k2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.212_b\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.212_f\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.212_i\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.212_i2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.212_j\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.212_j2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.213_k\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.214_c\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.214_j\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_a3\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_b5\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_d\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_d2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_d3\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_d4\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_d5\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_d6\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_d7\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_e2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_f3\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_f4\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_h\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_i\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_j\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_j3\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_j4\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_k2\n",
      "Warning:             The number of frames does not correspond for the sample             spNO.215_l\n",
      "Warning: The offset does not correspond for the sample            spNO.214_c\n"
     ]
    }
   ],
   "source": [
    "c = datasets.CrossDataset(cropped=True, color=True, resize=320)\n",
    "df = c.data_frame\n",
    "data = c.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f4032e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c_flow = datasets.CrossDataset(optical_flow=True, resize=320)\n",
    "data_flow = c_flow.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9fa351a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import py_evm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c8fc2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"../../data/shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "727f59ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mner_preprocess(onset, apex, i):\n",
    "    onset = (onset * 255.0).astype(\"uint8\")\n",
    "    apex = (apex * 255.0).astype(\"uint8\")\n",
    "\n",
    "    onset_g = cv2.cvtColor(onset, cv2.COLOR_RGB2GRAY)\n",
    "    apex_g = cv2.cvtColor(apex, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    pic_size = onset.shape\n",
    "    hsv = np.zeros(pic_size)\n",
    "    hsv[:, :, 1] = cv2.cvtColor(apex, cv2.COLOR_RGB2HSV)[:, :, 1]\n",
    "\n",
    "    flow = data_flow[i].transpose(1, 2, 0)[..., :2]\n",
    "\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    hsv[:, :, 0] = ang * (180 / np.pi / 2)\n",
    "    hsv[:, :, 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    hsv = np.asarray(hsv, dtype=np.float32)\n",
    "    # This line is added to avoid using float[0-255]\n",
    "    hsv /= 255.0\n",
    "    rgb_flow = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "    return rgb_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b63b14b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2031/2031 [50:11<00:00,  1.48s/it]\n"
     ]
    }
   ],
   "source": [
    "flows = np.zeros((df.shape[0], 3, 320, 320))\n",
    "for i, video in enumerate(tqdm(data, total=df.shape[0])):\n",
    "    mm_video = py_evm.magnify(video)\n",
    "    if df.loc[i, \"apexf\"] < mm_video.shape[0]:\n",
    "        flow = mner_preprocess(mm_video[0], mm_video[df.loc[i, \"apexf\"]], i)\n",
    "    else:\n",
    "        flow = mner_preprocess(mm_video[0], mm_video[-1], i)\n",
    "    flows[i] = flow.transpose(2, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "401ba4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        nn.init.xavier_normal_(m.weight.data)\n",
    "        nn.init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d208d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMER(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.meta = {'mean': [0.485, 0.456, 0.406],\n",
    "                     'std': [0.229, 0.224, 0.225],\n",
    "                     'imageSize': [224, 224]}\n",
    "        self.backbone = timm.models.resnet18(pretrained=True)\n",
    "        self.backbone = nn.Sequential(*(list(self.backbone.children())[:-2]))\n",
    "        self.features_8 = nn.AvgPool2d(kernel_size=[7, 7], stride=[1, 1], padding=0, ceil_mode=False, count_include_pad=False)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        self.fc3_top = nn.Sequential(\n",
    "            nn.Linear(512, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "        self.fc3_bot = nn.Sequential(\n",
    "            nn.Linear(512, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "        self.fc = nn.Linear(64 * 2, num_classes)\n",
    "        self.fc_top = nn.Linear(64, num_classes)\n",
    "        self.fc_bot = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features_7 = self.backbone(x)\n",
    "        \n",
    "        top = features_7[:, :, :3]\n",
    "        bottom = features_7[:, :, 3:]\n",
    "        \n",
    "        top = self.avgpool(top)\n",
    "        bottom = self.avgpool(bottom)\n",
    "        \n",
    "        top = top.view(top.size(0), -1)\n",
    "        bottom = bottom.view(bottom.size(0), -1)\n",
    "        # FC layers\n",
    "        top = self.fc3_top(top)\n",
    "        bottom = self.fc3_bot(bottom)\n",
    "        features = torch.cat((top, bottom), 1)\n",
    "        #Classification\n",
    "        output = self.fc(features)\n",
    "        output_top = self.fc_top(top)\n",
    "        output_bottom = self.fc_bot(bottom)\n",
    "        return output, output_top, output_bottom\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "408da4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def img_to_pil(img: np.ndarray):\n",
    "    img = np.array(img)\n",
    "    img = (img.transpose(1, 2, 0) * 255).astype(\"uint8\")\n",
    "    return Image.fromarray(img)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        img_to_pil,\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "        transforms.RandomCrop((224, 224), pad_if_needed=True),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                             std=[0.5, 0.5, 0.5])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c478d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(core.Config):\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    scheduler = None\n",
    "    evaluation_fn = [\n",
    "        partial(utils.MultiLabelF1Score, average=\"macro\"),\n",
    "        partial(utils.MultiLabelF1Score, average=\"binary\"),\n",
    "    ]\n",
    "    epochs = 1\n",
    "    model = partial(NMER, num_classes=len(core.Config.action_units))\n",
    "    optimizer = partial(optim.Adam, lr=0.0001, weight_decay=0.000001)\n",
    "    train_transform = {\"spatial\": transform, \"temporal\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b01f1e88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 5/5 [21:08<00:00, 253.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "48.4 & 45.5 & 53.5 & 43.0 & 41.4 & 44.7 & 42.5 & 35.9 & 44.9 & 44.7 & 37.7 & 43.1 & 43.8\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'fourd', 'mmew', 'casme3a', 'Average']\n",
      "38.9 & 41.0 & 40.9 & 41.5 & 42.1 & 38.2 & 40.4\n",
      "MultiLabelF1Score\n",
      "AUS: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'Average']\n",
      "19.1 & 19.2 & 43.3 & 9.3 & 6.3 & 9.1 & 12.5 & 4.8 & 18.1 & 22.6 & 3.3 & 6.4 & 14.5\n",
      "\n",
      "Datasets:  ['casme', 'casme2', 'samm', 'fourd', 'mmew', 'casme3a', 'Average']\n",
      "11.3 & 11.5 & 9.2 & 10.2 & 12.3 & 11.9 & 11.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "NMERValidation(Config).validate_n_times(df, flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "baacba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMERValidation(core.CrossDatasetValidation):\n",
    "    def __init__(self, config: Config, verbose: bool = True):\n",
    "        super().__init__(config)\n",
    "        \n",
    "    def train_one_epoch(self, epoch: int, dataloader: torch.utils.data.DataLoader):\n",
    "        if epoch % 10 == 0 and epoch != 0:\n",
    "            if self.optimizer.param_groups[1]['lr'] > 0.00001:\n",
    "                self.optimizer.param_groups[1]['lr'] = self.optimizer.param_groups[1]['lr'] * 0.5\n",
    "        num_updates = epoch * len(dataloader)\n",
    "        for i, (X, y) in enumerate(dataloader):\n",
    "            X, y = X.to(self.cf.device), y.to(self.cf.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            if self.mixup_fn:\n",
    "                X, y = self.mixup_fn(X.float(), y.float())\n",
    "            out, out_top, out_bot = self.model(X.float())\n",
    "            loss = (\n",
    "                self.criterion(out, y)\n",
    "                + self.criterion(out_top, y)\n",
    "                + self.criterion(out_bot, y)\n",
    "            )\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(\n",
    "                self.model.parameters(), 1, norm_type=2\n",
    "            )\n",
    "            self.optimizer.step()\n",
    "            num_updates += 1\n",
    "            if self.scheduler:\n",
    "                self.scheduler.step_update(num_updates=num_updates)\n",
    "            if self.cf.print_loss_interval:\n",
    "                if i % self.cf.print_loss_interval == 0:\n",
    "                    print(\n",
    "                        f\"{datetime.now()} - INFO - Epoch \"\n",
    "                        f\"[{epoch + 1}/{self.cf.epochs}][{i + 1}/{len(dataloader)}] \"\n",
    "                        f\"lr: {self.optimizer.param_groups[0]['lr']:>6f}, loss: {loss.item():>7f}\"\n",
    "                    )\n",
    "                    \n",
    "    def evaluate_model(\n",
    "        self, dataloader: torch.utils.data.DataLoader, test: bool = False\n",
    "    ) -> List[float] | Tuple[List[float], torch.tensor]:\n",
    "        \"\"\"\n",
    "        Evaluates the model given a dataloader and an evaluation function. Returns\n",
    "        the evaluation result and if boolean test is set to true also the\n",
    "        predictions.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        outputs_list = []\n",
    "        labels_list = []\n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                data_batch = batch[0].to(self.cf.device)\n",
    "                labels_batch = batch[1]\n",
    "                outputs, _, _ = self.model(data_batch.float())\n",
    "                outputs_list.append(outputs.detach().cpu())\n",
    "                labels_list.append(labels_batch)\n",
    "        self.model.train()\n",
    "        predictions = torch.cat(outputs_list)\n",
    "        labels = torch.cat(labels_list)\n",
    "        results = self.evaluation_fn(labels, predictions)\n",
    "        if test:\n",
    "            return results, predictions\n",
    "        return results\n",
    "    \n",
    "    def setup_training(self) -> None:\n",
    "        \"\"\"\n",
    "        Sets up the training modules, including model, criterion, optimizer, scheduler and mixup.\n",
    "        \"\"\"\n",
    "        self.model = self.cf.model()\n",
    "        self.model.apply(weight_init)\n",
    "        self.criterion = self.cf.criterion()\n",
    "        self.model.to(self.cf.device)\n",
    "        self.optimizer = self.cf.optimizer(\n",
    "            [{\"params\": (\n",
    "                list(Config.model().fc.parameters())\n",
    "                + list(Config.model().fc_top.parameters())\n",
    "                + list(Config.model().fc_bot.parameters())\n",
    "                + list(Config.model().fc3_top.parameters())\n",
    "                + list(Config.model().fc3_bot.parameters())\n",
    "            \n",
    "            )},\n",
    "             {\"params\": self.model.backbone.parameters(), \"lr\": 0.00001}\n",
    "            ])\n",
    "        self.scheduler = (\n",
    "            self.cf.scheduler(self.optimizer) if self.cf.scheduler else None\n",
    "        )\n",
    "        self.mixup_fn = self.cf.mixup_fn() if self.cf.mixup_fn else None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
